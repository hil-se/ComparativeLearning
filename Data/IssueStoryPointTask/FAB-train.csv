"issuekey","type","components","storypoint","title","description_text"
"FAB-30","Story","fabric-ledger",2,"Endorser simulation of transactions.","""Story: Developer needs the ability to gain signatures from endorsers as defined by a policy by simulating a transaction without writing to the ledger create, so that they can submit a transaction.    Endorsers simulate tx with state and reply with rw set of all keys that were modified.    A submitter composes a transaction consisting of [header, payload, rw-set] where rw-set is the set containing the state variables that the transaction reads from (read-set) and the state variables that the transaction writes to (write-set). The rw-set is created via transaction execution simulation (not writing to database). This simulation is also done by the endorsers of the transaction to fulfill the endorsement policy of the transaction."""
"FAB-149","Story","fabric-orderer",2,"BFT Orderers need to sign batches","""BFT orderers have to provide signatures so that validator peers can use the set of signatures to accept validity of a batch without having to connect to f+1 orderers.    All orderers already sign with their own key."""
"FAB-200","Story","fabric-ledger",8,"Ledger simple provenance: I want to see the full history of key values across time","""Querying for full history of keys will require a new history database. See attached slides for details."""
"FAB-196","Story","fabric-ledger",8,"Ledger APIs to query Blocks/Transactions, including rich query and history of key values","""- Ledger APIs have been implemented and need to be exposed to SDK:    -- GetBlockchainInfo    -- GetBlocksByNumber    -- GetBlockByNumber    -- GetBlockByHash    -- GetTransactionById    -- ExecuteQuery    """
"FAB-192","Story","fabric-ledger",2,"Ledger advanced simulation: As a consumer of the ledger APIs (Endorser peer chaincode), I need the ability to manipulate keys in various ways, so that I have flexibility in chaincode to get and set the state I need","""- Implement QueryExecutor.GetStateRangeScanIterator()    - Implement QueryExecutor.GetStateMultipleKeys()    - Implement TxSimulator.DeleteState()    - Implement TxSimulator.SetStateMultipleKeys()"""
"FAB-254","Sub-task","fabric-sdk-node",8,"node.js SDK - add API to send endorsed deployment transaction to orderer","""This initial phase is to send to an orderer based on SOLO. The API should take a proper parameter assembled from the returned data of the sendDeploymentProposal() call, and send to the orderer for consensus, which will then deliver to committers for validating and committing to ledger.    Note that the event notification on transaction """"complete"""", """"error"""" will be tracked separately."""
"FAB-277","Task","fabric-quality",2,"Enable power node in Jenkins CI","""@bsmitha requested us to setup Power node in Jenkins CI."""
"FAB-318","Story","fabric-sdk-node",8,"[node-SDK] Technical debt","""This will help with creating a cleaner workspace for node.js developers working on the node.js SDK, and eliminate sub-optimal parts that are prone to breaks:  - build scripts that does -g installs  - reliance on vagrant  - """"make"""" based build scripts are not best suited for node.js development"""
"FAB-325","Task","fabric-orderer",2,"Create Rawledger API","""Create a Rawledger API which can be used by any orderer.    This should also cover moving the ramledger implementation of Solo out into its own package, and converting solo to depend on the new abstraction."""
"FAB-359","Epic","fabric-peer",8,"Bootstrapping a blockchain network with Orderers and Peers","""Bootstrapping Fabric network including bootstrapping 2 components: Orderers and Peers. Orderers make up a network of nodes with mesh connections. Peers network uses gossip to communicate with one another but direct connection with the Orderer network. All connections are TLS.    Each Orderer is configured by an administrative CLI command, which provides the necessary bootstrapping data, including a list of trusted roots, a list of Orderer certificates and IP addresses, a set of specific consensus algorithm properties, and access control policies. With this information, an Orderer may start up and connect with other Orderers.    Each Peer requires at least the following configurations:  # An enrollment certificate to participate in the network. The certificate may come from any CA as long as the CA is part of the trusted roots on the consensus service that the Peer will connect to  # A list of the Orderer certificates and IP addresses, which the administrative CLI from the consensus service can generate  # A list of trusted root certificates  # An optional list of channels that the Peer should subscribe. Unless explicitly configured, the Peer does not subscribe to any channels upon starting up    """
"FAB-356","Task","fabric-crypto",8,"As an infrastructure developer i want to ensure that all crypto calls within the nodejs client go through the fabric crypto library (BCCSP)","""This requires that this library defined in FAB-354, and whose software provider was implemented in FAB-355/FAB-823, is used throughout the fabric client sdk in Node.  """
"FAB-355","Story","fabric-crypto",8,"As an infrastructure developer and application developer i want to have availale a software based crypto provider implementing the interface of FAB-354 in golang.","""Implement a software provider implementing the interface described in FAB-354 in Golang to be used by the peer core code."""
"FAB-349","Task","fabric-ledger",1,"Control rockdb logging","""Fabric peer uses default configurations for logging RocksDB - which produces massive logs in the LOG files. For better managing RockDB logs, RocksDB allows setting following logs related properties  - 1) max_log_file_size, 2) keep_log_file_num, and 3) info_log_level    Though a newer version (4.3) of RocksDB allows loading properties from an `ini` file (https://github.com/facebook/rocksdb/wiki/RocksDB-Options-File) - gorockdb package is yet to catch up for exposing this option into golang.    Current possibility is to expose these configs into core.yaml and programmatically set these on RocksDB options while opening the DB. """
"FAB-386","Story","fabric-orderer",2,"Add robust configuration mechanism for the orderer package","""The orderer service uses piecemeal configuration using environment variables today.  This should be done using Viper, but using the newer API which allows error on extraneous variables.    In the event that the newer version of Viper is not available, the similar but older version of the call can be used temporarily.    This should be re-usable across Solo, Kafka, and the RawLedger implementations."""
"FAB-383","Task","fabric-orderer",1,"Verify manual state transfer works","""As we discussed over the weekend, following Gari's suggestion. Needed in case things go terribly bad."""
"FAB-418","Story","fabric-orderer",8,"Enhance atomicbroadcast API to support channels","""In order to support delivering batches to only a subset of peers, the atomicbroadcast API must be enhanced to allow channel creation, channel membership polling or notifications, and broadcast or delivery to one or more channels.    This will require modifications to the `atomicbroadcast/ab.proto`.  This will cascade into modification of solo to support the new API."""
"FAB-497","Story","fabric-peer",3,"Create system chaincode at the peer to handle configuration changes","""When the peer receives a configuration transaction, as defined in FAB-496, it needs to call the Configuration System Chaincode (CSCC) which performs the following:  # map the changes into the correct read-write-set for the ledger to store  # process the configuration changes if applicable;  ex, removing a member CA from the chain, calling gossip  # commit the transaction to ledger    CSCC will provide the following functions:  # process """"join channel"""" for the peer to start receiving transactions on the specified channel  # process transaction on commit  # process """"queries"""" to return configuration data on channel (status, members, crypto)    For now, we will not require any endorsement of the transaction though this may be added in the future.  """
"FAB-496","Story","fabric-orderer",5,"Generate initial configuration transaction for orderer genesis block","""The orderer needs to be able to take its initial configuration and deterministically generate a configuration transaction which all orderers will agree on.  This transaction should be well formed, and must be able to be interpreted by both the ordering service and the peer."""
"FAB-492","Story","fabric-quality",8,"leverage GO obcsdk to use node.js API instead of REST","""Our GO obcsdk is used by a set of tests written in GO for consensus acceptance and regression, ledger stress tests, concurrency, and longrun testing. To talk to the Peers, client threads use REST calls. To leverage all these tests in v1.0 and beyond using node.js (especially needed if REST is deprecated), we must:  # Decouple the REST functions from the GO application layer, and create a well-defined API.  # Implement the node.js SDK communication interface methods, to perform the same functions as the existing REST functions.  # Provide a test environment variable for the GO application tests to choose either REST or node.js. """
"FAB-475","Story","fabric-orderer",8,"generic check for correct requests","""The consensus network should not add garbage data to the batches it produces.  Especially under byzantine assumptions, it is possible that byzantine nodes (client, primary) introduce invalid data into the batches.  To protect against this, requests proposed by a leader need to be validated for a correct signature from an authorized client.  This way a leader (or unauthorized client) can not add invalid requests.  This can be implemented as a generic component that can be shared by different consensus implementations.  In the case of bft, replicas check the batch preprepared by the primary and perform a view change when requests are invalid.  This component would be used by FAB-474 to filter requests before they get added to the fresh pool."""
"FAB-474","Story","fabric-orderer",8,"generic censorship prevention and duplicate request purge for BFT consensus","""We want to prevent the primary of sBFT (but really any replica in any BFT atomic broadcast) to censor requests (i.e., drop individual requests).      Proposal: Per discussion with [~vukolic], this could be addressed by a generic component (not be part of sbft core, nor specific to sbft), which keeps track of new requests (""""fresh""""), in-flight requests (""""pending"""", only at primary), and recently completed requests.  Timestamped entries are serviced infrequently (several second scale), and fresh requests will be brought to the attention of the remaining network, including the primary.  When a second, longer, timeout expires, the component signals to the atomic broadcast implementation that the leader should be changed.    Every time the atomic broadcast implementation observes a change in leader, this is communicated to the component and timeouts are adjusted to give the new leader time to act.    The leader also uses the registry of fresh requests to assemble a new batch.    This sounds deceivingly simple and probably will turn out to be more complicated than expected."""
"FAB-473","Story","fabric-orderer",8,"sbft: create standalone consensus peer","""create executable that will act as atomic broadcast client and use sbft as backend"""
"FAB-470","Task","fabric-orderer",2,"Make logging level configurable for solo orderer and config package","""I think a command-line flag (as we do in the Kafka orderer) will do to begin with, but we probably want to add this to the YAML file as well."""
"FAB-468","Task","fabric-orderer",2,"Add support MaxWindowSize and QueueSize","""MaxWindowSize sets an upper bound on a client's requested window, and QueueSize sets an upper bound on the maximum number of messages a client may have pending. These are not necessary to have but they are good features and they align the Kafka orderer with the Solo one."""
"FAB-467","Task","fabric-orderer",2,"Add support for orderer/config package","""Switch over the Kafka orderer to the config package introduced in FAB-386: https://gerrit.hyperledger.org/r/1153"""
"FAB-507","Task","fabric-orderer",2,"Each solo orderer client should have a separate flow control window","""The QueueSize configuration option is being applied across all orderer clients. Change this to apply on a per-client basis."""
"FAB-526","Task","fabric-orderer",1,"Add reconnection logic","""If the Kafka brokers are not up yet, the orderer should attempt to reconnect to them every X seconds for a period of Y seconds, instead of panicking right away.    This means there's no need for """"sleep 5s"""" hacks when bringing up a network for BDD tests via Docker Compose."""
"FAB-539","Story","fabric-crypto",5,"Implement crypto in python SDK","""Follow SDK spec and refer to nodeJS SDK implementation."""
"FAB-580","Story","fabric-crypto",8,"As a fabric developer working on endorser logic I want to do all the required security checks on a client proposal","""This is in accordance to FAB-351, and FAB-489."""
"FAB-601","Story","fabric-ledger",2,"Ledger versioning scheme: I want to use the block/transaction height as a variable's version, instead of an incrementing version number, so that I have traceability between state data and transaction data","""Ledger versioning scheme: I want to use the block/transaction height as a variable's version, instead of an incrementing version number, so that I have traceability between state data and transaction data"""
"FAB-600","Story","fabric-ledger",8,"As an endorser performing simulation, I want the state database to always be in sync with the blockchain ledger on the file system","""ledgernext was initially delivered in sprint1 to quickly unblock dependent components, in this task the simulation and state management code will be hardened, for example to ensure the state index is always consistent with the blockchain ledger."""
"FAB-618","Sub-task","fabric-sdk-node",2,"Add error paths to endorser-tests.js","""In the initial changeset there's only happy path. Need to add more error paths like what's done in ca-tests.js."""
"FAB-617","Sub-task","fabric-sdk-node",2,"Add headless unit tests for Peer.js and Member.js","""So that each function are tested for handling good and bad params, etc."""
"FAB-666","Task","fabric-orderer",2,"As an orderer I want to retrieve the genesis block and join the network","""Implement bootstrap startup procedure that accepts genesis block file containing configuration for orderer. Make sure the data is organized as specified in FAB-359."""
"FAB-659","Sub-task","fabric-sdk-node",8,"Merge master branch's bug fixes and tests into fabric-sdk-node","""the new repository """"fabric-sdk-node"""" was based on a pre-v0.6 version of the master branch. The master branch has since been further enhanced with bug fixes. We want to bring those into the new repo where make sense.    [~pmullaney] has already started working on migrating over the event hub feature into the new repo, so this effort doesn't need to take into account any code related to event hub."""
"FAB-706","Sub-task","fabric-orderer",1,"Create orderer common components dir","""The complexity with introducing pluggable pieces for filtering and validation into ordering is making the 'throw everything into the orderer directory' policy not make sense.  The directory structure should be re-arranged."""
"FAB-705","Sub-task","fabric-orderer",2,"Create a policy manager","""With the ability to specify policy in FAB-704 it is necessary for the orderer to track what policies are currently in effect and be able to evaluate whether a policy is satisfied by a given transaction.    Therefore, a framework for updating and evaluating policies is necessary."""
"FAB-704","Sub-task","fabric-orderer",2,"Create signature validation DSL for use by filtering framework and later more broad use","""At a high level, the initial configuration defines things like """"Only allow clients who have a certificate which is signed by one of these 6 parties"""", but there is no obvious way to express this in a datastructure.  Especially as more complicated signature schemes must be specified such as """"It must be signed by the network owner, and, it must also have 4 of the 7 stake holders sign off as well"""" the need for a domain specific language arises to express these concepts.    This should be defined in protobuf, as it is how we store and marshal things on the blockchain today."""
"FAB-702","Story","fabric-gossip",8,"Dynamic set of peers.","""Dissemination layer has to provide an ability of dynamic addition for new peer members, it has to be able to recover from network partition and congestion. Moreover it has to preserve node state integrity.    New coming or lagging peers will use the capabilities of this module to synchronize their state from the neighbor peers. """
"FAB-701","Story","fabric-orderer",8,"Connections between shims and Kafka cluster should be authenticated","""As of 0.9, Kafka supports TLS for client/broker and inter-broker communication.    We need to enable it, and also make sure that when a shim or broker is added/removed, the ACLs are updated accordingly.    There are no APIs provided by Kafka for this, so we will have to resort to executing scripts.    https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Authorization+Command+Line+Interface  http://www.confluent.io/blog/apache-kafka-security-authorization-authentication-encryption/    Some more context here: https://hyperledgerproject.slack.com/archives/fabric-consensus-dev/p1477597906002876    Feel free to break this story into tasks, but let's use this as a point of reference for comments and discussion."""
"FAB-742","Sub-task","fabric-gossip",1,"Create and define gossiping node meta object","""Once new node appears in the network it has to complete the state based on the information of the ledger height in other nodes. This information is disseminated during gossip keep alive mechanism, e.g. each node transfer its meta-state which should include information about ledger.    Need to provide an ability to store relevant info within nodes, serialize and de-serialize this information."""
"FAB-761","Story","fabric-orderer",1,"Orderer GRPC API","""Define a GRPC API for client to submit a transaction to Orderer (ie broadcast and deliver).     This is currently in ab.proto, which we need to beef up the description on error conditions."""
"FAB-789","Story","fabric-ledger",8,"As a fabric developer, I want to understand CouchDB performance as a ledger state database","""Initial assessment is complete.  Senthil please attach a community-friendly copy of the performance assessment to this work item."""
"FAB-788","Story","fabric-ledger",8,"As a fabric developer, I want to replace RocksDB with another key/value datastore","""RocksDB has a patent infringement license in it from Facebook. The legal team is therefore not comfortable with using it. For details read: https://github.com/facebook/rocksdb/blob/master/PATENTS    The alternatives include  1. LevelDB (https://github.com/google/leveldb) with a go wrapper (https://github.com/jmhodges/levigo),  2. *goleveldb* (https://github.com/syndtr/goleveldb) - a porting of leveldb in golang  3. BoltDB (https://github.com/boltdb/bolt)    BoltDB is suitable for read heavy workloads (e.g., LDAP) but has a relatively poor performance for read-write workloads.  Of the other two options, *goleveldb* is chosen because it is implemented in golang and hence easy to intergate and maintain.  In addition, as a precedent, ethereum go implementation also uses this package (https://github.com/ethereum/go-ethereum/blob/master/ethdb/database.go)"""
"FAB-782","Sub-task","fabric-sdk-node",2,"Remove sdk/node folder from ""fabric"" project in master","""[~cdaughtr] has done the work to merge all subsequent changes to v0.6 and master in the original location (fabric/sdk/node) to the new project (fabric-sdk-node), tracked in FAB-659. so there's no need to keep the old code around in fabric.    [~greg.haskins] [~rameshthoomu] want to make sure you guys are aware of this planned action. Hoping to do it asap. Would there be any concerns w.r.t the build steps and CI jobs? we'll for sure clean up the make file as part of this."""
"FAB-780","Sub-task","fabric-sdk-node",1,"Update readme for the fabric-sdk-node repo to be more contributor friendly","""should prominently include steps to build, set up test environment and run tests."""
"FAB-821","Task","fabric-orderer",0,"Size broadcaster's batchChan appropriately","""See https://gerrit.hyperledger.org/r/#/c/1627/3/orderer/kafka/broadcast.go@50 and [~bcbrock]'s comment for details.    batchChan is the buffered channel where the broadcaster part of the Kafka shim holds incoming messages until it's time to cut a new block. In the current solo-like implementation, setting the number of elements of this buffer equal to the number of messages a block is expected to have is short-sighted.    We are now moving towards a model where the shim just relays each message to the broker as it receives it, so the original problem goes away, but we should still come up with an appropriate capacity for this.    Do we expose this as a configuration parameter with a sensible default and call it a day? (And what makes for a sensible default?)"""
"FAB-839","Task","fabric-orderer",2,"Create per-session buffered channel for broadcast responses","""The Recv path should as clear from blocks as possible. An appropriately-sized buffered response channel per connected client and a non-blocking write to it is the way to go.    See https://gerrit.hyperledger.org/r/#/c/1627/5/orderer/kafka/broadcast.go@129 for more details."""
"FAB-835","Story","fabric-orderer",2,"As a Fabric user, I want to know how the Kafka-based ordering service works","""We've designed this out in the open, and all the logic is written down in the various JIRA issues that belong to FAB-32, and in #fabric-consensus-dev.    However, it's necessary to wrap everything up in a single document that acts as a point of reference."""
"FAB-833","Sub-task","fabric-crypto",8,"As an application developer I want to implement an application library to offer confidentiality of transaction data.","""This task relates to the implementation of the interface defined in previous work item of 830."""
"FAB-829","Story","fabric-crypto",8,"As an application/infrastructure developer I want to design a generic membership service interface","""This item reflects the work needed to design an interface for membership services operations (issuing/managing certificates, and authentication mechanisms using those certificates) in a way that that interface does not depend on the exact implementation/cryptographic primitives that the membership service uses.   This interface is to be integrated to core operations of the fabric, such that a fabric deployer who wishes to substitute only membership service component of the system, is able to do so without affecting the code of fabric core/transaction processing.   Wee need to define one interface used by the infrastructure (verification MSP interface) and one for the client to construct transactions (retrieving the corresponding certificates), and signing with its secret key.  """
"FAB-828","Story","fabric-ledger",2,"Create couchdb database automatically for main system ledger","""The assumption is that all chaincode will run in one CouchDB database for the system ledger, and there will be separate databases for each subledger."""
"FAB-826","Task","fabric-crypto",8,"As an infrastructure developer i want to implement ACLs on (channel) events","""Implement the technique designed in FAB-637 for registration (access control enforcement) to a channel's events. Extend that implementation to have a aper-channel access policy/check."""
"FAB-885","Task","fabric-peer",1,"Enable successful execution of endorser.feature without bootstrap","""This will not take into account bootstrapping, but will test the engine flow from the client prespective."""
"FAB-892","Story","fabric-orderer",2,"As an orderer I have to authenticate the peer that connects to me","""The orderer/shim needs to check that the peer's certificate links back to a CA that's referenced in the channel's genesis/reconfiguration block."""
"FAB-900","Story","fabric-quality",3,"Test Bootstrapping","""An admin would bootstrap the network and would need the following:  * users and certs for each peer  * orderer certs and URL/IP address for the network  * any possible subchannel information if network will be configured with such    The output is:  * the genesis block that contains cert info for all peers in the network  * a hash that is sent to each peer for determining if the genesis block that they receive from the network is genuine.  """
"FAB-924","Sub-task","fabric-sdk-node",2,"Develop an end-2-end test to drive all v1.0 APIs","""this is a happy path test that ensures all peer APIs have not regressed or changed, to ensure the SDK API and peer stay in sync"""
"FAB-932","Sub-task","fabric-sdk-node",1,"Add a gulp task for running tests with coverage reports","""""""gulp test"""" to run the whole test bucket  """"gulp test-headless"""" to run just the headless tests    both should print a report in the output and generate the HTMLs for the coverage report"""
"FAB-925","Sub-task","fabric-sdk-node",1,"Improve coding styles in headless-tests.js for chaining Promise-based APIs","""the current headless-tests.js have a lot of embedded promise-based calls, like below:    functionA()  .then(     function(result) {        // do stuff        functionB()        .then(           function(result) {...});     });    this is defeating the purpose of the design of Promise-based APIs, it should have been chained like below (note the """"return"""" statement on the call to functionB()):    functionA()  .then(     function(result) {        // do stuff        return functionB();     })  .then(     function(result) {...});  );  """
"FAB-950","Sub-task","fabric-sdk-node",1,"Have self-contained chaincode deployment setup so no manual prep is needed","""Tests that need to deploy chaincode need the following setup:  - GOPATH environment variable  - chaincode available at the folder corresponding to $GOPATH/src/<the GO package>    have this be part of the test fixture so contributors don't have to manually set it up locally. set process.env.GOPATH in the code to the test fixture folder just for the test execution."""
"FAB-998","Task","fabric-orderer",1,"Write test client that sends configuration envelope for new chain creation","""This is part of the FAB-819 story. The goal is to use the """"broadcast_configuration"""" client to send out a transaction that calls for the creation of a new channel. Then we will use the """"bd_counter"""" client to make sure messages show up on the new channel."""
"FAB-996","Task","fabric-orderer",1,"Add a commons/util package","""The point is to not have to rewrite the same common utility functions again and again.    This is what I have so far:    # Marshal(pb proto.Message) []byte  # Hash(data []byte) []byte  # ExtractEnvelope(block *ab.Block, index int) (envelope *ab.Envelope, err error)  # ExtractPayload(envelope *ab.Envelope) *ab.Payload    The Hash function exists in the core util package as ComputeCryptoHash, so I may have to remove that in the end. I'm doing it now cause I want to switch to SHA-2 (FAB-887)."""
"FAB-995","Task","fabric-orderer",2,"Rewrite Broadcaster so as to support ChainPartitions and DataHolders","""The Broadcaster creates a DataHolder reference and spawns a cutBlock goroutine for every chain that is created. It keeps track of which goroutines are running, and can terminate them if need be."""
"FAB-994","Task","fabric-orderer",1,"Create DataHolder type","""Holds all the data that the Broadcaster needs to keep track of, in order to eventually send a new block on the chain. There is a 1-to-1 mapping between chains and DataHolders."""
"FAB-993","Task","fabric-orderer",1,"Create ChainPartition type","""This maps to a Kafka partition, and is related to the two partitions per chain idea we're exploring for FAB-621. """
"FAB-1019","Story","fabric-quality",2,"Add unit tests for ledger applications on Fabric 1.0","""Add unit tests to example.go application in ledger examples."""
"FAB-1013","Task","fabric-orderer",0,"Turn validated new-chain configuration envelope into proper genesis block","""The ordering node should be able to turn a validated new-chain configuration envelope into a proper genesis block. The ordering logic will then be able to get that block directly and push it to the new chain, and also set-up all the related logic (cutBlock goroutine, etc.) based on the parameters extracted from that genesis block (batchTimeout, batchSize), etc."""
"FAB-1094","Sub-task","fabric-orderer",1,"Need utilities to break out a Block and get the ConfigurationEnvelope","""We have multiple places in the code where we need to unmarshall multiple things to get from Block to ConfigurationEnvelope.    Create a set of utility functions that can be called from anywhere"""
"FAB-1141","Epic","fabric-peer",3,"Bootstrap BDD","""Implement bootstrap BDD feature.  This feature will for the basis from which all future features will be based wrt to system composition."""
"FAB-1151","Epic","fabric-ledger",40,"Side DB - Channel Private Data - experimental feature","""* As a Fabric deployer, I would like to maintain data such that only its evidence is exposed to the chain, ordering service, and channel peers while the data itself is disseminated to peers based on policy, so that we can achieve finer-grained data confidentiality for transactions while still maintaining ledger consistency and still being able to leverage Fabric for both data evidence and dissemination of the data (but in a more private fashion).    *Design*     Slides attached."""
"FAB-1174","Task","fabric-orderer",1,"Specify path to orderer.yaml via an environment variable","""Allow an user to specify where on the file system the orderer configuration yaml file is located.    This makes orderer consistent with peer ( and its PEER_CONFIG_PATH ) and allows for easier creation of the docker image."""
"FAB-1257","Story","fabric-ledger",8,"As a chaincode developer, I want to use JSON-based data structures instead of table-based data structures, so that I have more control over queries","""Remove Table API from Hyperleger Fabric in v1.  * The v0.5/v0.6 Pseedo-table API does not map well to current or next generation Fabric capabilities   * Project teams have been confused and frustrated with table API limitations    Encourage all new chaincode to use JSON-based data structures  * Additional query benefits when using CouchDB state database  * Provide JSON-based samples to help community update table-based chaincode  * Initial sample: https://github.com/denyeart/table_to_json/blob/master/chaincode/table_to_json_chaincode.go    In the future Fabric may add support for relational state databases  * At that time it will make sense to introduce a ‘real’ table API without the limitations of the current pseudo-table API  """
"FAB-1280","Story","fabric-orderer",1,"Create fabric common components directory and move orderer shared components there","""The orderer has some common code which is of broader use to the fabric at large, not just the orderer.    In particularly, the configuration block parsing, and the policy parsing and evaluation are prime candidates for being shared in a modular way between the orderer and peer (and possibly other components).    This is being created in part by the request of [~muralisr] to faciliate some VSCC ESCC work."""
"FAB-1278","Story","fabric-orderer",3,"Introduce generic notion of execution in the orderer","""For the impending chain creation work, a second type of transaction will need to be 'executed' beyond a configuration transaction. This store is to generalizes the old configuration specific code paths into a re-usable path.    In particular, the broadcast filters must be generalized to be a more generic filtering mechanism.  Instead of replying with the matched rule type, and then having the invoker make decisions based on the match, the filters should return a Committer which can perform those actions with no specific knowledge from the caller."""
"FAB-1304","Story","fabric-orderer",13,"Hook into fabric ledger for rawledger implementation","""The orderer currently relies on its own rawledger implementations, a simple ram based ledger (which does not persist anything to disk) and a simple file based ledger which uses a very naive JSON encoding with 1 block per file.    Neither of these are likely to scale well for real systems and have always been intended to be testing tools while the real ledger is developed.    A shim needs to be written between the orderer rawledger API and the fabric ledger api to support deploying with the fabric backing ledger for production deployments."""
"FAB-1302","Story","fabric-orderer",3,"Add config inspection validation on chain creation transaction","""Today, chain creation requests are only validated based on the fact that they are well formed, and signed according to the policy for chain creation.    There is no checking to make sure that the orderers are specified correctly, that the orderer MSPs are included, etc.    What these checks are need to be determined as part of this story, as well as their implementation.  There is a plug point in the multichain systemChain.go code which is meant to handle this, but it currently is mostly a no-op."""
"FAB-1300","Story","fabric-orderer",5,"Provide metrics for the common orderer service endpoints","""In order to assess the health of the ordering service, we should expose basic metrics about the state of the ordering network like number of clients connected, transaction rates, chains and chain heights, etc."""
"FAB-1298","Story","fabric-orderer",2,"Remove queueing concept from Broadcast","""The broadcast API suffers from a deficiency today, that it immediately returns success/failure before the request has actually entered consensus.    The desired behavior would be to return success only after the request has entered consensus, but, this poses a problem when the broadcast queue overflows.  In the event that the broadcast queue overflows, incoming requests should be rejected to alert the client to slow down.    This results in the situation of:  1. Wait until after the queue drains to return the failure (which will not throttle the client and not provide immediate feedback, this is bad)  2. Return the success before the queue drains (which will not inform the client if for whatever reason the consensus system never actually accepts the request)    Since these options both have drawbacks and are mutually exclusive, a different solution is required.    This story is to add windowing to the broadcast API to mirror the deliver API.  If the client knows how big the buffer is at the server, then the client can delay sending new messages until it receives the success/failure after processing the queue.  If the client violates the protocol and overflows the queue, the client can be dismissed as malicious and hung-up on."""
"FAB-1308","Story","fabric-ledger",8,"I want to be able to read from CouchDB state database as an 'external' user (not using the peer's admin user)","""Currently only two modes are available when using CouchDB - completely open (no user security) and completely locked down (user security enabled).  Production environments utilize the locked down configuration, while development environments may decide to skip user security in order to allow direct access.    If user security is enabled, only the peer's admin user can read/write to CouchDB.  No other 'external' users can access CouchDB - access is locked down and all requests must go through the peer's CouchDB user.    If it is desired to have 'external' users be able to read (only) CouchDB directly, two changes would be required:    1) Add the 'external' users to the CouchDB database security object as members.  See http://docs.couchdb.org/en/2.2.0/api/database/security.html .  Currently peer writes the database security object with just the peer's admin user upon each startup (allowing for the ability to change the username).  Note - it may be possible to use a server admin instead of setting the admins role on each database, and only populate the members role.     2) Any database 'member' would have both read and write access.  To lock it down for read access only, a CouchDB 'validation function' (deployed as a design document to CouchDB) would be required, it could enforce that only the peer's admin user could perform writes."""
"FAB-1335","Sub-task","fabric-orderer|fabric-quality",3,"BDD tests: Kafka orderer should be resilient to faults","""     The following are the details for these tests.   * +Component+:  orderer   * +Description+:  Test scenarios with faults in the Kafka brokers, and the orderer shims.   * +Artifact Locations+:  test/feature/orderer.feature   * +Network Topology+:  3 orderers, 3 zookeepers, 4 kafka brokers, 4 peers   * +Client Driver+: behave    This test should show that as the partition leader changes, the network still functions as expected."""
"FAB-1334","Story","fabric-orderer",3,"Decide on block hashing specifics","""Today, the orderer is using the functions defined in `fabric/protos/common/block.go` for hashing the block header and data.    These functions are _definitely_ wrong, and were never intended to be long term solutions.  These functions need to be fixed to use a hashing algorithm and marshalling scheme (and possibly using a wide Merkle Tree for the BlockData).    This was discussed somewhat extensively in https://gerrit.hyperledger.org/r/#/c/1361/ but no conclusion was reached."""
"FAB-1333","Story","fabric-orderer",3,"Make orderer logging configurable (in a centralized way)","""Today, the orderer initializes loggers in almost every package, and statically sets their logging levels.  This was easy to speed development along, but this really needs to be configurable for the whole ordering process in a sane way, ideally lifted from the peer flogging stuff."""
"FAB-1349","Story","fabric-orderer",1,"Enforce restrictions on acceptable chain IDs","""This is motivated by the fact that Kafka imposes restrictions on the allowed topic names:  https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/common/Topic.scala#L29    Regardless of that, we should adopt similar restrictions.    Ideally, these will be a superset of the Kafka restriction set so that we don't have to add any extra code for the Kafka consenter case."""
"FAB-1352","Story","fabric-orderer",3,"Add time-based block cutting to Kafka consenter","""In the version that was rebased on top of the common components, this option was kept out in order to minimize the complexity of the changeset. The deliverable of this story is a Kafka consenter that respects the BatchTimeout config option.    """
"FAB-1351","Story","fabric-orderer",1,"Update broadcast_config sample client so that it posts appropriate config for Kafka consenter","""As things stand right now, the config it posts only works for solo. The client should have an extra flag that allows us to specify the consenter type, and then, by using the provisional bootstrapper, it should create the appropriate config."""
"FAB-1374","Task","fabric-orderer",1,"Remove bd_counter sample client","""I wrote this while developing the Kafka orderer for testing. The existing sample clients (broadcast_timestamp and deliver_stdout) provide the same functionality and in a more modular, Unix-like way. Keeping the bd_counter around just increases maintenance burden."""
"FAB-1366","Task","fabric-orderer",1,"Update Docker Compose files for Kafka consenter","""We should either list only those ENV vars where we need to modify the default values, or list all possible ENV vars to allow for easy editing later on. The Docker Compose files in their present form adopt a middle-ground solution: list only some ENV vars, and have several of them set to the default values."""
"FAB-1365","Task","fabric-orderer",1,"Introduce Kafka-specific container message types","""The revised Kafka consenter needs two special messages:    # A time-to-cut message that is used to mark the end of a block, and  # A no-op message that each shim posts when bootstrapped by the multichain manager to prevent the possibility of """"listening in"""" (seeking and consuming) on a topic/partition that nobody has posted to yet [1]. This is an operation that panics in Kafka: """"[ERROR] Cannot retrieve required offset from Kafka cluster: kafka server: The request attempted to perform an operation on an invalid topic.""""    These messages are special because they don't carry transactions, and because the Kafka consenter will treat them in a special way: it will ignore every time-to-cut message (for a specific block number) besides the first one, and it will ignore all """"no-op"""" messages when processing incoming messages from the chain partition.    A preview of these in action can be found here:  https://github.com/kchristidis/fabric/blob/47752ed61fcab1b26207a9e9075c1c793d723912/orderer/kafka/main.go#L142  https://github.com/kchristidis/fabric/blob/47752ed61fcab1b26207a9e9075c1c793d723912/orderer/kafka/main.go#L164  https://github.com/kchristidis/fabric/blob/47752ed61fcab1b26207a9e9075c1c793d723912/orderer/kafka/main.go#L204"""
"FAB-1364","Task","fabric-orderer",2,"Replace static bootstrapper with provisional one","""All consenters read several of their config settings (think sharedconfig) from the genesis block that is generated by a bootstrapper. The only bootstrapper available so far is the static one. However, when testing we need to be able to modify several of these config values on the fly.    Therefore the bootstrapper should be able to read a config object (which is itself created by reading the orderer.yaml file and -if set- its associated ENV vars).    An example of that would be the KafkaBrokers value. For unit tests the """"right"""" value is """"127.0.0.1:9092"""", whereas for the current Docker Compose-based BDD tests the right value is """"kafka0:9092"""".    Since this bootstrapper is no longer static, renaming the package seems appropriate.    For production we will need to introduce file-based bootstrapper that reads the genesis block created by the genesis block tool."""
"FAB-1363","Task","fabric-orderer",1,"Move ChainID method to ConsenterSupport","""What necessitates this move is that the Kafka multichain.Chain object returned/expected by HandleChain(), needs to be able to allocate the resources necessary to keep up with its respective chain when the Start() method is invoked by the multichain manager, as the contract of the Chain interface (defined in chainsupport.go) dictates.    Keeping up with the respective chain means that the Kafka multichain.Chain object needs to bring up a producer/consumer that connects to the corresponding chain partition, so it needs to know the chain ID. The only object passed to us during the HandleChain call is an object of type multichain.ConsenterSupport. Therefore, this interface needs to be extended with the ChainID() method.    I've noted the need for this during my review of this changeset:  https://gerrit.hyperledger.org/r/#/c/2763/ (skip to the comment timestamped 11-27 18:52, and its follow-up comment)    If you want to see how this will look in action for the Kafka consenter (coming in a follow-up changeset), please see:  https://github.com/kchristidis/fabric/blob/47752ed61fcab1b26207a9e9075c1c793d723912/orderer/kafka/main.go#L128  https://github.com/kchristidis/fabric/blob/47752ed61fcab1b26207a9e9075c1c793d723912/orderer/kafka/main.go#L143"""
"FAB-1362","Task","fabric-orderer",1,"Add KafkaBrokers to shared config","""The list of Kafka brokers used for ordering needs to be shared across the shims (ordering service nodes)."""
"FAB-1360","Task","fabric-orderer",1,"Introduce ChainPartition construct for Kafka","""The ChainPartition construct will be used to identify the Kafka topic/partition that the ordering shims should interact with when dealing with a particular chain."""
"FAB-1359","Task","fabric-orderer",1,"Drop custom flag support for Kafka orderer","""As we are slowly moving to a setup where the behavior of the orderer is controlled by the config options captured in the genesis block and the orderer YAML file (and their overrides via ENV vars), it's time to drop the flag support that the Kafka orderer provided.    * Remove all flags from the Kafka orderer.  * Add a """"verbose"""" option to the YAML file to control logging for the package that we use to interact with the Kafka cluster (sarama)."""
"FAB-1358","Task","fabric-orderer",1,"Convert all batchSize refs to the uint32 type","""Address the mismatch between the batchSize type as expressed in the localconfig package versus the sharedconfig package and the orderer configuration proto."""
"FAB-1382","Story","fabric-orderer",3,"Remove windowing concept from the Deliver API","""Per some performance testing feedback from [~bcbrock] it's much more efficient if we allow HTTP2/gRPC to handle the connection data windowing rather than attempting to implement it ourselves at a higher layer.    In order to remove windowing from deliver, there must be some other mechanism supplied to allow a client to retrieve a specific number of blocks.  This means that the Deliver API must also be enhanced to allow range specification."""
"FAB-1422","Story","fabric-ledger",2,"Ledger setInfo(): As a chaincode author, I want to pass information to VSCC for transaction validation context","""Proposal is to add a setInfo() on the simulator, for the chaincode to pass some transaction context that is to be used later for validation in VSCC, without anything getting written to permanent state (therefore don't want to use WriteSet).  This information would get included in the simulation results in the transaction, and VSCC would be able to reference it when performing custom validation logic.    (Murali, please fill in your immediate use case for it)."""
"FAB-1418","Sub-task","fabric-orderer",1,"Convert Policy from oneof to enum","""The Policy type for configuration is currently oneof{ SignaturePolicyEnvelope }.    This is somewhat convenient but is not extensible without modification of the common protos.    Instead, this should be switched to be the standard enumerated type, bytes model."""
"FAB-1416","Story","fabric-orderer",3,"Make policy manager pluggable with different policy providers","""Per discussion with [~ellaki] [~adecaro] and [~ales] the MSP managers would like to provide their own policy evaluation options.  This would be in addition to the NOutOf policies, but would exist within the current framework.    This story is to make the existing policy manager pluggable with different policy providers, so that the MSP manager may provide a policy provider for MSP type policies."""
"FAB-1441","Story","fabric-quality",5,"Behave backend utilities","""A test writer should be able to write feature tests using backend utilities to drive the tests such that any new test scenario can utilize the APIs while keeping the modification of the backend to a minimum.    *Output:* back-end utility functionality that drives the feature files. These utilities will include (but not limited to):    * docker_util    * remote_util   * grpc_util   * shell_util  """
"FAB-1430","Story","fabric-orderer",5,"Implement epoch and timestamp message replay protection","""The envelope header contains a timestamp and epoch both of which are ignored by the ordering service today. But, these should be leveraged for message replay prevention.    This will require synchronizing with the SDK/peer team to make sure these parameters are correctly set."""
"FAB-1446","Task","fabric-quality",2,"Add safesql to CI for go-based components","""Add https://github.com/stripe/safesql to our CI pipelines for all golang components that utilize a database. This will enhance our security by finding any potential SQL injection vulnerabilities before they are merged."""
"FAB-1503","Story","fabric-ledger",8,"Ledger history: When looking at the ledger history for a key, I want to see history with full transactional context ","""In addition to seeing the history of key values, we should be able to see the full transaction details for every update to the key.  This will require defining a new transaction structure to be returned."""
"FAB-1524","Sub-task","fabric-orderer",1,"Appropriately get configuration from block metadata on orderer restart","""The orderer needs to initialize the configuration for every chain, identify the ordering system chain specially, and initialize the other chains."""
"FAB-1523","Sub-task","fabric-orderer",1,"Populate metadata last configuration field","""Each block is supposed to contain a reference to the last configuration block, the configuration of which that block was generated under.    Although this is a separate requirement needed for instance for gossip, this is also useful for supporting restart of the ordering service so is being classified as a sub-task of FAB-1299."""
"FAB-1521","Sub-task","fabric-orderer",2,"Fix orderer rawledger interface to support restart","""The rawledger interface was originally implemented as a single chain initialized with a genesis block.  This causes problems on restart because a newer genesis block may already exist and passing the genesis block becomes nonsensical."""
"FAB-1574","Story","fabric-orderer",1,"Deliver API needs to check signatures against egress policy","""The deliver API will support signatures after FAB-1573, so it then needs to actually respect these signatures and only allow readers which are authorized by policy for a given chain."""
"FAB-1573","Story","fabric-orderer",2,"Deliver messages need to be signable","""The deliver message currently has no authentication associated with it.  Rather than invent yet another signing scheme, we should adapt the Envelope message to be used to send SeekInfo requests."""
"FAB-1563","Story","fabric-orderer",2,"Orderers need to filter incoming Broadcast messages by signature","""The framework to filter incoming transactions exist, as does the framework to manage policies, but currently the filtering framework does no policy enforcement on incoming broadcast messages, this needs to be fixed."""
"FAB-1611","Story","fabric-orderer",3,"Create configuration template for orderer user to consume","""The orderer is currently hackily copying code from the orderer bootstrapper to generate the new chain request.  This is not a real path, as this needs to be supplied by the orderer, this story should address that."""
"FAB-1603","Sub-task","fabric-peer",1,"Incorrect marshalling of transaction into block during block event generation","""Block delivered by events is not in the correct format."""
"FAB-1678","Story","fabric-orderer",8,"As an admin and developer, I need a way to inspect and create configuration transactions","""This story is to start working on the tools necessary for admins to work with configuration transactions, not only creating them, but also inspecting and signing them.    There are four principal components to this issue.    1. Bidirectional proto <=> deep JSON translation:  This is at the heart of the issue, and provides both a human readable, and human editable version of the configuration.  Because the configuration embeds other message types, like {{Envelope}} it is most natural to make this a generic proto <=> deeply unmarshaled JSON.  This means that the output should, to the extent possible, contain no binary marshaled fields.  For instance, a {{Block}} should show nested {{Envelope}} messages in its data, and these messages should show {{Payload}} messages, which should in tern show the unmarshaled version of the {{Data}} field, etc.  Correspondingly, it is important that this mapping be able to be returned into the native proto form.  Note, that the bidirectional marshaling can preserve meaning only, not literal bytes, as proto marshaling is non-deterministic.    2. A Config + Config -> ConfigUpdate utility:  This will allow the user to submit an original config and a modified config to produce a config update.  This will combine naturally with (1), so that the user may view the configuration in a human readable way, edit it, compute the update, and then see the update in a human readable form.    3. A REST API which exposes (1) and (2).    4. A CLI which exposes (1) and (2)    Finally, we may wish to add one additional API to (3)/(4), namely the ability to submit a Config, a Config Update, and have the server do a simulation of the result (including any errors produced because of insufficient signatures, or bad form).    For those interested in getting a jump on interacting with the deep JSON representation, please see a (unusually verbose) config update message attached as output_pretty.txt."""
"FAB-1710","Story","fabric-orderer",1,"Add orderer addresses configuration item","""Add a configuration item which will let the peers know in `JoinChannel` which orderer addresses may be connected to."""
"FAB-1760","Story","fabric-orderer",3,"Integrate configtx.Manager into peer","""The peer currently uses the dangerous and deprecated method of manually inspecting configuration blocks for configuration.  This has a multitude of security and correctness problems, but also produces a lot of redundant and unnecessary code.  The peer should be converted to utilize the existing configtx.Manager code which does proper configuration transaction validation and provides a simple interface for users of that configuration."""
"FAB-1748","Sub-task","fabric-orderer",1,"Refactor provisional bootstrap generator","""The old provisional bootstrapper was becoming increasingly convoluted for doing very little, this changeset deletes must/most of that code in favor of a much simpler approach."""
"FAB-1777","Sub-task","fabric-orderer",1,"Refactor orderer multichain package to prep for chainconfig","""The orderer multichain package has become a little unwieldy as more and more configuration based handlers have been added to it.  This changeset consolidates these many parameters into embedded structures to alleviate this problem in preparation for adding the chain config handler."""
"FAB-1776","Sub-task","fabric-orderer",1,"Move policy manager creation to common components","""The policy manager is currently only initialized within the orderer, but this is a common function and needs to be moved into the common components."""
"FAB-1856","Sub-task","fabric-peer",1,"Add callback feature on configtx update","""Per the gossip team, they require to be notified when the channel configuration changes.  This is to implement a way to push notification events to them."""
"FAB-1876","Story","fabric-gossip|fabric-orderer|fabric-peer",3,"Update anchor peers to be multiple configuration items","""Because write access to config is scoped by configuration item, it does not make sense for all anchor peers to be writable by any organization.  Instead, we should have one configuration item per anchor peer, with a modification policy corresponding to that org."""
"FAB-1875","Story","fabric-orderer",8,"Introduce identity channel to orderer","""There is an existing problem with syncing identity across channels.    # Application orgs cannot read the ordering system channel, so they cannot reasonably update their identity there.  # Application orgs cannot determine what channels they are a member of, so cannot easily script updates to their identity.  Further, because the identity may be at different levels and will definitely have different headers, one signature must be generated per channel.  # The orderer has no way to ensure that the MSP used in a channel creation request is up to date (except relative to the ordering system channel, which as already pointed out, is problematic to update).  # The orderer has no centralized place to get TLS certs from.  # The peer has no authoritative source for TLS certs or for local MSP data.  # If an application wishes to create a channel with an org they have no other channels with, it's not obvious how to retrieve their current MSP.    There are probably other benefits as well."""
"FAB-1880","Story","fabric-orderer",8,"Enable MVCC+Postimage for configtx","""The current configuration tx scheme requires a global sequence number be specified.  This is problematic as a DoS attack vector if single signers are allowed for modification of items (like anchor peers, or MSP definitions).  It should be a relatively straightforward change to modify this to be MVCC+postimage to eliminate the DoS sequence number contention problem."""
"FAB-1946","Sub-task","fabric-orderer",1,"Remove ChainHeader from ConfigurationItem","""In preparation of having one header across an entire update, this needs to be removed from the individual items."""
"FAB-1962","Sub-task","fabric-peer",1,"Switch peer tests to utilize test templates","""The peer already depends on the orderer template, but is not currently using the peer or MSP templates.  Where appropriate, especially the MSP template should be utilized."""
"FAB-1960","Sub-task","fabric-peer",1,"Create peer test template","""Just like the orderer, and the MSPs, a peer test template needs to be created to facilitate tests which require a valid genesis block for a chain."""
"FAB-1955","Story","fabric-orderer",3,"Generate test genesis block in tests.","""The unit tests require genesis materials for their chain, but this is currently a manual and hacky process.  This story is to fix this into a more automated flow."""
"FAB-1992","Story","fabric-orderer",3,"Move configtx signatures to be across whole config, not just individual items","""The current configtx scheme is a collection of signed configuration items.  This has the benefit of being very flexible, allowing a submitter to collect signatures from one set of parties for one set of items, a second set of signatures from a second set of parties for a second set of items, and then glue them together, and submit a valid reconfiguration.    However, this flexibility comes at the expense of requiring more signatures, and the added complexity does not seem worth the added flexibility.  This CR moves the signatures to the envelope level, but maintains the per item policy evaluation."""
"FAB-1983","Story","fabric-orderer",8,"Allow other chain hashing parameters","""Per FAB-1700 and FAB-1699, the chain hashing parameters are now included in the chain configuration.  However, for the v1 release it was not practical to actually utilize these values, so instead they are required at a fixed size until they can be implemented.    The chainconfig.Descriptor carries these values, but no one is currently consuming them.    This additionally includes implementing a Merkle tree for the block data structure."""
"FAB-2073","Story","fabric-orderer",13,"Implement hierarchical configtx structure","""The current configuration structure is a flat list, which causes some problems, especially when attempting to differentiate between the roles of ordering organizations and peer organizations.  A hierarchical model is slightly more complex from a data structure perspective, but is more natural and expressive.    This work should be careful to ensure that the older model can be supported in the degenerate case."""
"FAB-2105","Sub-task","fabric-orderer",1,"Add simple configuratoin schema protos","""Because the new configtx format is so much more flexible than the original, we need to make sure that it is locked down to keep people from going crazy with it.  The restrictions can be relaxed as the use cases are made, but initially the goal is to restrict the configuration to a minimal set and loosen from there.    To do this, protos for a simple schema should be defined so that the configtx manager can enforce the restrictive configuration scheme."""
"FAB-2104","Sub-task","fabric-orderer",1,"Move channel shared config to common","""The orderer and application config were both recently moved to common.  For the sake of consistency, the channel config should be moved from its current location in common under configtx like orderer and application."""
"FAB-2102","Sub-task","fabric-peer",1,"Move application shared config from peer to common","""Just as with the orderer configuration, having the peer configuration in a separate package is problematic, so this CR moves it to common."""
"FAB-2097","Sub-task","fabric-orderer",2,"Add ConfigNext proto","""Rather than modify the config protos and the config producers, parsing, and consumers all at once, this CR adds only the new protos, without removing the old, and makes the minimal changes required only to use the new proto format while on the wire."""
"FAB-2096","Sub-task","fabric-orderer",1,"Remove xxxCryptoHelper to mocks","""The real crypto helper was added, but the mock one was left in the real binary, moving to mocks."""
"FAB-2120","Sub-task","fabric-orderer",1,"Move configtx filter to orderer","""When configtx was moved from orderer to common it brought along the configtx.Filter, which is inherently an orderer concept and violates the rule of not importing from common into orderer."""
"FAB-2156","Sub-task","fabric-orderer",1,"Move orderer viper enhancements to common","""Before moving the orderer genesis generation to common, it needs the enhanced viper support added by the orderer."""
"FAB-2155","Sub-task","fabric-orderer",1,"Split orderer config into local and genesis components","""This split is necessary to prepare to migrate the orderer genesis creation into the common package to use as a starting point for generating genesis material."""
"FAB-2144","Sub-task","fabric-orderer",3,"Migrate configtx.Manager to parse ConfigNext","""While integrating the ConfigNext proto, adapter code was written to convert it back to the original Config type.  This conversion code needs to go away, and as a first step, the configtx.Manager needs to begin using the updated format."""
"FAB-2176","Sub-task","fabric-orderer",1,"Add ConfigUpdate proto","""In order to stabilize the protos, the ConfigUpdate protos need to go in first.  The existing code can be adapted simply to depend on a ConfigUpdate write set which includes the entire config.  Then, the actual partial config updates can be built on top of it."""
"FAB-2202","Sub-task","fabric-orderer",1,"Initialize configtx manager from Config, not Writeset","""As a transitional mechanism, the config currently depends on the WriteSet containing the entire configuration.  Instead, the config as written in the config envelope needs to be utilized."""
"FAB-2201","Sub-task","fabric-orderer",1,"Generate new config from udpated config map","""The configtx code currently shortcuts by assuming that the writeset contains exactly the entire config.  In order to support partial updates, this writeset should be overlayed on top of the existing config, then transformed back into a new config."""
"FAB-2210","Sub-task","fabric-orderer",1,"Rename CONFIGURATION_ to  CONFIG_","""This brings the enums into line, using the word config everywhere instead of a mix of config and configuration."""
"FAB-2339","Sub-task","fabric-orderer|fabric-peer",1,"Add simple tool to write out a genesis block","""Please refer to the file {{configtxgen.md}} in the fabric/docs directory for usage of this tool."""
"FAB-2470","Story","fabric-gossip",1,"Fix gossip proto style","""The gossip protos were moved under fabric/protos after the fabric/protos were restyled to conform to proto style guidelines.  The gossip protos need to be brought in line with this."""
"FAB-2468","Story","fabric-orderer",1,"Remove unnecessary header messages from configtx messages","""After an audit with Elli, it's been concluded that the ChannelHeader embedded in the configtx.proto Config and ConfigUpdate messages are unnecessary, that the only piece of information needed is the ChannelId.    By removing these, the messages will be simpler to construct and understand."""
"FAB-3125","Task","fabric-samples",1,"Remove sfhackfest from examples","""The sfhackfest example is not longer relevant to the master branch / v1.0.0"""
"FAB-3139","Task","fabric-peer",1,"Improve test coverage for github.com/hyperledger/fabric/core/comm package","""The current coverage for the package is 62.8% but the major gap in tests for functions found in connection.go """
"FAB-3136","Sub-task","fabric-build",1,"Include install script with each release package","""As we currently distribute the various runtime components as Docker images, it is convenient to include a script which will download the correct version of the images for a given release and platform.    With this task, we'll include a script which will pull all of the images for a given release"""
"FAB-3264","Sub-task","fabric-quality",3,"Add Config utility for Behave functional tests","""This config utility will contain functions that will be used when configuring a fabric network for use in the behave functional test runs. """
"FAB-3283","Sub-task","fabric-quality",3,"Add orderer test scaffolding","""This scaffolding will be the basis for implementing the orderer feature files."""
"FAB-3281","Sub-task","fabric-quality",3,"Import protobuf files from bddtests directory","""Instead of regenerating the python files based on the protobuf files, import the generating files for use in the utilities for these tests."""
"FAB-3338","Sub-task","fabric-quality",2,"Provide a sample deployment and topology for Docker Swarm Mode","""Docker 1.13+ has a built-in multi-host orchestration engine called """"Swarm Mode""""    This task is to provide the relevant artifacts and documentation to help create a sandbox topology using Docker Swarm"""
"FAB-3506","Sub-task","fabric-quality",3,"Behave peer scaffolding","""This scaffolding will be the basis for implementing the peer feature files.  """
"FAB-3523","Sub-task","fabric-gossip",1,"Modify comm implementation is use callback function to get secure dial options","""The current gossip implementation is initialized with a set of dial options which don't change during the lifecycle of the peer.  In order to always get the most up to date secure dial options (which basically means dial options with the latest set of trusted roots for remote peers / organizations) this task will add a callback function to the comm impl"""
"FAB-3675","Task","fabric-build",1,"add license check script to fabric repo","""see FAB-3674 for description"""
"FAB-3737","Task","fabric-build",1,"Generate changelog for v1.0.0-alpha2","""generate changelog for v1.0.0-alpha2"""
"FAB-3758","Sub-task","fabric-quality",2,"Add container start/stop functionality","""The tests should have the capability to start and stop containers.    [https://gerrit.hyperledger.org/r/#/c/9667]     """
"FAB-3754","Sub-task","fabric-quality",3,"Add endorser_util","""This should contain the code needed to perform the key endorser functionality such as   * install   * instantiate   * create channel   * join channel   * invoke chaincode   * query chaincode"""
"FAB-3753","Sub-task","fabric-quality",2,"Add a Readme for the system feature tests","""A readme that contains at least the following should be added to the test/feature directory:   * Getting Started   * Prereqs   * How to contribute       https://gerrit.hyperledger.org/r/#/c/9131/"""
"FAB-3738","Task","fabric-build",1,"obtain CII badge","""obtain a CII Badge from LF"""
"FAB-3830","Task","fabric-docs",1,"Create a description of why blockchain","""Would like to build the story from the very high level down to the details of Hyperledger Fabric. This is the first phase, description of the very high level components of blockchain. Ultimately would like to move to the over arching Hyperledger project umbrella, then each project can build off of it. But wanted to start the story here, so for now will host within fabric doc."""
"FAB-3779","Sub-task","fabric-quality",1,"need security vulnerability reporting process implemented and documented","""We need a documented process for submitting security issues relating to Fabric implemented and documented to satisfy the CII Badge requirements."""
"FAB-3774","Epic","fabric-docs",8,"A document that will outline considerations when starting a network","""This is a document that will have a lot of cross with best practices. Considerations and thoughts that need to happen when creating a new network. Starter list of items:    -  Who will define membership in the network, and how?  -  Where will my network be hosted?  -  What are the features I'll need?  -  What are the technical specifications I’ll need to make it work?  -  What kinds of special application layers will I need?    regarding    -  Governance - Fab-2308  -  :ref:`Membership-Services`  -  :ref:`Ordering-Service`  -  :ref:`Ledger` for database configuration - Fab-2308  -  Security Options  -  :ref:`SDK` s/APIs  -  :ref:`Assets`  -  :ref:`Channel` benefits"""
"FAB-3846","Story","fabric-quality",3,"Placeholder for behave tests ","""We have to create templates of the tests that will be executed using the behave framework. The Scenario name should look as follows:         Each scenario should be tagged with the @skip tag. This tag will be removed once the test is written and ready for use.     """
"FAB-3891","Task","fabric-build",1,"cut v1.0.0-alpha2 release ","""prepare for the alpha2 release process. -This will involve creating the """"release"""" branch as per the process proposal proposed by Dave at the Hackfest.-     -Suggest that we leave master as master and actually create a """"develop"""" branch after we tag the v1.0.0-alpha2 release on the master branch, and that we then shift the target of all CRs to the """"develop"""" branch from that point forward. Master will only merge FF merges from a temporary release branch created from """"develop"""" which will run through the gauntlet of tests before being merged to """"master"""" and cutting a release.-    -Note that this will also require that all in-flight CRs be resubmitted against the """"develop"""" branch.-    just tag and publish release without changing branch structure for now."""
"FAB-3981","Task","fabric-quality",1,"Provide various governance options for scenarios.","""Provide governance options of Dictatorial/Democratic/Unanimous as scenario options for controlling the default policy settings."""
"FAB-4107","Sub-task","fabric-orderer",3,"Add REST server component to expose proto translator","""This task is for introducing the server which will listen for api requests as discussed in the parent issue."""
"FAB-4106","Sub-task","fabric-orderer",3,"Create config update computation component","""This task is for creating the code necessary to take in two config messages, and compute the corresponding config update message."""
"FAB-4105","Sub-task","fabric-orderer",1,"Add proto translator method extensions to fabric proto messages","""With the proto translator and component pieces in place, the actual fabric messages which it is to translate must be annotated with the necessary methods to be translated."""
"FAB-4104","Sub-task","fabric-orderer",1,"Create proto translator for dynamic field components","""Some proto fields have component messages whose behavior is determined by some other context, such as where they appear relative to other messages.  These messages cannot be simply annotated like other the statically or variably opaque messages, but must instead be decorated at runtime with their descriptive attributes.  This task is for creating the component which handles these dynamic fields."""
"FAB-4103","Sub-task","fabric-orderer",1,"Create proto translator for variably opaque field component","""Some proto fields are marshaled proto messages who's type varies based on the other contents of the message (possibly including other statically marshaled fields).  This task if for creating the variably opaque field component."""
"FAB-4102","Sub-task","fabric-orderer",1,"Create proto translator for statically opaque field component","""Some proto fields are simply statically marshaled fields, namely their type is known at compile time.  This task is to handle the creation of the component to handle these."""
"FAB-4101","Sub-task","fabric-orderer",1,"Create proto translator nested field component","""Proto messages embedded inside of other proto messages must be passed back through the common translator component.  This component should act as a catch-all for otherwise unhandled proto messages."""
"FAB-4100","Sub-task","fabric-orderer",3,"Create proto translator component framework","""Doing bidirectional proto translation to/from deep JSON requires a significant amount of dynamic programming.  Having each message try to handle this work independently is a recipe for disaster, so the bulk of the reflection work needs to be centralized so that protos may be simply extended with methods which drive the proto translation framework.    This task is to cover designing and implementing this plug-able core reflection framework."""
"FAB-4233","Sub-task","fabric-sdk-java",1,"create v1.0.0-alpha3 release notes for fabric-sdk-java","""create release notes that generalize the changes since v1.0.0-alpha2"""
"FAB-4232","Sub-task","fabric-sdk-node",1,"create v1.0.0-alpha3 release notes for fabric-sdk-node","""create release notes for v1.0.0-beta that generalize changes since v1.0.0-alpha2"""
"FAB-4231","Sub-task","fabric-ca-build",1,"create release notes for fabric-ca","""create release notes that generalize the changes since alpha2 to be used in release tag"""
"FAB-4230","Sub-task","fabric-build",1,"create release notes text for fabric","""create release notes for fabric text that generalize the nature of changes since v1.0.0-alpha2"""
"FAB-4228","Sub-task","fabric-sdk-java",1,"tag v1.0.0-alpha3 release of fabric-sdk-java","""tag release with a commit message that includes:    release notes    known vulnerabilities    other known issues    changelog link"""
"FAB-4227","Sub-task","fabric-sdk-node",1,"tag v1.0.0-alpha3 for fabric-sdk-node","""tag release with a commit message that includes:    release notes    known vulnerabilities    other known issues    changelog link    create change log      """
"FAB-4223","Sub-task","fabric-ca-build",1,"tag v1.0.0-alpha3 release of fabric-ca","""tag release with a commit message that includes:    release notes    known vulnerabilities    other known issues    changelog link    create change log"""
"FAB-4222","Sub-task","fabric-build",1,"tag v1.0.0-alpha3 release of fabric","""tag release with a commit message that includes:    release notes    known vulnerabilities    other known issues    changelog link"""
