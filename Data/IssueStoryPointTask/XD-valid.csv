"issuekey","type","components","storypoint","title","description_text"
"XD-1840","Improvement","Documentation|REST",8,"Document and review REST API","""REST API needs to be finalized and documented for the GA release. The API to be reviewed by REST experts """
"XD-1839","Story","Runtime",8,"Do not allow the use of named channels in composed modules","""This needs closer inspection, but here are some things that currently do not work, either at the parser level, or at actual deployment time:  """
"XD-1851","Improvement","Runtime",5,"Introduce cache to ZooKeeperContainerRepository","""Add Cache implementation for ZooKeeperContainerRepository"""
"XD-1850","Bug","Runtime",3,"IllegalStateException when deploying orphaned stream modules upon a matching container arrival","""Upon a matching container arrival, if there are orphaned stream modules to be deployed, then following exception is thrown:  java.lang.IllegalStateException: Container missing     at org.springframework.util.Assert.state(Assert.java:385)     at org.springframework.xd.dirt.core.StreamDeploymentsPath.hasDeploymentInfo(StreamDeploymentsPath.java:275)     at org.springframework.xd.dirt.core.StreamDeploymentsPath.build(StreamDeploymentsPath.java:233)     at org.springframework.xd.dirt.server.ContainerListener.getContainersForStreamModule(ContainerListener.java:337)     at org.springframework.xd.dirt.server.ContainerListener.redeployStreams(ContainerListener.java:278)     at org.springframework.xd.dirt.server.ContainerListener.onChildAdded(ContainerListener.java:186)     at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:155)"""
"XD-1861","Bug","Configuration",3,"Fix XD config initializer for ZK connection string","""Spring Boot 1.1.1 has the following change:  https://github.com/spring-projects/spring-boot/commit/b75578d99c8d435e1f8bf18d0dbb3a2ddf56fdc4  where, an external property source precedence would get re-ordered after the application configuration properties. This change affects Spring XD config initializer which expects an external """"zk-properties"""" property source always preceding over the application configuration properties. """
"XD-1860","Improvement","DSL",0,"Support for configuring more than one broker in rabbit source","""Spring XD rabbit source supports these options  http://docs.spring.io/spring-xd/docs/1.0.0.BUILD-SNAPSHOT/reference/html/#rabbit  However, if there are multiple brokers available for a client to connect to then there is no way to configure that when creating a stream. I believe there is support for this already in the rabbitmq client (addresses field if I remember right from the meeting) but it needs to be exposed as one of the options in defining a stream with rabbitmq source. This way if one of the brokers die the client can automatically switch to one of the other configured brokers and provide high availability on the client side. """
"XD-1857","Bug","Hadoop",3,"Can't use webhdfs with hdfs sink","""When using spring.hadoop.fsUri set to webhdfs://localhost/ I'm getting an error:  java.lang.NoClassDefFoundError: javax/ws/rs/core/MediaType  including the following in xd/lib seems to fix this: - jersey-core-1.9.jar - jersey-server-1.9.jar """
"XD-1856","Story","Hadoop",5,"Add option to specify fsUri to hdfs sinks","""We should have an --fsUri parameter for hdfs and hdfs-dataset sinks so we can write to different file systems (hdfs, webhdfs)"""
"XD-1854","Story","Hadoop|Packaging",5,"Remove Hadoop v1 support","""Going forward it seems that providing Hadoop v1 will be of lesser importance and we might as well drop it now. SHDP 2.1 will also drop any v1 support.  Remove support for: - hadoop12 - Apache Hadoop 1.2.1 - cdh4 - Cloudera CDH 4.6.0 - hdp13 - Hortonworks Data Platform 1.3  Keep: - hadoop22 - Apache Hadoop 2.2.0 (default) - phd1 - Pivotal HD 1.1 - phd20 - Pivotal HD 2.0 - cdh5 - Cloudera CDH 5.0.0 - hdp21 - Hortonworks Data Platform 2.1  This should make configuration and documentation easier too. Not to mention testing.  This affects startup scripts and the shell plus the build script."""
"XD-1864","Improvement","UI",5,"Add paging support for UI list views","""As a user, I'd like to have _paging_ support so that I can scroll through the list of streams, jobs and containers.   Currently the following error is thrown when we cross >20 rows:  http://localhost:9393/jobs/definitions.json  JSON Response:   Stack trace: """
"XD-1863","Story","Packaging",5,"Create way to deploy custom modules for XD on YARN","""Need a way for end-user to package and add custom modules/scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It's not convenient to un-zip/re-zip this archive to add custom modules/scripts.  See - https://github.com/spring-projects/spring-xd/issues/931"""
"XD-1870","Bug","Stream Module",5,"Rabbit Sink & Source --host and --port are not updating module host/port.","""Acceptance Tests failed on the Rabbit Source and Sink Tests.  The test started failing when XD-1824 was introduced (Support RabbitMQ Cluster in source/sink).  This story added addresses to support rabbit cluster failover.   Currently if a user set --host --port to a remote Rabbit instance, XD will use the default host=localhost and port=5672.  However using --addresses does work.  """
"XD-1869","Improvement","Stream Module",1,"Provide option for sources/sinks to configure mapped headers to/from Messages","""See the discussion: https://gopivotal-com.socialcast.com/messages/20771872"""
"XD-1897","Improvement","Stream Module",3,"Spring XD - Handling sink failures","""If a sink fails for whatever reason, will it be possible to handle it? Say by sending the payload to an error queue for later processing when a JDBC or Mongo sink fails due to a database connectivity loss? Or the modules are designed by certain principles / contracts not to be meant to handle such failures? """
"XD-1901","Bug","REST|Runtime",2,"Job undeploy operation throws exception","""Job `undeploy` operation throws the following stacktrace:  ``` http-nio-9393-exec-5 zookeeper.ZooKeeperJobRepository - Exception while transitioning job 'j' state to undeploying org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/j/status  at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)  at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)  at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1266)  at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:260)  at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:256)  at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)  at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:252)  at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:239)  at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:39)  at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:177)  at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:199)  at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:1)  at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:68)  at org.springframework.xd.dirt.rest.XDController.undeploy(XDController.java:125)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ```"""
"XD-1899","Improvement","Runtime",2,"IllegalStateException on single node shutdown","""Upon shutdown via ^C, an IllegalStateException stack trace appears in the server logs. While harmless, the traces are annoying and should be prevented."""
"XD-1908","Story","Stream Module",1,"Remove Retry from TCP Sink","""Now that the bus supports retry it is no longer necessary to have the retry advice in the TCP Sink."""
"XD-1907","Story","UI",3,"Handle 'deploying' state at the Admin UI","""When the job is in """"deploying"""" state, until we decide whether the job is actually """"deployed"""" or """"failed""""/""""incomplete"""", there is no way to know if it is fine to launch/schedule (though the launching requests are going to go to the job launch request queue).   We could either disable both """"deploy""""/""""undeploy"""" until the state changes from """"deploying""""?"""
"XD-1906","Story","REST|Runtime|UI",3,"Handle Status Changes in Client (Dynamically update UI)","""As a minimum we need some common polling strategy on the client side to detect status changes of job + streams etc. (E.g. during deployment of streams/jobs)  Ideally, I would like to have this addressed on the server-side as well. It would be nice if we could propagate events between, containers and admin-server that would inform about any changes in the system. We could then use those to notify connected UI clients."""
"XD-1905","Story","Runtime",1,"DefaultContainerMatcher - Improve Logging and mention affected Module","""When deploying a definition with a container match criteria specified, and no container could be selected - the logging is ambiguous and should mention the affected module:  """
"XD-1912","Bug","Stream Module",3,"Rabbitmq source is not ingested the data into jdbc sink","""I am using Spring XD to ingest the data into Pivotal HD.My source is log files which is coming from logstash through Rabbitmq. I could able to ingest the log files in HDFS (by using Rabbitmq source and HDFS sink) However when i try to ingest the data directly into Hawq by using JDBC sink,it's not working. Shall we directly load Rabbitmq source into any databases like Hawq?   stream create --name pivotalqueue --definition """"rabbit --host=<my host name>   | jdbc   --columns='colum list'""""      ---Not working  I configured jdbc in jdbc.properties. There was no issue with jdbc configuration(because i tested this with simple tail source it's working and load the data into HAWQ. stream create --name pivotalqueue --definition """"tail --name=/tmp/xd/output/test.out   | jdbc  --columns='columns list'""""  ) """
"XD-1915","Story","Hadoop|Packaging",3,"Add Hadoop 2.4.x as an option","""Hadoop 2.4.1 is now a stable release and we should add support for running against it"""
"XD-1925","Improvement","Runtime",1,"Rename ModuleDeployer","""For more info, please see here:  https://github.com/spring-projects/spring-xd/pull/1021/files#r14617723"""
"XD-1918","Improvement","Documentation",1,"Update TypeConversion Page","""Need to update the examples in the TypeConversion doc, re spring social Tweet which is no longer used."""
"XD-1941","Bug","Packaging",3,"No main manifest attribute in xd-yarn-client jar","""Error deploying to YARN -   $ ./spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/bin/xd-yarn push -p spring-xd-1.0.0.BUILD-SNAPSHOT-yarn no main manifest attribute, in spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/lib/spring-xd-yarn-client-1.0.0.BUILD-SNAPSHOT.jar  probably related to boot changes"""
"XD-1940","Story","Packaging",3,"Clean up duplicated dependencies from XD on YARN installation","""Remove unnecessary/duplicated jars from the lib directory in spring-xd-yarn zip distribution"""
"XD-1950","Bug","Batch",1,"Single step partition support on filejdbc module uses module's datasource","""The filejdbc module's single step partition support configures to use jdbc module's datasource rather than XD's batch datasource.  ``` org.springframework.messaging.MessageHandlingException: org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback; uncategorized SQLException for SQL [SELECT JOB_EXECUTION_ID, START_TIME, END_TIME, STATUS, EXIT_CODE, EXIT_MESSAGE, CREATE_TIME, LAST_UPDATED, VERSION, JOB_CONFIGURATION_LOCATION from BATCH_JOB_EXECUTION where JOB_EXECUTION_ID = ?]; SQL state [null]; error code [0]; [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION); nested exception is java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)  at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:78)  at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy115.send(Unknown Source)  at org.springframework.xd.dirt.integration.bus.LocalMessageBus$3.handleMessage(LocalMessageBus.java:188)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.access$000(UnicastingDispatcher.java:48)  at org.springframework.integration.dispatcher.UnicastingDispatcher$1.run(UnicastingDispatcher.java:92)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback; uncategorized SQLException for SQL [SELECT JOB_EXECUTION_ID, START_TIME, END_TIME, STATUS, EXIT_CODE, EXIT_MESSAGE, CREATE_TIME, LAST_UPDATED, VERSION, JOB_CONFIGURATION_LOCATION from BATCH_JOB_EXECUTION where JOB_EXECUTION_ID = ?]; SQL state [null]; error code [0]; [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION); nested exception is java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)  at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:84)  at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)  at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)  at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:660)  at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:695)  at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:727)  at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:737)  at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:811)  at org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.getJobExecution(JdbcJobExecutionDao.java:267)  at org.springframework.batch.core.explore.support.SimpleJobExplorer.getStepExecution(SimpleJobExplorer.java:142)  at org.springframework.batch.integration.partition.StepExecutionRequestHandler.handle(StepExecutionRequestHandler.java:52)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)  at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)  at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)  at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)  at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)  at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)  at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)  at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)  at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)  at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)  ... 41 more Caused by: java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)  at org.sqlite.DB.newSQLException(DB.java:383)  at org.sqlite.DB.newSQLException(DB.java:387)  at org.sqlite.DB.throwex(DB.java:374)  at org.sqlite.NestedDB.prepare(NestedDB.java:134)  at org.sqlite.DB.prepare(DB.java:123)  at org.sqlite.PrepStmt.<init>(PrepStmt.java:42)  at org.sqlite.Conn.prepareStatement(Conn.java:404)  at org.sqlite.Conn.prepareStatement(Conn.java:399)  at org.sqlite.Conn.prepareStatement(Conn.java:383)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.apache.tomcat.jdbc.pool.ProxyConnection.invoke(ProxyConnection.java:126)  at org.apache.tomcat.jdbc.pool.JdbcInterceptor.invoke(JdbcInterceptor.java:109)  at org.apache.tomcat.jdbc.pool.DisposableConnectionFacade.invoke(DisposableConnectionFacade.java:80)  at com.sun.proxy.$Proxy109.prepareStatement(Unknown Source)  at org.springframework.jdbc.core.JdbcTemplate$SimplePreparedStatementCreator.createPreparedStatement(JdbcTemplate.java:1557)  at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:638)  ... 63 more 12:23:37,941  INFO main-EventThread server.ContainerRegistrar:254 - Undeploying module [ModuleDescriptor@d192973 moduleName = 'filejdbc', moduleLabel = 'filejdbc', group = 'csvjdbcjob0', sourceChannelName = [null], sinkChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map['resources' -> 'file:///tmp/xdtest/jdbc/delete_after_use.csv', 'initializeDatabase' -> 'true', 'names' -> 'col1,col2,col3', 'deleteFiles' -> 'true', 'driverClassName' -> 'org.sqlite.JDBC', 'url' -> 'jdbc:sqlite:/tmp/xdtest/jdbc/jdbc.db'], children = list[[empty]]] 12:23:37,941  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=filejdbc, type=job, group=csvjdbcjob0, index=0 @73cc35b5] 12:23:37,944 ERROR task-scheduler-1 step.AbstractStep:225 - Encountered an error executing step step1-master in job csvjdbcjob0 org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returned  at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)  at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)  at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)  at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)  at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)  at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)  at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)  at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)  at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)  at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)  at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy44.run(Unknown Source)  at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)  at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)  at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)  at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)  at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)  at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)  at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)  at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)  at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)  at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)  at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy115.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy115.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.endpoint.PollingConsumer.handleMessage(PollingConsumer.java:74)  at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:205)  at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:284)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:278)  at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)  at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:744) ```"""
"XD-1948","Story","Packaging",1,"Build should use Spring Boot plugin version 1.1.4 ","""The platform uses Boot version 1.1.4 so the plugin version used in build.gradle should match that."""
"XD-1944","Bug","Runtime",3,"Error deploying stream when admin running and container arrives after stream deployment request","""Steps to reproduce:  1. start xd-admin  2. start shell and create and deploy stream (""""time | hdfs"""")  3. start container  I got:  [2014-07-10 09:10:29.019] boot - 19923  INFO [DeploymentSupervisorCacheListener-0] --- InitialDeploymentListener: Path cache event: /deployments/streams/test, type: CHILD_ADDED [2014-07-10 09:10:29.137] boot - 19923  INFO [Deployer] --- StreamDeploymentListener: Deploying stream Stream{name='test'} [2014-07-10 09:10:29.146] boot - 19923  WARN [Deployer] --- StreamDeploymentListener: No containers available for deployment of stream test [2014-07-10 09:10:29.146] boot - 19923  INFO [Deployer] --- StreamDeploymentListener: Stream Stream{name='test'} deployment attempt complete [2014-07-10 09:11:08.003] boot - 19923  INFO [DeploymentSupervisorCacheListener-0] --- ContainerListener: Path cache event: /containers/007c2bcc-13f4-466e-95d3-bd926bb456ea, type: CHILD_ADDED [2014-07-10 09:11:08.006] boot - 19923  INFO [DeploymentSupervisorCacheListener-0] --- ArrivingContainerModuleRedeployer: Container arrived: 007c2bcc-13f4-466e-95d3-bd926bb456ea [2014-07-10 09:11:08.176] boot - 19923 ERROR [DeploymentSupervisorCacheListener-0] --- PathChildrenCache:  org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/test/modules   at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)   at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)   at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)   at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)   at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)   at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)   at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)   at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)   at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)   at org.springframework.xd.dirt.server.ArrivingContainerModuleRedeployer.deployUnallocatedStreamModules(ArrivingContainerModuleRedeployer.java:133)   at org.springframework.xd.dirt.server.ArrivingContainerModuleRedeployer.deployModules(ArrivingContainerModuleRedeployer.java:106)   at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:99)   at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   at java.util.concurrent.FutureTask.run(FutureTask.java:262)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   at java.util.concurrent.FutureTask.run(FutureTask.java:262)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   at java.lang.Thread.run(Thread.java:744) """
"XD-1960","Bug","Runtime",2,"Prevent deploying modules of same type on a given stream/job when new leadership election happens","""When the leadership election happens, the new deployment supervisor's container listener tries to deploy unallocated modules (via ArrivingContainerModuleRedeployer) into existing container that has the modules of the same type on a given stream/job already deployed.  Currently, on a given stream/job we don't allow more than one deployment of the same module type and there by avoiding any conflicting properties for the given module type. """
"XD-1959","Bug","Runtime",1,"NoNodeException after bouncing admin server","""Steps to reproduce:  h6. 1. Clear out ZK   h6. 2. Start admin  h6. 3. Deploy stream   Admin log:   h6. 4. Shut down and restart admin. The following is logged:  """
"XD-1958","Bug","Batch",5,"filejdbc job broken in distributed mode","""The filejdbc job is broken in distributed mode (redis and rabbit)  To reproduce:  export XD_TRANSPORT=rabbit  start xd-admin start xd-container  start shell and create this job:    results in JOB starting but never completing:    Steps:    When using Redis, I also get this stacktrace in container:   """
"XD-1957","Improvement","UI",1,"Remove footer from admin UI","""Please see the discussion here:  https://github.com/spring-projects/spring-xd/pull/1052#issuecomment-48761686"""
"XD-1956","Bug","Batch",3,"filepollhdfs --deleteFiles=true has no effect, files are not deleted","""Setting --deleteFiles=true has no effect any longer. This also causes the Script Integration Tests to fail.  Suspect this is related to the change here https://github.com/spring-projects/spring-xd/commit/6dbac167758ce23b9a4dbf07169b2d26d1eddef1 """
"XD-1953","Bug","Runtime",2,"Stacktrace on container with deployed modules is shutdown","""When the container that has deployed module is shutdown, following stacktrace is thrown:  10:10:27,560  INFO main-EventThread server.ContainerRegistrar:254 - Undeploying module [ModuleDescriptor@3a615460 moduleName = 'job', moduleLabel = 'job', group = 'j4', sourceChannelName = [null], sinkChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map[[empty]], children = list[[empty]]] 10:10:27,560  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=job, type=job, group=j4, index=0 @7df1aff2] 10:10:27,561 ERROR main-EventThread imps.CuratorFrameworkImpl:555 - Watcher exception java.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@422fd7b7 has been closed already  at org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)  at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)  at org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:164)  at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:219)  at org.springframework.xd.dirt.plugins.job.JobPlugin.removeModule(JobPlugin.java:70)  at org.springframework.xd.dirt.module.ModuleDeployer.removeModule(ModuleDeployer.java:204)  at org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:162)  at org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:140)  at org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:112)  at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:256)  at org.springframework.xd.dirt.server.ContainerRegistrar$JobModuleWatcher.process(ContainerRegistrar.java:753)  at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67)  at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)  at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498) 10:10:27,561  INFO main-EventThread zookeeper.ClientCnxn:512 - EventThread shut down 10:10:27,564  INFO Thread-2 jmx.EndpointMBeanExporter:433 - Unregistering JMX-exposed beans on shutdown"""
"XD-1961","Story","CLI",3,"Module info for jdbc sink and jobs are unreadable","""The 'module info' command renders text that is pretty much unreadable on a reasonably sized screen. See attached screen shot. Also all the jdbc pool settings are mixed in with module settings making for a confusing list of options. What the heck does 'fairQueue' have to do with filejdbc jobs?"""
"XD-1972","Improvement","Batch",3,"Add ability to define nested jobs","""h3.  Narrative As a developer, I need to be able to create a Spring XD job module that consists of a job orchestrating the execution of other Spring Batch jobs using the Spring Batch Job Step (see section 5.3.6 here: http://docs.spring.io/spring-batch/reference/html/configureStep.html) within the same module definition.  h3.  Acceptance Criteria # Define the """"contract"""" for a job module ## Currently the contract consists of a single job definition within the assembled {{ApplicationContext}} ({{context.getBean(Job.class)}}). ## The new version will need to document what job definition within the assembled {{ApplicationContext}} should be run as the entry point.  I'm assuming it would be by id ({{context.getBean(""""job"""")}} for example) of the job but am open to other options. # A custom job module that orchestrates multiple Spring Batch jobs via Job steps should be able to be deployed and executed as a single Spring XD module. ## Spring XD launches the job that conforms to the previously defined """"contract"""". ## Spring Batch manages the execution of the child jobs. # The existing OOTB jobs should work under the new """"contract"""".  h3.  Assumptions # The UI should """"just work"""" in that child jobs update the job repository independently so no updates should be needed for an MVP of this functionality. # *This will be a breaking change for users that have developed custom job modules.*  h3.  Out of Scope # Execution of child jobs that are remote (deployed on another node / {{ApplicationContext}}). # Dynamically assembling jobs via the shell's DSL or the UI. """
"XD-1967","Story","Packaging",5,"Dependendcies for Hadoop distros are broken ","""We used to have distro specific jars i the lib/[distro] directory. That is no longer working and all distros seem to contain mostly the same version (hadoop 2.2.0 dependencies)  This is the list for phd1 now:  avro-1.7.5.jar hadoop-annotations-2.2.0.jar hadoop-auth-2.2.0.jar hadoop-client-2.0.5-alpha-gphd-2.1.0.0.jar hadoop-common-2.2.0.jar hadoop-distcp-2.2.0.jar hadoop-hdfs-2.2.0.jar hadoop-mapreduce-client-app-2.2.0.jar hadoop-mapreduce-client-common-2.2.0.jar hadoop-mapreduce-client-core-2.2.0.jar hadoop-mapreduce-client-jobclient-2.2.0.jar hadoop-mapreduce-client-shuffle-2.2.0.jar hadoop-streaming-2.2.0.jar hadoop-yarn-api-2.2.0.jar hadoop-yarn-client-2.2.0.jar hadoop-yarn-common-2.2.0.jar hadoop-yarn-server-common-2.2.0.jar hadoop-yarn-server-nodemanager-2.2.0.jar jersey-core-1.9.jar jersey-server-1.9.jar jetty-util-6.1.26.jar protobuf-java-2.5.0.jar spring-data-hadoop-2.0.1.RELEASE.jar spring-data-hadoop-batch-2.0.1.RELEASE.jar spring-data-hadoop-core-2.0.1.RELEASE.jar spring-data-hadoop-store-2.0.1.RELEASE.jar """
"XD-1965","Story","Batch",3,"StepExecutionInfo can not be retrieved in distributed mode","""When constructing StepExecutionInfo, the TaskletType class could not be loaded as the spring-data-hadoop-batch jar is missing from admin classpath in distributed mode.  Following exception is thrown:  SEVERE: Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler processing failed; nested exception is java.lang.NoClassDefFoundError: org/springframework/data/hadoop/batch/hive/HiveTasklet] with root cause java.lang.ClassNotFoundException: org.springframework.data.hadoop.batch.hive.HiveTasklet  at java.net.URLClassLoader$1.run(URLClassLoader.java:366)  at java.net.URLClassLoader$1.run(URLClassLoader.java:355)  at java.security.AccessController.doPrivileged(Native Method)  at java.net.URLClassLoader.findClass(URLClassLoader.java:354)  at java.lang.ClassLoader.loadClass(ClassLoader.java:425)  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)  at java.lang.ClassLoader.loadClass(ClassLoader.java:358)  at org.springframework.xd.dirt.job.TaskletType.<clinit>(TaskletType.java:57)  at org.springframework.xd.dirt.job.StepExecutionInfo.<init>(StepExecutionInfo.java:94)  at org.springframework.xd.dirt.rest.BatchStepExecutionsController.details(BatchStepExecutionsController.java:98)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)"""
"XD-1962","Bug","Acceptance Testing",3,"Acceptance Tests fail to map some EC2 internal IPs to External IPs","""The acceptance tests interrogate the XD-Admin for the containers that are available.  When on EC2 the admin only returns the internal EC2 addresses without the associated suffix of .ec2.internal or .compute-1.internal.     [Defect] The acceptance tests only handled the most common suffix of .ec2.internal.  Thus some CI Acceptance tests will fail because, because the container's IPs were not properly mapped.  Thus the acceptance tests should map internal to external IP without regard to the suffixes EC2 issues.  FYI EC2 issues addresses in 2 different formats: ip-XXX-XXX-XXX-XXX.ec2.internal or domU-XX-XX-XX-XX-XX-XX.compute-1.internal.  The code only able to handle ip-XXX-XXX-XXX-XXX.ec2.internal.  """
"XD-1976","Bug","UI",5,"Unable to deploy job in UI","""This only happens when creating jobs via the CLI and deploying using the UI  On the job page: http://localhost:9393/admin-ui/#/jobs/definitions  I click [Deploy] for a Job and get a screen asking for Container Match Criteria and Job Module Count - clicking on the [Deploy] button on that screen does nothing - I see this error reported:  Deploying Job Definition undefined angular.js:9778 TypeError: Cannot read property 'jobDefinition' of undefined     at Scope.$scope.deployDefinition (http://localhost:9393/admin-ui/scripts/job/controllers/definition-deploy.js:52:78)     at http://localhost:9393/admin-ui/lib/angular/angular.js:10567:21     at http://localhost:9393/admin-ui/lib/angular/angular.js:18627:17     at Scope.$eval (http://localhost:9393/admin-ui/lib/angular/angular.js:12412:28)     at Scope.$apply (http://localhost:9393/admin-ui/lib/angular/angular.js:12510:23)     at HTMLButtonElement.<anonymous> (http://localhost:9393/admin-ui/lib/angular/angular.js:18626:21)     at HTMLButtonElement.jQuery.event.dispatch (http://localhost:9393/admin-ui/lib/jquery/jquery.js:5095:9)     at HTMLButtonElement.elemData.handle (http://localhost:9393/admin-ui/lib/jquery/jquery.js:4766:46) angular.js:9778"""
"XD-1975","Bug","Runtime",3,"Undeploying twitterstream logs warning - MessageDeliveryException","""To reproduce -   Download recent snapshot - http://repo.spring.io/libs-snapshot-local/org/springframework/xd/spring-xd/1.0.0.BUILD-SNAPSHOT/spring-xd-1.0.0.BUILD-20140715.101224-1-dist.zip  Start XD and shell - xd:>stream create --name tweets --definition """"twitterstream | file"""" --deploy  xd:>stream undeploy --name tweets   (Note: the IllegalStateException has been fixed for RC1, still need to fix the MessageDeliveryException)  There is an error logged in the logs:   """
"XD-1974","Story","UI",3,"Move [Back] button to top right","""The [Back] button is at lower left of the page which requires scrolling all the way to the bottom - could we move it to top right? Would make clicking back and forth for job executions much easier."""
"XD-1985","Story","Batch|Runtime",5,"Packaging of Guava 17 results in failure to deploy mapreduce job to Hadoop 2.4 based distros","""Trying to deploy the hashtagcount batch sample [1] to Hadoop 2.4.1 or Hortonworks HDP 2.1 fails with an IllegalAccessError exception.  Looks like a Guava versioning issue - Swapping out guava-17.0.jar for guava-11.0.2.jar in the xd/lib directory solves it.  Mark P suggested we try 16.0.1 which is what Curator uses and that seems to work as well.   Looking into changing the build to not force 17.0 which is the IO platform version.  http://upstream-tracker.org/java/compat_reports/guava/16.0.1_to_17.0/src_compat_report.html    I get the following exception:    [1] https://github.com/spring-projects/spring-xd-samples"""
"XD-1984","Story","Runtime",8,"Avoid all modules deploying to the first container instance upon system restart","""A possible approach is to set a configurable wait period when the first container arrives. If another container arrives during the wait period, reset the clock. When the wait period expires, start deploying modules. """
"XD-1983","Story","Runtime",3,"NodeExists Exception upon container disconnect/reconnect without admin leader","""When the container which has modules deployed disconnects/reconnects to the cluster while the admin leader isn't available, following exception is thrown: This is more likely to happen in single-node scenario as there is no admin leader re-election there. In distributed mode, we can always setup HA on admins so that the leadership re-election happens.  20:03:16,307 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache -  org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/deployments/modules/allocated/53f41042-8abd-443b-abfb-ba42a24fb9fb/foo.sink.log.1/metadata  at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)  at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)  at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)  at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)  at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)  at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)  at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)  at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)  at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)  at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)  at org.springframework.xd.dirt.server.ContainerRegistrar.writeModuleMetadata(ContainerRegistrar.java:486)  at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:461)  at org.springframework.xd.dirt.server.ContainerRegistrar.access$8(ContainerRegistrar.java:426)  at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:807)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)"""
"XD-1989","Story","CLI|Hadoop",5,"Remove warnings from Shell hadoop commands","""Some hadoop commands generate warnings/deprecation messages. We should try to get rid of most of them.  """
"XD-1996","Bug","UI",3,"Inconsistent failure while deploying job from admin UI","""After clicking 'deploy' on the definitions page, the 'deploy' button is deactivated and message says:  """"An error occurred. We were unable to retrieve the module name from the provided definition ...."""" and web console says:  TypeError: Cannot read property '0' of null     at Object.getModuleNameFromJobDefinition (http://localhost:9393/admin-ui/scripts/shared/services.js:43:26)     at http://localhost:9393/admin-ui/scripts/job/controllers/definition-deploy.js:35:36     at wrappedCallback (http://localhost:9393/admin-ui/lib/angular/angular.js:11319:81)     at http://localhost:9393/admin-ui/lib/angular/angular.js:11405:26     at Scope.$eval (http://localhost:9393/admin-ui/lib/angular/angular.js:12412:28)     at Scope.$digest (http://localhost:9393/admin-ui/lib/angular/angular.js:12224:31)     at Scope.$apply (http://localhost:9393/admin-ui/lib/angular/angular.js:12516:24)     at done (http://localhost:9393/admin-ui/lib/angular/angular.js:8204:45)     at completeRequest (http://localhost:9393/admin-ui/lib/angular/angular.js:8412:7)     at XMLHttpRequest.xhr.onreadystatechange (http://localhost:9393/admin-ui/lib/angular/angular.js:8351:11) """
"XD-1998","Story","Packaging",1,"Remove jersey test framework for xd/lib distribution","""The jars   jersey-test-framework-core-1.9.jar  jersey-test-framework-grizzly2-1.9.jar  are incorrectly classified as compile time deps in hadoop vs. testCompile.  """
"XD-1997","Story","Analytics",2,"Add comprehensive tests for AggregateCounterRepository","""The AggregateCounterTests were created to satisfy XD-1462, but currently they only have a couple tests to validate the time field processing. More comprehensive tests need to be added (including the testing of the Redis-based implementation in addition to in-memory).  For more info, see the comment here: https://github.com/spring-projects/spring-xd/pull/1087#issuecomment-49638189"""
"XD-2003","Story","Acceptance Testing",5,"In EC2 deployment, Allow users to set download jars into the lib/xd directory ","""In cases where the deployment requires jars that can not be included with the distribution, the user should be able to pull a jar from a http site and place it in lib/xd.    The use case is that when we removed the mysql jar from the distribution, the CI tests could not start the XD instances on EC2 without it.  It was suggested that we use the postgresql instead, but decided to continue the use of mysql for acceptance tests."""
"XD-2008","Story","Packaging",3,"Verify we meet all requirements to publish to maven central","""https://docs.sonatype.org/display/Repository/Central+Sync+Requirements  has a list of requirements.  This also means that https://jira.spring.io/browse/XD-1509 is critical to fix."""
"XD-2006","Improvement","Configuration",2,"Logging improvements","""Propose the following changes to our logging: * Create unique file names by including the pid in the file name - this allows each process (in particular containers) to maintain its own log file * Use DailyRollingFileAppender to roll files over on a daily basis """
"XD-2005","Bug","Runtime",3,"IllegalStateException when shutting down container","""  Sequence of events: * Stream module ZK path is removed * Event is raised * ZK connection is closed * Event handler causes module undeployment which includes unregistration of tap * Since connection is closed, exception is thrown """
"XD-2021","Bug","UI",1,"Admin UI: Deployment Status tooltip should close when the controller scope is lost","""Please refer to: https://github.com/spring-projects/spring-xd/issues/1119"""
"XD-2017","Improvement","REST",2,"Spring XD should log the address of the admin UI","""When I start xd-singlenode for instance, I would expect to see http://localhost:9393/admin-ui listed in the logs."""
"XD-2015","Bug","UI",2,"Spring XD UI: end-to-end tests do not work","""Currently, end-to-end tests of Spring XD UI will not run, as protractor relies on a non-existing chromedriver.exe file.  Either the configuration has to be removed from the Gruntfile or the necessary dependencies should be there."""
"XD-2034","Bug","Runtime",3,"Custom location for modules.yml not working","""tried local xd-admin/xd-container after setting    have my twitter stuff in modules.yml in that directory but not picked up by the twitterstream module  Also not working for me deploying on YARN, this used to work at some point, not sure how long ago I actually tested this part - M6/M7?  The setting used for YARN deployment:  """
"XD-2042","Story","Configuration|Testing",3,"Update XD-EC2 & Acceptance Test Configs to use 1.0.1 repo","""* Update XD-EC2 configs to Pull from 1.0.1 Repo * Update XD-EC2 Configs to use spring-xd-1.0.1.BUILD-SNAPSHOT dir  * Update test configs XD_HOME to spring-xd-1.0.1.BUILD-SNAPSHOT instead of spring-xd-1.0.0.BUILD-SNAPSHOT"""
"XD-2048","Improvement","Hadoop",20,"Do you have plan to support Spark?","""Do you have plans to support Spark? In version 1.0 GA, Spring XD has supported Hadoop, But it has not supported the brand new big data calculation platform Spark. do you have plans to support Spark in the future?"""
"XD-2066","Story","Acceptance Testing",5,"Tests sporadically fail when checking send counts with rabbit as transport","""Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail.  This is because, sometimes it takes 2 or more sends to get the data transmitted between modules.  With the current test structure this is considered a failure.  Is this the correct behavior?"""
"XD-2075","Bug","Stream Module",1,"Add --binary Option to MQTT Source","""See http://stackoverflow.com/questions/25226527/mqtt-source-spring-xd/25227531#25227531"""
"XD-2079","Story","Stream Module",2,"Add a Retry/Dead Letter Interceptor to the RabbitMQ Source","""Provide for retry and/or dead-lettering for the rabbit source (similar to the rabbit message bus)."""
"XD-2080","Bug","Runtime|Stream Module",5,"Modules do not redeploy properly when Zookeeper node is lost.","""* SHA baddfc24b08286a78392d5f565742c9bab5adfea * EC2 Environment ** Look at Zookeeper Ec2 Deployment Test Topology.png for a view of the topology  h2. The test scenario  # Bring up a up a 5 container 2 admin XD Cluster up using 3 ZK Server ensemble. # Create ticktock  stream """"time|log"""" # Deploy with --properties """"module.log.count=5"""" # Kill one of the ZK Servers in the ensemble  h2. Observed Behavior.  # In this particular scenario 3 containers were affected by killing (sudo kill <pid>) Zookeeper 2 # 2 Containers did not come back online even though they did show up in the runtime containers   h2. Timeline # 14:08:21 deployed stream # 14:09:10 kill server in ZK Ensemble # After waiting a few seconds ran runtime Modules (*Note:* log2 is undeployed and log5 is then deployed)  :  xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}   foo.sink.log.2     9a3a1846-bac4-4504-81fd-151665d851dc  {name=foo, expression=payload, level=INFO}  {count=5, sequence=2}   foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}  xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}   foo.sink.log.5     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo, expression=payload, level=INFO}  {count=5, sequence=5}   foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}  xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}   foo.sink.log.5     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo, expression=payload, level=INFO}  {count=5, sequence=5}   foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}  xd:>runtime containers   Container Id                          Host              IP Address     PID   Groups  Custom Attributes   ------------------------------------  ----------------  -------------  ----  ------  -----------------   0ba5e6ce-aedf-429c-b846-1cd4e32836c7  ip-10-2-209-174   10.2.209.174   1045   5c454a39-fc4c-4bd3-b828-08cd837dc4ba  ip-10-70-9-57     10.70.9.57     1099   707a968b-15a5-451f-9034-1e7f05cdcf97  ip-10-70-11-185   10.70.11.185   1055   98a32c62-302a-484b-af9c-d670f2a3cfc2  ip-10-110-186-48  10.110.186.48  1056  GROUPA   9a3a1846-bac4-4504-81fd-151665d851dc  ip-10-70-9-153    10.70.9.153    1020  GROUP0   h2.  Undeploy and redeploy stream   # 14:16:42 Undeploy and redploy with module.log.count=5 xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}   foo.sink.log.2     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo, expression=payload, level=INFO}  {count=5, sequence=2}   foo.sink.log.5     9a3a1846-bac4-4504-81fd-151665d851dc  {name=foo, expression=payload, level=INFO}  {count=5, sequence=5}   foo.source.time.1  98a32c62-302a-484b-af9c-d670f2a3cfc2  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}  xd:>runtime containers   Container Id                          Host              IP Address     PID   Groups  Custom Attributes   ------------------------------------  ----------------  -------------  ----  ------  -----------------   0ba5e6ce-aedf-429c-b846-1cd4e32836c7  ip-10-2-209-174   10.2.209.174   1045   5c454a39-fc4c-4bd3-b828-08cd837dc4ba  ip-10-70-9-57     10.70.9.57     1099   707a968b-15a5-451f-9034-1e7f05cdcf97  ip-10-70-11-185   10.70.11.185   1055   98a32c62-302a-484b-af9c-d670f2a3cfc2  ip-10-110-186-48  10.110.186.48  1056  GROUPA   9a3a1846-bac4-4504-81fd-151665d851dc  ip-10-70-9-153    10.70.9.153    1020  GROUP0    # 14:21:06 undeploy foo  """
"XD-2084","Story","Performance Testing",8,"Spring XD EC2 needs to setup cluster that uses static resources.","""h1. Summary  User wants the ability to deploy an ec2 cluster where the admin & containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines.   h2. Current functionality Currently spring-xd-ec2 sets up its containers & admin server to use a ZK, rabbit and redis that are provisioned and collocated with the admin server.    h2. Detail The following properties will be added to the spring-xd-ec2.properties # *spring_zk_client_connect* - contains a comma delimited list of zk hosts:ports for a ensemble.  The application will check to see if the port is open on at least of the servers in the list, if not deployment will fail.  Default is adminServer_host:2181. # *spring_rabbitmq_addresses* - contains a comma delimited list of hosts:ports for a rabbit cluster.  The application will check to see if the port is open on at least of the servers in the list, if not deployment will fail.  Default is adminServer_host:5672. # *spring_redis* - contains a host:port for a redis instance. The application will check to see if the port is open , if not deployment will fail.  Default is adminServer_host:5672. # *ec2_zone* - user can specify the zone to which the containers and admin will be deployed.  If not present AWS will decide which zone to deploy the cluster."""
"XD-2096","Story","UI",5,"UI: Visual representation of Stream/Job with deployed modules","""For a given stream/job, we need a visual representation of the stream/job with any deployed modules."""
"XD-2095","Story","UI",2,"UI: Ability to deploy stream with deployment properties","""Admin UI currently allows job to be deployed with deployment properties, we need similar way to deploy stream with the deployment properties (module count, container matching criteria)."""
"XD-2094","Story","UI",5,"UI: Cluster view of a container","""We need a visual representation of the XD cluster with runtime container and deployed modules."""
"XD-2093","Story","REST",3,"List Streams/Jobs based with deployed modules","""Currently, there is a """"stream list""""/""""job list"""" which shows the status of a given stream/job along with the DSL. and, there is """"runtime modules"""" which shows all the deployed modules with their container info.  We need a better REST endpoint that gives all the deployed modules for a given stream/job along with the status."""
"XD-2092","Improvement","REST|Runtime",2,"Enhance Container domain object","""Currently, org.springframework.xd.dirt.cluster.Container has name and attributes (container attributes). This can be enhanced to include all the deployed modules, number of deployed modules and any more useful info. and can subsequently be used to get a detailed runtime container info."""
"XD-2085","Story","Testing",5,"Test Recommended XD Cluster Strategy on slow/bad network","""h1. Run Acceptance tests on the following  deployments.    h2. Slow Network Simulate slow network by deploying a XD cluster where the ZK Ensemble is only available via WAN.    h2. Network packet loss Simulate cases where a network packets can be lost.   """
"XD-2103","Story","Stream Module",8,"Add Kafka sink","""As a user, I'd like to have the option to write into _Kafka_ sink so that I can publish mass data into Kafka broker."""
"XD-2114","Bug","Runtime",5,"Job stuck in ""deploying"" state when no containers are available","""A job gets stuck in """"deploying"""" state when a job is deployed when there are no containers available.  When a container is started after this event, the job doesn't automatically start because of the job is stuck in the """"deploying"""" state instead of the """"failed"""" state.    Refer to https://github.com/spring-projects/spring-xd/blob/193088dc164c73e07d7b4509de22241b28bf42b3/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/JobDeploymentListener.java  Update of the status in Zookeeper is inside the NoContainerException catch block.  This works correctly for streams."""
"XD-2115","Technical task","Stream Module",0,"Using taps with deployment property module.*.count=0 causes duplication of messages","""Setup: DIRT Spring XD, 2 Admins, 3 Containers  Step 1. Deploy the following streams (which would get deployed to all 3 containers)  stream create --name httpFoo --definition """"http | file"""" stream deploy httpFoo --properties """"module.*.count=0""""  stream create --name httpFooTap --definition """"tap:stream:httpFoo > file"""" stream deploy httpFooTap --properties """"module.*.count=0""""  stream create --name httpFooCounter --definition """"tap:stream:httpFoo > counter --name=httpFooCounter"""" stream deploy httpFooCounter --properties """"module.*.count=0"""" Step 2. Run runtime modules to ensure each module was deployed to every container  Step 3. Do a test curl call  http post --target http://container-1:9000 --data """"{\""""xlmagic\"""":\""""dorothy\""""}"""" Step 4. The httpFooTap and httpFooCounter will receive duplicate messages. The number of messages = # of containers. In our case, httpFoo.out exists only one 1 container. However, httpFooTap.out exists on all 3 containers and contains the same message. Similarly, httpFooCounter has a value of 3.  Looking at how the taps are represented in rabbit, this behaviour makes sense as XD is using fanout exchanges and each instance for a given tap is a consumer."""
"XD-2118","Story","Stream Module",5,"Create a shell command processor and sink","""Create processor and sink modules that can execute a shell command using stdin and stdout to stream data."""
"XD-2116","Improvement","Runtime",5,"Add REST resource sink","""Would be nice to have a sink for REST resources.  Might be configurable with an endpoint URI. Basic auth details would be a nice to have too.  Would perform a POST to the endpoint passing the payload."""
"XD-2139","Improvement","Stream Module",2,"Add ftp sink to default sink modules","""It would be nice to have a simple ftp sink. I had to do it for one of my projects. Therefore, the sink already exists. I would like to contribute but I don't know how you do the 'testing' part for that kind of module."""
"XD-2149","Technical task","Packaging",1,"Remove un-necessary libs from shell","""Shell currently adds all jars from xd/lib to its classpath.  Remove jars that are not needed to run shell."""
"XD-2148","Improvement","Packaging",1,"Create separate distribution for shell","""Create zip distribution for shell"""
"XD-2153","Improvement","Documentation",1,"Update Wiki to reflect the change from runtime x to cluster x","""Update the wiki to reflect the change from: runtime containers to cluster containers and runtime modules to cluster modules.  """
"XD-2170","Bug","Runtime",5,"NoNodeException for job creation","""The following exception was encountered by a few parties: for example https://gopivotal-com.socialcast.com/messages/21678398    No specific details on reproducing yet; although the Socialcast thread indicates:  {quote} I only hit this when I have tried to deploy a job that fails deployment the first time {quote}"""
"XD-2172","Improvement","Batch|Runtime",1,"Provide a way to customize the isolation level of the JobRepository","""The Gemfire XD database cannot be used to store the Spring XD metadata because the former doesn't support the default Spring Batch transaction isolation level ISOLATION_SERIALIZABLE.  There looks to be no way to configure the Spring XD's internal Spring Batch JobRepository with another isolation level.  The JobRepository instance is getting created with default settings by the Spring Batch'es {{SimpleBatchConfiguration}} and there are no custom {{BatchConfigurer}}s available to change the default settings of the JobRepository."""
"XD-2182","Technical task","Documentation",1,"Document how to enable LDAP security for admin endpoints","""As a user, I want to know how to enable and configure LDAP as an authentication provider for the administration server, so that I can set up my security configuration accordingly."""
"XD-2181","Story","Documentation",1,"Document how to enable SSL and Basic authentication ","""As a user, I want to know my configuration options are for enabling SSL/HTTPS and Basic authentication for administration endpoints, so that I can secure my application."""
"XD-2177","Story","CLI|Hadoop|Packaging|Runtime",3,"Add support for Pivotal HD 2.1 (XD 1.0.2 Release)","""*XD 1.0.2 Release + PHD 2.1 Upgrade - Action Items:*  * Update to SHDP 2.0.3 * Add Hadoop 2.5 (hadoop25) * Change PHD 2.x from phd20 to phd21 * Test PHD 2.0 with phd21  * Document that both PHD 2.1 and PHD 2.0 is supported with phd21  """
"XD-2190","Bug","CLI",1,"xd-shell from 1.0.1 doesn't work with 1.0.0 GA admin","""Targeting xd-shell from 1.0.1 to 1.0.0 GA admin server fails  server-unknown:>admin config info   -------------  -------------------------------------------------------------   Result         Unable to contact XD Admin Server at 'http://localhost:9393'.   Target         http://localhost:9393   Timezone used  Pacific Standard Time (UTC -8:00)   -------------  ------------------------------------------------------------- ------------------------------------------------------------------------------- An exception ocurred during targeting: java.lang.NullPointerException     at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:110)     at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:137)     at org.springframework.xd.shell.command.ConfigCommands.target(ConfigCommands.java:106)     at org.springframework.xd.shell.command.ConfigCommands.afterPropertiesSet(ConfigCommands.java:191) """
"XD-2201","Bug","Runtime",5,"Exception in a tap will stop the tapped stream from sinking data","""Exception in a tap will stop the tapped stream from sinking data.  h2. Background Running xd-singlenode. We experienced this when streaming data from a rabbit queue to hdfs. The stream was tapped and we had a groovy processor on the tap stream. Any exceptions in the processor stopped the main stream from writing data to the hdfs sink.  h2. Steps to reproduce. 1: Create a groovy script that throws an exception in  modules/processor/scripts/exceptionthrower.groovy. Code below  2: Create a sample main stream  3: Tail the log to confirm the data is going to the sink. We see  'sink.ticktock' appearing in the log as expected. 4: Add a tap to the stream that will throw an exception.  5: Tail the log and we see that there are no more 'sink.ticktock' strings being logged. Looks like the main stream is no longer sending messages to the sink. """
"XD-2203","Technical task","Documentation",0,"Make sure Spring XD's PDF reference doc has right release revision references","""The scope is to make sure that a new PDF is generated (both for 1.0.2 and 1.1 M1 releases) and/or revision references are correctly rendered.  """
"XD-2215","Bug","Runtime",2,"NPE in ContainerRedeploymentTests","""Running the distributed tests ({{-Drun_distributed_tests=true}}) against d109a3a and got the following:  """
"XD-2214","Bug","Configuration",1,"HTTPS Source Configuration issues","""1. The sample {{httpSSLproperties}} file that is included in the distribution contains the line:  {quote} keystore.passPhrase=secret {quote}  The correct key value is {{keyStore.passPhrase}}. This issue causes HTTPS sources to deploy, but not bind to the port.  2. The password is always defaulting to """"secret"""""""
"XD-2224","Story","REST",2,"REST: Make the Configurations REST endpoint pagination-aware","""Add pagination for:  http://localhost:9393/jobs/configurations  Related to XD-1864"""
"XD-2223","Story","REST",8,"Provide proper ordering for all REST endpoints","""With the implementation of XD-1864, we need to make sure that the (paginated) data returned from the REST endpoints has proper default ordering.  Up to now we have done client-side ordering in the Admin UI, but with server-side pagination, the server-side should support proper pagination as well.  Eventually, we may even decide to provide more flexible ordering options (ASC vs DESC, sort on different properties etc.), which may be a separate Jira."""
"XD-2234","Bug","Configuration",1,"Incorrect port in resource manager address overwrite","""the resource manager address overwrite is setting the port to 8032; the value cannot be set in servers.yml.  this occurs when pushing the config to hdfs and also when attempting to start the admin server on yarn.    [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[host:8032]  [root spring-xd-1.0.1.RELEASE-yarn]# ./bin/xd-yarn start admin    .   ____          _            __ _ _  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )   '  |____| .__|_| |_|_| |_\__, | / / / /  =========|_|==============|___/=/_/_/_/  :: Spring Boot ::        (v1.1.7.RELEASE)  2014-10-13 16:50:28,710 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created. 2014-10-13 16:50:28,724 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskExecutor' has been explicitly defined. Therefore, a default SyncTaskExecutor will be created. 2014-10-13 16:50:30,311 INFO [SpringYarnConfiguration] - Enabling CLIENT for Yarn 2014-10-13 16:50:30,335 INFO [SpringYarnConfiguration] - We couldn't figure out if we could use existing configuration 2014-10-13 16:50:30,335 INFO [SpringYarnConfiguration] - Building configuration for bean 'yarnConfiguration' 2014-10-13 16:50:30,383 INFO [SpringYarnConfigBuilder] - Existing yarnConfiguration: null 2014-10-13 16:50:30,658 INFO [ConfigurationFactoryBean] - Overwriting fsUri=[hdfs://host:8020] with fsUri=[hdfs://host:8020] 2014-10-13 16:50:30,659 INFO [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[host:8032]     """
"XD-2244","Bug","Stream Module",1,"Streams sending to Job Queue issue","""Look at the below Stream definition. This gets to """"deployed"""" state even without the corresponding job. And then from there the same Job or any other Job can't be deployed and it goes to a hung state.   Here is an example of the Stream definition:  stream create --name jobName --definition """"file --ref=true --dir=/tmp/springxdsource/dropbox --pattern=*.csv > queue:job:filetsjob-sample002"""" --deploy """
"XD-2243","Bug","Runtime",1,"Stream Definition Calls Times-out often","""We are using the SpringXD REST endpoints for creating and managing streams. With Version 1.0.0 and 1.0.1, the Stream Definition API Call Times-out at times. Here is the log from the admin node.  Look at the 30000 ms in the logs. I have also left a few other lines around for context.   API Call: http://<hostname>:9393/jobs/definitions  We need to come up with a fix for this.   14 Oct 2014 17:40:28,062   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/sample, type: CHILD_ADDED 14 Oct 2014 17:40:28,198   INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='sample'} 14 Oct 2014 17:40:38,847   INFO Deployer server.JobDeploymentListener - Deployment status for job 'filetsjob-sample002': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='filetsjob-sample002', type=job, label='filepollsomething'}' to container 'c77bc83e-bcba-4e4d-9753-e71f603566b1' timed out after 30000 ms} 14 Oct 2014 17:41:28,225   INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'sample': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='sample', type=sink, label='something'}' to container 'f877a8e8-08b3-44f9-8f73-bf163acb0cef' timed out after 30000 ms; Deployment of module 'ModuleDeploymentKey{stream='sample', type=source, label='http'}' to container 'c77bc83e-bcba-4e4d-9753-e71f603566b1' timed out after 30000 ms} 14 Oct 2014 17:41:28,227   INFO Deployer server.StreamDeploymentListener - Stream Stream{name='sample'} deployment attempt complete """
"XD-2242","Bug","Runtime",1,"NullPointerException while fetching runtime containers","""In SpringXD ver 1.0.1, runtime/containers fetches additional runtime modules information for each container.  When a user queries the runtime containers while a stream is being deploy it throws a NullPointerException.  See below:  15:56:02,829  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: path=/deployments/streams/testCreateHTTPStream_postData1413327352991, type=CHILD_ADDED 15:56:02,935  INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='testCreateHTTPStream_postData1413327352991'} 15:56:05,069 ERROR http-nio-9393-exec-9 rest.RestControllerAdvice - Caught exception while handling a request java.lang.NullPointerException  at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.updateDeploymentStatus(ZooKeeperModuleMetadataRepository.java:209)  at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.findAllByContainerId(ZooKeeperModuleMetadataRepository.java:313)  at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findAllRuntimeContainers(ZooKeeperContainerRepository.java:339)  at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:97)  at sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)  at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)  at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)  at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)  at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)  at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)  at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)  at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:620)  at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)  at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)  at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)  at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)  at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)  at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)  at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)  at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)  at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)  at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)  at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)  at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)  at java.lang.Thread.run(Thread.java:724) """
"XD-2241","Bug","Runtime",1,"NoNode Exception in SpringXD Admin","""Sorry to set it """"Blocker""""; but the problem makes SpringXD unusable. We are getting this weird, NoNode exception on the status ZNode. Example and Log given below. Once this happens, both streams and jobs cannot be deployed. For whatever reason the """"status"""" znode goes missing.    The only way for us to get the cluster back to working state, is to clear the zk znode /xd tree and restart spring-xd. At which point, we have to recreate all our streams and jobs back again..   /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status  NoNode Exception:  13 Oct 2014 14:16:16,044   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testDestroyStream1413234903170, type: CHILD_REMOVED 13 Oct 2014 14:16:16,705   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testListStreams1413234903170, type: CHILD_ADDED 13 Oct 2014 14:16:22,818   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testListStreams1413234903170, type: CHILD_REMOVED 13 Oct 2014 14:16:23,585   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testStreamSrcHttpTimeseriesSink1413234903170, type: CHILD_ADDED 13 Oct 2014 14:16:37,694   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001, type: CHILD_ADDED 13 Oct 2014 14:16:49,950   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testStreamSrcHttpTimeseriesSink1413234903170, type: CHILD_REMOVED 13 Oct 2014 14:16:54,490   INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'testCreateStream_SrcHttp_SinkFile1413234903170': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='testCreateStream_SrcHttp_SinkFile1413234903170', type=sink, label='file'}' to container 'd03bccd6-524b-4ff8-84d2-88f3f6daac42' timed out after 30000 ms; Deployment of module 'ModuleDeploymentKey{stream='testCreateStream_SrcHttp_SinkFile1413234903170', type=source, label='http'}' to container '52abf1c8-ba45-4994-8324-6079b03c670c' timed out after 30000 ms} 13 Oct 2014 14:16:54,493  ERROR Deployer server.InitialDeploymentListener - Exception caught while handling event org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: KeeperErrorCode = NoNode for /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:111)         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:95)         at org.springframework.xd.dirt.server.StreamDeploymentListener.deployStream(StreamDeploymentListener.java:185)         at org.springframework.xd.dirt.server.StreamDeploymentListener.onChildAdded(StreamDeploymentListener.java:100)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)         at java.util.concurrent.FutureTask.run(FutureTask.java:262)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)         at java.lang.Thread.run(Thread.java:744) Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status         at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)         at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)         at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)         at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)         at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)         at org.springframework.xd.dirt.server.StreamDeploymentListener.deployStream(StreamDeploymentListener.java:179)         ... 7 more 13 Oct 2014 14:16:56,251   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001, type: CHILD_REMOVED 13 Oct 2014 14:17:08,179   INFO Deployer server.JobDeploymentListener - Deployment status for job 'filetsjob-newjob001': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='filetsjob-newjob001', type=job, label='filepolltimeseries'}' to container '244d5076-f69d-42a4-8110-3b046cea2667' timed out after 30000 ms} 13 Oct 2014 14:17:08,181  ERROR Deployer server.InitialDeploymentListener - Exception caught while handling event org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: KeeperErrorCode = NoNode for /xd/deployments/jobs/filetsjob-newjob001/status         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:111)         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:95)         at org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:175)         at org.springframework.xd.dirt.server.JobDeploymentListener.onChildAdded(JobDeploymentListener.java:99)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)         at java.util.concurrent.FutureTask.run(FutureTask.java:262)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)         at java.lang.Thread.run(Thread.java:744) Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/filetsjob-newjob001/status         at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)         at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)         at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)         at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)         at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)         at org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:165)         ... 7 more 13 Oct 2014 14:17:10,553   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001, type: CHILD_ADDED  """
"XD-2257","Story","Performance Testing",1,"Vary producers size (DB-5)","""Use the number of consumers gave a maximum throughput in the previous test (say 10 consumers), message size 100 bytes, Prefetch 100.   Send 1M messages  Vary the number of producers.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.  *Number of producers:* * 2 * 4 * 6 * 10 * 50  During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up."""
"XD-2256","Story","Performance Testing",1,"Vary consumers size (DB-4)","""Using a single producer, message size of 1000 bytes, Pretch of 100.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.  Vary the number of consumers.   Measure the msg/sec rate and calculate the data transfer rate in MB/sec.  *Number of consumers:* * 1 * 2 * 4 * 6 * 10 * 50  During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up."""
"XD-2255","Story","Performance Testing",1,"Vary prefetch size (DB-3)","""Use a single producer, single consumer, message size of 1000 bytes.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.  Vary the prefetch size.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.  *Prefetch Sizes:* * 1 * 10 * 50 * 100 * 10000  During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up."""
"XD-2254","Story","Performance Testing",1,"Vary message size (DB-2)","""Use a single producer, single consumer, prefetch size = 50.  Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.  Vary the message size and measure the msg/sec rate and calculate data transfer rate in MB/sec.  *Message Sizes:* 100 bytes 1000 10,000 100,000   During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up."""
"XD-2253","Story","Performance Testing",1,"Baseline tcp measurements (DB-1)","""Using the [iperf tool|https://iperf.fr/], find out the transfer rate in MB/sec between three machines in a four machine configuration."""
"XD-2251","Improvement","Ingest",1,"The HTTP Source creates the ChannelPipeline inefficiently","""The ChannelPipelineFactory used by the HTTP source should cache expensive objects used by the ChannelPipeline between requests, because creating them every time is inefficient (and in the case of HTTPS it can become even more expensive). """
"XD-2310","Bug","Runtime",1,"Parsing issues with kafka-bus.xml","""Using Kafka as a transport option yields:  [2014-11-04 12:18:30.528] boot - 24061 ERROR [main] --- SpringApplication: Application startup failed org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Failed to import bean definitions from URL location [classpath*:/META-INF/spring-xd/transports/kafka-bus.xml] Offending resource: class path resource [META-INF/spring-xd/bus/message-bus.xml]; nested exception is org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute """"{1}"""" associated with an  element type  """"value"""".  at org.springframework.beans.factory.parsing.FailFastProblemReporter.error(FailFastProblemReporter.java:70)  at org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:85)  at org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:76)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:248)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseDefaultElement(DefaultBeanDefinitionDocumentReader.java:199)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:184)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.doRegisterBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:141)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.registerBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:110)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.registerBeanDefinitions(XmlBeanDefinitionReader.java:508)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:187)  at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsFromImportedResources(ConfigurationClassBeanDefinitionReader.java:313)  at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:138)  at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)  at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:330)  at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)  at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:254)  at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:94)  at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:609)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)  at org.springframework.xd.dirt.server.SingleNodeApplication.run(SingleNodeApplication.java:63)  at org.springframework.xd.demo.kafka.KafkaDemo.main(KafkaDemo.java:28)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134) Caused by: org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute """"{1}"""" associated with an  element type  """"value"""".  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:398)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:242)  ... 31 more Caused by: org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute """"{1}"""" associated with an  element type  """"value"""".  at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)  at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.fatalError(ErrorHandlerWrapper.java:177)  at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:441)  at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)  at com.sun.org.apache.xerces.internal.impl.XMLScanner.reportFatalError(XMLScanner.java:1436)  at com.sun.org.apache.xerces.internal.impl.XMLScanner.scanAttributeValue(XMLScanner.java:829)  at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanAttribute(XMLNSDocumentScannerImpl.java:439)  at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:255)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)  at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)  at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)  at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)  at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)  at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)  at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)  at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:428)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:390)  ... 36 more"""
"XD-2309","Improvement","Batch",5,"Incremental data import with jdbchdfs job","""Enhance the current jdbchdfs job in spring-xd to have an incremental load / delta load feature similar to sqoop. See sqoop documentation [here|http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_incremental_imports]. The job will need to maintain some state between executions in order to decide the start point for the next data load.   The jdbchdfs job definition could take the following 2 new options.   h5. checkColumn  optional Specifies the column to be examined when determining which rows to import. (the column should not be of type CHAR/NCHAR/VARCHAR/VARNCHAR/ LONGVARCHAR/LONGNVARCHAR). Column should be numeric or timestamp. h5. lastValue  optional If specified this will override any data saved from previous job runs. If not specified will take the saved max-value from the last job run. If no last job run data is available then it will not be an incremental load and all the data which satisfies the query will be used.  Sqoop provides 2 modes of operation for incremental load, 'append' and 'lastModified'. For jdbchdfs the job will always append as it is writing to a hdfs file.  Example: To import data from the database table some_table which has a last update column called lastUpdated, you could use.   The batch job should also be capable of being partitioned to run in parallel across multiple containers"""
"XD-2322","Bug","Runtime",3,"Enable configuration of replication factor on the Kafka message bus","""The field exists and it is referred to in application.yml, but it does not have a setter and the bus will always use the configured default, which is 1."""
"XD-2316","Bug","REST",3,"REST: ""jobs/configurations"" returns 404 if one job has error","""There is a bug in the deployments rest end-point.   *How to reproduce:*   * Deploy a Batch job (success) that for example does not all necessary libraries in the class-patch and thus causes a “java.lang.ClassNotFoundException”  *Result:*  You cannot retrieve the list of deployments list anymore using:  * http://localhost:9393/jobs/configurations  The rest endpoint will now report:  [{""""links"""":[],""""logref"""":""""NoSuchBatchJobException"""",""""message"""":""""Batch Job with the name myJob doesn't exist""""}]  This message is not entirely wrong…but extremely misleading. I think we should still return the entire list and rather mark the job as having an error.  Also returning an “404 Not Found” is misleading as well. """
"XD-2315","Story","UI",3,"UI: Add support for stoppable notifications","""* Update Angular Growl to v2 * Allowing for stoppable notifications (in case you want to see it for longer than 5 secs) """
"XD-2323","Bug","Batch",3,"Filejdbc jobs status shows ""STARTED"" even when job is complete","""SHA: 67473dc71332c0727516b6f3fd11a55561b2472e Deployment: 1 Admin, 2 Containers JobStore: HSQLDB OS: Mac OSX & Ubuntu Reproducible: Yes Job: job create foo \-\-definition """"filejdbc \-\-resources=file:filejdbctest/filejdbctest.out \-\-names=data --tableName=filejdbctest \-\-initializeDatabase=true """"\-\-deploy  When using Rabbit as a transport with more than one container and launching the job above.  The Job execution stays as """"STARTED"""" status, even though the job is actually finished.   We expect it to reach a state of """"COMPLETED"""".  Using Redis as a transport the job execution status does reach """"COMPLETED"""".     The execution step list shows:  Id  Step Name                Job Exec ID  Start Time               End Time                 Status   --  -----------------------  -----------  -----------------------  -----------------------  ---------   8   step1-master             4            2014-11-06 15:28:29,820                           STARTED   9   step1-master:partition0  4            2014-11-06 15:28:29,854  2014-11-06 15:28:29,890  COMPLETED"""
"XD-2325","Story","Ingest",1,"Set 'auto-startup' to false in Kafka source","""We have to explicitly set it to false, in order to avoid an early start of the poller and the associated DistpatcherHasNoSubscribersException."""
"XD-2326","Bug","Runtime",3,"Can't create stream running on Windows","""Trying to test on Windows and getting the following exception when createing a stream - 'stream create --name tictoc --definition """"time | log'  """
"XD-2331","Bug","Batch|REST",5,"Job deployment list returns 404 after Laptop wakes up","""*Version:* XD 1.0.1 Mac OSX 10.9.5  *Problem:* - Deployed a simple batch job in 'singlenode' - Laptop put to sleep mode - After login: notice that ZK is establishing connection  - Continues to clean-up prior to redeployment, but never goes through successfully - Listing job both in UI and Shell states it is """"undeployed""""  *Gunnar's experiment:* - System is running in Single Node - Laptop goes to sleep - After waking up your laptop from sleep, you cannot retrieve the list of deployed jobs anymore (in AdminUI)  *Error:* Only getting back a *404* - """"NoSuchBatchJobException"""", """"Batch Job with the name abcd doesn't exist"""""""
"XD-2335","Story","Performance Testing",1,"Update Performance AMI to include Kafka","""Create an AMI that will contain the Kafka Executable as well as the Kafka performance test tools."""
"XD-2334","Story","Performance Testing",2,"Create base perf test criteria","""Since Kafka and Rabbit have different strategies on how a message system is implemented, we will need to update the tests used on rabbit to work with Kafka.  While they will not be exactly the same as before, they should exercise the same principles. This story covers:  * Create the consumer and producer execution configurations for kafka-producer-perf-test.sh and kafka-consumer-perf-test.sh.  * Record the tests a spreadsheet much like the Rabbit Base test spreadsheet  """
"XD-2332","Story","REST|UI",5,"AdminUI - Provide Server-Side Cron Expression Validation","""It is easy to get a cron expression wrong.   Provide validation of the cron expression on the Schedule Job page using async validation.   * Submit the cron expression to the server-side - and validate that the expression is valid. * Send a success message back (we may even send back some meta data … e.g. when is the next execution going to take place) """
"XD-2342","Bug","Batch",3,"JDBCHDFS Job Password issue","""Password for 'jdbchdfs' job definition is only hashing the initial portion of the password not the entire password (See attached image).  The password has an '_' char but it shouldn't matter. The entire password should be masked with '*' instead."""
"XD-2341","Story","CLI",5,"Deleting a job and then re-adding a new definition with the same name fails","""Using single-node deployment of Spring XD 1.0 GA, we needed to redefine several batch jobs. We deleted the jobs (""""job destroy all""""). When attempting to re-add, we received an error that a job with the name already exists. Performing """"job list"""" confirms the jobs were gone. To workaround, I needed to terminate the instance (server) of Spring XD and restart it. Since this was the single-node deployment without a live stream of data coming in this was okay, but would have been a major problem if bouncing the Spring XD server was not acceptable (i.e., live data being actively received)."""
"XD-2345","Bug","UI",5,"XD UI not usable with IE 11","""Trying to use the XD UI with Internet Explorer (version 11.0.9600.17031) is difficult. The screen doesn't refresh when streams/jobs are created or deployed. Had to erase the browsing history continuously to get state updates to show in the UI."""
"XD-2344","Bug","UI",3,"UI should quote parameters containing a space","""Trying to deploy the `timestampfile` job using the UI.  Seems the UI doesn't quote string parameters that contains a space so the job creation fails.  Keeping all the defaults I get the following """"Resulting Definition"""" in the UI:  timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true  (note: the --format parameter has a space)  which causes:  XD100E:(pos 128): Found unexpected data after stream definition: 'HH' timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true *^ """
"XD-2353","Bug","Acceptance Testing",3,"Boot upgrade caused test failures","""spring.groovy.template.check-template-location=false must now be set in the properties file. """
"XD-2355","Bug","CLI",2,"xd-singlenode --verbose prints configuration information twice","""If you start xd-singlenode with the --verbose flag the configuration information is printed twice.  Steps to reproduce  1) run {{xd-singlenode --verbose}}  Example output: """
"XD-2366","Improvement","Documentation",2,"Doc generation accesses http://docbook.sourceforge.net","""When generating docs, the build tries to access  http://docbook.sourceforge.net/release/images/draft.png  You will observe output like:  """
"XD-2363","Bug","Documentation",0,"The word ""that"" is written in duplicate","""The word """"that"""" is written in duplicate. See the attached PNG file.  ========================================================== Caveats Note that that inputType and outputType parameters only apply to payloads that require type conversion. For example, if a module produces an XML string with outputType=application/json, the payload will not be converted from XML to JSON. This is because the payload at the module’s output channel is already a String so no conversion will be applied at runtime. ==========================================================  http://docs.spring.io/spring-xd/docs/1.0.1.RELEASE/reference/html/ """
"XD-2370","Story","Testing",1,"Remove Test Scripts From XD","""The acceptance tests cover the entire suite of script tests.  Thus they are no longer needed.  The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn't get an error.  This test (httpbash) was never called from the scripts CI build."""
"XD-2378","Story","REST|UI",5,"Add ability to logout using the Admin UI","""While there is a server endpoint to logout, we don't have that ability yet from the UI. As indicated by XD-2122 we will also need a meta-data REST endpoint  so we can interrogate whether security is enabled, whether the user is logged etc. So we can fulfill the requirements:   * Show a logout button only if a) security is enabled and b) user is logged in * Show the username and/or full name of the user being logged in  """
"XD-2390","Technical task","Batch|REST",3,"Add regression test","""Verify that network interruptions will not negatively affect the XD cluster.   Verify that a container that looses connectivity will be able to rejoin the cluster cleanly. Modules will redploy when the network is back up. """
"XD-2389","Improvement","Documentation",2,"Streams section of doc should explicitly mention that labels are required for ambiguous modules","""Currently I believe we only mention labels in this section of the doc: https://github.com/spring-projects/spring-xd/wiki/DSL-Reference#labels  And it is not even clear there that they are *required* when 2 or more module names would otherwise be ambiguous. It was probably written before we made that a mandatory part of the definition.  We should mention this somewhere in the 'streams' section of the manual. Even if none of the examples there currently have more than one occurrence of the same module, we should add one to illustrate this point. """
"XD-2395","Improvement","Hadoop",3,"Need a way to specify a specific namenode for a given hdfs based job","""A scenario where I have multiple jobs deployed to one singlenode or distributed instance of SpringXD that need to use different namenodes can easily exist.   The ability to specify a namenode, much the same way I can specify a directory would solve this problem.  The desired behavior would be to specify a namenode that wasn't set using 'hadoop config fs <namenode>' in the job description and have that value used instead of the value set at the SpringXD global level."""
"XD-2409","Bug","Hadoop",1,"hdfs-dataset sink with getName() method in Pojo","""Having a pojo:   with:   throws exception:   Which I believe is caused by `correlation-strategy-expression` spel in aggregator:   Changing `getName()` method in pojo to something else works."""
"XD-2415","Bug","Runtime",1,"Using custom classes for module properties leads to ClassNotFoundException","""Attached is module properties file. Both custom Java classes referenced in the properties are available in the JAR file under _SPRING_XD_HOME/xd/module/<the-module>/lib_ directory.  Following exception is thrown:   Please see attached patch file, this seems to be enough to resolve the problem. """
"XD-2416","Bug","DSL",1,"SpelParseException is thrown when using empty string ("""") inside of an expression","""I can only reproduce this when using single quotes around the expression:    The following two alternatives work fine though: """
"XD-2418","Story","Stream Module",1,"Kafka Sink: Support async Producer","""The kafka sink supports properties for an async producer (e.g. {{queue.buffering.max.ms}} ) but you cannot enable such a producer (only {{sync}} ). Async producers batch messages (at the risk of message loss).  Add a new property {{async}} default {{false}} and add the corresponding attribute to the {{<int-kafka:producer-configuration/>}} element  {{async=""""$\{async\}""""}}"""
"XD-2421","Bug","UI",2,"UI: List of Streams causes ""undefined is not an option""","""See Screenshot.  The error is caused when loading all stream definitions in method *loadStreamDefinitions*.   Only 1 or two streams exist in the system.  """
"XD-2427","Story","UI",1,"Use repo.spring.io as NPM repository","""In order to improve the build reliability, we should be using the NPM repo provided by *repo.spring.io*   See *spring-xd-ui/README.md* for further details."""
"XD-2425","Bug","Ingest",5,"SpringXD's syslog source does not fully support syslog RFC5424","""SpringXD's syslog source cannot parse rfc5424 messages into a Map. For the messages we get in RFC 3164, springXD converts these to a Map.  Since the rfc5424 data cannot be interpreted then the map contains just one key called 'UNDECODED'. The result of this is that we get a string that looks like this (when we convert the message to a String)   Should be something like this (note the values below are for illustrative purposes only and should not be used as test data)    h3. Root Cause Spring integration does not parse these messages. There is a JIRA for SI here: https://jira.spring.io/browse/INT-3450 """
"XD-2430","Story","Batch",8,"Create a Sqoop job and required batch tasklet integration code","""Based on the POC from XD-2124 we should create the actual implementation.  Things to consider to store in step context: - capture Log output/MapReduce job counters - capture last-value from incremental imports """
"XD-2428","Story","Documentation",0,"Mysql Libraries not shipped with XD by default","""The reference states the following:  """"The JDBC driver jars for the HSQLDB, MySql, and Postgres are already on the XD classpath""""  It looks like this is true for Postgres and HSQLDB, but I can't see a driver for MySQL shipped with the distribution."""
"XD-2491","Bug","Batch",3,"JDBCHDFS Master Process Timeout error","""The JDBCHDFS Master process fails with a timeout error while the child process is still processing data.  The error message on the error message on the master process is:  org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returned  at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)  at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)  at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)  at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)  at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)  at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)  at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)  at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)  at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)  at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)  at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy47.run(Unknown Source)  at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)  at sun.reflect.NativeMethodAccessorImpl"""
"XD-2486","Bug","Batch",8,"Context Deserialize Doesn't Use Parent First Classloader","""If a class is added to a batch execution context that is located in an isolated context, an exception will be thrown when that object is deserialized.  It appears the serialize doesn't use the ParentFirstClassloader during deserialization."""
"XD-2482","Improvement","Stream Module",1,"Add ""initialDelay"" to ""source:trigger""","""Currently, the {{source:trigger}} module is based on 3 profiles: {{date}}, {{cron}} or {{fixedDelay}}, where the latter has precedence over the former in {{TriggerSourceOptionsMetadata}}:    Therefore it is not possible to combine {{date}} and {{fixedDelay}} to start off at a specific point in time, and then repeat every X seconds.  This is a request to provide another parameter to {{source:trigger}} such as *{{initialDelay}}* to be able to achieve the desired behaviour."""
"XD-2495","Bug","Batch",3,"Add Request/Reply support to Kafka message bus","""* Environment: ** Can be reproduced on local machine with Admin and a single container. * create the following job ** job create ogg --definition """"filejdbc --resources=file:filejdbctest//filejdbctestpartition* --names=data --tableName=filejdbctest --initializeDatabase=true """" --deploy * note: this works on Rabbit and Redis as a message bus * The following exception is thrown on the admin: 6:54:22,856 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.JobDeploymentListener - Deployment status for job 'ogg': DeploymentStatus{state=failed,error(s)=java.lang.UnsupportedOperationException: Auto-generated method stub  at org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindRequestor(KafkaMessageBus.java:289)  at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.processPartitionedJob(JobPartitionerPlugin.java:69)  at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.postProcessModule(JobPartitionerPlugin.java:53)  at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployJobModule(DeploymentListener.java:289)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) }  * The following exception is thrown on the container 21:08:14,721 1.1.0.SNAP  WARN DeploymentsPathChildrenCache-0 config.ReleaseStrategyFactoryBean - No annotated method found; falling back to SequenceSizeReleaseStrategy, target:org.springframework.batch.integration.partition.MessageChannelPartitionHandler@692ee39f, methodName:null 21:08:15,946 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module java.lang.UnsupportedOperationException: Auto-generated method stub  at org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindRequestor(KafkaMessageBus.java:289)  at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.processPartitionedJob(JobPartitionerPlugin.java:69)  at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.postProcessModule(JobPartitionerPlugin.java:53)  at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployJobModule(DeploymentListener.java:289)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745)"""
"XD-2503","Bug","Runtime",3,"RabbitMQ Message bus, RabbitMQ Source/Sinks are throwing exceptions","""I believe it is being cause by the following PR: XD-2381: Split MessageBus and Analytics dependencies from DIRT PR:  1307 SHA: 8d28b2786acbdea1617d7e903b805e5af5369b90  *RabbitMQ Sink is throwing:*  *Rabbit Message Bus is throwing:* """
"XD-2510","Bug","Runtime",1,"Fix classpath issues for RabbitMQ source/sink","""RabbitMQ Sink is throwing: {quote} 09:44:16,031 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)     at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)     at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)     at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)     at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)     at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)     at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)     at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)     at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)     at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)     at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)     at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)     at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)     at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)     at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)     at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)     at java.lang.Thread.run(Thread.java:745) Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.     at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)     at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)     at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)     at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)     at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)     at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)     at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)     at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)     at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)     at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)     ... 30 more 09:44:16,036 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)     at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)     at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)     at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)     at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)     at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)     at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)     at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)     at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)     at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)     at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)     at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)     at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)     at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)     at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)     at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)     at java.lang.Thread.run(Thread.java:745) Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.     at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)     at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)     at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)     at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)     at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)     at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)     at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)     at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)     at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)     at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391) {quote}"""
"XD-2509","Bug","Runtime",2,"Solve CP issues for the Rabbit MessageBus","""Rabbit Message Bus is throwing:  {quote} 10:14:04,678 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failed,error(s)=org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader     at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66)     at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110)     at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:426)     at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.afterPropertiesSet(AbstractMessageListenerContainer.java:385)     at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.doRegisterConsumer(RabbitMessageBus.java:367)     at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.bindConsumer(RabbitMessageBus.java:308)     at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:183)     at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:138)     at org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)     at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)     at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)     at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)     at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)     at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)     at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)     at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)     at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)     at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)     at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)     at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)     at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)     at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader     at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:616)     at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:592)     at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:244)     at java.lang.reflect.WeakCache.get(WeakCache.java:141)     at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:455)     at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:738)     at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:121)     at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:111)     at org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:96)     at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.initializeProxy(SimpleMessageListenerContainer.java:586)     at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doInitialize(SimpleMessageListenerContainer.java:612)     at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:424)     ... 28 more {quote}"""
"XD-2508","Story","Stream Module",3,"MQTT: Support the New Spring Integration 4.1 Features","""HA Configuration, async sends.  http://docs.spring.io/spring-integration/reference/html/whats-new.html#4.1-mqtt"""
"XD-2506","Story","Documentation",1,"""script"" processor options incorrect on docs","""The EXAMPLE in the documentation (and the paragraph preceding the example) for the """"script"""" processor uses both """"location"""" and """"properties-location"""" options, but these are in actuality """"script"""" and """"locationProperties"""" according to """"module info processor:script"""" and the text of the documentation.  See: http://docs.spring.io/spring-xd/docs/1.0.2.RELEASE/reference/html/#script   {quote}To use the module, pass the location of a Groovy script using the location attribute. If you want to pass variable values to your script, you can optionally pass the path to a properties file using the properties-location attribute. All properties in the file will be made available to the script as variables.   {quote}"""
"XD-2505","Bug","Hadoop",3,"Undeploying HDFS module closes filesystem","""When using the hadoop namespace to create a hadoop configuration and filesystem, the FileSystemFactoryBean uses Hadoop FileSystem.get and not newInstance which will return a FileSystem from the cache.  When undeploying the module, the FileSystemFactoryBean destroy method will close the FileSystem which closes for all other deployed Hadoop modules throwing a java.io.IOException: Filesystem closed"""
"XD-2504","Story","Acceptance Testing",5,"Upgrade CI Acceptance AMI to HVM","""Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI Paravirtual is being phased out by Amazon.  Also so we can utilize VPC and placement groups in the future. """
"XD-2517","Story","Packaging",3,"Clean up spring-xd-batch sub-project","""We should move the org.springframework.xd.batch.jdbc.ColumnRangePartitioner and org.springframework.xd.batch.item.jdbc.FieldSetSqlParameterSourceProvider to the spring-xd-extension-batch project"""
"XD-2516","Bug","Configuration",3,"spring_rabbitmq_addresses environment variable is ignored","""When trying to configure XD to use a RabbitMQ instance other than the default localhost:5672, a user is supposedto updated the """"spring_rabbitmq_addresses"""" environment variable or the spring.rabbitmq.addresses setting in the servers.yml file.  In this case XD is ignoring this environment variable.    h3. Steps to reproduce   # set the transport by using """"export XD_TRANSPORT=rabbit"""" # set the spring_rabbitmq_addresses by """"export spring_rabbitmq_addresses=foo:5672"""" # Startup a admin container on your local machine # deploy ticktock #* this should fail #* start up a local rabbitmq #* deploy a new ticktock and stream will deploy.  """
"XD-2531","Technical task","Batch",1,"Document Sqoop job","""As a user, I'd like to refer to the documentation so that I can connect to Sqoop as recommended and create job definition based on the exposed _metadata_ options. """
"XD-2537","Bug","Stream Module",1,"BackPort script.xml Bug Fix","""An additional commit (https://github.com/spring-projects/spring-xd/commit/db1f585) for XD-2230 was applied only to master; it needs to be backported to 1.0.x.  {{s/$\{location\}/$\{script\}/}}   https://gopivotal-com.socialcast.com/messages/22909482"""
"XD-2539","Bug","Runtime",5,"XD 1.1.0.M2 Won't Run on Windows","""See http://stackoverflow.com/questions/27725905/spring-xd-1-1-0-m2-fails-to-start  With {{XD_HOME}} set with back-whacks, it fails on {{\U...}} with {{XD_HOME}} set with whacks, it fails with {{/xd\...}}. The StackOverflow failure is similar.  1.0.3 works fine.  """
"XD-2544","Story","Performance Testing",5,"Create a loadGenerator source module","""Create a load-generator source module that  will generate messages and dispatch messages to a XD stream.    """
"XD-2564","Improvement","YARN Runtime",2,"Enhance XD on YARN to use SHDP container clustering","""Currently yarn runtime needs two yarn appmaster instances(one for admins, one for containers). SHDP's container grouping added functionality to run different type of containers within a same appmaster.  Beyond this, container grouping will also give more functionality like ramping containers up/down on-demand, creating groups with different settings dynamically and restarting failed containers."""
"XD-2563","Bug","YARN Runtime",1,"XD on YARN broken due to missing messagebus libs","""Admin on YARN simply fails because messagebus libs are not copied in place during a build.  Already tried and simple fix is for gradle/build-dist.gradle:    and execute it together with copyMessageBusLibs task."""
"XD-2568","Story","Testing",5,"Yarn Environment for XD Acceptance Tests","""Create an 2.6 Yarn Environment on EC2 for which XD can be deployed for acceptance tests."""
"XD-2572","Story","UI",1,"Set fixed NPM version for Grunt Gradle Plugin","""Ensure build works in Windows environments"""
"XD-2577","Bug","YARN Runtime",5,"XD is not logging when deployed using yarn","""When deploying XD (admin & container) using Yarn we only get the first 495 characters of the log which is the Ascii Art and Documentation links. """
"XD-2575","Improvement","Hadoop|Stream Module",5,"HDFS sink should provide rolloverTime option not only idleTiemout","""When using HDFS sink with ildeTimeout and rollover options in stream definition we have noticed that idleTimeout does not give you a flexibility when you would prefer a file to rollover after specific time regardless of the activity/inactivity of the file.  Proposed option: rolloverTimeout timeout after file will be automatically closed  Link: #XD-2413"""
"XD-2574","Improvement","Stream Module",5,"Gemfire sink SpringXD module does not support multiple locators","""Gemfire sink module accepts useLocator, host and port properties but this only allows to use one locator at a time.  We have a need to use the Gemfire sink SpringXD Module in our Seamless access project that we want to go live in Q1. The Version of SpringXD we planned on using is 1.1  However we need HA and we need to connect to a cluster with multiple locators. Problem is this isn’t supported yet in SpringXD.  We have used multiple locators in many projects in EMC and we don’t want to revert back to a situation where we have to put virtual IPs in front of locators just for SpringXD.  Ref to the SpringXD docs found in 1.0.3 and 1.1.0GA versions:  “The locator option is mostly intended for integration with an existing GemFire installation in which the cache servers are configured to use locators in accordance with best practice. While GemFire supports configuration of multiple locators for failover, this is currently not supported in XD. However, using a single virtual IP backed by hardware routers for failover has proven to be an effective and simpler alternative.”  """
"XD-2578","Bug","Runtime",2,"Custom Module not loading class from the module/lib.","""The module/lib contains the necessary jars but it is not taken, I am attaching the simple custom module which contains just few beans. Here is how I am creating the job from the xd-shell job create --name job1 --definition """"job-custom"""" --deploy  The server logs contains this error *************************************************************************************** 10:43:20,193 1.1.0.M2  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@2963e1e2 moduleName = 'job-custom', moduleLabel = 'job-custom', group = 'job1', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map[[empty]], children = list[[empty]]] 10:43:20,697 1.1.0.M2 ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed java.lang.NoClassDefFoundError: org/springframework/oxm/Unmarshaller  at java.lang.Class.getDeclaredMethods0(Native Method)  at java.lang.Class.privateGetDeclaredMethods(Class.java:2531)  at java.lang.Class.getDeclaredMethods(Class.java:1855)  at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:571) ***************************************************************************************  I already had been discussing this over the forums but could not get much help. stackoverflow.com/questions/27878047/noclassdefinitionerror-with-simple-bean-configuration  If I place the spring-oxm jar in the spring-xd lib I get this error *************************************************************************************** java.lang.IllegalStateException: Cannot convert value of type [org.springframework.oxm.jaxb.Jaxb2Marshaller] to required type [org.springframework.oxm.Unmarshaller] for property 'unmarshaller': no matching editors or conversion strategy found  *************************************************************************************** """
