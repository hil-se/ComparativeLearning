"issuekey","type","components","storypoint","title","description_text"
"DM-9","Story","SAT|TCT",1,"Open up LSST software mailing lists","""We all benefit from making LSST software development as open as possible and conducive to outside volunteer contributions (*). One way to increase community involvement is to open up our development mailing lists to the public, analogous to the way other open source projects do. For example, we could have:  * software-devel@lsstcorp.org: the development mailing list, equivalent to current lsst-data * software-users@lsstcorp.org: the users mailing list, equivalent to current lsst-dm-stack-users mailing list (but it could possibly be replaced by StackOverflow/Confluence Questions) * lsst-dm@lsstcorp.org: internal, DM-staff only mailing list, for the *rare* discussions/notices that should go out to staff only.  (*) Though we don't rely on them for meeting the project specs (legally required disclaimer :) )."""
"DM-71","Story","Database",8,"Data Distribution Design v1","""Need to come up with detailed design covering how we will deal with data distribution: managing multiple replicas, recovering from faults, adding new nodes to the cluster, registering new data from L2 ingest and user data (L3)."""
"DM-68","Bug","Qserv",0,"Qserv should fail when table not registered in CSS","""""""Table does not exist"""" message from CSS is currently ignored and query proceeds. Example, a query """"select count(*) from t"""" where t does not exist will successfully return 0 rows."""
"DM-52","Story","Qserv",3,"Qserv configuration - detailed design","""Detailed design covering how all Qserv components will be configured for runtime. """
"DM-78","Improvement","Developer Infrastructure",1,"Save a git-branch when a forced push is detected","""Create a gitolite hook that will save a branch when a forced push is detected.  E.g., if we have a ticket: 'tickets/DM-AAAA' and someone rebases it and pushes  with '--force' before applying the update --- then the hook will branch off the old state into (say):  backups/tickets/DM-AAAA/NNNN where NNNN is a monotonically increasing number (per branch)."""
"DM-148","Improvement","afw",1,"Improve naming of getters in AmpInfoTable","""The names of the methods to get values from a record on AmpInfoCatalog are potentially confusing.    This is because the convention is to call the getters get[attributename].  We could change the method names in the AmpInfoCatalog, or add methods in the SWIG wrapper."""
"DM-98","Bug","ip_isr",2,"clean up isr utility code","""There is some commented code in isr.py.  This should be removed or updated so that it works."""
"DM-228","Story","Qserv",8,"Setup dev test environment","""Setup whole Qserv environment, including installing data set, and validate it by running some simple queries. Suggest changes/improvements as appropriate."""
"DM-224","Story","Qserv",3,"Switch to MariaDB","""We should switch Qserv to the MariaDB Foundation based MySQL."""
"DM-213","Story","Qserv",5,"Setup multi-node testbed","""It'd be useful to test Qserv using Winter2014 or Summer2014 data set on a multi-node cluster, just to exercise all pieces of the software and double check we are not missing anything."""
"DM-202","Story","Qserv",8,"Qserv: unit testing (query execution) ","""Design and build toy prototype of a test framework for testing query execution module. This might require a mock framework, as we want to be able to test things in isolation, without testing everything around the query execution module at the same time. This is related to DMTF-16570-21."""
"DM-199","Story","Qserv",20,"Develop new master-worker result system ","""Reimplement how results are returned from worker to the czar. Currently it relies on mysqldump, which is fairly inefficient. This is related to DMTF-1650-045"""
"DM-242","Story","afw",3,"switch from '.' to '_' in afw::table fields","""We've been mapping '.' to '_' in afw::table I/O, which unnecessarily complicates lots of things.  We'd like to switch to using '_' in the field names themselves, which requires ending this mapping in I/O, but we need to be backwards compatible.  So we'll add a version to the FITS headers, and continue the mapping if the version is not present or is less than some value.  Until we do this, the new field names being used in meas_base won't round-trip."""
"DM-278","Story","Qserv",1,"Improve handling errors occuring in AsyncQueryManager","""AsyncQueryManager is initialized based on configuration file, if the configuration is invalid, an exception should be thrown (eg in _readConfig()) and gracefully handled upstream."""
"DM-273","Story","Developer Infrastructure",1,"Develop and then create the organizational structure for DM Confluence space","""Before we start populating the DM Confluence space with active pages, we should define an overall organizational structure/taxonomy."""
"DM-272","Improvement","Developer Infrastructure",2,"Move TCT-relevant  twiki documentation to Confluence","""Congregate all the trac TCT-relevant documents (standards, policies, guidelines, meeting history) onto Confluence."""
"DM-271","Story","Continuous Integration",100,"Setup the new Buildbot CI system","""Setup the Buildbot 0.8.8 testbed for the DM environment.  This includes: (1) setting up slaves on the set of common OS on which the DM stack runs; (2) creating a new continuous integration slave using the new eupsPkg-based build and distribution support,  Definition of done: * Every git change of master should trigger a build of master * If a build failed, an e-mail will be sent to lsst-data (if the build succeeds, nothing happens) * Failures due to internal buildbot issues (e.g., config problems, transient system availability issues, timeouts, etc.) should go to the buildbot owner. * Allow user-triggered builds via web page (with specified refs to be built), with a common user (until we get LSSTC LDAP directory hooked up). It's understood that locking may not be fully implemented/fleshed out in this story. * It should be possible for a user on lsst-dev to easily setup the stack for either a failed or a successful build. """
"DM-280","Story","meas_base",5,"clean up multiple aperture photometry code","""I've been doing some minor work on the HSC-side ApertureFlux algorithm, and I wanted to record some concerns here (from both me and RHL) that should be addressed in the new meas_base version:  - We should consider merging ApertureFlux and EllipticalApertureFlux into the same algorithm (with a config field to choose whether to use elliptical apertures).  We could still register it twice, with a different default config value, and this should eliminate a lot of code duplication.  We could also consider having them inherit from a common base class (instead of having EllipticalApertureFlux inherit from ApertureFlux, as is done now).  - We should test that the threshold at which we switch from Sinc to naive apertures is obeyed exactly.  - We should create a flag for the failure mode in which an aperture cannot be measured because we go off the edge of the image, and test that it appears at the right point.  If possible, we should set this flag and measure what area we can within that aperture, instead of just bailing out.  - (Somewhat off-topic) We should consider having utility functions on SourceSlotConfig to set all slots to None for use in unit tests."""
"DM-290","Story","Qserv",8,"Eliminate dependence of query analysis on parser and antlr","""I would like to write and compile query analyzer code completely independently of the parser and ANTLR (transitively). This doesn't seem to work right now. This is not currently possible.  This might take any where from a day to a week. (I'm not sure if we can finish anything in half a day, if you include the testing, review, feedback, and revision process, but perhaps unit testing will make that faster).  Updates to follow after the scope is estimated.  Dependencies to be broken: query --> parser, antlr (due to predicate depending on antlr nodes) qana --> parser, antlr """
"DM-298","Story","Qserv",1,"restarting mysqld breaks qserv","""Restaring mysqld results in unusable qserv (even if the restart happens when qserv is completely idle). The error message is:  ERROR 2013 (HY000): Lost connection to MySQL server during query This happens most likely because qserv caches the connection, which becomes invalid when server is restarted. I am guessing the same will happen when there is a long period of inactivity (the connection times out).  (transferred from trac 2853)"""
"DM-296","Story","Qserv",5,"fix namespaces in all Qserv core modules","""This was suggested by the code review for ticket 1945 (https://dev.lsstcorp.org/trac/wiki/SAT/CodeReviews/1945), pasted below:  common/src/*:  While it's not required by the coding standards, I'm a big proponent of using namespace scopes in .cc files, which usually save you from needing namespace aliases and will certainly save you from having prefix every declaration with qserv::.  At some point I'd recommend changing the header file extension from .hh to .h to match the rest of the LSST DM code, unless it's a big backwards compatibility issue.  (transferred from trac ticket 2528)"""
"DM-313","Story","Qserv",2,"cleanup includes in Qserv core modules","""Includes need cleanup: group into standard lib, boots and local, sort as appropriate etc. Also, unify forward declarations."""
"DM-309","Story","Qserv",8,"Jira for Qserv","""Jira setup for Qserv, includes things like adding new tasks, transferring tasks from trac, epic/story/task division, assigning story points, setting scrum board, just learning things and more..."""
"DM-322","Story","Qserv",2,"Trim python importing by czar in app.py","""Clean up the way modules are imported in qserv master, use relative import when appropriate instead of lsst.qserv.master.<package>   (migrated from Trac #2369)"""
"DM-321","Story","Qserv",2,"Re-think thread.cc and dispatcher.cc python interface","""The mess of thread.cc and dispatcher.cc need to be re-thought and re-designed so that the interface is smaller and more obvious.  """
"DM-326","Bug","Developer Infrastructure",1,"Libraries being built in lib64 on OpenSUSE, when EUPS tables assume lib","""A report from Darko Jevremovic <darko@aob.rs>: {quote} Hi Mario,  I managed to build stack v8 on OpenSuse13.1  There were standard problems with lib/lib64 - namely system builds libraries in $PREFIX/lib64 and some programs are hard wired for $PREFIX/lib  if you could  change the last line of  mysqlclient-5.1.65+3/ups/eupspkg.cfg.sh  from  (cd $PREFIX/lib && ln -s mysql/* . )  to  ( cd $PREFIX && if [ ! -f """"lib"""" ] ; then  ln -sf lib64 lib; fi &&cd $PREFIX/lib && ln -s mysql/* . )  or something along that line (am not sure whether the syntax would  work).  Also if you could add  in the same manner to ups/eupspkg.cfg.sh  ( cd $PREFIX && if [ ! -f """"lib"""" ] ; then  ln -sf lib64 lib; fi)  for the following packages:  minuit2 gsl cfitsio wcslib {quote} """
"DM-337","Story","Qserv",1,"removed dead code in stringUtil.h","""Remove obsolete strToDoubleFunc (and more) in util/stringUtil.h."""
"DM-335","Story","Qserv",8,"Migrate std::lists to std::vectors","""Suggested by Andy when reviewing DM-296, discussed at Qserv mtg 3/27.  std::list --> std::vector  * why? Default now is vector, iterating over vector is much more efficient than over list  * revisit on case by case bases, do not blindly replace  * preferred solution: typedef, and name it in a way that conveys the intent (e.g., might call it a """"container""""), underneath use vector"""
"DM-334","Story","Qserv",2,"Cut Qserv release","""It'd be very useful to have fully functioning Qserv release with the latest set of changes (build, packaging, CSS, Daniel's fixes etc) during the Hackathon week."""
"DM-355","Story","Qserv",0.5,"Install and tag multiple Qserv versions on the same distserver","""Done in DM-366"""
"DM-354","Improvement","afw",2,"Add cameraGeom overview to Doxygen documentation","""The CameraGeom package needs an overview page (part of afw's main.dox) as part of the Doxygen documentation. I think it's up to Simon or me to add this."""
"DM-370","Story","Qserv",5,"improved how default values for CSS are handled","""Need to improve how defaults are handled in qserv_admin. There seems to be some desire to warn when values are not set--how about setting defaults and just printing what configuration is being used? If this is something human-created, we should have reasonable defaults and not bother the user, unless no default is viable. I think we should only be strict on machine-generated input, where we would like to catch bugs as soon as possible.   (This came up in the review of DM-56, the review comments are captured in DM-225)"""
"DM-366","Story","Qserv",5,"Refactor install/distribution procedures using lsst-sw",""" Here's Andy Salnikov remark, during #3100 review : https://dev.lsstcorp.org/trac/ticket/3100#comment:18"""
"DM-365","Story","Qserv",3,"Integration tests dataset should be packaged in eupspkg","""A qserv-integration-tests package should be created : - it would allow to manage easily, in ups/qserv.table, tests version for a given Qserv version. - it would allow to install Qserv dependencies related to testing, like partition (and other data ingest code which may arrive."""
"DM-372","Story","Qserv",2,"fix testQueryAnalysis","""5 tests fail in the testCppParser."""
"DM-384","Story","afw",1,"Add Versioning to SourceTable in lsst::afw::table","""Add version to afw::table::SourceTable.  Persist that version number to fits file when the table is saved, and restore when the table is restored.  Tables created and saved to disk prior to this modification will have the version number 0, by default.  Tables created with the S14 version will have the version number 1.    This change is to enable a new version of slots and field naming conventions as needed by the Measurement Framework overhaul, at the same time allowing current clients of SourceTable to continue to function.  The work to define and persist the slots depending on the version will be on a separate issue.  Should not appear as an alterable member of the metadata, but should be saved with the metadata and reloaded when the file is reloaded.  getVersion and setVersion methods will be used to allow clients to alter this number."""
"DM-380","Bug","Developer Infrastructure",1,"loadLSST bug(s) for csh, ksh","""A flaw in the v8.0 loadLSST scripts (and/or in eups/bin/setups) causes the following errors:     1) When using ksh:     And indeed, there is no eups/bin/setups.ksh file.     2) When attempting to run the installation demo (v7.2.0.0):    [The same issue appears with csh, unsurprisingly.]    After hand-editing the demo.sh script to omit the """"/default"""" string from the offending line, the demo runs normally to completion.     Note that everything works fine for bash with v8.0, which is what I tested awhile back. """
"DM-435","Story","pipe_tasks",8,"add aperture-correction measurement code to the end of calibrate","""At the end of CalibrateTask, we'll want to compute the PSF and aperture fluxes of the PSF stars, and send those to the PSF model to be stored and interpolated (using the featured added via DM-434).  We'll also need to run any other flux measurement algorithms that need to be tied to the PSF fluxes on these same stars; because these can be somewhat slow, we probably want to limit these measurements to only the PSF stars, rather than requiring all these algorithms to be run as part of calibrate.measurement.  The relationships between these fluxes and the PSF fluxes will be additional fields to be added to and interpolated by the PSF.  The HSC implementation of this work (as well as that of DM-436) was done on issue HSC-191: https://hsc-jira.astro.princeton.edu/jira/browse/HSC-191 There were changes to many packages, but the relevant ones for LSST are: https://github.com/HyperSuprime-Cam/afw/commit/057fb3c0581c512d5664f1883a72da950c9eae9d https://github.com/HyperSuprime-Cam/meas_algorithms/compare/HSC-3.0.0...u/jbosch/DM-191 https://github.com/HyperSuprime-Cam/pipe_tasks/compare/4c3a53e7238cbe9...u/jbosch/DM-191"""
"DM-429","Story","meas_base",3,"Make NoiseReplacer outputs reproduceable","""We need a way to get back the noise-replaced Exposure as it was when a particular source was measurement, after the measurement has been run, without having to run noise-replacement on all the previous objects again.  There is already code in afw::math::Random to output its state as a string; I think we should probably just save this string in the output catalog.  This will require some API changes to allow the NoiseReplacer to modify the schema and set a field in the output records."""
"DM-405","Story","Qserv",5,"Write Linux Standard Base - compliant init.d scripts","""Qserv services init.d scripts have to rely on LSB, in order to work on multiple systems.  Remark : xrootd has to be launched as a background process (i.e. with a & at the end). But this always send of return code equal to 0, even if xrootd fails to start, a shell function wait_for_pid will be implemented in xrootd init.d scritps to solve that (inspired from mysqld init.d script)."""
"DM-446","Story","meas_base",1,"Setup PeakLikelihoodFlux with new Algorithm Framework","""Move PeakLikehoodFlux to meas_base framework """
"DM-470","Story","Qserv",1,"Rework exceptions in css (python side)","""Rework exceptions in css/KwInterface.py: split into key-value related exceptions, possibly moving the rest that deals with db/tables into client.  This came up in the CSS review, see DM-225: """"CssException feels a bit out of place...."""""""
"DM-468","Story","meas_base",1,"Alias measurement.plugins to measurement.algorithms","""The config item in the old measurement task, measurement.algorithms was changed to measurement.plugins in meas_base.  The creates a backward compatibility issue for code which refers to this class member.  Jim's suggested fix is to alias plugins with algorithms in the new measurement task."""
"DM-481","Story","Qserv",0,"Unit tests install directory","""Hello,  Tests target seems to be correctly defined in core/modules/SConstruct (cf. getTests() function), but tests doesn't seems to be nor built or runned.  In DM-58 branch i've introduced a few line of code which now build the tests.  For now, tests binaries are located in build/moduleName/ directory, do you think we should let the tests here or install it :  - in the Qserv install directory ? - in a tests/ subdirectory of Qserv install directory ? - other solution ? - do we set an option to scons procedure in order to build, and run, these unit tests ?  Thanks,  Fabrice"""
"DM-488","Story","Developer Infrastructure",1,"Make JIRA notification e-mail more useful","""From HipChat/Data Management:  [12:09] Mario Juric: @jbosch @KTL @KSK Could you double-check if any of you got an e-mail from Jira on Saturday (Apr 12th) re issue DM-78 (I made you reviewers, but it looks like you weren't notified)? [12:10] K-T Lim: I don't recall and can't determine now; it would have been deleted (irrevocably). [12:10] Simon Krughoff: I did get an email. [12:10] Jim Bosch: @mjuric, ah, it appears that I actually did.  The fact that I was a reviewer was just buried, and I didn't notice it. [12:10] Simon Krughoff: I must have missed that I was a reviewer. [12:10] Mario Juric: OK, thanks!   That gives me not one, but two useful data points (#1 -- emails work, #2 -- they're useless :) ). [12:12] Simon Krughoff: I'm not sure why they are useless.  The emails from trac were a very important part of my workflow as far as being notified of review responsibility goes.   Maybe it's just the volume from Jira. [12:14] Jim Bosch: Yeah, same here.  Though the volume from JIRA hasn't been so bad, so I don't think that's it.  Maybe my brain just has to get used to the new email format. [12:14] K-T Lim: (In my case, I'm mostly paying attention to the RSS feed although the mailbox serves as a backup.) [12:22] Robert Lupton: One of the things that made gnats a good bug tracker was that the emails contained the right amount of information (I did have source code...), and trac was pretty good too when we tuned it;  bugzilla always used to be awful.  I bet we can fiddle with Jira to make its mail more useful;  I don't just mean filtering what it sends, but making sure that each email is self contained, but not too long"""
"DM-521","Story","Qserv",5,"Confusing error message (non-existing column referenced)","""A query that references non existing column for non-partitioned table results in a confusing message: """"read failed for chunk(s): 1234567890"""".  To repeat, run something like   Similar error occurs when we try to reference non-existing table, try something like:   """
"DM-520","Improvement","Qserv",1,"Remove old partitioner/ loader and duplicator","""Once Fabrice has migrated the integrated tests towards using the new partitioner and duplicator, we should delete the old partitioner/duplicator (in {{client/examples}})."""
"DM-518","Story","Qserv",1,"Rework exceptions in qserv client","""There is a bunch of (I think) unnecessary translation from KvException to QservAdmException. Can't you just handle printing KvException in CommandParser.receiveCommands(), and get rid of the CSSERR error code? (This is in /admin/bin/qserv-admin.py)  (this came up in DM-225)"""
"DM-513","Story","Qserv",8,"fix threading issues in CSS watcher","""Fix problems with threads in watcher.py brought up in DM-225 by Serge:  * A thread per database doesn't scale  * There is a thread leak when a database is deleted  * There is another design problem, in that each database thread looks like it is holding on to the same lsst.db.Db instance under the hood. I don't remember any consideration for thread safety from the lsst.db code when I reviewed it. Note for one that it is not safe to use a MySQL connection simultaneously from multiple threads (and I seem to recall that you are caching a connection inside Db instances). In practice, even the Python GIL may not save you, since calls into C code (i.e. the mysql client library) may very well release it."""
"DM-510","Story","Qserv",2,"Tweak metadata structure for driving table and secondary index","""There seem to be confusion about driving table and secondary index. At the moment in zookeeper structure we have   Issues to think about:  * we can't call it objIdIndex, it is too lsst-specific.  * drivingTable and keyColName - perhaps these should be at database level, which means we would only allow one drivingTable and one secondary index per database?  * or, maybe instead of database level, it is a partitioning parameter? Note that two databases might use different name for secondary index or driving table, yet they might be joinable. That argues for introducing a new group, something like /DATABASE/partitioning in addition to /DATABASE_PARTITIONING.  * consider renaming drivingTable to keyTable  * do we really need secIndexColName and keyColName? Can't we get rid of one, and rename to keyColName? """
"DM-509","Story","Qserv",1,"rename ""dbGroup"" to ""storageClass"" in CSS metadata","""It is meant to be used to indicate L1, L2, L3... At Qserv design week we decided to rename it (original plan was to remove it all together) """
"DM-508","Story","Qserv",2,"shorten internal names in zookeeper","""rename DATABASE_PARTITIONING to PARTITIONING  rename DATABASES to DBS"""
"DM-506","Story","Qserv",1,"improve generating kvMap in testFacade.cc","""Generating the kvmap file, and pasting it into a string inside the test program. (this was brought up in DM-225)"""
"DM-505","Story","Qserv",1,"improve initialization of kvMap in testQueryAnalysis","""Build the kvMap at build-time and embed it into the executable. (this was brought up in DM-225)"""
"DM-530","Story","Qserv",5,"Table column names in new parser","""Running tests (qserv-testdata.sh) on pre-loaded data I have observed that many test fail for the only reason that the column names in the dumped query results are different between mysql and qserv. Here is an example of query reqult returned from mysql:  and this is the same query processed by qserv:   We discussed this already with Daniel yesterday and at qserv meeting today, here I just want to collect what we know so far so that we can return to this again later.   As Daniel explained to me this is the result of the new parser assigning aliases to the columns which do not define aliases for themselves. This helps with tracking query proceeding through the processing pipeline. Daniel's observation is that different database engines may assign different names to result columns (or some may not even assign any names), there is no standard in that respect so there is no point in trying to follow what one particular implementation does. Additionally there are issues with conflicting column names and names which are complex expressions.  Difference in column names breaks our tests which dump complete results including table header. The tests could be fixed easily, we could just ignore table headers when dumping the data. More interesting issue is that there may be use cases for better compatibility between mysql and qserv including result column naming. In particular standard Python mysql interface allows one to use column names to retrieve values from queiry result. If qserv assigns arbitrary aliases to the columns it may confuse this kind of clients.  This issue depends very much on what kind of API qserv is going to provide to clients. If mysql (wire-level) protocol is going to be the main API (which would allow all kinds of mysql clients to talk to qserv directly) then we should probably think more about compatibility with mysql. OTOH if we decide to provide our own API then this may not be an issue at all (but we still need to fix current test setup which is based on mysql).  We probably should discuss API question at our dev meeting."""
"DM-527","Bug","afw",1,"make Image construction robust against integer overflow","""I just fixed a bug on the HSC side (DM-523) in which integer overflow in the multiplication of width and height in image construction caused problems.  We should backport this fix to LSST."""
"DM-546","Story","Qserv",3,"scons rebuilds targets without changes","""I'm seeing something strange when I run scons from current master - running 'scons install' after 'scons build' re-compiles several C++ files even though nothing has changed between these two runs: {code:bash} $ scons build scons: Reading SConscript files ... ... scons: Building targets ... scons: `build' is up to date. scons: done building targets.  $ scons install scons: Reading SConscript files ... ... scons: Building targets ... swig -o build/czar/masterLib_wrap.cc -Ibuild -I/usr/include/python2.6 -python -c++ -Iinclude build/czar/masterLib.i g++ -o build/czar/masterLib_wrap.os -c -g -fPIC -D_FILE_OFFSET_BITS=64 -fPIC -I/u2/salnikov/STACK/stack/Linux64/protobuf/2.4.1/include -I/u2/salnikov/STACK/stack/Linux64/xrootd/qs5/include/xrootd -I/u2/salnikov/STACK/stack/Linux64/mysql/5.1.65/include -Ibuild -I/usr/include/python2.6 build/czar/masterLib_wrap.cc g++ -o build/control/AsyncQueryManager.os -c -g -fPIC -D_FILE_OFFSET_BITS=64 -fPIC -I/u2/salnikov/STACK/stack/Linux64/protobuf/2.4.1/include -I/u2/salnikov/STACK/stack/Linux64/xrootd/qs5/include/xrootd -I/u2/salnikov/STACK/stack/Linux64/mysql/5.1.65/include -Ibuild -I/usr/include/python2.6 build/control/AsyncQueryManager.cc g++ -o build/control/dispatcher.os -c -g -fPIC -D_FILE_OFFSET_BITS=64 -fPIC -I/u2/salnikov/STACK/stack/Linux64/protobuf/2.4.1/include -I/u2/salnikov/STACK/stack/Linux64/xrootd/qs5/include/xrootd -I/u2/salnikov/STACK/stack/Linux64/mysql/5.1.65/include -Ibuild -I/usr/include/python2.6 build/control/dispatcher.cc g++ -o build/control/thread.os -c -g -fPIC -D_FILE_OFFSET_BITS=64 -fPIC -I/u2/salnikov/STACK/stack/Linux64/protobuf/2.4.1/include -I/u2/salnikov/STACK/stack/Linux64/xrootd/qs5/include/xrootd -I/u2/salnikov/STACK/stack/Linux64/mysql/5.1.65/include -Ibuild -I/usr/include/python2.6 build/control/thread.cc g++ -o build/merger/TableMerger.os -c -g -fPIC -D_FILE_OFFSET_BITS=64 -fPIC -I/u2/salnikov/STACK/stack/Linux64/protobuf/2.4.1/include -I/u2/salnikov/STACK/stack/Linux64/xrootd/qs5/include/xrootd -I/u2/salnikov/STACK/stack/Linux64/mysql/5.1.65/include -Ibuild -I/usr/include/python2.6 build/merger/TableMerger.cc scons: `install' is up to date. scons: done building targets. {code}  This is kind of unexpected, or at least I can't understand now why it happens. Trying to run with --debug=explain shows that some dependencies have disappeared and in some dependencies order is different. No clue yet what that means and how it could happen. Need to study our scons scripts to understand what is going on."""
"DM-566","Story","meas_base",3,"Fix Doxygen Doc for new meas_base classes","""The final stage of moving the old algorithms to meas_base will be to generate the doxygen documentation and be sure that it is useful.  We will do this after the  cleanup of the old meas_algorithms code."""
"DM-560","Story","Qserv",1,"cleanup includes - add module name","""Change places like  to    """
"DM-559","Story","Qserv",1,"clean up include <> --> """" for third party includes","""According to our coding standard 4.15: https://dev.lsstcorp.org/trac/wiki/C%2B%2BStandard/Files#a4-15.OnlysystemincludefilepathsSHALLbedelimitedwith  we should be using """""""" for boost, but in quite a few places we do not:   """
"DM-583","Story","ip_diffim",20,"Investigate Approaches to Dcr","""This story captures the work of investigating the implications of the different options to compensate for Dcr: ignore objects with extreme colors, compensate for Dcr in measurement, and compensate per-image at the per-object/pixel level.  We anticipate the latter option will be required going forward, but we need to do the background work to justify this.  We need to understand exactly which classes will need to make use of Dcr information, and what the limitations are of operating at the per-pixel level (e.g. blends)."""
"DM-590","Story","afw",1,"load non-LSST FITS tables as version 1","""In DM-384 and DM-242, we disabled the periods-to-underscores translations for new tables (""""version 1"""") but left it in place for old tables (""""version 0"""").  In addition, when reading a table without a version number, we assumed it was version 0, to maintain backwards compatibility.  I think we should modify this slightly: we should assume a table without a version number is version 0 if and only if it also has the AFW_TYPE key.  Otherwise we should assume it is version 1.  This will allow us to load externally-produced tables without turning any underscores they contain into periods, while still maintaining backwards compatibility with older tables written by afw."""
"DM-587","Bug","obs_cfht",1,"The way the observation date is translated by obs_cfht breaks the defect registry.","""The fields of the observation date and time as stored in the CFHT-LS headers are not padded with zeros.  This makes the sqlite DATETIME constructor return a NULL string when the observation time is < 10hrs.  The fix is to force the fields to be padded when the metadata from the input files are ingested."""
"DM-597","Story","Qserv",1,"reorganize client module","""move everything in the client package (qserv_admin*, associated tests and examples) to admin/  move css/bin/watcher.py to admin/  """
"DM-596","Story","Qserv",2,"Fix automated tests after css migration","""After yesterday's merge of DM-58 into master automated tests do not work any more. The part which is broken now is loading of metadata into qserv. We need to replace old script which created metadata with something different that creates metadata using new CSS.   The code which loads metadata in tests is in QservDataLoader class, createQmsDatabase() method (in tests/python/lsst/qserv/test/ directory)."""
"DM-593","Story","Developer Infrastructure|TCT",2,"Update all DM Software Copyright and License Agreement notices to reflect AURA/LSST","""The lsstcorp.org/LegalNotices/{LsstLicenseStatement.txt  LsstSourceCopyrightNotice.txt} need to be updated to reference AURA/LSST. The referenced list of LSST partner institutions needs to be either resurrected or the reference deleted.  The git repository for devenv/templates needs the Copyright templates to be  updated.  LsstLicenseStatement.txt needs to be updated to include recent additions of 3rd party tools' Licenses (~10 tools)  to the DM stack  and all the QSERV 3rd party tools' Licenses (~25 tools).  The Copyright banner in all software needs to be updated to reflect the new reality of AURA/LSST in place of LSST Corporation.  Files with no Copyright banner, need to add it.  Update may occur 'the next time' the code file is updated. THis needs to be broadcast to the developers once the Copyright templates and the website versions are updated."""
"DM-609","Improvement","afw",1,"afw unit tests not built unless afwdata available","""If afw_data is not available then the afw unit tests are not built. I think it would make more sense to build all of them and run those we can (not all depend on afw_data). One advantage is that a version of afw installed using """"eups distrib install"""" would include built tests, so the tests could be run. This is presently not practical because the SConstruct file is not installed (I intend to open a ticket about that, as well)."""
"DM-608","Bug","Qserv",3,"referring to table without database context crashes czar","""Running a query like """"select * from Object"""" if we do not have database context results in    Need to gracefully catch the zookeeper -8. Need to detect that empty database name is passed in Facade. Need to avoid it higher up. """
"DM-614","Story","Qserv",1,"rename qserv_admin.py to qserv-admin.py","""We have 6 scripts in qserv/admin/bin that start with """"qserv-"""", and one that starts with """"qserv_"""", we should rename qserv_admin to qserv-admin."""
"DM-612","Story","Qserv",2,"remove obsolete QMS-related code","""try running    There is a lot of old unused qms related code."""
"DM-611","Story","Qserv",2,"Switch kazoo version to 2.0b1 or later","""While we aren't using any of the new features of Kazoo's 2.x series, the removal of zope.interface as a dependency is a worthwhile feature.  The 2.0b1 release seems at least as stable as our own code, so I don't think we'll see any negative effects.  This ticket covers: - Upgrade of the packaged kazoo from 1.3.1 to 2.0b1 (or later). - (optionally) patches for kazoo's setup.py so that it doesn't search for and try to download any dependencies. This can be done in a later ticket, though.  I note that kazoo can be run without installation: you can untar it, cd into the directory, and if you run python from there, you can immediately """"import kazoo"""" and use it. Hence we could avoid setup.py completely and just copy the """"kazoo"""" subdirectory into some directory in the PYTHONPATH."""
"DM-630","Story","Qserv",5,"Non-partitioned table query returns duplicated rows","""Running automated test I noticed that a query on non-partitioned table returns multiple copies of the same row, one copy per chunk. Here is example:   Czar log file shows that it correctly finds that table is non-chunked but sends query to each chunk anyway:   Looking at the code together with Daniel we found that at the Python level (czar/app.py) the code that dispatches query does not check for chunkLevel, this is likely why this happens. The code to look at is in {{InbandQueryAction._applyConstraints()}} method."""
"DM-626","Story","Qserv",1,"ORDER BY and DISTINCT do not work reliably in qserv","""Queries with ORDER BY and DISTINCT are buggy. For example, results do not always come ordered and order changes from one run to another:   This was done with testdata/case01 data, let me know if you need to load that data.  Also, using case03 data, e.g.  returns 6 rows in qserv (vs 1 in mysql).  The full list of DISTINCT failures is (all with testdata/case03): - 0002_fetchRunAndFieldById.txt - 0021_selectScienceCCDExposure.txt - 0030_selectScienceCCDExposureByRunField.txt """
"DM-625","Story","Qserv",1,"Too many connections from czar to zookeeper","""I have just managed to crash qserv czar by running repeated queries against it. What I see in the logs:  qserv-czar.log:   and zookeeper.log: """
"DM-621","Story","Qserv",8,"User friendly single node loading script","""This entails the creation of an end-to-end loading script that, given database and table param files, a SQL table schema and one or more CSV data files, places appropriate metadata into zookeeper, runs the partitioner, and finally creates and loads chunk tables."""
"DM-633","Bug","Qserv",3,"Query sessions are never destroyed","""Please see DM-625, when I run say 10 """"select count(*) from LSST.Object"""" queries, for each query a new AsyncQueryManager is created in dispatcher, but the sessions are never destroyed."""
"DM-637","Bug","Qserv",1,"complexity of eups dependencies relationships  for db package","""Hello,  I'm currently trying to use the very last version of db package (the one which relies on sconsUtils), but, in order to make it works with Qserv, I had to introduce next update : {code:bash} fjammes@clrlsstwn02-vm:~/src/qserv-packager/dist/dependencies/db (master) $ git diff HEAD~1 diff --git a/ups/db.cfg b/ups/db.cfg index e1ae31b..a469061 100644 --- a/ups/db.cfg +++ b/ups/db.cfg @@ -3,7 +3,7 @@  import lsst.sconsUtils    dependencies = { -    """"required"""": [""""mysqlclient"""", ], +    """"required"""": [""""mysql"""", ],  }    config = lsst.sconsUtils.Configuration( diff --git a/ups/db.table b/ups/db.table index 8c8d831..9e770a3 100644 --- a/ups/db.table +++ b/ups/db.table @@ -1,5 +1,5 @@  setupRequired(python) -setupRequired(mysqlclient) +setupRequired(mysql)  setupRequired(mysqlpython)  setupRequired(sconsUtils) {code}  Is there a solution to describe  in eups that mysqlclient is included in mysql ?  Thanks,  Fabrice"""
"DM-648","Story","Qserv",5,"Add support for running unit tests in scons","""Add code in scons that runs unit tests for Qserv."""
"DM-646","Story","Qserv",2,"Implement DISTINCT aggregate in qserv","""It looks like DISTINCT aggregate is not supported yet in qserv. Daniel told me that this should be relatively straightforward to add. Adding this ticket so that we do not forget it."""
"DM-661","Bug","Qserv",0.5,"Parser has inverted order for ""limit"" and ""order by""","""  Works in MySQL, fails in Qserv (ERROR 4120 (Proxy): Error executing query using qserv.)    Works in Qserv, fails in MySQL (limit should be after order by) """
"DM-666","Bug","Qserv",3,"partition package has to detect eups-related boost","""partition package doesn't detect eups-related boost. This has to be fixed by using sconsUtils, or hand-made procedure.  {code:bash} [fjammes@lsst-dev lsstsw]$ export LD_LIBRARY_PATH=""""$LSSTSW/anaconda/lib:$LD_LIBRARY_PATH"""" [fjammes@lsst-dev lsstsw]$ setup boost 1.55.0.1+1 [fjammes@lsst-dev lsstsw]$ rebuild partition            partition:  ok (0.5 sec).                boost:  ok (0.3 sec).               python:  ok (0.3 sec).                scons:  ok (0.4 sec). # BUILD ID: b49               python: master-gcbf93ab65b (already installed).                scons: 2.1.0+8 (already installed).                boost: 1.55.0.1+1 (already installed).            partition: master-gf2ef2cf2dc ERROR (1 sec). *** error building product partition. *** exit code = 1 *** log is in /lsst/home/fjammes/src/lsstsw/build/partition/_build.log *** last few lines: :::::  scons: Reading SConscript files ... :::::  Checking for C++ library boost_system-mt... no :::::  Checking for C++ library boost_system... no :::::  Checking for C++ library boost_thread-mt... no :::::  Checking for C++ library boost_thread... no :::::  Checking for C++ library boost_filesystem-mt... no :::::  Checking for C++ library boost_filesystem... no :::::  Checking for C++ library boost_program_options-mt... no :::::  Checking for C++ library boost_program_options... no :::::  Missing required boost library! # BUILD b49 completed. {code}"""
"DM-664","Story","Qserv",2,"""out of range value"" message when running qserv-testdata (loader.py)","""Fabrice  I am getting """"out of range value"""" when I run the qserv-testdata:  Are you seeing that too?   2014-05-09 18:11:55,975 {/usr/local/home/becla/qserv/1/qserv/build/dist/lib/python/lsst/qserv/admin/commons.py:134} INFO     stderr : /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'calib_detected' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'calib_psf_candidate' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'calib_psf_used' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_negative' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_badcentroid' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'centroid_sdss_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_edge' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_interpolated_any' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_interpolated_center' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_saturated_any' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_saturated_center' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_cr_any' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_cr_center' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'centroid_gaussian_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'centroid_naive_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'shape_sdss_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'shape_sdss_centroid_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'shape_sdss_flags_unweightedbad' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'shape_sdss_flags_unweighted' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'shape_sdss_flags_shift' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'shape_sdss_flags_maxiter' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flux_psf_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flux_psf_flags_psffactor' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flux_psf_flags_badcorr' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flux_naive_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flux_gaussian_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flux_gaussian_flags_psffactor' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flux_gaussian_flags_badcorr' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flux_sinc_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_psf_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_psf_flags_maxiter' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_psf_flags_tinystep' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_psf_flags_constraint_r' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_psf_flags_constraint_q' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_dev_flux_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_dev_flags_psffactor' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_dev_flags_badcorr' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_dev_flags_maxiter' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_dev_flags_tinystep' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_dev_flags_constraint_r' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_dev_flags_constraint_q' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_dev_flags_largearea' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_exp_flux_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_exp_flags_psffactor' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_exp_flags_badcorr' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_exp_flags_maxiter' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_exp_flags_tinystep' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_exp_flags_constraint_r' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_exp_flags_constraint_q' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_exp_flags_largearea' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_combo_flux_flags' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_combo_flags_psffactor' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'multishapelet_combo_flags_badcorr' at row 1   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'calib_detected' at row 2   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'calib_psf_candidate' at row 2   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'calib_psf_used' at row 2   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_negative' at row 2   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_badcentroid' at row 2   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'centroid_sdss_flags' at row 2   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_edge' at row 2   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_interpolated_any' at row 2   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_interpolated_center' at row 2   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_saturated_any' at row 2   self.cursor.execute(stmt) /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column 'flags_pixel_saturated_center' at row 2   self.cursor.execute(stmt) """
"DM-674","Bug","pex_config",2,"fix handling of nested control objects","""Work on the HSC side has revealed some problems with nested control objects being wrapped into config objects.  This is a pull request for those changes (along with writing a unit test for some of them).  Some (but not all of these changes) are part of Trac ticket #3163 (https://dev.lsstcorp.org/trac/ticket/3163), which I'll now close as a duplicate."""
"DM-676","Story","Middleware",2,"Implement HTCondor dynamic classad solution for Slot based values","""The HTCondor team will be updating their HOWTO for managing Slot based classads/dynamic classads set by a cron startd process.  We currently have a technique for  dynamic slot based values that is iinefficient from a negotiation perspective, and we will want to update to a more optimal approach that the HTCondor team plans to provide."""
"DM-689","Story","Qserv",1,"During scons configure : check if mysql isn't runing","""Mysqld can't be configured is its running before configuration step."""
"DM-707","Story","Qserv",2,"cleanup exception code in CSS","""Reported by Serge:  In CssException.h youve got:    This is inconsistent (shouldnt it be CssRunTimeException_XXX, or maybe even CssRunTimeError?), lengthy, violates the LSST C++ naming conventions, and doesnt match the KvInterface docs, which all still talk about a CssException class that does not exist. Can we consider changing this to something more like:    ? Then we can succinctly throw and catch css::NoSuchTable, css::AuthError etc"""
"DM-706","Story","Qserv",1,"cleanup extra file names in docstring","""Reported by Serge in email:  When using doxygen to document C++ source, you can mark a comment block with just:    in which case doxygen assumes you want the comment block tied to the file it appears in. We seem to have lots of """"@file <fileName> statements all over the place, which is an extra thing we have to remember to change when renaming files. Is there some reason to do it that way that Im missing?"""
"DM-704","Story","Developer Infrastructure",2,"Better review notification e-mails","""Russell writes:  {quote} I think our system for getting code reviewed using JIRA needs some improvements. It seems that people don't always know that they have been assigned to review a ticket. Also, even if I know I have been assigned to review a ticket, I find it hard to find on JIRA.  More concretely, I would like to see these improvements: - Much clearer notification that one has been assigned as a reviewer. Presently the email is quite generic and easy to miss. In fact I find that most JIRA notifications are rather hard to read -- it's not always easy to see what has changed and thus why I should care. The signal to noise ratio is poor.  - By default a user should see which issues they have been assigned as reviewer when they log into JIRA. (If there is a way to reconfigure the dashboard for this, I'd like to know about it, but it really should be the default). One way to fix this, of course, is to reassig the ticket when putting it into review, but we have good reasons to avoid that.  -- Russell {quote}  and I added:  {quote} In fact, you don't know that the ticket has passed into review unless you scroll all the way to the bottom of the comment.  If the comment associated with the change in status is long and you don't scroll all the way down, then you may not know that you were assigned to review.  With Trac, the important information was at the top of the e-mail. {quote}"""
"DM-703","Story","Continuous Integration",1,"Use of HipChat for Buildbot CI failure notifications should be explored","""K-T recommended the use of HipChat rather than email when notifying users of a buildbot build failure.  The purpose was twofold: get immediate attention from the developers and help change the culture towards using HipChat more.  This Issue is to explore the feasibility of using HipChat for the notifications."""
"DM-710","Story","Qserv",1,"Reduce and comment client configuration file","""Client configuration file '~/.lsst/qserv.conf) is used by integration test procedure.  Next improvments are required : 1. use templates in it 2. client config file should retrieve templated values from mother config   file"""""""
"DM-737","Story","Qserv",8,"Rendering an IR node tree should produce properly parenthesized output","""It appears that rendering a tree of IR nodes doesn't always result in correct generation of parentheses. Consider the following tree: {panel} * OrTerm ** BoolFactor *** NullPredicate **** ValueExpr ***** ValueFactor: ColumnRef(""""refObjectId"""") ** BoolFactor *** CompPredicate **** ValueExpr ***** ValueFactor: ColumnRef(""""flags"""") **** Token(""""<>"""") **** ValueExpr ***** ValueFactor: Const(""""2"""") {panel}  which corresponds to the SQL for: """"refObjectId IS NULL OR flags<>2"""". If one prepends this (via {{WhereClause.prependAndTerm()}}) to the {{WhereClause}} obtained by parsing """"... WHERE foo!=bar AND baz<3.14159;"""" and renders the result using {{QueryTemplate}}, one obtains:      {{... WHERE refObjectId IS NULL OR flags<>2 AND foo!=bar AND baz<3.14159}}  This is equivalent to      {{... WHERE refObjectId IS NULL OR (flags<>2 AND foo!=bar AND baz<3.14159)}}  which doesn't match the parse tree - one should obtain:      {{... WHERE (refObjectId IS NULL OR flags<>2) AND foo!=bar AND baz<3.14159}}  This issue involves surveying all IR node classes and making sure that they render parentheses properly. {color:gray}(One way we might test for this is to parse queries containing parenthesized expressions where removal of the parentheses changes the meaning of the query. This would give us some IR that we can render to a string and reparse back into IR. If the rendering logic is correct, one should obtain identical IR trees).{color} Other possibilities that might explain the behavior above is that the input tree is somehow invalid or that {{WhereClause.prependAndTerm}} creates invalid IR."""
"DM-720","Improvement","SAT|TCT",20,"Upgrade various external packages","""I note that the LSST and HSC versions of external packages are slightly out of sync.  I propose uprevving the LSST packages to match as HSC has tested these versions.  {quote} cfitsio               3.360             HSC cfitsio               3310+2            sims Winter2014 current b4 b5 b6 b3 doxygen               1.8.2+2           sims b4 Winter2014 current b5 b6 b3 doxygen               1.8.5             HSC eigen                 3.1.1+2           Winter2014 current b5 b6 b3 b4 eigen                 3.2               HSC fftw                  3.3.2+2           Winter2014 current b5 b6 b3 b4 fftw                  3.3.3             HSC gsl                   1.15+2            Winter2014 current b5 b6 b3 b4 gsl                   1.16              HSC minuit2               5.22.00+2         Winter2014 current b5 b6 b3 b4 minuit2               5.28.00           HSC mysqlclient           5.1.65+3          Winter2014 current b5 b6 b3 b4 mysqlclient           5.1.73            HSC pyfits                3.1.2+2           sims b4 Winter2014 current b5 b6 b3 pyfits                3.2               HSC scons                 2.1.0+7           sims b4 Winter2014 current b5 b6 b3 scons                 2.3.0             HSC sqlite                3.7.14+2          Winter2014 current b5 b6 b3 b4 sqlite                3.8.2             HSC wcslib                4.14        wcslib                4.14+3            b4 Winter2014 current b5 b6 b3 xpa                   2.1.14+2          Winter2014 current b5 b6 b3 b4 xpa                   2.1.15            HSC {quote} """
"DM-742","Story","Qserv",3,"Use geom eups package for installing geometry","""Use geom eups package instead of downloading geometry.py during Qserv configuration step."""
"DM-751","Bug","Qserv",3,"Replacing boost system lib with eups libs breaks scons build","""While detecting boost, Qserv build system checks for both system lib and then eups lib. This procedure use next code :  {code:python} class BoostChecker:     def __init__(self, env):         self.env = env         self.suffix = None         self.suffixes = [""""-gcc41-mt"""", """"-gcc34-mt"""", """"-mt"""", """"""""]         self.cache = {}         pass      def getLibName(self, libName):         if libName in self.cache:             return self.cache[libName]          r = self._getLibName(libName)         self.cache[libName] = r         return r      def _getLibName(self, libName):         state.log.debug(""""BoostChecker._getLibName() LIBPATH : %s, CPPPATH : %s"""" % (self.env[""""LIBPATH""""], self.env[""""CPPPATH""""]))         if self.suffix == None:             conf = self.env.Configure()              def checkSuffix(sfx):                 return conf.CheckLib(libName + sfx, language=""""C++"""", autoadd=0)   As the """"-mt"""" suffix is searched before the empty suffix, previous command succeed.In my example boost_regex-mt is a system lib. When launching """"scons build"""", then CheckLib only looks for boost in /data/fjammes/stack/Linux64/boost/1.55.0.1/lib, not in /usr/lib/. This behaviour is eups-correct, but prevents to find boost_regex-mt.  In this example, a trivial solution is to reverse self.suffixes in python code, but a better solution would be to prevent g++ to use default search paths (e.g. : /usr/lib and /usr/include) in the second command. Is it possible to to it with scons ?  Mario, did you meet the same problem with sconsUtils ?    Thanks  Fabrice"""
"DM-767","Story","afw|ip_diffim|ip_isr|meas_algorithms|pipe_tasks",2,"Determine scope of XY0 convention update","""It's unclear exactly how much effort will be involved in making a change to how the XY0 is used.  If the parent/child argument is removed completely this change could be quite invasive and wide reaching."""
"DM-766","Story","afw",3,"Improve afw::CameraGeom::utils code","""Some of the utility code in CameraGeom was not completely ported in W13 and documentation is in need of updating."""
"DM-764","Story","pex_exceptions",5,"Exception naming convention","""The naming convention for exceptions in pex_exceptions is quite redundant.  This issue will make the convention more compact and update all packages that make use of pex_exceptions."""
"DM-781","Story","Qserv",2,"research mysql cluster ndb","""Checkout mysql cluster ndb from the perspective of data distribution - could it be potentially useful to store data related to data distribution?"""
"DM-780","Story","Qserv",5,"Access patterns for data store that supports data distribution ","""Data distribution related data store includes things like. chunk --> node mapping, locations of chunk replicas, runtime information about nodes (and maybe also node configuration?). Need to understand access patterns - who needs to access, how frequently etc. """
"DM-778","Story","Qserv",8,"Restructure and package logging prototype","""Restructure and package log4cxx-based prototype (currently in branch u/bchick/protolog). It should go into package called """"log"""""""
"DM-775","Story","XLDB",8,"XLDB-2015 report","""Writing the report, most work done by Daniel, with input from Jacek and K-T."""
"DM-772","Story","Qserv",2,"Package log4cxx","""Fabrice, can you package log4cxx? I should have asked you earlier, sorry I waited so long, not it becoming urgent! Bill is almost done with his logging prototype and will be turning it into a real package, and we need to have log4cxx packages. Many thanks.  log4cxx version 0.10.0, which was released in 4/3/2008 but is still undergoing """"incubation"""" at Apache. """
"DM-794","Story","Qserv",2,"SQL injection in czar/proxy.py","""Running automated tests for some queries I observe python exceptions in czar log which look like this:   I believe this is due to how query string is being constructed in czar/proxy.py: {code:py} class Lock:      writeTmpl = """"INSERT INTO %s VALUES (%d, %d, '%s', %f);""""  # ...................             self.db.applySql(Lock.writeTmpl % (self._tableName, chunkId, code, msg, timestamp)) {code}  If {{msg}} happens to contain quotes then resulting query is broken. One should not use Python formatting to construct query strings, instead the parameters should be passed directly to {{cursor.execute()}} method. """
"DM-786","Story","Qserv",3,"JOIN queries are broken","""Running a simple query that does a join:    results in czar crashing with:   This query has been taken from integration tests (case01, 0003_selectMetadataForOneGalaxy.sql) """
"DM-783","Story","Qserv",1,"Disable failing test cases in automated tests","""There are currently 4 test cases failing in out automated tests. Until we have a fix we want to disable them."""
"DM-800","Story","Qserv",3,"Zookeeper times out","""I noticed running some queries, leaving system up and them returning few hours later and running more queries can result in:    It needs to be investigated (if we can reproduce) """
"DM-817","Story","Qserv",1,"qserv have to use boost from stack","""To quote Jacek and KT:   So we need to switch qserv to eups-boost. This should be easy once DM-751 is done, just add boost to qserv.table. Then one can remove conditional part of {{BoostChecker}} which works with system-installed boost. """
"DM-814","Story","Qserv",1,"Cleanup in core/examples and core/doc","""- core/examples and core/doc seems to be out of data.  Some cleanup here would be welcome."""
"DM-845","Story","daf_persistence",2,"Eliminate image origin argument from butler for (un)persisting image-like objects","""Eliminate the image origin argument for butler get and put when dealing with image-like objects."""
"DM-843","Story","afw",2,"Restore names of methods that return pixel iterators and locators","""Restore the names of methods that return pixel iterators and pixel locators on image-like classes. (This is part of the final stage of eliminating LOCAL pixel indexing)."""
"DM-841","Story","daf_persistence",2,"Change data butler I/O of image-like objects to require imageOrigin if bbox specified (temporary)","""As part of making PARENT the default for image origin, change the data butler to require that imageOrigin be specified if bbox is specified when reading or writing image-like objects.  Note: this ticket turns out to be unnecessary, as all the few necessary change are done as part of DM-840."""
"DM-840","Story","afw|ip_diffim|meas_algorithms",2,"Change code so ImageOrigin must be specified (temporary)","""Image-like classes have a getBBox method and various constructors that use an ImageOrigin argument which in most or all cases defaults to LOCAL. As the first stage in cleaning this up, try to break code that uses the default as follows: * Remove the default from getBBox(ImageOrigin) so an origin must be specified. * Change the default origin of constructors to a temporary new value UNDEFINED  * Modify code that uses image origin to fail if origin is needed (it is ignored if bbox is empty) and is UNDEFINED.  Note: this is less safe than changing constructors to not have a default value for origin, because the error will be caught at runtime rather than compile time. However, that is messy because then the bounding box will also have to be always specified, and possibly an HDU, so it would be a much more intrusive change."""
"DM-837","Story","meas_base",2,"Rewrite multiple-aperture photometry class","""We've never figured out how to handle wrapping multiple-aperture photometry algorithms.  They can't use the existing Result objects - at least not out of the box.  We should try to write a new multiple-aperture photometry algorithm from the ground up, using the old ones on the HSC branch as a guide, but not trying to transfer the old code over.  The new one should:  - Have the option of using elliptical apertures (as defined by the shape slot) or circular apertures.  - Have a transition radius at which we switch from the sinc photometry algorithm to the naive algorithm (for performance reasons)."""
"DM-833","Story","meas_algorithms|pipe_tasks",3,"implement coaddition for aperture corrections","""We need to be able to coadd aperture corrections in much the same way we coadd PSFs.  See the HSC-side HSC-798 and HSC-897 implementation for a prototype: https://hsc-jira.astro.princeton.edu/jira/browse/HSC-798 https://hsc-jira.astro.princeton.edu/jira/browse/HSC-897 with code here: https://github.com/HyperSuprime-Cam/meas_algorithms/compare/d2782da175c...u/jbosch/DM-798 https://github.com/HyperSuprime-Cam/meas_algorithms/compare/c4fcab3251...u/price/HSC-897a https://github.com/HyperSuprime-Cam/pipe_tasks/compare/6eb48e90be12d...u/price/HSC-897a"""
"DM-832","Story","meas_base",2,"add persistable class for aperture corrections","""We need to create a persistable, map-like container class to hold aperture corrections, with each element of the container being an instance of the class to be added in DM-740.  A prototype has been developed on DM-797 on the HSC side: https://hsc-jira.astro.princeton.edu/jira/browse/HSC-797 and the corresponding code can be found on these changesets: https://github.com/HyperSuprime-Cam/afw/compare/32d7a8e7b75da6f5327fee65515ee59a5b09f6c7...tickets/DM-797"""
"DM-829","Story","meas_base",3,"Algorithm API without (or with optional) Result objects","""In this design prototype, I'll see how much simpler things could be made by making the main algorithm interface one that sets record values directly, instead of going through an intermediate Result object.  Ideally the Result objects would still be an option, but they may not be standardized or reusable."""
"DM-827","Story","pex_exceptions|utils",8,"Reimplement C++/Python Exception Translation","""I'd like to reimplement our Swig bindings for C++ exceptions to replace the """"LsstCppException"""" class with a more user-friendly mechanism.  We'd have a Python exception hierarchy that mirrors the C++ hierarchy (generated automatically with the help of a few Swig macros).  These wrapped exceptions could be thrown in Python as if they were pure-Python exceptions, and could be caught in Python in the same language regardless of where they were thrown.  We're doing this as part of a """"Measurement"""" sprint because we'd like to define custom exceptions for different kinds of common measurement errors, and we want to be able to raise those exceptions in either language."""
"DM-854","Bug","Qserv",8,"duplicate column name when running near neighbor query","""Running a simplified version of near neighbor query on test data from case01:    Result in an error on the worker:    It is fairly obvious what is going on. """"SELECT t1.x, t2.x"""" is perfectly valid, but if we add """"INSERT INTO SELECT t1.x, t2.x"""", we need to add names, eg. something like """"INSERT INTO SELECT t1.x as x1, t2.x as x2"""""""
"DM-863","Bug","Qserv",1,"near neighbor does not return results","""A query from qserv_testdata (case01/queries/1051_nn.sql) runs through Qserv, but it returns no results, while the same query run on myql does return results.  The exact query for qserv is:   """
"DM-869","Story","Qserv",0.5,"disable extraneous warnings from boost (gcc 4.8)","""Compiling qserv on ubuntu 14.04 (comes with gcc 4.8.2) results in huge number of warnings coming from boost. We should use the flag """"-Wno-unused-local-typedefs""""."""
"DM-873","Story","XLDB",3,"XLDB - strategic positioning","""Discussions with strategic partners. Improving website and adding new context (community, speakers). 1-pager document"""
"DM-875","Bug","Continuous Integration",40,"lsst_dm_stack_demo","""lsst-dm_stack_demo has obsolete benchmark files (circa Release 7.0)  which fail to serve the purpose of validating, for the user, the correct functioning of a freshly built Release v8.0 stack.   At the very least,  the benchmark files should be regenerated for each official Release. Tasks:   (1) Build the benchmark files for Release v8.0  (2) Debate (a) recommending the  use of 'numdiff'  to check if the output is within realistic bounds.   Or, (b) develop another procedure to better show how the current algorithms compare to the algorithms used at the benchmarked Release. (3) Depending on result of the debate on #2: for: (a) provide appropriate 'numdiff' command invocation in manual.; for (b) implement the new procedure."""
"DM-874","Bug","Developer Infrastructure",1,"W'14 newinstall.sh picks up wrong python?","""newinstall.sh fails with:  Installing the basic environment ...  Traceback (most recent call last):   File """"/tmp/test_lsst/eups/bin/eups_impl.py"""", line 11, in ?     import eups.cmd   File """"/tmp/test_lsst/eups/python/eups/__init__.py"""", line 5, in ?     from cmd        import commandCallbacks   File """"/tmp/test_lsst/eups/python/eups/cmd.py"""", line 38, in ?     import distrib   File """"/tmp/test_lsst/eups/python/eups/distrib/__init__.py"""", line 30, in ?     from Repositories import Repositories   File """"/tmp/test_lsst/eups/python/eups/distrib/Repositories.py"""", line 8, in ?     import server   File """"/tmp/test_lsst/eups/python/eups/distrib/server.py"""", line 1498     mapping = self._noReinstall if outVersion and outVersion.lower() == """"noreinstall"""" else self._mapping                                  ^ SyntaxError: invalid syntax  Perhaps from running the wrong version of python.  Full script/log is attached. """
"DM-903","Improvement","meas_algorithms",1,"SourceDetectionTask should only add flags.negative if config.thresholdParity == ""both""","""The SourceDetectionTask always adds """"flags.negative"""" to the schema (if provided) but it is only used if config.thresholdParity == """"both"""".  As adding a field to a schema requires that the table passed to the run method have that field this is a significant nuisance when reusing the task.  Please change the code to only modify the schema if it's going to set it. """
"DM-914","Story","ip_diffim",2,"Provide Task documentation for SnapPsfMatchTask","""See summary"""
"DM-913","Story","ip_diffim",2,"Provide Task documentation for ImagePsfMatchTask","""See summary"""
"DM-911","Story","ip_diffim",2,"Provide Task documentation for DipoleMeasurementTask","""See Summary. """
"DM-933","Story","meas_algorithms",1,"Photometric calibration uses a column ""flux"" not the specified filter unless a colour term is active","""The photometric calibration code uses a field """"flux"""" in the reference catalog to impose a magnitude limit.  If a colour term is specified, it uses the primary and secondary filters to calculate the reference magnitude, but if there is no colour term it uses the column labelled """"flux"""" and ignores the filtername.    Please change the code so that """"flux"""" is ignored, and the flux associated with filterName is used."""
"DM-951","Story","Continuous Integration",20,"Add Doxygen documentation on rebuilds","""Master-branch doxygen documentation should be rebuild on every full master build."""
"DM-957","Story","meas_algorithms|meas_base|pipe_tasks",2,"Use aliases to clean up table version transition","""The addition of schema aliases on DM-417 should allow us to clean up some of the transitional code added on DM-545, as we can now alias new versions of fields to the old ones and vice versa."""
"DM-966","Bug","pex_config",2,"fix int/long conversion on 32-bit systems and selected 64-bit systems","""tests/wrap.py fails in pex_config on 32-bit systems and some 64-bit systems (including Ubuntu 14.04) with the following: {code:no-linenum} tests/wrap.py  ...EE.E. ====================================================================== ERROR: testDefaults (__main__.NestedWrapTest) Test that C++ Control object defaults are correctly used as defaults for Config objects. ---------------------------------------------------------------------- Traceback (most recent call last):   File """"tests/wrap.py"""", line 89, in testDefaults     self.assert_(testLib.checkNestedControl(control, config.a.p, config.a.q, config.b))   File """"/home/boutigny/CFHT/stack_5/build/pex_config/tests/testLib.py"""", line 987, in checkNestedControl     return _testLib.checkNestedControl(*args) TypeError: in method 'checkNestedControl', argument 2 of type 'double'  ====================================================================== ERROR: testInt64 (__main__.NestedWrapTest) Test that we can wrap C++ Control objects with int64 members. ---------------------------------------------------------------------- Traceback (most recent call last):   File """"tests/wrap.py"""", line 95, in testInt64     self.assert_(testLib.checkNestedControl(control, config.a.p, config.a.q, config.b))   File """"/home/boutigny/CFHT/stack_5/build/pex_config/tests/testLib.py"""", line 987, in checkNestedControl     return _testLib.checkNestedControl(*args) TypeError: in method 'checkNestedControl', argument 2 of type 'double'  ====================================================================== ERROR: testReadControl (__main__.NestedWrapTest) Test reading the values from a C++ Control object into a Config object. ---------------------------------------------------------------------- Traceback (most recent call last):   File """"tests/wrap.py"""", line 82, in testReadControl     config.readControl(control)   File """"/home/boutigny/CFHT/stack_5/build/pex_config/python/lsst/pex/config/wrap.py"""", line 212, in readControl     __at=__at, __label=__label, __reset=__reset)   File """"/home/boutigny/CFHT/stack_5/build/pex_config/python/lsst/pex/config/wrap.py"""", line 217, in readControl     self.update(__at=__at, __label=__label, **values)   File """"/home/boutigny/CFHT/stack_5/build/pex_config/python/lsst/pex/config/config.py"""", line 515, in update     field.__set__(self, value, at=at, label=label)   File """"/home/boutigny/CFHT/stack_5/build/pex_config/python/lsst/pex/config/config.py"""", line 310, in __set__     raise FieldValidationError(self, instance, e.message) FieldValidationError: Field 'a.q' failed validation: Value 4 is of incorrect type long. Expected type int For more information read the Field definition at:   File """"/home/boutigny/CFHT/stack_5/build/pex_config/python/lsst/pex/config/wrap.py"""", line 184, in makeConfigClass     fields[k] = FieldCls(doc=doc, dtype=dtype, optional=True) And the Config definition at:   File """"/home/boutigny/CFHT/stack_5/build/pex_config/python/lsst/pex/config/wrap.py"""", line 131, in makeConfigClass     cls = type(name, (base,), {""""__doc__"""":doc})   ---------------------------------------------------------------------- Ran 8 tests in 0.017s  FAILED (errors=3) {code}  There is a partial fix on u/jbosch/intwrappers; this seems to work for Ubuntu 14.04, but not on 32-bit systems."""
"DM-964","Story","afw",1,"Include aliases in Schema introspection","""Schema stringification and iteration should include aliases somehow.  Likewise the extract() Python methods."""
"DM-967","Bug","Qserv",1,"qserv-configure.py is broken in master","""It looks like there was a bug introduced either during the merge of DM-622 with master or right before that. Running {{qserv-configure.py}} from master fails now:  I assign this to myself, Fabrice is on vacation now and we need to fix this quickly."""
"DM-982","Story","meas_extensions_photometryKron",3,"convert meas_extensions_photometryKron to new measurement framework","""This is a low-priority ticket to replace the old-style plugins in meas_extensions_photometryKron with new ones compatible with meas_base.  As this isn't a part of the main-line stack, we should delay it until other the meas_base conversion is nearly (or perhaps fully) complete."""
"DM-981","Story","meas_extensions_shapeHSM",3,"convert measurement algorithms in meas_extensions_shapeHSM","""This is a low-priority ticket to replace the old-style plugins in meas_extensions_shapeHSM with new ones compatible with meas_base.  As this isn't a part of the main-line stack, we should delay it until other the meas_base conversion is nearly (or perhaps fully) complete."""
"DM-980","Story","ip_diffim",5,"convert measurement algorithms in ip_diffim","""ip_diffim includes a few measurement algorithms which need to be converted to the new framework."""
"DM-978","Story","meas_base|pipe_tasks",1,"add base class for measurement tasks","""We should consider adding a base class for measurement tasks (SingleFrameMeasurementTask, ForcedMeasuremedTask) that includes the callMeasure methods.  I'm hoping this will help cleanup callMeasure and improve code reuse."""
"DM-977","Story","meas_base",2,"Documentation audit and cleanup for meas_base plugins","""Many meas_base Plugins and Algorithms have poor documentation, including several whose documentation is a copy/paste relic from some other algorithm.  These need to be fixed."""
"DM-976","Story","meas_base",2,"Detailed documentation for meas_base tasks","""We should follow RHL's example for detailed task documentation and document all meas_base tasks."""
"DM-984","Story","meas_base",2,"allow partial measurement results to be set when error flag is set","""We need to be able to return values at the same time that an error flag is set.  The easiest way to do this is to have Algorithms take a Result object as an output argument rather than return it.  We'll revisit this design later. """
"DM-993","Story","Qserv",1,"improve message from qserv_testdata","""Currently, when I try to run qserv-benchmark but qserv_testdata was not setup, I am getting    It is important to note in the section for eups users that this has to be called BEFORE qserv is setup, otherwise it has no effect. """
"DM-991","Story","Qserv",2,"add query involving a blob to the integration tests","""We need to add a query (or more?) to the qserv_testdata that involve blobs. Blobs are interesting because they might break some parts of the qserv if we failed to escape things properly etc. """
"DM-989","Story","Qserv",2,".my.cnf in user HOME directory breaks setup script","""Presence of {{.my.cnf}} file in the user HOME directory crashes {{qserv-configure.py}} script if parameters in {{.my.cnf}} conflict with parameters in {{qserv.conf}}.  How to reproduce: * create .my.cnf file in the home directory:  * try to run {{qserv-configure}}, it fails with error:   It looks like {{~/.my.cnf}} may be a left-over from some earlier qserv installation. If I remove it and re-run {{qserv-configure.py}} now it's not created anymore. Maybe worth adding some kind of protection to {{qserv-configure.py}} in case other users have this file in their home directory."""
"DM-1001","Bug","ip_diffim",1,"Modify assertAlmostEqual in ip_diffim subtractExposures.py unit test","""In unit test, the comparison     self.assertAlmostEqual(skp1[nk][np], skp2[nk][np], 4)   fails.  However if changed to    self.assertTrue(abs(skp1[nk][np]-skp2[nk][np]) < 10**-4)  which is the desired test, this succeeds.   This ticket will remove all assertAlmostEquals from subtractExposure.py and replace with the fundamental comparison operator of the absolute value of the differences."""
"DM-999","Story","Qserv",1,"rename config file(s) in Qserv","""Rename local.qserv.cnf to qserv-czar.cnf. It is quite likely there are some other config files that would make sense to rename. If you see some candidates, let's discussion on qserv-l and do the renames."""
"DM-1004","Story","ip_diffim",2,"Provide Task documentation for ModelPsfMatchTask","""See Description (it's currently called PsfMatch) """
"DM-1017","Bug","meas_base",2,"fix testForced.py","""testForced.py is currently passing even though it probably should be failing: it's trying to get centroid values from a source which has neither a valid centroid slot or a Footprint with Peaks (I suspect because transforming a footprint might remove the peaks).  Prior to DM-976, that would have caused a segfault; on DM-976, I've turned it into an exception, which is then turned into a warning by the measurement framework."""
"DM-1015","Story","meas_base",1,"convert GaussianFlux to use shape, centroid slots","""We should cleanup and simplify the GaussianFlux algorithm to simply use the shape and centroid slot values instead of either computing its own or having configurable field names for where to look these up."""
"DM-1013","Story","meas_base",2,"Classification should set flags upon failure","""The classification algorithm claims it can never fail.  It can, and should report this."""
"DM-1012","Story","meas_base",1,"remove temporary workaround in new SkyCoord algorithm","""SingleFrameSkyCoordPlugin is using the Footprint Peak, not the centroid slot.  According to comments in the code, this is a workaround for some problem with centroids.  This needs to be fixed."""
"DM-1010","Story","meas_base",1,"fix names of meas_base plugins to match new naming standards","""Some meas_base plugins still have old-style algorithm names."""
"DM-1018","Bug","Continuous Integration",2,"Fix incorrect eupspkg config for astrometry_net","""The clang patch from 8.0.0. version was (correctly) deleted. However, the patch identity was still left in the eupspkg config's protocol.  This will delete the last vestige of the formerly necessary clang patch."""
"DM-1022","Story","Qserv",0.5,"fix warnings related to libraries pulled through dependent package","""This came up during migrating qserv to the new logging system, and it can be reproduced by taking log4cxx, see DM-983, essentially:    cloning log package (contrib/log.git), building it and installing in your stack, and finally taking the branch u/jbecla/DM-207 of qserv and building it.  The warnings looks like:    and they show up when I build qserv package, and are triggered by the liblog. I suspect sconsUtils deal with that sort of issues, but since we have our own scons system for qserv it is not handled. Fabrice, can you try to find a reasonable solution for that? Thanks!"""
"DM-1038","Epic","Qserv",40,"S15 Implement Query Mgmt in Qserv","""Initial version of system for managing queries run through qserv. This includes capturing information about queries running in Qserv. Note, we are not dealing with query cost estimate here, (it will be covered through DM-1490)."""
"DM-1029","Bug","Qserv",2,"""source"" command is not in standard shell","""{{qserv-start.sh}} script fails when installed on Ubuntu12.04:   It complains about {{source}} command. {{source}} is not standard POSIX shell command, it is an extension which exists in many shells. Apparently in older Ubuntu version {{/bin/sh}} is stricter about non-standard features.   To fix the script one either has to use standard . (dot) command or change shebang to {{#!/bin/bash}}. This of course applies to all our executable scripts."""
"DM-1028","Bug","Qserv",2,"qserv-version.sh produces incorrect version number","""I have just installed qserv on a clean machine (this is in a new virtual machine running Ubuntu12.04) which got me version 2014_07.0 installed:   but the {{qserv-version.sh}} script still thinks that I'm running older version: """
"DM-1041","Story","pipe_tasks",1,"eliminate confusing config side-effects in CalibrateTask","""CalibrateTask does some unexpected things differently if you configure it certain ways, because it perceives certain processing as only being necessary to feed other steps.  In particular, if you disable astrometry and photometric calibration, it only runs measurement once, because it assumes the only purpose of the post-PSF measurement is to feed those algorithms.  This (as well as poor test coverage) made it easy to break CalibrateTask in the case where those options are disabled a few branches back.  After conferring with Simon and Andy, we think the best solution is to remove this sort of conditional processing from CalibrateTask, which should also make it much easier to read.  Instead, we'll always do both the initial and final phase of measurement, even if one of those phases is not explicitly being used within CalibrateTask itself."""
"DM-1045","Improvement","Continuous Integration",2,"Create a permanent and accessible mapping of the BB# and the bNNN. ","""Create a permanent and accessible mapping of the BB# and the bNNN.   The users are interested in the BB# since is is used to point to the STDIO file form the entire stack build. The bNNN is needed because the daily life of the developer revolves around the stack tagged alternately by the bNNN tags and/or the DM Release tags. """
"DM-1055","Story","Qserv",2,"Remove unnecessary pieces from qserv czar config","""The config file for the qserv czar has some items that are no longer relevant, and in this issue, we focus on the ones that are clearly the responsibility of our qserv css.  This ticket includes: -- removing these items from the installation/configuration templates -- removing these items from sample configuration files -- removing these items from the code that reads in the configuration file and sets defaults for these items -- fixing things that seem to break as a result of this cleanup.  danielw volunteers to assist on the last item, as needed.  """
"DM-1054","Story","Qserv",0.5,"init.d/qserv-czar needs LD_LIBRARY path","""With the addition of log we now need to find some shared libraries from stack. Current version of qserv-czar init.d script does not capture LD_LIBRARY_PATH, so we should add it there. """
"DM-1059","Story","meas_base",2,"track down difference in SdssShape implementation","""The meas_base version of SdssShape produces slightly different outputs from the original version in meas_algorithms, but these should be identical.  We should understand this difference rather than assume its benign just because it's small."""
"DM-1058","Story","afw",1,"fix SubSchema handling of ""."" and ""_""","""SubSchema didn't get included in the rest of the switch from """"."""" to """"_"""" as a field name separator.  As part of fixing this, we should also be able to simplify the code in the slot definers in SourceTable."""
"DM-1077","Story","TCT",2,"Audit TCT recommendations to ensure that all standards updates were installed into Standards documents.","""Audit TCT recommendations to ensure that all standards updates were installed into Standards documents.  It was found that the meeting recorded in: [https://dev.lsstcorp.org/trac/wiki/Winter2012/CodingStandardsChanges] failed to include two recommendations:   * recommended: 3-30: I find the Error suffix to be usually more appropriate than Exception. ** current: 3-30. Exception classes SHOULD be suffixed with Exception.  * recommended but not specifically included: Namespaces in source files: we should use namespace blocks in source files, and prefer unqualified (or less-qualified) names within those blocks over global-namespace aliases. ** Rule 3-6 is an amalgam of namespace rules which doesn't quite have the particulars desired. FYI: The actual vote was to:  """"Allow namespace blocks in source code (cc) files.""""  To simplify the future audit, all other recommendations in that specific meeting were verified as installed into the standards."""
"DM-1076","Story","afw",2,"convert afw::table unit tests to version 1","""Most afw::table unit tests explicitly set version 0.  We should change these to test the new behaviors, not the deprecated ones."""
"DM-1073","Story","pipe_tasks",1,"remove old forced photometry tasks","""After meas_base has been fully integrated, remove the old forced photometry tasks from pipe_tasks"""
"DM-1072","Story","meas_base",1,"create forced wrappers for algorithms","""We have multiple algorithms in meas_base which could be used in forced mode but have no forced plugin.  We should go through the algorithms we have implemented and create forced plugin wrappers for these."""
"DM-1071","Story","ip_diffim|lsst_dm_stack_demo|obs_sdss|pipe_tasks",2,"Switch default measurement tasks to meas_base","""We should set the default measurement task in ProcessImageTask to SingleFrameMeasurementTask, and note that SourceMeasurementTask and the old forced photometry drivers are deprecated."""
"DM-1070","Story","meas_base",2,"switch default table version to 1","""Now that all tasks that use catalogs explicitly set the table version, it should be relatively straightforward to set the default version to 1 in afw.  Code that cannot handle version > 0 tables should continue to explicitly set version=0."""
"DM-1068","Story","meas_base",1,"audit and clean up algorithm flag and config usage","""Check that meas_base plugins and algorithms have appropriate config options and flags (mainly, check that there are no unused config options or flags due to copy/paste relics)."""
"DM-1067","Story","meas_base",1,"move algorithm implementations out of separate subdirectory","""We should move the code in the algorithms subdirectory (and namespace) into the .cc files that correspond to individual algorithms.  They should generally go into anonymous namespaces there.  After doing so, we should do one more test to compare the meas_base and meas_algorithms implementations."""
"DM-1083","Story","afw",1,"Fix overload problems in SourceCatalog.append and .extend","""This example fails with an exception: {code:py} import lsst.afw.table as afwTable schema = afwTable.SourceTable.makeMinimalSchema() st = afwTable.SourceTable.make(schema) cat = afwTable.SourceCatalog(st) tmp = afwTable.SourceCatalog(cat.getTable()) cat.extend(tmp) {code}  Expected behavior is that the last line is equivalent to {{cat.extend(tmp, deep=False)}}."""
"DM-1088","Story","Middleware",2,"Investigate HTCondor config settings to control speed of ClassAd propagation","""With default settings we do not have good visibility as to whether an updated ClassAd on a compute node (e.g., CacheDataList now has ccd """"S00"""") will be in effect on the submit node in time for a Job to be matched to an optimal HTCondor node/slot.   There are several components (negotiator, schedd, startd) and their associated activities that could impact the time that it takes for a new ClassAd on a worker node to 'propagate' back to the submit side. We investigate these configuration settings to try to determine what thresholds for configuration settings are required to meet a given time cadence of job submissions."""
"DM-1113","Epic","ip_isr",20,"Make the API for ISR explicit","""The run method of the IsrTask currently takes a dataRef which has getters for calibration products.  This makes the task hard to re-use because one needs a butler and because the interface is opaque.  This task will make the IsrTask API more transparent.  JK: In PMCS this would be Krughoff S"""
"DM-1143","Epic","Test Data",40,"Investigate candidates for Verification and Integration Data Sets","""The task here is to develop a data set that can be used both for continuous integration (build tests) and automatic QA (integration tests). We want to maximise the richness of the data set in terms of its usefulness, but minimise it in terms of its size. DN to co-ordinate contributions.     [DN 95%  FE 5%]"""
"DM-1138","Epic","Developer Infrastructure",5,"Demonstrate & iterate with team on documentation toolchain   ","""Following from DM-1137, this epic relates to demonstrating various options for documentation tools workflows to the team, gathering input as to the preferred solution, adopting a workflow, and defining any specific implementation choices.   This is part of curating our documentation infrastructure. """
"DM-1137","Epic","Developer Infrastructure",20,"Evaluate python/c++ documentation generation and publication tools ","""This epic related to documentation that is provided as part of normal development activities. The desire is to keep this documentation in and near the codebase as this is best practice for it being maintainable. At the other end, we wish to publish this documentation in a coherent and searchable way for users. A number of tools exist in this area and this item requires a preliminary evaluation to be made.   This is part of curating our documentation infrastructure.  [FE 75% DOC 100% starting August 20th] """
"DM-1135","Story","meas_modelfit",20,"test how large pixel region used in galaxy fitting needs to be","""Using simulations built on DM-1132 and driver code from DM-1133, test different pixel region sizes and shapes, and determine at what point shear bias due to finite fit region drops below a TBD threshold."""
"DM-1126","Story","afw",8,"design new Footprint API","""This issue is for *planning* (not implementing) some changes to Footprint's interface, including the following:  - make Footprint immutable  - create a separate SpanRegion class that holds Spans and provides geometric operators does not hold Peaks or a """"region"""" bbox (Footprint would then hold one of these).  - many operations currently implemented as free functions should be moved to methods  - we should switch the container from vector<PTR(Span)> to simply vector<Span>, as Span is nonpolymorphic and at last as cheap to copy as a shared_ptr.  The output of this issue will be a set of header files that define the new interface, signed off by an SAT design review.  Other issues will be responsible for implementing the new interface and fixing code broken by the change."""
"DM-1125","Story","meas_algorithms",3,"avoid usage of measurement framework in star selectors","""At least one of the star selectors uses the old measurement framework system to measure the moments of a cloud of points.  With the new versions of all the measurement plugins, it should be much easier (and cleaner) to just call the SdssShape algorithm directly, instead of dealing with the complexity of applying the measurement framework to something that isn't really an image."""
"DM-1152","Story","Qserv",2,"Css C++ client needs to auto-reconnect","""The zookeeper client in C++ that the czar uses doesn't auto-reconnect. This is a capability provided in the kazoo library that qserv's python layer provides, but isn't provided in the c++ client.  The zookeeper client disconnects pretty easily: if you step through your code in gdb, the zk client will probably disconnect because its threads expect to keep running. zk sessions may expire too. Our layer should reconnect unless there is really no way to recover without assistance from the calling code (e.g. configuration is wrong, etc.).  This ticket includes only basic reconnection attempting, throwing an exception only when some """"reconnection-is-impossible"""" condition is met."""
"DM-1151","Story","ip_isr",2,"Fix example of IsrTask to be callable with data on disk","""Currently the example of the IsrTask takes a fake dataref.  This is hard to use with real data.  In DM-1113 we will update IsrTask to not take a dataRef.  This will make it easy to update the example script to work with real data.  This ticket will also include removing from the unit tests any fake dataRefs that have become unnecessary as a result of DM-1299.  """
"DM-1147","Story","Qserv",2,"Create a top-level qserv_distrib package","""qserv_distrib will be a meta-package embedding qserv, qserv_testdata and partition."""
"DM-1160","Epic","SUIT",20,"SUI catalog and image interactive visualization with LSST data","""Using the current software components developed in IPAC to put together a prototype of visualization capabilities. The purpose is to exercise the data access APIs developed by SLAC and get feedback from DM people and potential users of the tool.  20% Goldina, Zhang 10% Roby, Ly, Wu, Ciardi """
"DM-1161","Story","meas_base",8,"Cleanup SdssShape","""We should do a comprehensive cleanup of the SdssShapeAlgorithm class.  This includes removing the SdssShapeImpl interface (never supposed to have been public, but it became public) from other code that uses it, and integrating this code directly into the algorithm class.  We should also ensure that the source from which the algorithm is derived is clearly cited -- that's Bernstein and Jarvis (2002, http://adsabs.harvard.edu/abs/2002AJ....123..583B); see also DM-2304."""
"DM-1188","Story","shapelet",2,"rewrite low-level shapelet evaluation code","""While trying to track down some bugs on DM-641, I've grown frustrated with the difficulty of testing the deeply-buried (i.e. interfaces I want to test are private) shapelet evaluation code there.  That sort of code really belongs in the shapelet package (not meas_multifit) anyway, where I have a lot of similar code, so on this issue I'm going to move it there and refactor the existing code so it all fits together better."""
"DM-1197","Improvement","afw",2,"Support some mixed-type operations for Point and Extent","""The current lack of automatic conversions in python is pretty irritating, and I think it's a big enough issue for people writing scripts that we should fix it.  In particular, allow  (and the respective operations in the opposite order where well defined) It would also be good to allow the all functions expecting PointD to accept PointI, but I'm not sure if swig makes this possible.  It's probably not worth providing C++ overloads for all of these functions (and to be consistent we should probably do all or none).  I realize that you invented these types to avoid bare 2-tuples, but I'm not convinced that we shouldn't also provide overloads to transparently convert tuples to afwGeom objects."""
"DM-1196","Story","ip_isr",1,"exampleUtils in ip_isr is wrong about read corner","""https://dev.lsstcorp.org/cgit/LSST/DMS/ip_isr.git/tree/examples/exampleUtils.py#n95 Says that the read corner is in assembled coordinates.  This is not true, it is in the coordinates of the raw amp.  That is, if the raw amp is in electronic coordinates (like the lsstSim images) it is always LL, but if it is pre-assembled, it may be some other corner.  This should probably use the methods in cameraGeom.utils to do the image generation."""
"DM-1195","Story","obs_cfht",1,"There is a bug in the prescan bbox for megacam.","""The bounding box of the prescan region in the megacam camera should have zero y extent (I think).  Instead it goes from y=-1 to y=2.  This is either a bug in the generation of the ampInfoTables or in the way the bounding boxes are interpreted."""
"DM-1192","Epic","Developer Infrastructure",20,"Write a transition plan to move gitolite and Stash repositories to GitHub","""As recommended by the SAT meeting on 2014-09-16, we need this document to promote the use of GitHub by other subsystems within the project and to understand the impacts on DM.  The plan should include, but is not limited to: * Whether and how the repositories should be reorganized. * How existing commit attributions will be translated. * Moving comments in Stash to GitHub"""
"DM-1213","Story","Qserv",1,"cleanup order/grouping of header files","""We want: * header for the class * then system * then third party * then lsst * then qserv  We currently don't have the """"lsst"""" group (with a few exceptions), and we call the last one """"local"""" in most places."""
"DM-1211","Story","Third Party Software",2,"anaconda is too outdated to work with pip","""The version of anaconda distributed with the stack is too outdated to be used with pip (and probably other things). The issue is an unsafe version of ssh.  A workaround is to issue this command while anaconda is setup:  Warning: it is unwise to try to update anaconda itself (with """"conda update anaconda"""") because that will revert some of the changes and may result in an unusable anaconda.  I think what is required is an obvious change to ups/eupspkg.cfg.sh  The current version of anaconda is 2.0.1 based on http://repo.continuum.io/archive/  Note: there is no component for anaconda. I will submit another ticket."""
"DM-1218","Story","afw|lsst_dm_stack_demo|meas_algorithms|meas_base|obs_sdss|pex_config|pipe_tasks",2,"Support multiple-aperture fluxes in slots","""We should be able to use multiple-aperture flux results in slots.  While this is technically possible already by setting specific aliases, it doesn't work through the usual mechanisms for setting up slots (the define methods in SourceTable and the SourceSlotConfig in meas_base).  After addressing this, we should remove the old SincFlux and NaiveFlux algorithms, as the new CircularApertureFlux algorithm will be able to do everything they can do."""
"DM-1217","Story","meas_base",3,"Refactor meas_base Python wrappers and plugin registration","""meas_base currently has a single Swig library (like most packages), defined within a single .i file (like some packages).  It also registers all of its plugins in a single python module, plugins.py.  Instead, it should:  - Have two Swig libraries: one for the interfaces and helper classes, and one for plugin algorithms.  Most downstream packages will only want to %import (and hence #include) the interface, and having them build against everything slows the build down unnecessarily.  The package __init__.py should import all symbols from both libraries, so the change would be transparent to the user.  - Have separate .i files for each algorithm or small group of algorithms.  Each of these could %import the interface library file and the pure-Python registry code, and then register the plugins wrapped there within a %pythoncode block.  That'd make the implementation of the algorithms a bit less scattered throughout the package, making them easier to maintain and better examples for new plugins."""
"DM-1254","Story","Data Archive",5,"Metadata Store - design v1","""Research potential off-the-shelf candidates. Propose initial version of metadata design. """
"DM-1251","Story","Qserv",3,"CSS design for query metadata v1","""The goal of this ticket (and DM-1250) is to try to understand what kind of per-query metadata is necessary to provide client-transparent query processing in case when czar/proxy could die or be restarted.  Some relevant info is in the Trac: https://dev.lsstcorp.org/trac/wiki/db/Qserv/CSS/RunTimeState"""
"DM-1245","Story","Qserv",3,"Install scisql plugin (shared library) outside of eups stack.","""sciSQL plugin is currently deployed in eups stack (i.e. $MYSQL_DIR/lib/plugin) during configuration step. Nevertheless eups stack should be immutable during configuration step.  MySQL plugin-dir option may allow to deploy sciSQL plugin outside of eups stack (for example in QSERV_RUN_DIR)."""
"DM-1242","Epic","Systems Engineering",3,"Risk Register refresh 1/2015","""Periodic review of DM risk register contents.  Covers preparation for a review expected at the end of January 2015, the only one during Winter 2015."""
"DM-1237","Epic","Systems Engineering",8,"LSE-75: Refine WCS and PSF requirements","""Clarify the data format and precision requirements of the TCS (or other Telescope and Site components) on the reporting of WCS and PSF information by DM on a per-image basis.  Depends on the ability of the T&S group to engage with this subject during the Winter 2015 period.  Can be deferred to Summer 2015 without major impacts.  Current PMCS deadline for Phase 3 readiness of LSE-75 is 29-Sep-2015."""
"DM-1233","Epic","Systems Engineering",20,"Refine requirements and use cases for Level 3 facilities","""Refine the requirements and use cases for the three branches of Level 3 capabilities exposed to users:  * Level 3 programming toolkit (user reconfiguration / extension of DM pipelines and stack)  * Level 3 compute cycle delivery (user access to 10% of compute base)  * Level 3 data product storage    Deliverables:  * Refinement, if necessary, to Level 3 requirements in DMSR  * Flowed-down requirements as a separate document.  Sufficient detail to allow a breakdown of the deliverables in the three areas of Level 3 by annual release cycle through construction period."""
"DM-1232","Epic","Systems Engineering",3,"LSE-72: Bring Summer 2014 work to CCB approval","""Remaining work is to proofread the SysML-ization by Brian Selvy of the LSE-72 draft, do any required cleanup in conjunction with the OCS team, and advocate for LCR-202 (already exists) at the CCB."""
"DM-1231","Epic","Systems Engineering",0,"LSE-69: Bring to Phase 3","""Reflects work needed in Summer 2015"""
"DM-1285","Story","Middleware",2,"Improve Startup of HTCondor Jobs","""Adjust configuration parameters of HTCondor config and/or submission files to improve speed at which HTCondor jobs start in both the replicator pool and worker pool."""
"DM-1282","Story","afw",2,"multi-level replacement in Schema aliases","""Schema aliases should support more than one level (i.e. an alias may resolve to another alias)."""
"DM-1281","Story","afw",1,"add Schema method to join strings using the appropriate delimiter","""Delimiters in Schema field names are version-dependent.  One can currently use {{schema[""""a""""][""""b""""].getPrefix()}} to join fields using the appropriate delimiter, but this is confusing to read."""
"DM-1293","Story","pipe_tasks",8,"Implement designed tests for processCcd","""Implement the designed tests with the installed data."""
"DM-1287","Story","Qserv",2,"Propose and document a recipe to build Qserv in eups","""In-place build is available and documented."""
"DM-1305","Story","shapelet",1,"Tests fail in shapelet when building on OS X 10.9","""When building the master on pugsley.ncsa.illinois.edu, shapelet builds successfully, but two tests fail:    ===============  More info on pugsley.ncsa.illinois.edu:   pugsley:lsstsw mjuric$ sw_vers  ProductName: Mac OS X  ProductVersion: 10.9.5  BuildVersion: 13F34   pugsley:lsstsw mjuric$ clang -v  Apple LLVM version 5.1 (clang-503.0.40) (based on LLVM 3.4svn)  Target: x86_64-apple-darwin13.4.0  Thread model: posix  ============  The files are in {{/Users/mjuric/test/lsstsw/build/shapelet/}}."""
"DM-1335","Story","Middleware",2,"Create instance with a Floating IP Associated through the nova CLI","""We see that in working with the Horizon GUI, it is fairly straightforward to give an instance a public IP address by associating a Floating IP with the current local IP.    However, we will want to be able to accomplish this task both remotely and programmatically within workflow.  As a step towards this, we target the solution of this via the nova CLI."""
"DM-1334","Story","Middleware",1,"Test the creation of basic OpenStack instances on the new ISL testbed [IceHouse]","""A new version & implementation of the ISL OpenStack testbed is up and running. The new cloud is using IceHouse, the ninth OpenStack release. We get started on this platform by verifying that basic instance creation is working.  We target the creation of an instance through the (Horizon) GUI interface,  and via the nova CLI. """
"DM-1333","Story","meas_base",2,"resolve factor of two difference in GaussianFlux","""After changing the implementation of GaussianFlux to use the shape slot rather than estimate the shape itself by re-running the SdssShape code, Perry saw a 5-15% difference in the fluxes (I'm not sure of the sign).  The new behavior (using the shape) is consistent with what we'd have gotten with the old code when the little-used """"fixed"""" config option was enabled (not surprising, as that just looked up the SdssShape measurement by name, instead of via slots).  I suspect the difference is coming in because of the factor of two between SdssShape's """"raw"""" measurements - the actual Gaussian-weighted moments - and the factor of 2 it applies to make its measurements equivalent to ideal unweighted moments.  The correct weight function to use for GaussianFlux includes this factor of 2 (i.e. it's larger than the """"raw"""" moments), and it's likely either the old code wasn't including this or the new code isn't.  We need to determine which one, and if necessary, fix the new code."""
"DM-1332","Story","meas_base",2,"address no-shape warnings in GaussianFlux","""GaussianFlux relies on the shape slot, and puts noisy warnings in the logs when the shape slot fails.  However, we probably don't want to add a new flag for GaussianFlux to indicate this failure mode, because it'd be entirely redundant with the shape slot flag.  We should figure out some other way to squash this warning - how we do that may depend on whether this is addressed before or after the C++ redesign.  We should also consider having GaussianFlux add an alias to the schema to point back at the shape slot flag, creating what looks like a specific flag for this failure while actually just being a link back to the shape slot flag.  That's probably not worth doing within the current C++ interface, however, as it'd require some unpleasant mucking around with ResultMappers."""
"DM-1331","Story","meas_base",1,"squash edge errors in SdssCentroid","""SdssCentroid doesn't trap exceptions that are thrown due to being too close to the edge, resulting in noisy warnings in the logs.  Instead, it should catch the low-level exception and re-throw as MeasurementError, after defining a flag field for this specific failure mode."""
"DM-1318","Story","lsst_dm_stack_demo|meas_base",1,"update expected results file in SDSS demo test","""Update the expected outputs in the SDSS DM stack demo repo to match what we expect from the new meas_base framework."""
"DM-1317","Story","Middleware",2,"Create Docker Image / Dockerfile for LSST Stack for ubuntu","""Create an installation of the LSST Stack v9_2  within a Docker Image for ubuntu for easing the import of LSST software into an OpenStack instance,  We create  the image utilizing a Dockerfile to make systematic  the creation of such images. """
"DM-1316","Story","Middleware",1,"Deploy LSST stack within OpenStack instances on ISL testbed","""Deploy the LSST Stack within OpenStack instances within the ISL testbed -- this could be for multiple flavors CentOS, Ubuntu, etc, and this could be done by pulling Docker Images to the instances.   There will also likely be some initial debugging of starting instances within the ISL platform as a new installation has been stood up Sept 2014. """
"DM-1314","Story","Qserv",0.5,"Publish Qserv S14 version on lsst distribution server","""In order to publish this version please tag Qserv master tip with """"2014_09.0"""" and then run: {code:bash} ssh lsstsw@lsst-dev # command below can't be runned in buildbot, as it doesn't support qserv_distrib build rebuild -t 2014_09.0 qserv_distrib # bXXX is provided by previous command publish -t qserv -b bXXX qserv_distrib publish -t 2014_09 -b bXXX qserv_distrib {code} """
"DM-1313","Story","Systems Engineering",2,"Identify Conditions information in LSE-130 that is required for Alert Production","""LSE-69 declares that there are two categories of Conditions data (telemetry) required by DM from the Camera: those items that are needed for Alert Production (for which the AP components at the Base will need a whitelist, and for which the Camera has a tighter latency requirement), and those that are not (but are then presumably needed in DRP or other deferred productions).  It states that the subset needed for AP should be enumerated in LSE-130.  The action here is to create an initial version of that list."""
"DM-1312","Story","Systems Engineering",2,"Proofread docgen'ed version of LSE-72","""Brian Selvy is producing a SysML version of the LSE-72 updated edited by [~gpdf].  The action here is to proofread the docgen of that version once it is ready."""
"DM-1311","Story","Systems Engineering",1,"Enter LSE-69 update into EA as SysML","""Covers entering the contents of the LSE-69 update into EA as SysML, with associated updating of diagrams, and the creation of a docgen'ed version for CCB action."""
"DM-1310","Story","Systems Engineering",1,"Create change request for LSE-69","""Create a change request to bring LSE-69 up to date and capture the Summer 2014 work."""
"DM-1309","Story","Systems Engineering",3,"Edit agreed-upon changes into Word version of LSE-69","""A meeting around 9/26/2014 agreed on a set of revisions to LSE-69, with some language still needed from [~gpdf].  This action is to edit the tracked-changes Word version of LSE-69 containing the notes from that meeting into a final copy that can be reviewed by the Camera team and used as input to editing the SysML version of the ICD."""
"DM-1352","Story","Middleware",8,"ORIGINATORID value can churn too quickly.","""The ORIGINATORID is a 64-bit word consisting of an IPv4 host address, 16-bit process id, and 16-bit local value.   In addition to the 16-bit process id not being standard across platforms (Mac OS >Leopard goes to 99999), the churn rate for the local value should be much higher than just 16 bits.  This could be fixed to changing ORIGINATORID to a 32-bit process id and a separate value for the local value, which would be specified together in the DM event selector.   I have to look into this more to see if this is a viable solution.  This might need to go to three separate values to future proof it (i.e., ipv6)."""
"DM-1348","Story","Middleware",5,"Update tests to use unit test framework","""The tests for this package predate the unit test framework that other package use.  Update the tests to uses the unit test framework and get rid of any duplicate  or obsolete tests."""
"DM-1347","Story","Middleware",2,"Refine Event base class to allow ActiveMQ filterable settings","""The current Event.cc base class needs to be refined to remove and old-style data release terms that aren't used anymore.  Plus, it needs to be easily extensible to allow other types of dictionaries of terms that will be used in the message headers to make them filterable on the server side."""
"DM-1343","Story","Middleware",2,"Write Unit test for new DM message appender class","""Write unit tests for DM message appender class.  This might also require some tests for a configurator class, if that class is created."""
"DM-1340","Story","Middleware",2,"Read through log4cxx documentation and log.git code","""Read through the log4cxx documentation and become familiar with how the log.git package is set up."""
"DM-1355","Story","Qserv",3,"Re-arrange how Qserv directories are installed","""we already touched question about installation directory structure at a meeting, maybe we can improve things by re-arranging how things are installed      we are currently installing stuff into four directories: cfg, bin, lib, proxy     to make it look more standard and to avoid clash with qserv source directories we could move cfg and proxy to a different location (something like share/qserv to make it more root-install-friendly in case we ever want to install under /usr)     this change (if you want to do it) deserves separate ticket, do not do it in this ticket """
"DM-1354","Story","Middleware",2,"Install docker 1.1.2 in an ISL OpenStack CentOS  instance, perform basic checks","""Install docker 1.1.2 in an ISL OpenStack CentOS 6.5 instance, and perform  basic checks such stopping and starting the docker daemon, changing default settings such as size limit of containers/images,  pulling  standard images from docker hub, starting containers from these images, etc. """
"DM-1362","Story","Systems Engineering",2,"Edit pull interface and other Summer 2014 work into LSE-68 in Word","""Deliverable: circulate a Word-based draft of LSE-68 in which the """"push"""" interface is removed, and the """"pull"""" interface is refined to include the guider and other Summer 2014 work.  Note that the use of """"pull"""" for the guider applies whether or not the proposed guider redesign is accepted."""
"DM-1360","Story","Qserv",1,"Fix minor loose ends from new result plumbing","""Some of the more minor issues raised in comments from DM-199 were left undone prior to merging. This ticket addresses them.  For more information, please see:  https://github.com/LSST/qserv/pull/2 . """
"DM-1358","Bug","buildbot",2,"End-to-end demo  fails to exit with the correct status  when Warning would be correct.","""The output  of demo2012 results in an output file which is compared against a benchmarked file. Currently the comparison allows a deviation from the benchmark based """"on the the number of digits in the significands used in multiple precision arithmetic"""";  that  number is currently set to 11.  An example using that setting is: @ Absolute error = 5.9973406400e-1, Relative error = 9.1865836000e-4 ##2566    #:25  <== 29.7751550737 ##2566    #:25  ==> 29.7478269835  Additionally, the current use returns: a 'Fatal' error if the code itself fails to execute correctly; a """"Warning' error if the any of the benchmarked quantities do not meet the comparison criteria; 'Success' if the comparison meets all criteria.  It is noted that the buildbot 'Warning' color indicator is not currently being displayed when the comparison fails. That is a coding error.  This Issue will: * ensure that BUILDBOT_WARNING(S) causes the correct display color when appropriate.   This Ticket has been split into two parts. This is part 1.  Part 2 is DM-1379 """
"DM-1364","Story","meas_base",3,"replace ""bad data"" flag in SdssCentroid","""SdssCentroid has a """"bad data"""" flag that doesn't actually convey any information about what went wrong.  This should be replaced with one or more flags that provide more information."""
"DM-1363","Story","Qserv",2,"Avoid use of ~/.my.cnf (used by css watcher)","""See https://jira.lsstcorp.org/browse/DM-1258?focusedCommentId=29230&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-29230.  {{~/.my.cnf}} is used by css watcher, an optional tool used for monitoring css. It is a symlink to $QSERV_RUN_DIR/etc/my-client.cnf.  The css watcher could use MySQL credentials located in ~/.lsst/qserv.conf (used by integration tests wich are a Qserv/MySQL client)"""
"DM-1376","Story","partition|Qserv",2,"Ensure that the partition package is C++11 clean and compiles on OSX 10.9","""The LSST buildbot infrastructure recently changed to building everything with --std=c++0x, which broke the partition package, and hence automated Qserv builds. While debugging this, I discovered that the partition package does not build on OSX 10.9, and considering how minimal its dependencies are, it really should. The OSX issue can be fixed by avoiding {{using boost::make_shared}}.  The partition package should be cleaned up to avoid all use of {{using}}. If we decide to use C++11 in Qserv, then the codebase should also be modernized (in particular, there are use-cases for static_assert, nullptr, etc... ). """
"DM-1375","Story","Middleware",2,"Create Docker Image / Dockerfile for LSST Stack for CentOS6.5","""Make a Dockerfile for systematic generation of docker images using a Centos6.5 base image  containing the LSST Stack (v9_2 at the moment) and library dependencies."""
"DM-1372","Bug","skymap",0.5,"Errors in testHealpixSkyMap.py","""There is a failing unit test when healpy is supplied.  The problem is that the method boundary is not defined in the version of healpy we supply for the sims, however boundaries does exist.  If I replace boundary with boundaries, the test passes."""
"DM-1388","Story","Systems Engineering",2,"Submit LCR for LSE-68","""Create an LCR, including a summary of changes, for LSE-68."""
"DM-1387","Story","meas_deblender",5,"Generate a master list of Objects given detections in multiple bands/epochs","""Once we've detected Sources in multiple bands we need to merge the positions to generate Objects.  This is a little complicated (or at least messy):  - The positions have errors  - If the seeing is different in different visits, objects may be blended in some but not all exposures  - If we use more than one detection pass (e.g. smoothing when looking for faint objects, not smoothing for bright) this has similar-but-different consequences (but we should probably deal with in the per-band processing)  - Objects move, so even if the positions are within the errors the motion may still be detectable """
"DM-1386","Story","afw|meas_deblender",5,"Merge Footprints from different bands/epochs","""The current concept of the deblender assumes that the inputs are  - A merged set of Footprints that define which pixels are part of the blend  - A merged set of Peaks within that merged Footprint  Please generate these merged Footprints (which will be defined in (x, y) coordinates in the tract/patch coordinate system). """
"DM-1394","Bug","buildbot",2,"Eups 1.5.4 requires each new shell to source the eups setups.sh","""eups v 1.5.4 requires each new shell to source ...eups/../bin/setups.sh.  This requires the buildbot scripts: runManifestDemo.sh, create_xlinkdocs.sh, be updated to individually  do that task.  Add  demo2012: bin/demo.sh . """
"DM-1396","Story","css|Qserv",2,"Design CSS schema to support database deletion","""Need to implement deleting databases. Deliverable: a design of the system that will be capable of deleting a distributed database including all copies of that database on all workers, all replicas of all chunks are deleted. It should be possible to """"create database x"""" at any time later."""
"DM-1404","Story","Middleware",2,"Create suite of Dockerfiles / docker images for LSST Stack for ubuntu, CentOS","""Building on issues DM-1317 and DM-1375 where initial images and Dockerfile's were constructed, we can now use these Dockerfile's as prototypes to extend the set of Dockerfiles & images.  We observe that by making  simple (scriptable) edits to the initial Dockerfile, we can run 'docker build' to make docker images for several combinations of OS and base compiler gcc version."""
"DM-1407","Bug","Qserv",0.5,"Add return code for integration tests","""Integration test have to returns non-zero when failing. This will ease use of CI or debugging tools ({{git bisect}}, buildbot)."""
"DM-1424","Story","Middleware",1,"Create persistent volume of Cinder block storage and attach to instance","""We create a persistent volume of Cinder block storage and attach to working instance.  When it was created, the instance does have a specified amount of ephemeral disk, but this disk will be destroyed with the instance.  We want to test that we can create a persistent volume of block storage, attach it to an instance, format the storage with a file system, and mount the volume for use with processing, where data/output can be retained after the instance is destroyed. """
"DM-1431","Story","Middleware",2,"Process sample sdss data with LSST Stack in a Docker container in OpenStack","""Process sample sdss data, starting with the lsst_dm_stack_demo, with LSST Stack in a Docker container in an OpenStack instance. """
"DM-1443","Story","Developer Infrastructure",1,"Github Transition: pull request discussion, retention - proof of concept","""Store review comments / PR discussion into relevant git repositories  Code & process to do this on a continuous basis post-transition will be a different issue, """
"DM-1440","Story","Developer Infrastructure",3,"Github Transition: Naming conventions for repositories","""The Simulations team has requested that repos in general and the numerous DM repos in particular are prefixed in a way that would make fitering them out of searches and display easy (for example, their repos are prefixed sims_*)  This would be an evident useability aid to DM developers and outside contributors too.   Obtain a decision on how to allow users to quickly isolate repositories they are interested in. """
"DM-1439","Story","afw",1,"afw tests use the same name for a dummy file: test.fits","""The afw package  uses a file named: test.fits in multiple testers.  If the user sets up the build to use multiple CPU (-j #), then there is the risk that the shared filename will be affected by more than one tester at a time.   In the case which provoked this Issue, the tester: testSimpleTable.py, reported that the file was missing.  A simple rerun managed to get past the error.  I recommend that the different testers use uniquely named demo files."""
"DM-1434","Story","Middleware",13,"State diagram for jobs in progress","""Build a state diagram showing job progress throughout a run."""
"DM-1448","Improvement","afw|ip_isr",1,"Move code for mock images into afw so it reusable.","""There is some code in the exampleUtils in $IP_ISR_DIR/examples that could be of wider use.  Specifically there is code to generate mock darks, flats, and raw data from a mock camera.  There is also code to generate a mock dataRef.  It could be used more widely if moved someplace else.  Russell suggested afw.cameraGeom.utils."""
"DM-1444","Story","Middleware",2,"Test absence of individual components","""Test absence of individual components of the AP simulator.  Bring each down, run the system, and restart just those components to see if the system still operates as expected"""
"DM-1463","Story","meas_base",1,"SdssShape shiftMax config item is being ignored","""The code we ported from meas_algorithms sets the maxShift to 2 without regard to the config item which is supposed to set that value."""
"DM-1462","Story","meas_base",1,"Add NaN check to PixelFlags","""The test of PixelFlags in measureSources.py (from measAlg) requires a check to be sure that the center inputs are not NaN."""
"DM-1461","Story","meas_base",3,"C++ Redesign -- Result definition for custom algorithms","""Additions to Jim's redesign to make it easier to define custom results."""
"DM-1469","Story","Developer Infrastructure",1,"Github Transition Plan: Reverse mirror for beta-tester repositories","""Test the reverse mirror for beta-testers.  Straw man:  1. Break the mirror for anybody beta-testing github workflow 2. Mirror back to new gitolite area: """"mirror"""")  Method:  https://help.github.com/articles/duplicating-a-repository/  """
"DM-1464","Story","meas_base",1,"Design Review prep for C++ redesign","""Write up the design developed on DM-829 and push it through review."""
"DM-1475","Bug","Qserv",0.5,"Fix 2014_09 documentation","""Replace {{NEWINSTALL_URL=http://sw.lsstcorp.org/pkgs/}} with: {{NEWINSTALL_URL=http://sw.lsstcorp.org/eupspkg/}}  and {{eups distrib install qserv_distrib 2014_10.0}} with:  {{eups distrib install qserv_distrib -t 2014_10}}"""
"DM-1481","Story","SUIT",20,"Discover/learn what others are doing in astronomy software","""Attend the annual  ADASS conference to keep up with the software development in the astronomy community.  Trey Roby, Tatiana Goldina, Xiuqin Wu plan to attend the ADASS 24."""
"DM-1480","Bug","buildbot",3,"Buildbot master takes exception when exiting from mail notifier after dynamic email sent.","""Buildbot master exits without posting the required statically-addressed email notification if a dynamically-addressed was sent.   This fix needs to ensure that the required (by buildbot specification) static email is sent even if it has to be directed to a dead-letter box (which it is)."""
"DM-1498","Story","Qserv",5,"Package Qserv master and worker instance in Docker","""Learn Docker basics and then package a Qserv mono-node instance."""
"DM-1497","Story","Qserv",5,"Package Qserv mono-node instance in Docker","""Learn Docker basics and then package a Qserv mono-node instance."""
"DM-1506","Bug","Qserv",0.5,"Support new version of newinstall.sh","""newinstall.sh now creates loadLSST.bash instead of loadLSST.sh. This has to be taken in account in Qserv automated install script: qserv-install.sh and in Qserv documentation."""
"DM-1505","Story","pex_config",1,"confusing error message when enabling unregistered items in RegistryField","""pex_config seems to split out this confusing error message when trying to enable (i.e. append to .names) a registry item that doesn't exist: {code:hide-linenum}   File """"/home/lam3/tigress/LSST/obs_subaru/config/processCcd.py"""", line 51, in <module>     root.measurement.algorithms.names |= [""""jacobian"""", """"focalplane""""]   File """"/tigress/HSC/LSST/lsstsw/anaconda/lib/python2.7/_abcoll.py"""", line 330, in __ior__     self.add(value)   File """"/tigress/HSC/LSST/lsstsw/stack/Linux64/pex_config/9.0+26/python/lsst/pex/config/configChoiceField.py"""", line 72, in add     r = self.__getitem__(value, at=at) AttributeError: 'SelectionSet' object has no attribute '__getitem__' {code}"""
"DM-1515","Story","sconsUtils",1,"sconsUtils fails to identify Ubuntu's gcc","""On Ubuntu 12.04, gcc --version says: {code:hide-linenum} gcc (Ubuntu/Linaro 4.6.3-1ubuntu5) 4.6.3 Copyright (C) 2011 Free Software Foundation, Inc. This is free software; see the source for copying conditions.  There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.   Happily, everything seems to work anyway, as the fall-back options for the unknown compiler work fine with this one."""
"DM-1514","Story","afw",1,"calling extend with a SchemaMapper should support positional arguments","""Calling {{catalog.extend(other, mapper)}} isn't equivalent to {{catalog.extend(other, mapper=mapper)}} because the second argument is the boolean {{deep}}.  When a SchemaMapper is passed as the second argument, we should recognize it for what it is."""
"DM-1529","Story","Middleware",2,"Reorganize docker image repositories and align with github","""A heterogeneous collection of docker images have been accumulating within the public docker repository  daues/lsstdistrib . Such a heterogeneous collection prevents the assignment of a """"latest"""" tag to allow users to easily obtain the most recent image for a particular item (detailed version numbers, labels currently required.)     Thus we should break out the single repository into multiple repositories where are """"latest"""" tag will be effective.  We also make  github repositories of matching names to hold the Dockerfiles which produced images (a common pattern for github/dockerhub usage, especially with automated builds; so we start this practice.) """
"DM-1524","Improvement","afw",2,"Switch readMetadata' return value from PropertySet to PropertyList","""It'd be useful if readMetadata would return PropertyList instead of PropertySet, because in many situations order matters. For details, see discussion in DM-1517"""
"DM-1541","Story","Qserv",8,"Add support for transmitting [VAR]BINARY column data","""The code that pulls data out of a {{MYSQL_ROW}} and puts it into a protobuf {{RowBundle}} does not handle binary data correctly. See [_fillRows|https://github.com/LSST/qserv/blob/master/core/modules/wdb/QueryAction.cc#L217] for the relevant code.  The issue is that the generated {{add_column(const char*)}} member function of {{RowBundle}} treats the input as C-style NULL-terminated strings. But in the case of {{BINARY}} column data (and {{VARBINARY}}/{{BLOB}} variants, maybe also {{BIT\(n\)}}), the contents can contain embedded NULLs. We are currently using such columns for user defined types in MySQL (e.g. image bounding polygons), so it's important to get this right. On the protobuf side the fix is as simple as calling {{add_column(const char* value, int size)}} instead. I'm not a MySQL C API expert, but the size will presumably have to be obtained/derived from the corresponding {{MYSQL_FIELD}}.  """
"DM-1539","Story","Qserv",2,"Add support for mysql JDBC driver","""SUI which rely on JDBC fail because they internally issue some queries that are not yet supported by Qserv. Need to patch it (in the short term), and add proper support (in the long term). This story covers the patching only. The queries that upset Qserv are listed below.   """
"DM-1538","Bug","Qserv",0.5,"Fix qserv_testdata documentation","""qserv_testdata relies on sconsUtils, and its build procedure has to be clearly documented."""
"DM-1545","Story","afw",5,"Span-based shrink operations for Footprint","""Analogous to DM-1128, but shrinking rather than growing footprints."""
"DM-1582","Bug","Qserv",1,"Qserv spatial restrictor names are case sensitive","""The SQL grammar treats Qserv spatial restrictor names case insensitively, but {{qana/QservRestrictorPlugin.cc}} does not, which means that one must use e.g. {{qserv_areaspec_box}} rather than {{qserv_areaSpec_box}}. We are loose with case in a lot of our wiki pages, so we really should fix this to avoid confusing users. Also, case insensitivity is consistent with MySQL behavior for UDF names."""
"DM-1579","Story","meas_astrom",5,"Implement replacement for A.net index files","""Astrometry.net index files are hard to generate and hard to read.  We need another, more flexible, more standard system for storing reference files.  We should also be able to read FITS files and other formats, but having a standard format with the utilities to create and query them is a must.  Coming up with a format that satisfies astrometry.net's solver may be too hard, because a.net requires quads, which a non-blind solver may not need. However, a format that we can convert to something suitable for a.net would probably suffice (conversion would presumably be a separate task that is run once).  It will be easier to identify a suitable format once we have identified at least one solver other than than a.net that we wish to implement or adapt. hscAstrom appears to use a catalog of star positions, which is nice and simple."""
"DM-1578","Story","meas_astrom",2,"Move photocal out of meas_astrom","""It is confusing that photocal is in meas_astrom.  I assume that is historical.  I think it could probably live in pipe_tasks."""
"DM-1573","Story","meas_astrom|meas_base|pipe_tasks",8,"Basic validation of LSST pipeline on HSC data","""Get the pipeline running on HSC data to the point where nothing is obviously wrong."""
"DM-1571","Story","Data Archive|Qserv",2,"Setup Qserv for SUI tests","""Setup Qserv on lsst-db2 with and load some reasonable data set (perhaps PT 1.2). One potential caveat: we need to setup access for some accounts that are ideally other than our internal qsmaster."""
"DM-1590","Story","meas_base",1,"Break down & discuss DM-1074","""I will take the lead on DM-1074. First step will be to sit with [~jbosch], get a feeling for what needs to be done, and sketch out a set of stories."""
"DM-1587","Story","Data Archive",2,"Define structure of web form for collecting metadata about existing data sets","""Web alpha version of the form (using django or Fermi Java webservices code) that collects input from users about data repositories. Authentication not covered in this version."""
"DM-1601","Story","Qserv",1,"Add support for c-style comments in front of queries sent to qserv","""Connecting to qserv from java fails because the jdbc driver inserts comments. """"/* ... */"""" in front of queries (example pasted below). The fix involves removing the comments at the proxy level   """
"DM-1600","Technical task","pipe_tasks",2,"Determine if Astrometry class is desired","""The question is whether the Astrometry class is the thing that is overridden or if the AstrometryTask has component configurables that are overridden.  Also, determine location default implementation."""
"DM-1607","Story","Qserv",1,"Add unit tests to test c-style comments in/around queries","""I should have thought about it when doing DM-1601 but I didn't... it'd be good to add test queries that test comments before/after/inside query."""
"DM-1603","Bug","Qserv",2,"Qserv scons scripts do not pick up the version of swig provided by eups","""See the summary. The consequence is that the Qserv integration tests fail on systems that provide swig 2.x+ - there seems to be some implicit dependency on SWIG 1.x. The reason may be that swig is getting confused about shared_ptr to objects that are defined in one module, but used in another (recent swig reorganization split czar and css into two separate swig modules)."""
"DM-1630","Story","Developer Infrastructure",1,"New RFCs should result in dm-devel E-mails and HipChat postings","""Email notices of new RFCs filed with a DM component go to dm-devel Email notices of new RFCs filed with a DM component go to Data Management chat room Email notices of all new RFCs go to Bot: RFC room """
"DM-1629","Bug","Developer Infrastructure",1,"Adopted/Retired RFCs are not counted as resolved","""Also, marking an RFC as Adopted brings up a box with a message applicable to the Closed status."""
"DM-1626","Story","Qserv",1,"Build 2014_12 Qserv release","""The title says it all. Please open ticket for next release when closing this one."""
"DM-1621","Story","Qserv",1,"Add unit test to to verify zookeeper versioning works","""This is a follow u pto DM-1453, we need to add a unit test that will prove that mismatched versions in zookeeper and software are properly handled."""
"DM-1617","Story","Qserv",8,"Client library for accessing distributed database/table information from CSS","""Provide Python interface for accessing information in CSS which is relevant to distributed management, such as database/table/node data. This interface can be used also by data loader and replicator."""
"DM-1616","Story","Qserv",5,"Implement remote host access for management framework","""To manage remote workers we need a way to access services on remote machines that run workers. Services may be something like mysql (which we would prefer to run without TCP port open) and optionally xrootd. This ticket will implement Python module which will hide a complexity of doing things like ssh/port forwarding/authentication from the client."""
"DM-1615","Story","Qserv",5,"Design and implement CSS structure for distributed Qserv setup","""For management of the distributed databases/tables we need info in CSS about all workers and tables. The info will be created by data loader and updated by replicator which do not exist yet. For this issue we need to provide python API which can fill the same information in CSS so that we can build and test other pieces needed for this epic."""
"DM-1614","Story","Qserv",1,"Add support for mysql JDBC driver (v2)","""MySQL client 4.1 and higher is stripping out comments before sending them to server, so the fixes done in DM-1539 are not sufficient."""
"DM-1608","Story","meas_algorithms|meas_base",2,"Move meas_algorithms unit tests to meas_base framework","""The following tests in meas_algorithms need to be ported to the meas_base framework:  measure.py psfSelectTest.py testPsfDetermination.py ticket2019.py testCorrectFluxes.py (though this cannot be done until the algorithm exists)"""
"DM-1635","Story","SUIT",1,"Remove redundant CORS headers from Firefly's http response","""Make sure CORS related headers are not sent when the Origin header is missing.  Firefox does not like it."""
"DM-1632","Story","Qserv",1,"Build 2014_11 Qserv release","""The title says it all. Please open ticket for next release when closing this one.  Tasks to do:  - publish last buildbot build under a temporary eups-tag (""""qserv-dev"""")and test it, if it works fine: - create git-tags for Qserv and dependencies - publish the release with eups-tags """"qserv"""" and """"YYYY_MM"""" - generate and publish the doc for release """"YYYY_MM"""" - update release number in Qserv code and set """"YYYY_MM+1"""" as release in dev and """"YYYY_MM"""" as stable release (update {{admin/bin/qserv-version.sh}}, {{doc/source/conf.py}}, {{doc/source/toplevel.rst}}) - generate and publish the doc for release """"YYYY_MM+1""""  - look at the doc - commit  {{admin/bin/qserv-version.sh}}, {{doc/source/conf.py}}, {{doc/source/toplevel.rst}} with current ticket number   This procedure should be validated and documented."""
"DM-1653","Story","Qserv",8,"Extend data loading script to support multi-node setup","""Implement simplest use case for data loading with one or more worker database separate from czar database. Simplest means minimal functionality in what concerns access to workers, just assume for now that we can connect to every worker directly using regular TCP connection. It should be possible to just add a list of worker nodes as an option to loader script and send the chunks in some random order to the workers in that list. Of course chunks for different tables should end up on the same host, so some form of chunk management is needed (use for now whatever is defined in CSS doc on trac)."""
"DM-1661","Bug","Qserv",2,"czar log4cxx link/load bug","""Under ubuntu 14.04 (at least), the czar falls over at load time with an unresolved sym for typeinfo for log4cxx::helpers::ObjectPtrBase while loading the css python wrapper shared lib."""
"DM-1659","Story","meas_base",1,"Aperture Flux back into an abstract class","""The last change to ApertureFlux to make it work with the new C++ design changed ApertureFluxAlgorithm into an instantiatable class.  However, I have now figured out how to make this work with SWIG while still allowing measure and fail to be defined by default at the ApertureFlux level..  So this issue is to put things back in order."""
"DM-1658","Story","Qserv",2,"Add git bisect tool for Qserv repos","""{code:bash} fjammes@clrlsst-dbmaster-vm:~/src/qserv (u/fjammes/DM-627 $%) $ qserv-test-head.sh -h  Usage: qserv-test-head.sh [options]    Available options:     -h          this message     -q          quick: only rebuild/install new Qserv code,                 and perform test case #01    Rebuild from scratch, configure and run integration tests against   a Qserv git repository.   Pre-requisite:     source loadLSST.bash     setup qserv_distrib -t qserv     setup -k -r ${QSERV_SRC_DIR}    Can be used with 'git bisect' :     cd ${QSERV_SRC_DIR}     git bisect start     git bisect bad     git bisect good git-commit-id     git bisect run /home/fjammes/src/qserv_testdata/bin/qserv-test-head.sh {code}  Code is in DM-627 ticket branch."""
"DM-1655","Story","SUIT",2,"Working with SLAC on definition of metadata store","""Follow up metadata store schema development to ensure SUI will be able to use it. Define the fields that should go into Data Definition table. Define the fields that must be present in the image metadata table, which SUI will be searching."""
"DM-1673","Story","Qserv",1,"Allow SWIG override for broken SWIG installations","""Dependency on SWIG 2.0+ was introduced into Qserv, and this broke Qserv building on systems relying on SWIG 1.3.x.  This ticket introduces basic code to override SWIG_LIB on those systems to allow use of the broken installation (some SWIG search paths are fixed during its build process otherwise)."""
"DM-1670","Story","SUIT",5,"Begin looking at how Python Pandas can be used for LSST data analysis.","""Pandas is well integrated with the other parts of SciPy: numpy, matlibpy, etc.  Its a good candidate for data analysis, especially where time series are involved. However, there are no multidimensional columns, poor metadata support for FITS files and a need to use masks instead of NaN values. These may, or may not, be problems.  There is a 400 page book about Pandas, so it will take some further time to learn its value, especially with astronomical data in different situations."""
"DM-1668","Story","SUIT",2,"Create SQL code to read Qserv into Python Pandas data frame","""This works well, at least for a simple case. You can move directly from a query statement to a Pandas data frame for analysis in just a few lines of code. Here is the start of an iPython Qserv session showing how easy it is.  In [6]: import pandas as pd In [7]: import pymysql as db  In [8]: conn = db.connect(host='lsst-db1.ipac.caltech.edu',port=4040, user='qsmaster', passwd='', db='LSST')  In [11]: df = pd.read_sql(""""select deepCoaddId, tract, patch, ra, decl from DeepCoadd"""", conn)  In [12]: df Out[12]:     deepCoaddId  tract   patch        ra      decl 0      26607706      0  406,11  0.669945  1.152218 1      26673242      0  407,11  0.449945  1.152218 2      26804242      0   409,2  0.011595 -0.734160 3      26673154      0   407,0  0.449945 -1.152108  """
"DM-1667","Story","SUIT",2,"Install PgMySQL and use to connect to local Qserv.","""Used """"pip"""" to install it. """"Conda"""" should work as well. Therefore, it should be easy to make it part of the delivered system: VM, container, tar file, after the fact download, etc. It has documentation, uses the MIT license, under active development and available from PyPI. DB connection is straight forward and requires little experience to get meaningful work done."""
"DM-1695","Story","Data Archive",8,"Implement interfaces for Data Access Services","""Implement proof of concept, skeleton of the prototype. The work will continue in follow up stories in February and in S15."""
"DM-1685","Bug","meas_base",1,"Minor bug in a test","""tests/centroid.py has a bug in testMeasureCentroid: """"c"""" is undefined in the following bit of code: """
"DM-1715","Story","Qserv",1,"Disable query killing","""Apparently killing a query through Ctrl-C is confusing xrootd. Disable query killing (which seems to be only partly implemented)."""
"DM-1713","Epic","Data Archive",5,"S15 Image & File Archive v2","""System for tracking existing image data sets integrated with metadata services."""
"DM-1710","Story","afw",1,"ValueError in lsst.afw.table.Catalog.extend()","""  The above fails, saying:  """
"DM-1709","Story","Qserv",8,"Implement result sorting for integration tests","""We need to be able to sort results, because we can't always rely on ORDER BY. So we need a formatting per query in the integration tests (sort result for some, don't sort for others etc.)    The following queries have been disabled because we don't have result sorting, so once it is implemented, we will need to re-enabled them prior to closing this ticket:  """
"DM-1706","Epic","Qserv",5,"S15 Analyze Qserv Performance","""Final analysis of Qserv performance, measure KPIs. Based on LDM-240, we are aiming to demonstrate:  * 50 simultaneous low volume queries, 18 sec/query  * 5 simultaneous high-volume queries, 24 h/query  * data size: 10% of DR1 level.  * Continuous running for 24 h with no software failures.  """
"DM-1705","Epic","Qserv",100,"S15 Tune Qserv","""Fix scalability and performance issues uncovered through large scale tests DM-1704"""
"DM-1721","Epic","Qserv",40,"S15 Improve Query Coverage in Qserv","""Query coverage in the qserv integration testing is very limited, we have been turning off more and more queries and we were making the qserv code and the data loader more strict. This epic covers work (fixes and improvements) related to * re-enabling test queries marked as """"fixme"""" (when it make sense, some queries are for features that are not implemented yet) * adding more queries to test interfaces and features that are implemented but are not currently tested."""
"DM-1720","Story","Qserv",2,"Make secondary index for director table only","""Following discussion on qserv-l, we only need to generate """"secondary"""" index for director table, no other table is supposed to have it. Need to modify data loader to recognize which table is director table and generate index only for that table. """
"DM-1731","Story","Qserv",1,"fix table file handling of MANPATH in dependencies","""As discussed on DM-1220, the table files for:  - mysqlproxy  - protobuf  - lua  - expat should have the MANPATH entry removed entirely, while:  - xrootd should have """":"""" added to the end of its MANPATH value, to allow the default paths to be searched as well."""
"DM-1733","Story","Qserv",1,"Build 2015_01 Qserv release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-1738","Story","meas_deblender",1,"deblender artifacts in noise-replaced images","""We still see noise artifacts in some deblended images on the LSST side when running the M31 HSC data.  They look like the result of running NoiseReplacer on HeavyFootprints in which the children can extend beyond the parents.  This was fixed on the HSC side on DM-340 (before the HSC JIRA split off), and I *think* we just need to transfer the fix to LSST."""
"DM-1735","Story","Developer Infrastructure",1,"Have newinstall.sh check itself against distrib version","""We want to alert people who are just using a newinstall.sh they have lying around (old or hacked up or...) that they are not using the official server version.  """
"DM-1743","Bug","Qserv",1,"CSV reader for Qserv partitioner doesn't handle no-escape and no-quote options properly","""Both the no-quote and no-escape CSV formatting command line options should not have a default value, as specifying any value turns off field escaping and quoting. Furthermore, when quoting is turned off, the reader incorrectly treats embedded NUL characters as a quote character."""
"DM-1744","Bug","Qserv",1,"Fix SWIG_SWIG_LIB empty list default value","""See Serge message to Qserv-l """"xrootd premature death"""": {quote} However, there are bigger problems. First of all, master doesnt build for me. I get this error:    File """"/home/lsstadm/qserv/SConstruct"""", line 104:     env.Alias(""""dist-core"""", get_install_targets())   File """"/home/lsstadm/qserv/SConstruct"""", line 90:     exports=['env', 'ARGUMENTS'])   File """"/home/lsstadm/stack/Linux64/scons/2.3.0+1/lib/scons/SCons/Script/SConscript.py"""", line 609:     return method(*args, **kw)   File """"/home/lsstadm/stack/Linux64/scons/2.3.0+1/lib/scons/SCons/Script/SConscript.py"""", line 546:     return _SConscript(self.fs, *files, **subst_kw)   File """"/home/lsstadm/stack/Linux64/scons/2.3.0+1/lib/scons/SCons/Script/SConscript.py"""", line 260:     exec _file_ in call_stack[-1].globals   File """"/home/lsstadm/qserv/build/SConscript"""", line 39:     canBuild = detect.checkMySql(env) and detect.setXrootd(env) and detect.checkXrootdLink(env)   File """"/home/lsstadm/qserv/site_scons/detect.py"""", line 225:     xrdLibPath = findXrootdLibPath(""""XrdCl"""", env[""""LIBPATH""""])   File """"/home/lsstadm/qserv/site_scons/detect.py"""", line 213:     if os.access(os.path.join(path, fName), os.R_OK):   File """"/home/lsstadm/stack/Linux64/anaconda/2.1.0/lib/python2.7/posixpath.py"""", line 77:     elif path == '' or path.endswith('/'):  which is caused by the fact that env[LIBPATH] looks like:  [[], '/home/lsstadm/stack/Linux64/antlr/2.7.7/lib', '/home/lsstadm/stack/Linux64/boost/1.55.0.1.lsst2/lib', '/home/lsstadm/stack/Linux64/log4cxx/0.10.0.lsst1+2/lib', '/home/lsstadm/stack/Linux64/xrootd/4.0.0rc4-qsClient2/lib', '/home/lsstadm/stack/Linux64/zookeeper/3.4.6/c-binding/lib', '/home/lsstadm/stack/Linux64/mysql/5.1.65.lsst1/lib', '/home/lsstadm/stack/Linux64/protobuf/2.4.1/lib', '/home/lsstadm/stack/Linux64/log/10.0+3/lib']  The first element is [], which comes from https://github.com/LSST/qserv/blob/master/site_scons/state.py#L173 where a PathVariable called SWIG_SWIG_LIB is given a default value of []. I can fix the build by changing the default to an empty string but I dont know enough scons to say whether thats the right thing to do. Can one of the scons gurus confirm thats the right fix? {quote}"""
"DM-1754","Story","SUIT",8,"Update auto build tool to work with new split repositories ","""After the repository split, changes are required to get the auto build tool to work properly. Firefly and Firefly based applications are built using Gradle system.  """
"DM-1771","Story","meas_base",1,"move executionOrder from plugin config class to plugin class","""We originally put the executionOrder parameter (which determines when a plugin is run, relative to others), in the config object, simply because that's where it was in the old framework.  But it's really not something that should be configurable, as it depends only on the inputs the algorithm needs, which don't change."""
"DM-1770","Story","metaserv",2,"Support DDL in MetaServ - design","""DDL information is embedded as comments in the master version of the schema (in """"cat"""" repo). Currently we are only using it for schema browser. This story involves designing the procedure involving loading DDL information into MetaServ. We need to be ready to support a variety of scenarios: * we are getting already preloaded database, need to just load metadata about it to metaserv (we might have the original ascii file with extra information, or not) * we are starting from scratch, need to initialize database (including loading schema), and need to load the information to the metaserv * we already have the database and metadata in metaserv, but we want to change something (eg. alter table, or delete table, or delete database)."""
"DM-1762","Story","Qserv",3,"Export SUI data (DC_W13_Stripe82_subset)","""- import sui.sql.bzip2.out (produced by Serge) into MySQL for DeepSource and DeepForcedSource tables: - remove columns chunkId and subChunkId for each chunk table - merge all chunk table into the main table - join DeepSource and DeepForcedSource to add coordinates of DeepSource (director) object in DeepForcedSource table. then dump  DeepSource and DeepForcedSource  to files DeepSource.csv and DeepForcedSource.csv  - Load this file using Qserv loader.  A sample should be made and tested first to validate this procedure. This sample could be added in qserv_testdata"""
"DM-1761","Improvement","pipe_tasks",1,"Provide input data for exampleCmdLineTask.py","""{{pipe_tasks/examples/exampleCmdLineTask.py}} reads data from a repository. The comments in {{pipe_tasks/python/lsst/pipe/tasks/exampleCmdLineTask.py}} suggest that    There are a few problems with that:  * External contributors don't have access to {{lsst*}}; * Even though that data exists now, it's unclear how long it will remain there, or what steps are being taken to preserve it; * The mention of this data is fairly well buried -- it does appear in the documentation, but it's certainly not the first thing a new user will stumble upon.  At least the first two points could be addressed by referring to a publicly available data repository. For example, the following works once {{afwdata}} has been set up:    Although this has the downside of only providing a single image."""
"DM-1785","Story","Database",1,"Add rotAngle to baseline schema","""Add """"rotAngle DOUBLE"""" to every table that has image ra/decl.  """
"DM-1783","Story","meas_extensions_photometryKron",5,"fix faint source and minimum-radius problems in Kron photometry","""This transfers some improvements to the Kron photometry from the HSC side:  - HSC-983: address failures on faint sources  - HSC-989: fix the minimum radius  - HSC-865: switch to determinant radius instead of semimajor axis  - HSC-962: bad radius flag was not being used  - HSC-121: fix scaling in forced photometry  The story points estimate here is 50% of the actual effort, as the work (already done) also benefited HSC."""
"DM-1793","Bug","afw",0,"remove reference data members from FootprintFunctor","""The FootprintFunctor class uses references for data members, which could cause memory problems if the class (or a subclass) is ever initialized with a temporary.  Fixing this would probably require changing the constructor to take a shared_ptr, however, so it would break a lot of downstream code.  I'd rather actually rewrite FootprintFunctor entirely (one of the goals for Epic DM-1107), but it's not clear when that will happen; if it slips too much, this issue is to remind us to fix at least this problem."""
"DM-1792","Bug","Qserv",1,"Update documentation and automatic install script w.r.t. new newinstall.sh script","""newinstall.sh script has evolved and breaks Qserv install procedure."""
"DM-1803","Epic","Qserv",8,"S15 Explore Qserv Authorization","""Explore authorization centrally: use information generated by parser. Either generate dummy query and run on mysql that runs near czar, or use info produced by parser to determine if user is authorized.  Note, we want to limit this to ~1 week, just to reveal potential problems, or do a quick proof of concept."""
"DM-1802","Story","afw|ndarray",1,"remove unused local typedefs","""gcc 4.8 now warns about locally-defined typedefs that aren't used.  We have a few of these in ndarray and afw::gpu that should be removed."""
"DM-1797","Technical task","Data Archive",1,"Package flask","""The Data Access Webservice APIs are relying on flask, so we need to package flask according to the LSST standards. For my initial testing, I just run """"sudo aptitude install python-flask"""".  """
"DM-1810","Story","ip_diffim",2,"segfaults in ip_diffim on gcc 4.8","""I'm seeing test segfaults in ip_diffim on gcc 4.8, similar to those resolved on DM-1725, but with no similar smoking gun yet.  Preliminary indication is that the problem is actually in meas_algorithms."""
"DM-1824","Story","Systems Engineering",1,"Define issues to be addressed","""Work with TCS contacts (Jacques Sebag, Paul Lotz, etc.) to define the principal issues"""
"DM-1821","Story","Systems Engineering",0,"Clarify scope of DM data quality analysis requirement","""Clarify in LSE-140 that the DM data quality analysis referred to is primarily that of the Level 1 data products."""
"DM-1820","Epic","Systems Engineering",1,"LSE-140: Collect desired changes for future release","""Prepare for a future revision (Phase 3) of LSE-140.  Collect issues to be addressed in the revision.  Determine if any affect Phase 2 scope (which would require a prompt revision).  It is not anticipated that there will be an actual revision of LSE-140 during the Winter 2015 cycle, because additional detail on calibration requirements will not be available in time."""
"DM-1819","Story","Systems Engineering",2,"Complete LSE-140 work as needed to produce final document","""Complete any review-driven revisions of LSE-140 and support the CCB meeting and following final document preparation."""
"DM-1818","Story","Systems Engineering",1,"Support completion of final document","""Based on CCB approval of LSE-72 on 10 October, support the completion of the final copy of the document for posting on Docushare."""
"DM-1816","Story","Systems Engineering",2,"Convert LSE-130 to SysML","""Following CCB recommendation of approval of LSE-130 draft, convert Word draft to SysML and provide a docgen to Robert McKercher for final posting. """
"DM-1814","Story","Systems Engineering",2,"Support Camera CD-2 (mainly re: LSE-130)","""Provide slides and other information needed for CD-2, mainly relative to the open questions around LSE-130"""
"DM-1812","Story","Systems Engineering",8,"Determine LSE-130 impact of collimated projector calibration plan","""During a working meeting with Robert Lupton and Chris Stubbs, determine the impact on LSE-130 of the introduction of the collimated projector for calibration."""
"DM-1841","Bug","Qserv",5,"Fix query error on case03: ""SELECT scienceCcdExposureId FROM Science_Ccd_Exposure_Metadata"" ","""Xrootd prevents the worker to return more than 2MB data.  On GB-sized data:   On integration test case 04: """
"DM-1854","Epic","SUIT",20,"SUI propose a structure definition for user workspace","""Workspace is an integral part of SUI. We want to start the discussion and definition of workspace concept and structure.     SUI team had several discussions and Xiuqin presented the results at the DM AHM at SLAC. The slides and the discussion notes are here: https://confluence.lsstcorp.org/display/DM/Workspace+discussion"""
"DM-1844","Story","Qserv",2,"Test Qserv on SL7","""Needed to run Qserv on CC-IN2P3 cluster."""
"DM-1843","Story","ctrl_events",2,"Permit PropertySets to be represented in event payloads","""In the old marshalling code, property sets were representable within the payload of the event.   This was removed in the new marshalling scheme.   There are things (ctrl_orca) that still used this, so this needs to be added to the new marshaling code.  At the same time, new new filtering code can not allow this to be added, because the JMS headers only take simple data types."""
"DM-1875","Epic","SUIT",40,"SUI infrastructure implementation","""Identify the hardware resources needed at NCSA for short term development and  Set up the basic git repository and build system Explore multi resolution images display for background iamge"""
"DM-1873","Epic","SUIT",40,"SUI 2D data visualization (XY plot)","""Better algorithm in spatial binning to visualize large number of catalog sources Plot histogram for tabular data Plot basic light curve """
"DM-1868","Story","dbserv|ImgServ|metaserv",3,"Define JSON Results for Data Access Services","""As discussed at [Data Access Hangout 2015-02-23|https://confluence.lsstcorp.org/display/DM/Data+Access+Hangout+2015-02-23], we should support json format. This story covers defining structure of JSON results for Data Access Services (dbserv, imgserv, metaserv) """
"DM-1860","Story","Developer Infrastructure",2,"Update documentation for v10_0 release","""All done bar obtaining some release notes. """
"DM-1887","Story","SUIT",1,"HDF5 file format study","""Xiquin, Loi, Trey, and myself discussed HDF5 as a default format to return result set and metadata from lower-level database services vs. traditional IPAC table. Here is the summary:  Advantages of IPAC Table format  - Simple and human-readable, contains a single table - Fixed length rows (easy to page through) - Supported by many astronomical tools  - Provides a way to pass data type, units, and null values in the header - More metadata can be added through keywords (attributes)  Disadvantages of IPAC table format   - Steaming can not be started before all data are received  need to know column width before the table can be written (csv is better alternative) - Only alpha-numeric and '_' characters are allowed in column names (small subset of available characters) - Only predefined datatypes and one attribute type (string) - ASCII representation requires about twice as much storage to represent floating-point number data than the binary equivalent.  Advantages of HDF5  - Can represent complex data and metadata (according to LOFAR, good to represent time series) - Structured data, arbitrary attribute types, datatypes can be combined to create structured datatypes - Flexible datatypes: can be enumerations, bit strings, pointers, composite datatypes, custom atomic datatypes - Access time and storage space optimizations - Partial I/O: Chunked data for faster access - Supports parallel I/O (reading and writing) - Built-in compression (GNU zlib, but can be replaced with others) - Existing inspection and visualization tools (HDFView, MATLAB, etc.)  Disadvantages of HDF5  - Complex - Tuned to do efficient I/O and storage for """"big"""" data (hundreds of megabytes and more), not efficient for small reads/writes. - Requires native libraries (available in prepackaged jars, see below) - Not human readable - (?) Not yet widely supported by astronomical tools (counter-examples: AstroPy, IDL, more at hdfgroup site)  Tools and Java wrappers:  * JHI5 - the low level JNI wrappers: very flexible, but also quite tedious to use. * Java HDF object package - a high-level interface based on JHI5. * HDFView - a Java-based viewer application based on the Java HDF object package.  * JHDF5 - a high-level interface building on the JHI5 layer which provides most of the functionality of HDF5 to Java. The API has a shallow learning curve and hides most of the house-keeping work from the developer. You can run the Java HDF object package (and HDFView) on the JHI5 interface that is part of JHDF5, so the two APIs can co-exist within one Java program. (from StackOverflow answer, 2012)  * NetCDF-Java is a Pure Java Library, that reads HDF5. However, it's hard to keep pure java version up-to-date with the standard, does not support all the features.  A way to set up native libraries (3rd option from JHDF5 FAQ):      """"Use a library packaged in a jar file and provided as a resource (by putting the jar file on the class path). Internally this uses the same directory structure as method 2., but packaged in a jar file so you don't have to care about it. Jar files with the appropriate structure are cisd-jhdf5-batteries_included.jar and lib/nativejar/.jar (one file for each platform). This is the simplest way to use the library.""""       """
"DM-1885","Story","SUIT",2,"Contribute to the workspace capability discussion ","""This include past experience, collection of use cases. """
"DM-1880","Story","Data Archive",5,"Implement RESTful interfaces for Database (GET)","""Implement RESTful interfaces for Database (see all D* in https://confluence.lsstcorp.org/display/DM/API), based on the first prototype developed through DM-1695. The work includes adding support for returning appropriately formatted results (support the most common formats). This covers """"GET"""" type requests only, """"POST"""" will be handled separately."""
"DM-1878","Story","SUIT",20,"Collect, understand, and define more use cases","""This is an on-going effort. The collected use cases will be posted at confluence page https://confluence.lsstcorp.org/pages/viewpage.action?pageId=41784036. """
"DM-1901","Story","Qserv",8,"Re-implement data loading scripts based on new worker control service","""Once we have new service that controls worker communication we'll need to reimplement WorkerAdmin class based on that."""
"DM-1900","Story","Qserv",5,"Worker management service - design","""We need to replace direct worker-mysql communication and other administrative channels with a special service which will control all worker communication. Some light-weight service running alongside other worker  servers, probably HTTP-based. Data loading, start/stop should be handled by this service."""
"DM-1897","Story","Qserv",2,"Modify CSS structure to support table deletion","""Modify CSS structures to support DROP TABLE, as defined in DM-1896."""
"DM-1919","Story","Qserv",1,"Address misc. compiler warnings","""Fix places where compiler is warning about some things we are doing on purpose and which we don't intend to change.  This helps keep compiler noise down so its easier to notice """"real"""" warnings."""
"DM-1917","Story","Qserv",1,"Fix missing virtual destructors","""The compiler is warning about some derived class hierarchies that are lacking virtual destructors.  We should add at least empty implementations to the base classes of these hierarchies."""
"DM-1904","Epic","afw",8,"Continued footprint improvements","""A redesigned API and support for topological operations within the Footprint class.  This continues the work started in DM-1107 in W15.  Breakdown: jbosch 15%; swinbank 85%"""
"DM-1903","Story","meas_base|pipe_tasks",2,"Implementation of calibration transformation framework","""Following DM-1598 there will be a detailed design and prototype implementation for the calibration & ingest system. This issue covers cleaning up that code, documenting it, having it reviewed, and merging to master."""
"DM-1954","Story","meas_base",20,"HSC backport: deblended HeavyFootprints in forced photometry","""This is a transfer for changesets for [HSC-1062|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1062].    Unlike most of the HSC backport issues for multiband deblending, these changes will require significant modification the LSST side, because we need to apply them to the new forced measurement framework in meas_base rather than the old, HSC-only one in meas_algorithms and pipe_tasks.    Also include [HSC-1256|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1256], [HSC-1218|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1218], [HSC-1235|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1235], [HSC-1216|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1216]."""
"DM-1953","Story","meas_extensions_photometryKron",1,"Post meas_base move changes to Kron","""These are to note leftovers from DM-982.  They could be done in a single issue. 1.  I commented code out referring to correctfluxes, but it will need to be restored once it is available in the new framework.  2.  Jim asked me to replace the computeSincFlux which is currently in PsfImage.cc in meas_algorithms with a similar call in meas_base/ApertureFlux.cc.  I did not do this because it became rather complicated, and can just as easily be done when the meas_algorithms routine is moved or removed.  Basically, the templating in ApertureFlux is on Pixel type, whereas in meas_algorithms it is on ImageT (where ImageT is not necessarily a single class hierarchy -- e.g., Image and MaskedImage).  So I left this for now."""
"DM-1952","Story","Qserv",0.5,"Change log priority for message ""Unknown column 'whatever' in 'field list'""  ","""Next message should be logged with ERROR priority:  """
"DM-1945","Story","pipe_tasks",8,"HSC backport: multiband processing for coadds","""This issue includes transferring changesets from many HSC issues:  - HSC-1060  - HSC-1064  - HSC-1065  - HSC-1061  Most of this is in multiBand.py in pipe_tasks, but there are scattered changes elsewhere (including updates to camera mappers to include the new datasets, for which we'll need to modify more than just obs_subaru).  However, before we make these changes, we'll need to open an RFC to gather comments on the design of this task.  We should qualify there that this is not a long-term plan for consistent multiband processing (which we'll be starting to design on DM-1908), but a step towards better processing in the interim.  Note: while I've assigned this to [~lauren], as I think it will be very helpful for her to get familiar with this code by doing the transfers, the RFC will have to involve a collaboration with [~jbosch], [~price], and Bob Armstrong, as we can't expect someone who wasn't involved in the design to be able to write a document justifying it."""
"DM-1943","Story","afw",8,"HSC backport: convert Peak to PeakRecord","""This issue covers transferring all changesets from [HSC-1074|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1074] and its subtasks, as well as:  - An RFC to propose the API change, and any requested modifications generated by the RFC.  - Additional fixes to downstream code that's broken by this change (HSC-side changesets should be present for most of downstream fixes, but perhaps not all)."""
"DM-1974","Bug","Qserv",2,"Fix enclose, escape, and line termination characters in qserv-data-loader","""Add this string to mysql loader 'LOAD DATA INFILE' command:    and add params in cfg file."""
"DM-1973","Story","Qserv",1,"Build 2015_02 Qserv release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-1972","Story","Infrastructure",2,"upgrade SWIG to 3.0.8 or later","""SWIG 3.0.5 is now out and has several useful fixes w.r.t. 3.0.2 (which we are presently using) including:  - A bug we've had to work around involving templated methods of classes  - improved handling of new-style enums (they are no longer hoisted into the global namespace, which was a serious misfeature of SWIG 3.0.2)    I propose we try it out using buildbot (when we have some time), and if it works, we adopt it. Adopting it will help us relax the restrictions on what C++11 features can be used in C++ header files."""
"DM-1982","Bug","Qserv",1,"Fix JDBC timestamp error","""JDBC driver returns an error on next query:  """
"DM-1987","Epic","afw",40,"Redesign/Refactor WCS and Coord","""%50 KSK, %50 RO Currently WCS is mutable and Coord objects are heavyweight.  Refactor WCS to be immutable and make Coord less heavyweight.  Include lists of Coord objects.  It's possible astropy could inform in that area.  Also, remove TanWcs in favor of TanSipWcs since TanWcs can have SIP terms."""
"DM-1994","Improvement","Developer Infrastructure",1,"Story point display and roll-up in epic display","""I understand that there is a pending request to display the story points for individual story issues in the mini-table in which they are displayed for an epic.  It would also be useful to see a rolled-up total of the story points for the defined set of stories - so that, among other things, this could be compared to the story point value for the epic.  Ideally the story points for the roll-up might be displayed as """"nn (mm)"""" where nn is the total points and mm is the number of points remaining to do (or done already - I don't care which as long as the definition is clear)."""
"DM-2009","Improvement","afw",2,"Please add cbegin and cend to afw tables","""It would be helpful if afw tables had the C++11 iterator methods cbegin and cend that return iterators-to-const."""
"DM-2005","Story","ndarray",2,"switch ndarray to external package","""There is already an external ndarray project on GitHub (we've been using a fork of that).  We should merge the forks and switch to using the external package. """
"DM-2029","Bug","Developer Infrastructure",0,"Update Confluence build instructions to match github move","""The Build tool documentation   https://confluence.lsstcorp.org/display/LDMDG/The+LSST+Software+Build+Tool  refers to   git clone git@git.lsstcorp.org:LSST/DMS/devenv/lsstsw.git  This should be updated to reflect the move to GitHub  git clone https://github.com/lsst/lsstsw.git   """
"DM-2060","Story","Qserv",0.5,"Rename TaskMsgFactory2","""Rename TaskMsgFactory2 to TaskMsgFactory.    Please see DM-211 for more information."""
"DM-2058","Bug","Qserv",2,"Data loader should always create overlap tables",""" We have discovered that some overlap tables that are supposed to exist were not actually created. It looks like partitioner is not creating overlap files when there is no overlap data and loader is not creating overlap table if there is no input file. Situation is actually symmetric, there could be non-empty overlap table but empty/missing chunk table. When we create one table we should always make another as well. """
"DM-2057","Story","Qserv",2,"Attend Scale 13x conference","""Attend database talks, in particular the MaxScale proxy talk (http://www.socallinuxexpo.org/scale/13x/presentations/advanced-query-routing-and-proxying-maxscale?utm_campaign=north-american-trade-shows&utm_source=hs_email&utm_medium=email&utm_content=16099082&_hsenc=p2ANqtz-_MFjfxvpCdmV_Ax2RKDdOGypHPQ85UL-UMuy0eRs_MrlJ2qJVp-MXx-g7_-dAQsq0trpA61hkZrzO-3gp6bKVkpK52fQ&_hsmi=16099082).  If anyone has questions they would like me to ask, please post them here as well.  I will post notes to this issue. """
"DM-2054","Epic","QA",40,"Release engineering  Part One","""Bucket for public stack releases  [FE at 75%, JH at 75%]"""
"DM-2052","Epic","QA",20,"Maintain list of OSes that pass build and integration testing ","""Provide an automatiically generated and updated pages showing operating systems that are successfully building  and integrating the stack from source.   [FE at 75%, JH at 75%]"""
"DM-2050","Epic","QA",100," Integration and test monitoring architecture Part I","""[retitled to better capture cycle scope]    Develop and deploy a layer to capture the outputs, initially numeric,  of integration testing afterburners such as sdss_demo, hsc_demo, and  others developed this cycle. Also capture meta-information such as  execution time and memory footprint. Propose log format to standardise  production of such informations. Investigate notification system based  on trending away from expected values. Investigate data provisioning  of integration tests such as storage of test data in GithubLFS.    [75% JMP 25% JH]        """
"DM-2097","Story","xrootd",1,"Package andyH xssi fixed version (>2MB answer pb) in eups","""See DM-1847 - Andy made a patch, it'd be good to the xrootd we use for our stack."""
"DM-2096","Story","Database",8,"Long term database work planning","""Long term planning (updating LDM-240)."""
"DM-2095","Story","dbserv",1,"Port dbREST.py to db","""dbREST_v0.py in dbserv is currently using MySQLdb instead of going through the db API, because we need to use parameter binding for security reasons. We should switch to using db, once the db interfaces will support it. """
"DM-2094","Story","metaserv",1,"Port metaREST.py to db","""metaREST_v0.py in metaserv is currently using MySQLdb instead of going through the db API, because we need to use parameter binding for security reasons. We should switch to using db, once the db interfaces will support it. """
"DM-2131","Story","meas_base",1,"Resolve compiler warnings in new measurement framework","""When building {{meas_base}}, or any other measurement plugins which follow the same interface, with clang, I see a bunch of warnings along the lines of:    This is an artefact of a [workaround for SWIG issues|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=20284390]; the warnings aren't indicative of a fundamental problem, but if we can avoid them we should.  While we're at it, we should also fix:  """
"DM-2129","Epic","Qserv",40,"S19 Improve Query Coverage in Qserv","""This epic holds budgeted effort for work directed at improving query coverage (additional or previously unsupported query types) in Qserv"""
"DM-2141","Story","ci_hsc|lsst_distrib|lsstsw|meas_extensions_shapeHSM|obs_subaru",1,"Add meas_extensions_shapeHSM to lsstsw, lsst_distrib","""meas_extensions_shapeHSM has just been resurrected from bitrot, and should be included in our distribution.    Contrary to DM-2140, it should probably not be included in lsst_apps, as it's not clear we want to add a dependency on tmv and GalSim there."""
"DM-2139","Story","metaserv",8,"Support DDL in MetaServ - implementation","""DDL information is embedded as comments in the master version of the schema (in """"cat"""" repo). Currently we are only using it for schema browser. This story involves building tools that will load the DDL schema into MetaServ. Design aspects are covered in DM-1770."""
"DM-2161","Story","dbserv|ImgServ|webserv",2,"Setup webserv for SUI tests","""We need to setup a service (eg on lsst-dev) that can be used by the IPAC team to play with our webserv/metaserv/dbserv/imgserv.  The server runs on lsst-dev machine, port 5000. To ssh-tunnel, try:   An example usage:   """
"DM-2159","Story","ImgServ",3,"Implement Image Response for ImgServ","""This story covers implementing proper response, and the header metadata for the fits image response."""
"DM-2157","Bug","Qserv",1,"Data loader crashes on uncompressed data.","""Vaikunth just mentioned to me that the is a crash in data loader when it tries to load uncompressed data:   It looks like we never tested loader on uncompressed data and there is a bug in handling uncompressed data. """
"DM-2171","Story","dbserv|metaserv|webservcommon",3,"Implement JSON Results for MetaServ and DbServ","""Implement JSON results for Metadata Service (see all M* in https://confluence.lsstcorp.org/display/DM/API),  and Database Service (see all D*) as defined in DM-1868"""
"DM-2173","Bug","db",1,"Disable testDbLocal.py in db if auth file not found","""tests/testDbLocal.py can easily fail if required mysql authorization file is not found in user home dir. Skip the test instead of failing in such case."""
"DM-2190","Story","Qserv",2,"Documentation for data loader","""Vaikunth had some """"expected"""" troubles playing with data loader options for his DM-1570 ticket. Main issue I believe is the absence of the documented use cases and their corresponding data loader options. I'll try to add a bunch of common use cases to RST documentation and also verify that all options behave as expected."""
"DM-2186","Story","meas_astrom",2,"Move astrometry_net wrapper code from meas_astrom to a new package","""Remove all astrometry.net wrapper code from {{meas_astrom}} and put it in a new package named {{meas_extensions_astrometryNet}}.  """
"DM-2199","Story","Qserv",1,"Build 2015_03 Qserv release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe. """
"DM-2193","Story","afw",5,"Add assertXNearlyEqual to afw","""We often want to compare two WCS for approximate equality. afw/image/testUtils has similar functions to compare images and masks and I would like to add one for WCS    This ended up being expanded to adding functions for many afw classes (not yet including image-like classes, though existing functions in image/testUtils for that purpose should probably be wrapped or rewritten on a different ticket)"""
"DM-2243","Story","db",1,"Extend API: expose cursor","""Extend API to expose cursor. This was brought up by Andy in DM-2137. """
"DM-2241","Story","Data Archive|SUIT",1,"Raw image definition and usage","""SUI needs to serve raw data to the user community. We want to understand the use cases and definition of raw data. More specifically, what meta data will be available in the FITS file that we call raw image? """
"DM-2257","Story","Qserv",1,"Allow eups xrootd install script to be relocatable","""xrootd lib/ directory should be s relative symlink to lib64, no a full path link."""
"DM-2270","Story","Middleware",2,"Move VMs to Docker containers","""We anticipate being able to move from the VMs that we currently use to using docker.  This will require some coordination with Greg Daues to see how HTCondor is configured.  """
"DM-2279","Bug","db",1,"Fix problems with mysql timeout","""We added some code for supporting reconnecting (see https://dev.lsstcorp.org/trac/ticket/3042) but clearly not enough to recover from connection timeouts. This needs to be addressed."""
"DM-2277","Technical task","Qserv",2,"Document HOW-TO setup-up krb5 for easy cluster access","""{code:bash} su aptitude install krb5-user # edit /etc/krb5.conf w.r.t ccage one # then as desktop user kinit ssh ccqservxxx   sshconfig: {code:bash} Host ccqservbuild GSSAPIAuthentication yes GSSAPIDelegateCredentials yes ForwardX11 yes HostName ccqservbuild.in2p3.fr #ProxyCommand ssh -W %h:%p cc   Host ccqserv1* GSSAPIAuthentication yes GSSAPIDelegateCredentials yes ForwardX11 yes HostName %h.in2p3.fr ProxyCommand ssh -W %h:%p ccqservbuild {code}"""
"DM-2282","Story","dbserv|metaserv",1,"Switch to using db connection pool","""Switch to using the db connection pool. Note, in addition to getting auto-reconnect, in metaserv that would handy if we need to talk to multiple database servers simultaneously."""
"DM-2281","Story","db",1,"Implement connection pool","""Implement a class that manages a connection pool, and optionally, if configured, restarts connection as needed in case of timeout."""
"DM-2280","Bug","afw",2,"The TAN_PIXELS cameraGeom coordinate system should be with respect to the center of the focal plane","""The TAN_PIXELS cameraGeom coordinate system (the position on a detector if there is no optical distortion) is presently defined with respect to the center of the detector -- i.e. a star at the center of the detector will have the same position in PIXELS and TAN_PIXELS coordinates. That is a mistake. TAN_PIXELS should be defined with respect to the center of the focal plane, since it then reflects the effects of having optical distortion or not.  Fixing this will help meas_astrom match stars. The effects of not fixing it are making the matcher search farther for a fit. As long as we allow sufficient offset in the matcher config the current system will work, but it is not ideal."""
"DM-2294","Bug","Qserv",2,"Unable to start cmsd on Qserv worker node","""Some build issues have qlready been fixed in commit: 9dd378829e8751a6852356967411c20580e2a1c3  Here's the log:  {code:bash} [fjammes@ccqserv101 ~]$ cat /qserv/qserv-run/var/log/worker/cmsd.log 150309 21:19:46 9794 Starting on Linux 3.10.0-123.8.1.el7.x86_64 Copr.  2004-2012 Stanford University, xrd version v20140617-203cf45 ++++++ cmsd worker@ccqserv101.in2p3.fr initialization started. Config using configuration file /qserv/qserv-run/etc/lsp.cf =====> all.adminpath /qserv/qserv-run/tmp =====> xrd.port 1094 =====> xrd.network nodnr Config maximum number of connections restricted to 4096 Config maximum number of threads restricted to 2048 Copr.  2007 Stanford University/SLAC cmsd. ++++++ worker@ccqserv101.in2p3.fr phase 1 initialization started. =====> all.role server =====> ofs.osslib libxrdoss.so  =====> oss.localroot /qserv/qserv-run/xrootd-run =====> cms.space linger 0 recalc 15 min 10m 11m =====> all.pidpath /qserv/qserv-run/var/run =====> all.adminpath /qserv/qserv-run/tmp =====> all.manager ccqserv100.in2p3.fr:2131 =====> all.export / nolock The following paths are available to the redirector: w  /   ------ worker@ccqserv101.in2p3.fr phase 1 server initialization completed. ++++++ worker@ccqserv101.in2p3.fr phase 2 server initialization started. Plugin Unable to find  required version information for XrdOssGetStorageSystem in osslib libxrdoss.so ------ worker@ccqserv101.in2p3.fr phase 2 server initialization failed. 150309 21:19:46 9794 XrdProtocol: Protocol cmsd could not be loaded ------ cmsd worker@ccqserv101.in2p3.fr:1094 initialization failed {code}"""
"DM-2309","Story","Qserv",0.5,"Update dev quick-start guide to new git repositories","""The quick-start documentation for developers still points to the old git repositories. The RST document needs to be updated to the GitHub repos."""
"DM-2307","Technical task","meas_base",2,"Measurement transforms for shapes","""Provide calibration transforms for algorithms measuring shapes."""
"DM-2306","Technical task","meas_base",5,"Measurement transforms for centroids","""Provide calibration transforms for all algorithms measuring centroids."""
"DM-2305","Technical task","meas_base",3,"Measurement transforms for Flux","""Provide calibration transforms for flux measurements to magnitudes."""
"DM-2316","Story","Data Archive|Database|SUIT",2,"Clarify expectations for unauthenticated user data access","""h4. Short version:  Clarify what existing community practices, notably including VO interfaces, appear to rely on the availability of unauthenticated access to information in astronomical archives.  h4. Details:  At the February DM All Hands, [~frossie] raised an objection when it was mentioned that there is a presumption that all user access to LSST data through the DM interfaces (as opposed to through EPO) will be authenticated.  We don't appear to have ever documented an explicit requirement that all access be authenticated.  The basic controlling requirement is OSS-REQ-0176, """"The LSST Data Management System shall provide open access to all LSST Level 1 and Level 2 Data Products, as defined in the LSST System Requirements and herein, in accordance with LSSTC Board approved policies. ..."""", which was a carefully crafted indirection at a time when the policy for non-US/Chile access was still being developed.  However, this presumption has been around for a long time.  It is inherent to the project policy that access to the non-Alert data will be limited to individuals who are entitled to it.  No matter what we think the final policy might be, we do have to design a system that can be consistent with this policy.  [~frossie] stated that the astronomical community relies on certain types of data and metadata - she mentioned coverage maps, among others - being available through unauthenticated interfaces.  This ticket is to ask her (and others) to collect documentation of those existing practices, so that we can figure out what the expectations may be and how to respond to them in our design."""
"DM-2312","Bug","obs_test",1,"obs_test's table file is out of date","""obs_test's table file is somewhat out of date. Problems include:  - afw is required but missing  - meas_algorithms and skypix are used by bin/genInputRegistry.py, which is only used to create the input repo so these can be optional  - daf_persistence is not used  - daf_base is only used by bin/genInputRegistry.py, so it can be optional (though it is presumably setup by daf_butlerUtils in any case)"""
"DM-2347","Improvement","afw",1,"(In)equality semantics of Coords are confusing","""Viz:    {{c1}} is simultaneously equal to *and* not equal to {{c3}}!"""
"DM-2343","Story","afw",1,"Move afw_extensions_rgb functionality into afw proper","""See RFC-32 """
"DM-2341","Story","Qserv",5,"Use parallel ssh to manage Qserv on IN2P3 cluster","""IN2P3 sysadmin won't manage Qserv through puppet. So Qserv team has to provide ssh scripts to do this.  """
"DM-2340","Story","Middleware",2,"Reprise SDRP processing metrics","""In support of an SDRP-based science talk of Yusra AlSayyad, we spent some cycles gathering/summarizing processing middleware results and metrics from the US side of processing of the Split DRP.  This information from notes, logs, databases, etc provided contextual information on the processing campaign that produced the SDRP science results. """
"DM-2334","Story","Qserv|xrootd",5,"Simplify interactions with XrdOss","""The qserv code is still using the old ssi scheme for the cmsd, this needs to be rewritten. For  details, see  https://listserv.slac.stanford.edu/cgi-bin/wa?A1=ind1503&L=QSERV-L#3"""
"DM-2349","Story","metaserv",1,"Add unit tests to SchemaToMeta","""Add unit tests, also improve variable names as suggested by K-T in comments in DM-2139"""
"DM-2356","Story","SUIT",1,"Identify the hardware resources needed at NCSA for short term development ","""Supply the hardware resources needed at NCSA for short term development. It is captured in DM-2327  """
"DM-2367","Story","Continuous Integration",8,"run lsstswBuild.sh in a clean sandbox","""The """"driver"""" script, lsstswBuild.sh, used by the buildbot slave on lsst-dev to initiate a """"CI run"""" has a number of environment assumptions (binaries in the $PATH, paths to various components, hostnames, etc.).  This prevents it from [easily] being invoked on any other host.  As lsstswBuild.sh builds a number of packages that are not in the lsst_distrib product, the os level dependencies for these other products need to be determined.  In addition, the current version of lsstswBuild.sh and related scripts on lsst-dev are not version controlled."""
"DM-2364","Story","webserv",1,"Revisit the choice of using flask","""We should quickly revisit if flask is the right choice for us.  Related: reportedly, our simple flask-based webserver is using more CPU in an idle state than expected. It might be useful to profile things, and look into that. """
"DM-2363","Story","afw",1,"RGB code introduces dependency on matplotlib","""While the new RGB code looks like it's just calling NumPy, NumPy is actually delegating to matplotlib under the hood when it writes RGB(A) arrays.  It also turns out that code is broken in matplotlib prior to 1.3.1 (though that shouldn't be a problem for anyone but those who - like me - are trying to use slightly older system Python packages).  I think think this means we should add an optional dependency on matplotlib to the afw table file, and condition the running of the test code on matplotlib's presence (and, ideally, having the right version).  I'm happy to do this myself (since I'm probably the only one affected by it right now)."""
"DM-2383","Story","Continuous Integration",2,"migrate package deps from sandbox-stackbuild to a proper puppet module","""There is a growing list of known package dependencies in the sandbox-stackbuild repo and a need to use this information for independent environments (such as CI).  This list of packages should be lifted out into an independent puppet module that can be reused."""
"DM-2382","Story","pipe_base",1,"Make sure the command-line parser warns loudly enough if no data found","""A user recently got confused when calling parseAndRun didn't call the task's run method. It turns out there was no data matching the specified data ID. Make sure this generates a loud and clear warning."""
"DM-2380","Story","Test Data",2,"Retrieve HSC engineering data","""HSC data becomes public 18 months after it was taken, so data taken during commissioning are now available.  We would like to use this data for testing the LSST pipeline.  It needs to be downloaded from Japan."""
"DM-2390","Story","Qserv",1,"Errors need to be checked in UserQueryFactory from QuerySession objects","""UserQueryFactory doesn't check its QuerySession object for errors after setQuery. Thus it continues setting things up after the QuerySession knows the state is invalid."""
"DM-2387","Story","Qserv",1,"Build testQDisp.cc on ubuntu","""testQDisp.cc needs flags -lpthread -lboost_regex to build on ubuntu."""
"DM-2411","Bug","Qserv",1,"Allow qserv-admin.py to delete a node","""Registered workers in CSS with qserv-admin.py are currently not able to be removed (no DELETE NODE type command). Also, changing node status from ACTIVE to INACTIVE needs to be fixed."""
"DM-2417","Bug","Qserv",1,"Data loader script crashes trying to create chunk table","""Vaikunth discovered a bug in data loader when trying to load a data into Object table:  It looks like I did not do enough testing after my recent improvement in creating chunk tables. It tries to create the chunk table with """"CREATE TABLE IF NOT EXISTS ..."""" but that actually generates """"warning exception"""" on mysql side when table is already there. Need to catch this exception and ignore it."""
"DM-2427","Story","afw",3,"Implement SpanSet applyFunctor methods","""Implement methods that apply arbitrary functors to pixels within a SpanSet, as described on RFC-37.    The only tricky part of this implementation will be the """"traits"""" classes that allow different target objects to interpreted differently.  I'd be happy to consult on this; I have a rough idea in my head, but it needs to be fleshed out."""
"DM-2426","Story","afw",2,"Implement SpanSet+ellipse operations","""Implement the following SpanSet operations:   - Construct from an ellipse - note geom::ellipses::PixelRegion; this should do most of the work.   - Compute centroid - see old Footprint implementation   - Compute shape (quadrupole moments) - see old Footprint implementation    One complication here is that this will introduce a circular dependency between afw::geom and afw::geom::ellipses.  That's easy to address at the C++ level, but it's tricky in Python (which package imports the other?)  I'll be emailing dm-devel shortly to start a discussion on how to address this problem."""
"DM-2423","Bug","meas_photocal",1,"Weighting in photometric calibration is incorrect","""Dominique points out that the zero point calibration uses errors not inverse errors to calculate the zero point.  git annotate reveals: bq. 24c9149f python/lsst/meas/photocal/PhotoCal.py (Robert Lupton the Good 2010-12-13 05:03:12 +0000 353)     return np.average(dmag, weights=dmagErr), np.std(dmag, ddof=1), len(dmag)  Please fix this.  At the same time, we should add a config parameter to soften the errors. """
"DM-2429","Improvement","meas_extensions_photometryKron",1,"Add aperture corrections to meas_extensions_photometryKron","""When transitioning {{meas_extensions_photometryKron}} to the new measurement framework, aperture correction was omitted pending the completion of DM-85. It needs to be re-enabled when that epic is complete."""
"DM-2435","Story","afw",1,"Reading an Exposure from disk aborts if the Psf is of an unknown type","""Attempting to read an Exposure (in this case via the butler) fails if the PSF class isn't available.  An exception would be reasonable, but an assertion failure is not.  Running the attached script on tiger-sumire with bq. setup python anaconda; setup -T v10_1_rc2 lsst_apps; setup -j distEst -t HSC; setup -j -r ~/LSST/obs/subaru  """
"DM-2430","Story","Qserv",1,"Make qserv server-side log messages more standard","""Qserv server-side Python logging appears to mostly use a common format: """"{{%(asctime)s %(name)s %(levelname)s: %(message)s}}"""".  It also mostly uses a common date format: """"{{%m/%d/%Y %I:%M:%S}}"""".  But I see instances of: * """"{{%(asctime)s %(levelname)s %(message)s}}"""" * """"{{%(asctime)s - %(name)s - %(levelname)s - %(message)s}}"""" *  """"{{%(asctime)s \{%(pathname)s:%(lineno)d\} %(levelname)s %(message)s}}"""" * and now, after DM-2176, """"{{%(asctime)s \[PID:%(process)d\] \[%(levelname)s\] (%(funcName)s() at %(filename)s:%(lineno)d) %(name)s: %(message)s}}""""  Unless these are used in very different contexts, it will aid automated log processing for them to be more standardized.  In addition, the date format is unacceptable as it does not use RFC 3339 (ISO8601) format and does not include a timezone indicator (which means the default {{datefmt}} is insufficient).  This must be fixed.  See also DM-1203."""
"DM-2442","Story","Middleware",3,"iRODS usage, devel survey","""Read up on current IRODS usage and development track. """
"DM-2441","Story","Middleware",2,"iRODS test: Register data in place","""In our first tests of iRODS, we have used """"iput"""" to load data into iRODS cache spaces (the iRODS Vault).  For large collections already in a well known location on a server, one may want to leave the data in place but still manage it with iRODS. To do this one can use """"ireg"""" to register the data with IRODS without the upload process."""
"DM-2436","Story","afw",0.5,"Cherry-pick ""fix makeRGB so it can replace saturated pixels and produce an image"" from HSC","""HSC-1196 includes fixes and test cases for {{afw}}. After review on HSC, they should be checked/merged to LSST."""
"DM-2456","Story","SUIT",8,"Participate in April design process","""Most work here was with designing firefly tools API related details."""
"DM-2455","Bug","meas_base",1,"uncaught exceptions in GaussianFlux","""{{SdssShapeAlgorithm::computeFixedMomentsFlux}}, which is used to implement {{GaussianFlux}}, now throws an exception when the moments it is given are singular.  That shouldn't have affected the behavior of {{GaussianFlux}}, as it contains an earlier check that should have detected all such bad input shapes.  But that doesn't seem to be the case: we now see that exception being thrown and propagating up until it is caught and logged by the measurement framework, resulting in noisy logs.  We need to investigate what's going wrong with these objects, and fix them, which may be in {{SdssShape}} or in the {{SafeShapeExtractor}} {{GaussianFlux}} uses to sanitize its inputs."""
"DM-2451","Bug","Qserv",1,"Fix interface between QservOss and new cmsd version","""QservOSS gives an error when attempting to run queries on the worker from the czar. Error log snippet:   """
"DM-2467","Story","ImgServ",8,"Implement stitching multiple patches across tract boundaries in a coadd v2","""* Find region that returns multiple tractPatchLists for testing.  * Request region via central point (RA, Dec) with width and height definable in arcseconds and pixels.  * May be extend web interface to other data sets, and/or good seeing SkyMaps. """
"DM-2466","Story","lsstsw",1,"lsstsw ./bin/deploy needs LSSTSW set to install products in the right place","""I  cloned lsstsw into ~/Desktop/templsstsw and cd'd into it and typed ./bin/deploy and was shocked to find it installed everything into ~/lsstsw, leaving an unsable mess: some files were in templsstsw and some in ~/lsstsw.  The short-term workaround is to manually set LSSTSW before running ./bin/deploy, but this should not be necessary; bin/deploy should either set LSSTSW or not rely on it. I don't recall this problem with earlier versions of lsstsw; I think this is a regression.  For now I updated the instructions at https://confluence.lsstcorp.org/display/LDMDG/The+LSST+Software+Build+Tool but I look forward to being able to revert that change."""
"DM-2477","Story","afw",8,"Design API and RFC design","""Use the HSC implementation of the base class as a point of reference for designing an integrated Approximate and Interpolate class.  The design take into account Chebyshev, spline, and Gaussian process mechanisms.  Want to take into consideration client code.  I.e. it shouldn't make current consumers more complicated (background and aperture correction to name two).  RFC the designed API."""
"DM-2475","Story","Qserv",1,"Build 2015_04 Qserv release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-2492","Story","shapelet",1,"shapelet unit tests attempts to access display on failure","""When tests/profiles.py tests fail, they attempt to create live plots without checking for any variables that indicate that the display should be used.  These plots should be disabled, as they obscure the real error when the display is not available."""
"DM-2491","Story","Middleware",1,"Initial survey of Datacat for LSST ","""Jacek, Brian Van Klaveren have sent along some initial overview/description of their work on Datacat;      https://confluence.slac.stanford.edu/display/~bvan/LSST+Datacat+Overview  We start examining this in the context of our studies of managing data collections at NCSA."""
"DM-2497","Story","Qserv",1,"Fix g++ 4.9 return value implicit conversion incompato","""g++ 4.9 enforces the """"explicit"""" keyword on type conversion operators in return value context.  This mean bool checkers along the lines of  bool isValidFoo() { return _smartPtrFoo; }  require an explicit cast to compile under g++ 4.9 with -std=c++0x.  There were a handful of these in our code; found and fixed."""
"DM-2511","Story","meas_astrom",2,"The distance field of match lists should be set","""The meas_astrom AstrometryTask returns a match list that has distance = 0 for all elements. Neither the matcher nor the WCS fitter are setting this field, and both ought to."""
"DM-2508","Story","Qserv",8,"Information exchange between processes - implementation","""Implement system for information exchange between cmsd and xrootd, per instructions in DM-2507"""
"DM-2506","Story","metaserv",2,"Document structure of our custom ddl ascii schema","""Need to better document what is supported / accepted by schemaToMeta.py. We are currently relying on cat/sql/baselineSchema.sql as the guide."""
"DM-2521","Story","lsstsw",1,"Update repo.yaml for first set of Sims Stash repo moves","""The repos.yaml file needs to be updated with correct repository locations once SIM-1074 is completed."""
"DM-2518","Story","QA",1,"Add a CFHT-based post-build integration test to the sandbox build","""From [~boutigny]    I have installed some simple stack validation tools working on CFHT data in {{/lsst8/boutigny/valid_cfht}}    Here is the content of the README file :    ------------------------------------------------------------------------------------------------------------------------  This directory contains a set of utilities to validate a stack release with CFHT data    At the moment, only validation plots for the astrometry are produced    Directories :  -------------  rawDownload     : contain raw CFHT images (flat, dark, bias, fringe,... corrected)  reference_plots : contain reference plots corresponding to the best results obtain so far.    Files :  -------  setup.cfht       : stack environment setup  valid_cfht.sh    : run processCcd taks on the cfht images     valid_cfht.sh init : create the input/ouput directories, ingest raw images and run processCcd     valid_cfht.sh      : without the """"init"""" argument, runs processCcd assuming that the directory structure exists and that the raw images have been ingested.  valid_cfht.py    : run some analysis on the output data produced by valid_cfht.sh  processConfig.py : configuration parameters for processCcd  run.list         : list of vistits / ccd to be processed by processCcd    Requirements :  --------------  obs_cfht : tickets/DM-1593  astrometry_net_data : SDSS_DR9 reference catalog corresponding for CFHT Deep Field #3  ------------------------------------------------------------------------------------------------------------------------    Basically it produces a set of plots stored in a png image that can be compared to a reference plot corresponding to the best results obtained so far with stack_v10_0    I hope that this is useful. Just be careful that I wrote these scripts with my own """"fat hand full of fingers"""" and that it is just basic code from a non expert. If it is useful, I can certainly add more plots to validate the psf determination, photometry, etc.    Comments, suggestions and criticisms are very welcome."""
"DM-2538","Story","webserv",3,"RESTful python client","""Develop basic abstractions for restful apis in a python client"""
"DM-2536","Technical task","afw",2,"Backwards compatibility for reading slots and measurements from FITS","""Rename fields to match the new slot and measurement naming conventions."""
"DM-2535","Technical task","afw",2,"Backwards compatibility for reading compound fields from FITS","""Read old-style afw::table compound fields in as scalar fields, using the new FunctorKey conventions."""
"DM-2533","Technical task","afw",1,"Remove version attribute from Schema","""Remove the Schema attribute and its getters and setters.  This change won't be something we can merge to master on its own, as it doesn't provide backwards-compatible FITS reading that will added in future tasks."""
"DM-2543","Story","SUIT",8,"Python APIs for Firefly ","""We need Python APIs to interface with Firefly visualization components.  This is the first set of many functions.  """
"DM-2551","Bug","pipe_base",1,"ANetAstrometryTask's debug doesn't fully work","""{{ANetAstrometryTask}}'s debug code calls (deprecated) method {{Task.display}}, which raises an AttributeError on this coce:    """
"DM-2549","Improvement","afw",2,"The string repr of Coord should show the coordsys and angles in degrees","""The default string representation of Coord (e.g. std::cout << coord in C++ and str(coord) in Python) is to show class name and a pair of angles in radians.  It would be much more useful if the default display showed the angles in degrees, as that is what people are used to. Also, it would be very helpful if the display included the name of the coordinate system. This is especially needed for the base class, as it is quite common to get shared_ptr to Coord and have no idea what coordinate system it is.  At present there is a lot of code that unpacks the angles and explicitly displays them as degrees to get around this problem. But it seems silly to have to do that."""
"DM-2547","Bug","Qserv",8,"Fix again interface between QservOss and new cmsd version","""QservOSS gives an error when attempting to run queries on the worker from the czar. Error log snippet:   """
"DM-2546","Bug","ctrl_events",1,"Host.cc doesn't find gethostname and HOST_NAME_MAX under el7","""el7 gives an error that it can't find HOST_NAME_MAX."""
"DM-2545","Story","base",1,"LaTeX support in Doxygen broken","""LaTeX markup in Doxygen documentation ought to be rendered properly for display in HTML. It isn't: it's just dumped to the page as raw text. See, for example, [the documentation for {{AffineTransform}}|https://lsst-web.ncsa.illinois.edu/doxygen/xlink_master_2015_04_15_07.01.28/classlsst_1_1afw_1_1geom_1_1_affine_transform.html#details]."""
"DM-2554","Technical task","afw",2,"Remove most compound fields from afw::table","""Remove all Point, Moment, Coord, and Covariance compound fields.  Array fields should be retained for now; it's not clear if we want to remove it or not, or how to handle variable-length arrays if we do."""
"DM-2552","Bug","Qserv",5,"xrootd can't be started via ssh","""{code:bash} qserv@clrinfopc04:~/src/qserv$ ssh localhost -vvv """"~qserv/qserv-run/2015_02/etc/init.d/xrootd start"""" ... debug3: Ignored env _ debug1: Sending command: ~qserv/qserv-run/2015_02/etc/init.d/xrootd start debug2: channel 0: request exec confirm 1 debug2: callback done debug2: channel 0: open confirm rwindow 0 rmax 32768 debug2: channel 0: rcvd adjust 2097152 debug2: channel_input_status_confirm: type 99 id 0 debug2: exec request accepted on channel 0 Starting xrootd.. debug1: client_input_channel_req: channel 0 rtype exit-status reply 0 debug1: client_input_channel_req: channel 0 rtype eow@openssh.com reply 0 debug2: channel 0: rcvd eow debug2: channel 0: close_read debug2: channel 0: input open -> closed  and the same problem occurs. So the problem seems to be with xrootd, and not the startup scripts.   """
"DM-2555","Story","SUIT",1,"Create and advertise Firefly mailing list","""Create an IPAC mailing list for all users of Firefly.  Advertise it to the interested communities (including the LSST Camera group) and through the Github site.  The mailing list firefly@ipac.caltech.edu has been created and all the interested partied have been subscribed to the list."""
"DM-2579","Bug","afw",1,"Calling AliasMap::get("""") can return incorrect results","""It looks like empty string arguments can cause AliasMap to produce some incorrect results, probably due to the partial-match logic being overzealous."""
"DM-2582","Story","mysql-proxy",5,"Research MaxScale as a mysql-proxy replacement","""We have been told by Monty that MaxScale is the replacement of the mysql-proxy. Based on DM-2057 the sentiment is that it won't work for our needs. We should very briefly document what our needs are, how we use the proxy now, and if we think MaxScale is not good-enough, say it why, and discuss with Monty and his team."""
"DM-2581","Story","log4cxx",1,"log4cxx build failure on OS X","""[~frossie] writes:  {quote} I have a log4cxx failure on a Macp while building lsst_distrib. Attaching file in case someone has any bright ideas for me in the morning {quote}"""
"DM-2580","Story","Qserv",5,"Implement user-friendly template customization","""Qserv configuration tool has to be improved to allow developers/sysadmin to easily use their custom configuration files (with custom log level, ...) for each Qserv services.    An optional custom/ config file directory will be added, and configuration files templates which will be here will override the ones in the install directory.    This should be thinked alongside configuration management inside Docker container."""
"DM-2594","Story","lsstsw",1,"Change repos.yaml for next set of Simulations Stash repos","""The next set of Simulations Stash repository migrations is laid out in SIM-1121."""
"DM-2593","Story","Qserv",8,"Client API for new worker management service","""We have new worker management service which has HTTP interface, now we need to provide simple way to access it from Python basically wrapping all HTTP details into simple Python API. """
"DM-2599","Bug","afw",3,"afw.Image.ExposureF('file.fits.fz[i]') returns the image in 'file.fits.fz[1]' ","""It seems that afwImage.ExposureF ignores the extension number when this is passed on as part of the filename and uses the image in extension number 1. This is not the case with afwImage.MaskedImageF which correctly uses the input extension number passed in the same way.  The problem has been checked on OSX Yosemite 10.10.3 with  the is illustrated in  the following code https://gist.github.com/anonymous/d10c4a79d94c1393a493  which also requires the following image in the working directory: http://www.astro.washington.edu/users/krughoff/data/c4d_130830_040651_ooi_g_d1.fits.fz """
"DM-2595","Story","Qserv",5,"Symlink data directory at configuration","""We decided to introduce symlinks in order to protect data. This is in particular useful when we need to reinstall qserv, but we have valuable, large data set that we want to preserve. This story introduces symlinks to data: when Qserv is reinstalled, only the symlink is destroyed, and the data stay untouched."""
"DM-2606","Story","afw",2,"HSC backport: recent Footprint fixes","""This is a backport issue to capture subsequent HSC-side work on features already backported to afw.  It includes (so far) the following HSC issues:   - [HSC-1135|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1135]   - [HSC-1129|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1129]   - [HSC-1215|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1215]"""
"DM-2625","Story","Qserv",1,"Create service for managing watcher","""We need to be able to start/stop the watcher implemented through DM-2624. This story involves extending our scripts for starting various qserv services to manage watcher."""
"DM-2624","Story","Qserv",1,"Implement DROP table in watcher","""Implement DROP table using the watcher designed in DM-2623."""
"DM-2623","Story","Qserv",2,"Design Basic Watcher","""Design watcher, including its interactions with other components (mysql, css, etc). In the near term, the watcher will handle deleting tables and databases."""
"DM-2636","Improvement","afw|coadd_utils|ctrl_execute|datarel|ip_diffim|meas_algorithms|meas_astrom|obs_base|obs_lsstSim|obs_sdss|obs_test|pex_config|pipe_base|pipe_tasks|utils",3,"Update code to use the function provided in DM-2635","""As per RFC-44: update existing code that finds packages using eups.getProductDir or by using environment variables to use the function added in DM-2635"""
"DM-2635","Improvement","utils",2,"Provide a function to return the path to a package, given its name","""As per RFC-44 we want a simple function in utils that returns the path to a package given a package name. This has the same API as eups.getProductDir, but hides our dependence on eups, as per the RFC."""
"DM-2634","Story","Firefly",8,"add new image stretch algorithm to Firefly visualization ","""There is a need to include two new stretch algorithms, which are asinh and power law gamma.  The algorithm is as follow: * asinh ## input        zp: zero point of data        mp: maximum point of data        dr:  dynamic range scaling factor of data.  It ranges from 1-100,000        bp: black point for image display        wp: white point for image display ## calculate rescaled data value        rd = dr *(xPix - zp)/mp ## calculate normalized stretch data value         nsd = asinh(rd)/asinh(mp-zp) ## calculate display pixel value        dPix = 255 * (nsd-bp)/wp       Note: The bp, wp values specify how far outside of the scale data one wants the image to display.  By default, setting bp=0 and wp=dr.    * power law gamma ## input \br        zp: zero point of data        mp: maximum point of data        gamma: gamma value for exponent ## calculate rescaled data value        rd = xPix - zp ## calculate normalized stretch data value         nsd =  rd^(1/gamma) / (mp0zp)^(1/gamma) ##  calculate display pixel data value         dPix = 255 * nsd       """
"DM-2630","Story","Qserv",3,"Document configuration tool main use cases","""- Document main use case for qserv-configure.py: install Qserv master/worker node with externalized data directory  - Hide complex configuration options?    """
"DM-2629","Bug","Qserv",1,"Fix build for gcc 4.7.2 and gcc 4.8.2","""#include <condition_variable> is missing in threadSafe.h"""
"DM-2627","Story","Qserv|qserv_testdata",5,"Add support for configuring multi-node integration tests","""The multi-node integration test software produced through DM-2175 has hardcoded node names. This story will allow user to configure it. Current plan is to pre-set integration test for several different configurations, e.g., single-node, 2-node, 8-node (and maybe eg 24-node), and user would supply node names through a configuration file."""
"DM-2679","Bug","Qserv",1,"Fix default LOAD DATA options","""Integration tests in multi-node produced the following error during data loading:   The default options for MySQL LOAD DATA need to be fixed for this."""
"DM-2672","Story","Qserv",1,"Build 2015_06 Qserv Release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-2671","Story","Qserv",1,"Build 2015_05 Qserv Release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-2694","Story","Qserv",8,"Revisit mysql connections from worker","""Revisit the code that handles mysql connections in qserv. At the moment Qserv will maintain a connection per chunk-query, up to a hardcoded limit (GroupScheduler: 4, ScanScheduler:32).  Also, we have to gracefully handle connection issues (such as dropped connection, or if we hit the max_connections limit)."""
"DM-2692","Story","Middleware",2,"Rule for automatic replication in iRODS","""Maintaining extra copies/replicas on separate resources is an important tenet in iRODS, with this practice considered key for prevention of data loss. The automatic replication of files upon ingest can be encoded via a system rule, so that data is preserved as a inherent part of storing in iRODS."""
"DM-2683","Bug","Qserv",1,"Fix case05 3009_countObjectInRegionWithZFlux freeze","""This prevents 2014_05 release to pass integration tests."""
"DM-2682","Bug","Qserv",1,"Add missing empty-chunk-path on Ubuntu 14.04","""QSERV_DATA_DIR/var/lib/qserv wasn't created on Ubuntu 14.04 and this was breaking loader script. It was working on SL7 for unknown reason. Creation of the directory has been added to qserv-czar config script."""
"DM-2712","Story","Qserv",2,"Migrate boost::shared_ptr to std::shared_ptr","""We are mixing boost and std shared_ptrs. This should be cleaned up - use std:shared_ptr consistently everywhere. In a few places we have other types of pointers, (e.g weak_ptr). Migrate these too."""
"DM-2711","Story","Qserv",5,"Migrate boost:thread to std::thread","""We are mixing boost and std threading libraries. This should be cleaned up - use std:thread consistently everywhere."""
"DM-2710","Bug","Qserv",1,"Mutex use before creation","""qana/QueryPlugin.cc contains a static boost::mutex, that is used by static class member functions to register plugin implementations. Its constructor is not guaranteed to be called before the static registerXXXPlugin (see e.g. qana/AggregatePlugin.cc) instances use it to register plugin classes."""
"DM-2708","Bug","Qserv",2,"Understand race condition in Executive::_dispatchQuery","""Inserting a log (presumably just a delay) in Executive::_dispatchQuery after the new QueryResource but before the Provision call causes queries to fail.  The particular test query was """"select count(*) from Object"""" on test case 01."""
"DM-2716","Bug","Qserv",2,"Fix connection leak (2nd iteration)","""Fix connection leak (and memory leak and thread leak) -- we are leaking 2 per query."""
"DM-2722","Story","Qserv",1,"Revisit design of query poisoner","""As we discovered through DM-2698, poisoner tends to hold onto query resources even after the query completes. We should revisit whether than can be redesigned and improved, so that when query finishes, all resources related to that query are immediately automatically released. This story involves just the planning part, implementation will be done through separate stories."""
"DM-2718","Story","lsstsw",1,"Upgrade EUPS used by lsstsw","""As discussed, bump it up when you get a chance please. """
"DM-2729","Bug","Qserv",1,"Fix a few more g++ 4.9.2 compatos","""Some of the recent boost -> std changes don't compile/link under gcc 4.9.2, because of some poor #include hygiene (including <thread> when we should include <condition_variable>, not explicitly including <unistd.h>, etc.)  Also, -pthread linker option is required when using std::thread under gcc 4.9.2. """
"DM-2728","Bug","Firefly",2,"Build should fail if node.js is not present","""Problem: I built Firefly by mistake w/o having node on my path. The build didn't signal any errors, but generated an unusable webapp that wouldn't load.  Expected behavior: the build should have failed and warned the user that node.js is missing."""
"DM-2734","Bug","qserv_testdata",1,"Add config file for test dataset 04 tables","""Following the changes to default LOAD DATA settings in DM-2679, two tables in test case 04 need to have a config file to include their in.csv format."""
"DM-2737","Story","pipe_tasks",1,"Build a DiscreteSkyMap that covers a collection of input exposures","""This is essentially a rehash of the old trac Ticket #[2702| https://dev.lsstcorp.org/trac/ticket/2702], originally reported by [~jbosch], which reads:  """"I'd like to add a Task and bin script to create a DiscreteSkyMap that bounds a set of calexps specified by their data IDs. This makeDiscreteSkyMap.py could be used instead of makeSkyMap.py when the user would rather compute the pointing and size of the skymap from the input data than decide it manually.""""  The work was done by [~jbosch] & [~price] and exists on branch {{u/price/2702}} in {{pipe_tasks}}, but it was never merged to master.  I plan to simply rebase the commits in that branch onto master."""
"DM-2740","Improvement","meas_astrom",2,"Make ANetAstrometryTask more configurable","""The current ANetAstrometryTask has a solver that is not easy to retarget. This makes testing with hscAstrom needlessly difficult. My suggestion is to make the solver a true Task instead of a task-like object, and make it retargetable using a ConfigurableField instead of a ConfigField. This is very easy to do because the solver is already a task in all but name. """
"DM-2738","Technical task","Qserv",1,"Remove #include ""XrdOuc/XrdOucTrace.hh"" from Qserv code","""See next emails:  Hi Fabrice,  Absolutely!  Andy  On Wed, 13 May 2015, Fabrice Jammes wrote:  > Hi Andy, > > Thanks, > > In my understanding, you're ok if I remove the existing > #include """"XrdOuc/XrdOucTrace.hh"""" > from Qserv source code. I'll do it soon. > > Have a nice day, > > Fabrice > > Le 12/05/2015 23:41, Andrew Hanushevsky a crit : >> Hi Fabrice, >> >> Well, no. We have a long-standing approach that qserv should not depend on anything outside of XrdSsi public interfaces. This is the only way to easily protect sqserv code from infrastructure changes. So, I would not. If you want to copy something like that for >> >> qserv please do, it's simple enough. But in the end qserv needs to be self-contained in that it does not depend on xrootd code just the public ssi interfaces. >> >> Andy >> >> -----Original Message----- From: Fabrice Jammes >> Sent: Tuesday, May 12, 2015 9:06 AM >> To: Andrew Hanushevsky >> Subject: About xrdssi client logging >> >> Hi Andy, >> >> Hope you're doing well. >> Could you please tell me if its usefull to include >> #include """"XrdOuc/XrdOucTrace.hh"""" >> in our xrdssi client code? >> >> Indeed client seems to only print DBG macro output, that's why I was >> wondering if XrdOucTrace was only use on the server side. >> If yes, I will remove it from our client. >> >> Thanks, and have a nice day, >> >> Fabrice """
"DM-2752","Bug","Database",1,"db 10.1+4 tests randomly fail with python egg installation error","""The unit tests for DB seem to fail at random and always pass on a second build attempt.  My hunch is that multiple tests are running in parallel all attempting to install the mysql module but I haven't investigated.    """
"DM-2748","Bug","Qserv",2,"Add clear message when integration test fails","""Integration test fails without printing a clear message at the end, and for now a query is broken: 0011_selectDeepCoadd.txt but it isn't printed at the end of tet output."""
"DM-2762","Bug","Qserv",3,"Avoid leaking memory allocated by mysql_thread_init","""mysql/MySqlConnection.cc contains the following comment:   The comment is not really correct with regards to thread pooling. Instead, each rproc::InfileMerger has an rproc::InfileMerger::Mgr which contains a util::WorkQueue that spawns a thread, and so we are failing to call mysql_thread_end at least once per user query. This has been verified using the memcheck valgrind tool. """
"DM-2770","Bug","sconsUtils",1,"sconsUtil install target does not respond to either force=True or --force","""I've been unable to figure out how to bypass the install 'force' check, but have confirmed that this is the correct expression by commenting it out:    https://github.com/lsst/sconsUtils/blob/54c983ffe9714a33657c4388de3506fe7a40518d/python/lsst/sconsUtils/installation.py#L92      """
"DM-2779","Story","Qserv",2,"Fix race in Foreman","""The Foreman implementation passes a TaskQueue pointer corresponding to running tasks down to the task scheduler without holding a lock. This means that the scheduler can inspect the running task list (usually to determine its size) while it is being mutated."""
"DM-2777","Story","Qserv",2,"Fix races in BlendScheduler","""_integrityHelper() from wsched/BlendScheduler inspects a map of tasks and is sometimes called without holding the corresponding mutex. My theory is that it is observing the map in an inconsistent state, leading to assert failure and hence worker death, and finally to hangs/timeouts on the czar."""
"DM-2789","Improvement","obs_base",3,"rename CameraMapper.getEupsProductName() to getPackageName() and convert to abstract method","""Per discussion on this PR related to DM-2636:  https://github.com/lsst/daf_butlerUtils/pull/1#issuecomment-104785055    The CameraMapper.getEupsProductName() should be renamed to getPackageName() and converted to an abstract method.  This will eliminates a runtime, and thus """"test time"""", dependency on EUPS.  As part of the rename/conversion, all subclasses that are not already overriding getEupsProductName() will concurrently need to have getPackageName() implemented."""
"DM-2787","Story","afw",5,"Footprint dilation performance regression","""In DM-1128 we implemented span-based dilation for footprints. A brief test on synthetic data indicated that this was a performance win over the previous version of the code.    In May 2015, this code was merged to HSC and applied to significant quantities of real data for the first time. A major performance regression was identified:    {quote}  [May-9 00:26] Paul Price: processCcd is now crazy slow.  [May-9 00:29] Paul Price: Profiling...  [May-9 00:40] Paul Price: I'm thinking it's the Footprint grow code...  [May-9 00:44] Paul Price: And the winner is. Footprint construction:  [May-9 00:44] Paul Price: 2    0.000    0.000  702.280  351.140 /home/astro/hsc/products/Linux64/meas_algorithms/HSC-3.8.0/python/lsst/meas/algorithms/detection.py:191(makeSourceCatalog)        2    0.005    0.002  702.274  351.137 /home/astro/hsc/products/Linux64/meas_algorithms/HSC-3.8.0/python/lsst/meas/algorithms/detection.py:228(detectFootprints)      15    0.001    0.000  698.597  46.573 /home/pprice/hsc/afw/python/lsst/afw/detection/detectionLib.py:3448(__init__)      15  698.596  46.573  698.596  46.573 {_detectionLib.new_FootprintSet}  [May-9 00:53] Paul Price: If I revert HSC-1243 (""""Port better Footprint-grow code from LSST""""), then the performance regression goes away.  @jbosch @jds may be interested...  {quote}    The source of the regression must be identified and resolved for both HSC and LSST."""
"DM-2782","Story","SUIT",2,"Firefly Tools API: Add advance region support","""Firefly Tools API: Add advance region support  Improve firefly's region functionality to support a """"dynamic region"""".  Data can be added or removed from this region by API calls.  Allow any amount of region lines to be added or removed.  Make sure performance is good.  Also, document the current Firefly region support."""
"DM-2792","Story","meas_astrom|pipe_tasks",1,"Make the new astrometry task the default task","""The new astrometry task should be the default astrometry task, but we need to make sure it is good enough first."""
"DM-2799","Bug","obs_base",2,"Tests for daf_butlerUtils should not depend on obs_lsstSim","""Currently two of the tests in {{daf_butlerUtils}} depend on {{obs_lsstSim}}. They will never run in a normal build because {{obs_}} packages can not be a dependency on {{daf_butlerUtils}}.    After discussing the options with [~ktl] the feeling is that {{ticket1640}} should be rewritten to remove the dependency and {{ticket1580}} can probably be removed."""
"DM-2827","Story","dbserv",8,"Implement RESTful interfaces for Database (POST)","""Implement RESTful interfaces for Database (see all D* in https://confluence.lsstcorp.org/display/DM/API), based on the first prototype developed through DM-1695. The work includes adding support for returning appropriately formatted results (support the most common formats). This covers """"POST"""" type requests only, """"GET"""" will be handled separately."""
"DM-2804","Story","Qserv",8,"Implement query metadata skeleton","""Skeleton implementation of the Query Metadata - including the APIs and core functionality (accepting long running query and saving the info about it)"""
"DM-2803","Story","qserv_testdata",8,"Adapt multi-node tests to latest version of qserv / loader","""The multi-node integration tests have to be updated to work with the latest changes to qserv, in particular the loader, which broke already working tests lately."""
"DM-2847","Epic","SUIT",40,"SUI Firefly server side Python job management","""In order to support Camera team needs and L3 data production, Firefly server needs to be able to start a Python job with proper input data and get the output data as a result of running the Python job. This will make the future integration of Firefly and DM pipeline stack much easier. """
"DM-2854","Bug","Qserv",2,"Fix Qserv SsiSession worker race","""The worker SsiSession implementation calls ReleaseRequestBuffer after handing the bound request to the foreman for processing. It therefore becomes possible for request processing to finish before ReleaseRequestBuffer is called by the submitting thread, resulting in a memory leak."""
"DM-2849","Story","afw",2,"Tweaks to OO display interface","""When I wrote the initial version of display_firefly I found a few minor issues in the way I'd designed the Display class; at the same time, [~lauren] found some missing functions in the backward-compatibility support for ds9.    Please fix these;  note that this implies changes to afw, display_ds9, and display_firefly.  """
"DM-2870","Story","butler",2,"Learn about Butler","""Transferring knowledge from K-T to the DB team."""
"DM-2869","Story","butler",2,"Learn about Butler","""Transferring knowledge from K-T to the DB team."""
"DM-2868","Story","butler",2,"Learn about Butler","""Transferring knowledge from K-T to the DB team."""
"DM-2867","Story","butler",2,"Learn about Butler","""Transferring knowledge from K-T to the DB team."""
"DM-2866","Story","butler",2,"Learn about Butler","""Transferring knowledge from K-T to the DB team."""
"DM-2865","Story","afw",2,"Merge BoundedField from HSC as is","""To make headway on aperture corrections, we are bringing the HSC implementation of BoundedField over."""
"DM-2864","Bug","Qserv",8,"Fix bug related to selecting rows by objectId from non-director table","""The following example illustrates the problem:    Let's select one raw from qservTest_case01_qserv        Then select it, but use """"sourceId"""" in the query, all good here:      But if we add """"objectId"""", the row is not found:        Similarly, even without sourceId constraint, the query fails:      """
"DM-2883","Story","afw",1,"wcslib is unable to read PTF headers with PV1_{1..16} cards","""SCAMP writes distortion headers in form of PVi_nn (i=1..x, nn=5..16) cards, but this is rejected (correctly) by wcslib 4.14;  there is a discussion at https://github.com/astropy/astropy/issues/299    The simplest """"solution"""" is to strip the values PV1_nn (nn=5..16) in makeWcs()  for CTYPEs of TAN or TAN-SIP and this certainly works.    I propose that we adopt this solution for now.  """
"DM-2887","Bug","Qserv",8,"Fix broken IN - it now takes first element only","""IN is broken - it only uses the first element from the list. Here is the proof:    """
"DM-2885","Story","Qserv",5,"Improve confusing error message","""Selecting a column that does not exist results in confusing error. Example:        ERROR 4120 (Proxy): Error during execution:  -1 Ref=1 Resource(/chk/qservTest_case01_qserv/6630): 20150605-16:23:42, Error in result data., 1, (-1)    Similarly,         prints  ERROR 4120 (Proxy): Error during execution:  -1 Ref=1 Resource(/chk/qservTest_case01_qserv/6630): 20150605-16:23:52, Error in result data., 1,   Ref=2 Resource(/chk/qservTest_case01_qserv/6631): 20150605-16:23:52, Error merging result, 1990, Cancellation requested  Ref=3 Resource(/chk/qservTest_case01_qs (-1)    (note, sourceId does not exist in Object table)      """
"DM-2892","Story","css|Qserv",1,"Keep track of database of the director table","""An L3 child table might very well have an LSST data release Object table as its director, while almost certainly not living in the DR database. To support it, we should keep track of the database name holding director's table. Note, this is related to DM-2864 - the code touched in that ticket should be checking the director's db name.    Don't forget to add a unit test that will exercise it!"""
"DM-2891","Bug","meas_algorithms",2,"meas.algorithms.utils uses measurement algorithms that are no longer available","""meas.algorithms.utils uses GaussianCentroid and SdssShape, but now that they have moved to meas_base the code no longer works.    Please fix this.  I'd prefer to leave the functionality to visualise PSFs in meas_algorithms, but if necessary file an RFC to move it elsewhere.  """
"DM-2890","Story","ip_isr",1,"isrTask assumes that the Exposure has a Detector","""While trying to use the isrTask to interpolate over bad columns in PTF data I discovered that the code assumes that the Exposure has a Detector attached.    Please remove this restriction.  """
"DM-2900","Story","qserv_testdata",2,"Add queries that exercise non-box spatial constraints","""Qserv has code to support:   * qserv_areaspec_box   * qserv_areaspec_circle   * qserv_areaspec_ellipse   * qserv_areaspec_poly    but only the first one (box) is exercised in our integration tests. This story involves adding queries to test the other 3."""
"DM-2895","Story","Developer Infrastructure",1,"treat lsst_apps, lsst_libs and lsst_thirdparty as top level products not required by lsst_distrib","""Per discussion on RFC-55, it was determined that  lsst_apps and lsst_libs and lsst_thirdparty maybe be treated as separate top level products that lsst_distrib need not depend on them nor do they need to be included as part of CI builds."""
"DM-2911","Story","Qserv",1,"Build 2015_07 Qserv Release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-2910","Story","obs_cfht",1,"obs_cfht is broken with the current stack","""obs_cfht's camera mapper is missing the new packageName class variable, so it is not compatible with the current stack.    I suggest fixing obs_sdss and obs_subaru as well, if they need it."""
"DM-2909","Improvement","sconsUtils",1,"Remove unused code from sconsUtils","""The code in {{deprecated.py}} in {{sconsUtils}} is not used by anything anywhere. [~jbosch] has indicated that the file can simply be removed."""
"DM-2905","Improvement","scons",1,"Update Scons to v2.3.4","""Scons has not been updated in over a year. RFC-61 agreed that we should upgrade it now before tackling some other {{scons}} issues."""
"DM-2919","Story","pipe_tasks",1,"PhotoCalTask mis-calling Colorterm methods","""When I implemented DM-2797 I made a few errors in pipe_tasks:  - PhotoCalTask mis-calls two methods of Colorterm by providing filterName, which is not needed  - ColortermLibrary.getColorterm mis-handles glob expressions (the two arguments to fnmatch.fnmatch are swapped).    We also need a unit test for applying colorterms, but that will require enough work that I have made a separate ticket for it: DM-2918. Meanwhile I have tested my changes by running Dominique's CFHT demo. This proves that the colorterm code runs, but does not prove that the terms are correctly applied."""
"DM-2917","Bug","obs_cfht",1,"obs_cfht unit tests are broken","""obs_cfht has one unit test """"testButler"""" that uses git://git.lsstcorp.org/contrib/price/testdata_cfht. 4 of the tests fail, as shown below.    In addition, testdata_cfht is huge, and the tests barely use any of it. It's worth considering making a new test repo that is smaller, or if the amount of data is small enough, move it into afwdata or obs_cfht itself.    """
"DM-2934","Story","Developer Infrastructure",1,"Add RFD issue type to RFC project","""To support the RFD process adopted in [RFC-53], an RFD issue type in the RFC project is required.  While we could add RFD-specific fields to it, I think it's simplest if it's just generic with details provided in the Description."""
"DM-2929","Bug","afw",2,"Some AFW tests are not enabled with no explanation","""Running {{coverage.py}} on the AFW test suite indicated that two test classes in {{tests/wcs1.py}} are disabled. {{WCSTestCaseCFHT}} was added by [~rhl] in 2007 but disabled during a merge a long time ago by [~jbosch] in 2010 but with no indication as to why. {{WCSRotateFlip}} appeared in 2012 (added by [~krughoff]) but doesn't appear in the {{suite}} list at the end and so does not execute.    Similarly {{testSchema.py}} has two tests that are not run: {{xtestSchema}} and {{testJoin}}. I assume {{xtestSchema}} is deliberately disabled but could there at least be a comment in the test explaining why?    My feeling is that we should either run the tests or they should be removed. Having them their gives the impression they are doing something useful.    Less importantly, {{warpExposure.py}} has some support code for comparing masked images that was written in 2009 by [~rowen] but which is not used anywhere in the test."""
"DM-2927","Improvement","sconsUtils",1,"Modernize sconsUtils code to python 2.7 standard","""As part of the work investigating DM-2839 I modernized the sconsUtils code to meet current coding standards (using {{in}} rather than {{has_key}}, using {{items()}} rather than {{iteritems}} etc). Since I'm highly doubtful that DM-2839 is going to be closed any time soon I will separate out the modernization patches into this ticket."""
"DM-2931","Story","afw",1,"We write truncated Wcs data to  extended HDU tables in Exposures","""When we write Wcs to extra HDUs in Exposures they are truncated if other than TAN/TAN-SIP.  Please don't write them.    A better long term solution is needed.  In particular, we shouldn't be duplicating this information unnecessarily, and we need to be able to persist e.g. TPV to the tables so as to support CoaddPsf.  These issues are not included here."""
"DM-2930","Bug","Qserv",5,"Fix problem with Qserv related to restarting mysql","""I noticed some strange (reproducible!) behavior: if I run:        then restart mysqld        then the query:      consistently fails every single time.    To fix it, it is enough to restart xrootd."""
"DM-2936","Story","Firefly",3,"Refactor Histogram in edu.caltech.ipac.visualize.plot package.","""The Histogram has 6 constructors to handle 6 bitpixel data types which are byte, short integer,  integer, long integer, float and double.  Since FitsRead has now only works on float, there the  Histogram should be refactored accordingly."""
"DM-2938","Bug","pipe_tasks",1,"CalibrateTask has an unwanted ""raise"" in it","""On 2014-06-30 commit 696b641 a developer added a bare """"raise"""" as a debugging aid to the CalibrateTask in pipe_tasks. That change was accidentally merged to master. I confirmed it was an accident and am filing this ticket as a way to remove the raise and run buildbot before merging to master."""
"DM-2940","Bug","afw|display_ds9",1,"DS9 tests fail if DS9 not running in some configurations","""There are a few issues with the robustness of the {{testDs9.py}} tests in AFW.    * The tests are skipped if the {{display_ds9}} package can not be loaded but they should also skip if {{ds9}} is missing or if {{ds9}} can not be loaded. The latter is especially important during builds that unset {{$DISPLAY}}.  * The launching code in {{initDS9}} can not notice the simple case of {{ds9}} immediately failing to load. It simply assumes that there are delays in launch. The reason for this is that {{os.system}} does not return bad status if the command has been started in the background. Another scheme for starting {{ds9}} should be considered. Maybe a different exception could be raised specifically for failing to start it.  * At the moment each test independently has a go at starting {{ds9}}. This makes the tests take a very long time (made worse by {{_mtv}} also trying multiple times) despite it being clear pretty quickly that {{ds9}} is never going to work.  * Currently the {{mtv}} tests must run early as they are the only tests that attempt to start {{ds9}} if it is not running. If the two tests that call {{mtv}} are disabled two other tests fail. Ideally the {{initDS9}} code should be called in all cases."""
"DM-2945","Bug","Qserv",1,"Wmgr refuses to serve queries from remote interface","""Vaikunth discovered that wmgr returns 404 for all operations. It looks like wmgr can serve requests coming from 127.0.0.1 interface but returns 404 for queries from non-local interface."""
"DM-2944","Story","meas_algorithms|meas_deblender|pipe_tasks",1,"SourceMeasurementTask still referenced in our stack","""SourceMeasurementTask is gone, but we still have code that refers to it, including:      I will handle pipe_tasks calibrate.py as part of DM-435."""
"DM-2952","Story","SUIT",3,"Crop needs to be refactored","""This class needs to be refactored to be in consist with FitsRead class which treats all data type as float.  Thus the bitpix in this class does not have to be treated based on its value."""
"DM-2949","Story","datarel",1,"remove dead code and dependencies from datarel","""Removing the {{datarel}} package entirely has proved to be difficult (DM-2928, DM-2948), so instead I'm simply going to remove non-ingest code (and dead ingest code) from the package, along with its dependencies on {{ap}} and {{testing_endToEnd}}.  Other dependencies will be retained even if they aren't necessary for the code that will remain in {{datarel}}, to support {{lsstDoxygen}}'s use of {{datarel}} as a top-level package for documentation generation."""
"DM-2948","Story","buildbot|lsstDoxygen",3,"Remove explicit buildbot dependency on datarel","""The buildbot scripts have an explicit dependency on the {{datarel}} package, which we'd like to remove from the stack.  It uses {{datarel}} as the top-level product when building the cross-linked HTML documentation; {{lsstDoxygen}}'s {{makeDocs}} script takes a single package, and generates the list of packages to include in the Doxygen build by finding all dependencies of that package.    So, to remove the explicit dependency on {{datarel}}, we need to either:   - find a new top-level product with a Doxygen build to pass to {{makeDocs}} (e.g. by adding a trivial Doxygen build to {{lsst_distrib}})   - modify the argument parsing in {{lsstDoxygen}} to take a list of multiple products (it *looks* like the limitation to one package is only in the argument parsing), and pass it a list of top-level products in the buildbot scripts.    This is currently a blocker for DM-2928, which itself a blocker for DM-1766, which has now been lingering for a few weeks now.  I'm going to look for other ways to remove the block on the latter, but I don't have a solution yet."""
"DM-2966","Story","Qserv",2,"Design CSS that supports updates","""Design how to redesign CSS, we currently take a snapshot when char starts. It is too static. """
"DM-2982","Bug","Qserv",1,"Updating node status in qserv-admin to INACTIVE fails","""In qserv-admin.py when attempting to update a node status from ACTIVE to INACTIVE the following error is produced:    """
"DM-2981","Story","afw|meas_algorithms",8,"polygon masking in CoaddPsf","""We need to create polygon-based masks of the usable area of the focal plane, persist them with exposure, and include them in coaddition of PSFs and aperture corrections.    This includes HSC issues HSC-972, HSC-973, HSC-974, HSC-975, HSC-976.    At least some of this will be blocked by DM-833, which is the port issue for coaddition of aperture corrections."""
"DM-2980","Story","pipe_tasks",5,"refactor coaddition code","""The HSC fork has coaddition code in two places: pipe_tasks and hscPipe.  The code in hscPipe is what we use (though that depends on the code in pipe_tasks in places), while the code in pipe_tasks is more similar to what's currently on the LSST side.    We want to bring the refactored version in hscPipe back to LSST, but we want to put it directly in pipe_tasks to remove the code duplication that currently exists on the HSC side.    Work on this issue should begin with an RFC that details the proposed changes.    Note that this should not bring over the """"safe coadd clipping"""" code, which is DM-2915."""
"DM-2977","Story","meas_modelfit",2,"Miscellaneous CModel improvements from HSC","""This improves handling of several edge case failure modes, tweaks the configuration to improve performance, and adds some introspection useful for Jose Garmilla's tests.    Includes HSC-1288, HSC-1284, HSC-1228, HSC-1250, HSC-1264, HSC-1273, HSC-1240, HSC-1249, HSC-1238, HSC-990, HSC-1155, HSC-1191"""
"DM-2976","Story","afw",2,"SourceCatalog.getChildren requires preconditions but does not check them","""This is a code transfer from HSC-1247."""
"DM-2992","Story","SUIT",8,"Search processors to get image, table, or json from an external task","""Implement three search processors, which use the External Task Launcher (DM-2991):    - to get a table (possibly in binary FITS format)  - to get an image  - to get JSON"""
"DM-2989","Story","SUIT",2,"XY plot need to be able to handle multiple tables with the same name","""XY plot was relying on a table request object to cache previously loaded tables.  This was done for performance reason.  However, table request is not reliable since the same request may be submitted multiple times."""
"DM-2987","Story","SUIT",2,"Modify IpacTableParser to support extra wide table.","""IpacTableParser fail to load IPAC table with extra wide headers and columns.  Replace the logic for reading headers and columns information so that it will support any file/size."""
"DM-2985","Story","SUIT",2,"Integrate javascript build with gradle","""Integrate javascript build tools webpack with gradle."""
"DM-2993","Bug","webservcommon",1,"Products must not depend on anaconda","""{{setupRequired(anaconda)}} should be removed from webservcommon.table.    We want to keep the stack buildable with any python 2.7, and should not explicitly depend on anaconda."""
"DM-2997","Story","anaconda",1,"Bump eups anaconda package to 2.2","""By popular request. """
"DM-3031","Story","Middleware",2,"Addressing File corruption in iRODS 4.1.x","""We examine solutions for repairing corrupt files within an iRODS 4.1.x zone."""
"DM-3030","Story","Developer Infrastructure",1,"Set up Discourse for evaluation.","""  Server up on DO at community.lsst.org. Email needs fixing before volunteer users can be invited. """
"DM-3029","Story","Developer Infrastructure",1,"Set up Slack for evaluation","""  Free account procured and tested by various volunteers; next step is to apply for non-profit status which gives us the first paid tier free to 100 users. """
"DM-3090","Improvement","Qserv",1,"Implement test suite for new class SqlTransaction","""Some test that shows that transactions are properly committed/aborted would be nice to have."""
"DM-3037","Story","Qserv",1,"remove lsst/log wrapper from Qserv","""lsst/log API looks stable now, so removing the wrapper would simplify the code."""
"DM-3091","Story","Qserv",0.5,"Remove unused function populateState() ","""Qserv doesn't seem to relaunch no more chunk query in case it fails (see DM-2643)    And this function is now unused:  {code:bash}  qserv@clrinfopc04:~/src/qserv (master)$ grep -r populateState core/  core/modules/qdisp/Executive.cc:void populateState(lsst::qserv::qdisp::ExecStatus& es,  {code}  """
"DM-3102","Story","log|Qserv",5,"Resolve segmentation fault in LoggingEvent destructor","""There seems to be a possible race condition in log4cxx::spi::LoggingEvent::~LoggingEvent. I've had multiple segmentation faults in that function. In all cases, another thread was involved in writing. In at least 2 cases, the second thread was in XrdCl::LogOutFile::Write.  """
"DM-3104","Story","Qserv",8,"Add ""ORDER BY"" clause to lua SQL query on result table","""If user query has """"ORDER BY"""", then lua  can't just execute """"SELECT * FROM result"""" because the order for such query is not guaranteed. To fix that, we need to add """"ORDER BY"""" clause to the """"SELECT * FROM result"""" query on the lua side.    Once we have the above, we might want to remove """"ORDER BY"""" from the query class which runs a merge step on the czar (this has to be done in query analysis step)."""
"DM-3110","Story","Qserv",1,"qserv code cleanup","""I made some random cleanup of the qserv code while playing with css v2. I want to push these changes to master, thus I am creating this story for this. It involves improvements to logging in UserQueryFactory and Facade (both are now per-module), removing unnecessary namespace qualifiers, and whitspace cleanup."""
"DM-3109","Story","Qserv",3,"Add support for accessing schema from QueryContext","""When we are analyzing a query, sometimes there are situations where we need to know the schema of tables involved in a query. It will also be useful for checking if user is authorized to run query, and for queries like """"SHOW CREATE TABLE"""". This story involves writing code that will provide access to schema."""
"DM-3108","Story","pipe_tasks",1,"Use aperture flux for photometric calibration","""This is a port of work performed on HSC but without a ticket. Relevant commits are:    * [05bef6|https://github.com/HyperSuprime-Cam/meas_astrom/commit/05bef629adc37e44ea8482aab88e2eb38a47e3a0]  * [4a6be5|https://github.com/HyperSuprime-Cam/meas_astrom/commit/4a6be51c53f61e70f151de7f29863cb723197a99]  * [69d35a|https://github.com/HyperSuprime-Cam/obs_subaru/commit/69d35a890234e37c1142ddbeff43e62fe36e6c45]  * [9c996d|https://github.com/HyperSuprime-Cam/obs_subaru/commit/9c996d75c423ce03fb54c4300d9c7561b5c1ea99]"""
"DM-3106","Story","afw|ip_diffim|meas_algorithms|meas_base|meas_modelfit|pipe_tasks",2,"Add slot for calibration flux","""This is a port of [HSC-1005|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1005]."""
"DM-3133","Story","dbserv|ImgServ|metaserv|webcommon|webserv|webserv_client",1,"add ""dax_"" prefix to data access related packages","""As agreed at [Data Access Mtg 2015/07/13|https://confluence.lsstcorp.org/display/DM/Data+Access+Meeting+2015-07-13], add dax_ prefix towebserv, webservcommon, webserv_client, dbserv, imgserv, metaserv"""
"DM-3126","Bug","Developer Infrastructure",2,"gcc 4.8 package does not create a symlink bin/cc","""I created a new lsst package named """"gcc"""" that contains Mario's gcc 4.8 package. I used it to build lsst_distrib on lsst-dev and it worked just fine. Unfortunately the package does not include bin/cc (which should be a symlink to bin/gcc), and this is wanted because the LSST build system uses cc to build C code.    The desired fix is to modify the installer to make a symlink bin/cc that points to bin/gcc."""
"DM-3142","Improvement","meas_astrom",3,"Port HSC optimisations for reading astrometry.net catalog","""Some astrometry.net catalogs used in production can be quite large, and currently all of the catalog must be read in order to determine bounds for each component.  This can make the loading of the catalog quite slow (e.g., 144 sec out of 177 sec to process an HSC image, using an SDSS DR9 catalog).  We have HSC code that caches the required information, making the catalog load much faster.  The code is from the following HSC issues:    * [HSC-1087: Make astrometry faster|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1087]  * [HSC-1143: Floating point exception in astrometry|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1143]  * [HSC-1178: Faster construction of Astrometry.net catalog|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1178]  * [HSC-1179: Assertion failure in astrometry.net|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1178]    While there have been some changes to the LSST astrometry code that will mean we can't directly cherry-pick the HSC code, yet I think the main structure remains, so the approach can be copied without much effort."""
"DM-3141","Story","meas_astrom",1,"Reduce verbosity of astrometry","""The astrometry.net solver that runs by default in meas_astrom 10.1 is very verbose.  Here's an example running HSC data with an SDSS reference catalog:      The verbosity of the astrometry module is out of proportion with the rest of the modules, which makes it difficult to follow the processing.    This is a pull request for fixes I have made."""
"DM-3140","Improvement","lsstsw",1,"add gcc to list of packages in lsstsw","""Add gcc to the list of packages in etc/repos.yaml in lsstsw"""
"DM-3139","Improvement","obs_subaru|pipe_tasks",0.5,"HSC backport: extra ""refColumn"" class attributes in multiband","""This is a transfer for changesets for [HSC-1283|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1283].  """
"DM-3137","Story","afw|pipe_tasks",1,"Handle bad pixels in image stacker","""We currently OR together all mask bits, but we need to be cleverer about how we handle pixels that are bad in some but not all inputs.    This is a port of work carried out on [HSC-152|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-152]."""
"DM-3151","Story","Continuous Integration|lsstsw",1,"CI validation of lsstsw's repos.yaml","""Having some sort of automatic """"lint check"""" of the repos.yaml file is desirable due to the length of time required to do a full up test of lsstsw.  It should be possible to cobble a sanity checker together that can be run from travis-ci."""
"DM-3160","Improvement","meas_base",1,"Improve name and default value of MeasureApCorrConfig.refFluxAlg","""The config name refFluxAlg should be refFluxField (since it is a flux field name prefix) and the default should be  base_CircularApertureFlux_5 instead of base_CircularApertureFlux_0 (thus giving a reasonable radius instead of one that is ridiculously too small).    I should have handled it on DM-436 but it slipped through."""
"DM-3154","Improvement","meas_astrom|pipe_tasks",2,"meas_astrom still using eups in tests","""In DM-2636 we modified the tests to be skipped if EUPS is not available. I've had a closer look and all the ones I have glanced at seem to be easily fixable to run without EUPS. The tests seem to be using EUPS to locate the {{meas_astrom}} (effectively asking EUPS for the location of the test file), then a path to the astrometry.net test data within the {{tests/}} directory is located and then EUPS is asked to setup {{astrometry_net_data}} using that path. Since the table files are all empty this is the equivalent to simply assigning the {{ASTROMETRY_NET_DATA_DIR}} environment variable directly to the path in the tests sub-directory.    Making this change to one of the tests seems to work so I will change the rest."""
"DM-3153","Improvement","meas_base",1,"meas_base still uses eups in tests","""{{tests/centroid.py}} uses EUPS to determine the location of the data file used by the test. This needs to be fixed to use a location relative to the test file."""
"DM-3181","Story","Qserv",1,"Build and Test 2016_02 Qserv Release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-3179","Story","Qserv",3,"Build and Test 2015_12 Qserv Release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-3178","Story","Qserv",3,"Build and Test 2015_11 Qserv Release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-3177","Story","Qserv",3,"Build and Test 2015_10 Qserv Release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-3176","Story","Qserv",3,"Build and Test 2015_09 Qserv Release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-3175","Story","Qserv",1,"Build 2015_08 Qserv Release","""See https://confluence.lsstcorp.org/display/DM/Qserv+Release+Procedure for recipe."""
"DM-3174","Bug","pipe_tasks",1,"CalibrateTask instantiates measureApCorr, applyApCorr and photocal subtasks using the wrong schema","""CalibrateTask instantiates measureApCorr, applyApCorr and photocal subtasks using the initial schema """"schema1"""" instead of the final schema. Normally this would not matter since most of the fields are shared, but aperture correction wants aperture flux at a larger radius than the narrowest option, and schema1 may only provide the narrowest option.    In any case it is safer to instantiate those three subtasks using the final schema, since they are only ever run on the final schema. (Several other subtasks are run on both the initial and final schema, and should continue to be instantiated using schema1)."""
"DM-3173","Improvement","pipe_tasks",1,"In CalibrateTask if one disables psf determination then aperture correction will fail","""In pipe_tasks CalibrateTask, by default aperture correction uses source flag """"calib_psfUsed"""" to decide if a source is acceptable to use for measuring aperture correction. If PSF determination is disabled then this flag is never set and aperture correction will fail with a complaint that there are 0 sources.  """
"DM-3182","Bug","meas_base|pipe_tasks",5,"Aperture correction not applied for some measurements","""Aperture correction needs to be applied every time a measurement is run after it is first measured in CalibrateTask. As of DM-436 aperture correction is only being applied in CalibrateTask, which for example means the information is overwritten during the final measurement of ProcessImageTask.run.    This is probably best done by adding code to apply aperture correction to BaseMeasurementTask, so it is inherited by SingleFrameMeasurementTask and ForcedMeasurementTask."""
"DM-3192","Story","Qserv",8,"Re-implement watcher based on new CSS implementation","""Current watcher implementation (in {{admin/bin/watcher.py}}) is based on direct watching of zookeeper updates via kazoo. If we are to re-implement CSS based on mysql then watcher needs to be updated to support it. Mysql does not have watch mechanism, so it has to be done via polling or using some other mechanism if synchronous notifications are needed."""
"DM-3196","Story","afw|obs_decam",2,"makeWcs() chokes on decam images in 10.1","""In 10.0, processCcdDecam.py could process decam images to completion (whether the WCS was read correctly is a different question). Now it fails on makeWcs() (see traceback below), and I suspect this change in behavior is related to DM-2883 and DM-2967.    Repository with both data and code to reproduce:  http://www.astro.washington.edu/users/yusra/reproduce/reproduceMakeWcsErr.tar.gz  (apologies for the size)    The attachment is a document describing the WCS representation in the images from the community pipeline, courtesy of Francisco Forster.    Please advise. This ticket captures any changes made to afw.         """
"DM-3194","Story","Qserv",0.5,"Fix cluster install procedure and improve docker support","""Document how-to update cluster from Qserv release:    See  http://www.slac.stanford.edu/exp/lsst/qserv/2015_07/HOW-TO/cluster-deployment.html"""
"DM-3199","Story","Qserv",8,"Standardize Qserv install procedure: step 1 build docker container for master/worker instance and development version ","""- shmux could be used for parallel ssh (remove Qserv builtin one)  - look at """"serf and consul"""" (See Confluence pages)  - improve doc: http://www.slac.stanford.edu/exp/lsst/qserv/2015_07/HOW-TO/index.html  - run multiple instances/versions of Qserv using different run dir/ports and the same data"""
"DM-3209","Improvement","meas_astrom",0.5,"Add debugging for astrometry.net solver","""To be able to debug astrometric matching, it helps to be able to visualise the source positions, the distorted source positions, and the reference positions.  This is a pull request to add these."""
"DM-3204","Story","Qserv",5,"W16 Data Access and Db Release Documentation","""Write Release documentation covering Data Access and Database work."""
"DM-3228","Story","Nebula OpenStack",2,"evaluate NCSA OpenStack against SQRE requirements and provide feedback - part 1","""See also https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=LDMDG&title=NCSA+Nebula+OpenStack+Issues"""
"DM-3227","Bug","Nebula OpenStack",1,"openstack API endpoint is broken","""Similar to what was observed in DM-3226, the referral endspoint returned by     are not FQDNs.  This fundamentally breaks any attempt to use the API one step past authenticating with keystone.    This is an example HTTP response:      """
"DM-3223","Story","Qserv",2,"Improve czar-worker communication debugging","""Add features to make it easier to debug communication problems. Particularly, record the source of a message, and remove extraneous messages."""
"DM-3218","Bug","Nebula OpenStack",1,"unable to create public images","""Errors are returned when attempting to upload an image marked as public."""
"DM-3214","Bug","afw",1,"ChebyshevBoundedField should use _ not . as field separators for persistence","""ChebyshevBoundedField uses """"."""" instead of """"\_"""" as field separators in its afw table persistence. This is the old way of doing things, and unfortunately causes errors when reading in older versions of tables, becaus afw converts """"."""" to """"_"""" in that situation.    This shows up as a unit test failure in DM-2981 (brought over from HSC) when an older version table is read in.    It is an open question whether to fix this as part of DM-2981 (which conveniently has a test that shows the problem, though not intentionally so) or separately, in which case a new test is wanted. In the former case I'm happy to do the work so I can finish DM-2981.    Many thanks to Jim Bosch for diagnosing the problem."""
"DM-3249","Story","Qserv",8,"Revisit and document user-facing aspects of async queries","""Outline all aspects of async queries that are affecting users, discuss with the DM team, and document. This includes things like:   * managing async queries (checking status, terminating)   * retrieving results from async queries   * managing query results (purging policies etc)   * probably more, need to think about it..."""
"DM-3245","Story","Qserv",2,"Add support for SUBMIT query parsing to czar","""We need to be able to pass information from user about query type (sync/async). This may require tweaking the parser.  """
"DM-3243","Story","afw|meas_algorithms",1,"Include polygon bounds in CoaddPsf logic","""This is a port of [HSC-974|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-974]. Original description:    The {{CoaddPsf}} class should use the polygon bounding areas that were added to {{Exposure}} and {{ExposureRecord}} in DM-2981 (was: HSC-973) when determining which PSF images to coadd."""
"DM-3241","Story","Firefly",20,"Create images for the mask bits at server side","""LSST FITS images will have a extension that indicate the mask bits. In order to overlay the masks on the primary image, we need to turn the mask bits into a set of images. This task is to take the requested bits and FITS as input, output a set of images for each requested bit. Each bit will have different color. """
"DM-3237","Bug","Qserv",1,"Fix problems with no-result queries on multi-node setup","""For queries like:        select * from Object where id = <non existent id>    qserv can't map it to any chunk, and it ends up executing      SELECT *     FROM qservTest_case01_qserv.Object_1234567890 AS QST_1_     WHERE objectId=<non existent id>    the chunk 1234567890 is a special chunk and it exists on all nodes.    And that fails with:    (build/qdisp/QueryResource.cc:61) - Error provisioning, msg=Unable to  write  file; multiple files exist. code=2 """
"DM-3259","Story","ip_isr|obs_subaru|pipe_tasks",1,"Define polygon bounds for CCDs based on vignetted regions","""This is a port of [HSC-976|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-976] to LSST. The original issue description was:    We should set the polygon bounds (added in DM-2981 [was HSC-973]) for HSC CCD exposures to cover the non-vignetted regions. This should probably be done in ISR or some other camera-specific location.    Note that, contrary to the description in DM-2981, this functionality was not included there."""
"DM-3258","Story","meas_algorithms|pipe_tasks",1,"CoaddPsf.getAveragePosition() is not a valid position","""This is a port of [HSC-1138|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1138] to LSST. That is an aggregate of two related minor fixes:    * {{CoaddInputRecorder}} should default to {{saveVisitGoodPix=True}} so that average positions in the {{CoaddPsf}} can be properly weighted;  * {{computeAveragePosition}} and {{doComputeKernelImage}} should be consistent about the data included when determining whether a source is off image."""
"DM-3257","Story","meas_base",2,"Port flux.scaled from HSC","""[HSC-1295|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1295] introduces {{flux.scaled}}, which measures the flux within a circular aperture that is set from the size of the PSF, scaled by some factor.  Stephen Gwyn recommends using this as our fiducial calibration flux."""
"DM-3253","Story","Qserv",8,"Unify KVInterface python and c++ interfaces","""Swig the C++ mysql-based KvInterface implementation.   """
"DM-3349","Story","afw",2,"Add test case for ExposureRecord::contains","""In DM-3243 we ported from HSC the ability to take account of the associated {{validPolygon}} when checking whether a point falls within an {{Exposure}}. This functionality was not accompanied by an adequate unit test."""
"DM-3347","Improvement","afw",1,"assertWcsNearlyEqualOverBBox and friends is too hard to use as a free function","""assertWcsNearlyEqualOverBBox and similar functions elsewhere in afw were written to be methods of lsst.utils.tests.TestCase, so their first argument is a testCase. This is fine for use in unit tests, but a hassle to use as free functions because the user must provide a testCase argument (though it need only be a trivial class with a fail(self, msgStr) method). Worse, that minimal requirement is not documented, so technically providing a simple mock test case is unsafe.    I have two proposals:  - Document the fact that testCase need only support fail(self, msgStr). This makes it clear how to safely use these functions as free functions.  - Allow testCase to be None, in which case RuntimeError is raised. That makes these functions even easier to use as free functions.  """
"DM-3358","Story","qserv_testdata",5,"Add mysql-based test to multi-node integration test","""At the moment multi-node integration test runs only on multi-node using Qserv, it does not run on plain mysql, and thus we can't validate results. The story involves tweaking qserv_testdata such that we can run mysql test on the czar, and compare results from mysql and qserv."""
"DM-3356","Story","SUIT",1,"Fix Firefly build script so it'll work with latest version of gradle","""Firefly build was failing when using gradle version 2.5.  Minor changes to the dependencies declaration fixed it."""
"DM-3355","Story","Firefly",1,"Support the FITS cube reader","""RSA needs to be able to read in the FITS cube generated by Herschel project. We need to guide the effort so the code is generic enough for non-Herschel data."""
"DM-3391","Story","SUIT",2,"Refactor Zscale.java class ","""In early this year, the decision all data types would be converted to float in FitsRead.  Thus,the bitpixel is not relevant.  In Zscale, it still uses bitpixel to test the data type.  It should be refactored in the same manner as FitsRead etc. """
"DM-3390","Story","Qserv",3,"Re-generate data for large scale tests at in2p3","""Sources were incorrectly duplicated, need to be redone"""
"DM-3387","Improvement","meas_algorithms",1,"Make use of good pixel count when building CoaddPsfs","""When building a CoaddPsf we have the ability to take account of the number of pixels contributed by the inputs (see http://ls.st/paj and DM-3258). However, the {{CoaddPsf}} constructor fails to use this information. It should copy this field when copying the provided {{ExposureCatalog}}, so that {{computeAveragePosition}} can use it."""
"DM-3377","Story","Infrastructure",20,"Initial issue investigation for the nebula openstack","""    The nebula openstack system at NSCA first became available ~Fri Jul 24 and  the week of Jul 27 -- 31 was spent testing and debugging issues that the                 LSST team identified within, for example, DM-3225, DM-3219, DM-3227 and others.  """
"DM-3398","Bug","webserv",1,"Fix problem with default_engine","""Fix the problem:    {quote}  08/04/2015 05:39:47 werkzeug INFO: 141.142.237.30 - - [04/Aug/2015 17:39:47] """"GET /meta/v0/ HTTP/1.1"""" 200 -  08/04/2015 05:39:49 __main__ ERROR: Exception on /meta/v0/db [GET]  Traceback (most recent call last):    File """"/home/becla/stack/Linux64/flask/0.10.1+8/lib/python/Flask-0.10.1-py2.7.egg/flask/app.py"""", line 1817, in wsgi_app      response = self.full_dispatch_request()    File """"/home/becla/stack/Linux64/flask/0.10.1+8/lib/python/Flask-0.10.1-py2.7.egg/flask/app.py"""", line 1477, in full_dispatch_request      rv = self.handle_user_exception(e)    File """"/home/becla/stack/Linux64/flask/0.10.1+8/lib/python/Flask-0.10.1-py2.7.egg/flask/app.py"""", line 1381, in handle_user_exception      reraise(exc_type, exc_value, tb)    File """"/home/becla/stack/Linux64/flask/0.10.1+8/lib/python/Flask-0.10.1-py2.7.egg/flask/app.py"""", line 1475, in full_dispatch_request      rv = self.dispatch_request()    File """"/home/becla/stack/Linux64/flask/0.10.1+8/lib/python/Flask-0.10.1-py2.7.egg/flask/app.py"""", line 1461, in dispatch_request      return self.view_functions[rule.endpoint](**req.view_args)    File """"/nfs/home/becla/stack/repos/dax_metaserv/python/lsst/dax/metaserv/metaREST_v0.py"""", line 59, in getDb      return _resultsOf(text(query), scalar=True)    File """"/nfs/home/becla/stack/repos/dax_metaserv/python/lsst/dax/metaserv/metaREST_v0.py"""", line 122, in _resultsOf      engine = current_app.config[""""default_engine""""]  KeyError: 'default_engine'    {quote}"""
"DM-3411","Story","workspace",20,"workspace functions specification document","""The first version of the document is here https://confluence.lsstcorp.org/pages/viewpage.action?pageId=41783931"""
"DM-3404","Story","pipe_tasks",2,"Port HSC updates to ingestImages.py","""ingestImages.py provides a camera-agnostic manner of creating a data repository (including a registry).  The HSC fork contains multiple improvements not present on the LSST side.  We need these in order to ingest the HSC data."""
"DM-3400","Bug","meas_base",1,"Eliminate circular aliases in slot centroid definition","""[~smonkewitz] has discovered that our schema aliases for even the default configuration of measurement algorithms involve cycles, because the slot centroid algorithm contains a reference to its own flag.  Fixing this should just involve an extra check in {{SafeCentroidExtractor}}."""
"DM-3419","Story","obs_decam",2,"obs_decam unit test for reading data ","""The unit test wasn't working before and I edited the unit test of reading raw data. This got included with DM-3462.   This unit test needs testdata_decam to be setup.      The test fails with the stack b1597 at makeWcs (DM-3196).   The afw branch u/yusra/DM-3196 is a temporary fix before DM-3196 is resolved.      """
"DM-3437","Story","dbserv",2,"Add column names metadata to db query results","""Per discussion at data access meeting Aug 10, it'd be good to send column names with the query results."""
"DM-3442","Story","meas_astrom|pipe_tasks",2,"Processing y-band HSC data fails in loading reference sources","""    We should be able to fix this by setting config parameters (e.g., {{calibrate.astrometry.solver.defaultFilter}} or {{calibrate.astrometry.solver.filterMap}}), but how do we keep that synched with the choice of reference catalog?  And once we get past astrometry, we also have the same problem in photocal."""
"DM-3440","Story","Continuous Integration|meas_extensions_photometryKron",1,"add meas_extensions_photometryKron to lsstsw, lsst_distrib","""meas_extensions_photometryKron should be added to the CI system, since we are trying to keep it updated.    This is blocked by DM-2429 because that includes a fix for a unit test (which the CI system would have caught)."""
"DM-3451","Story","Qserv",2,"Resolve problem with running many simultaneous queries","""When we run with 110 simultaneous queries, czar fails with """"uncaught exception"""""""
"DM-3450","Story","Qserv",1,"Tweaks to configurations discovered during S15 tests","""Apply tweaks we found useful when running large scale tests. This includes:  # etc/my.cnf: change max_connections to 512  # add"""":  {quote}export XRD_REQUESTTIMEOUT=64000  export XRD_STREAMTIMEOUT=64000  export XRD_DATASERVERTTL=64000  export XRD_TIMEOUTRESOLUTION=64000{quote}  to init.d/qserv-czar  # add :  {quote}ulimit -c unlimited{quote}  to all startup scripts in init.d. This will make sure core file is always dumped when we have problems."""
"DM-3459","Bug","afw|meas_base|meas_extensions_photometryKron|meas_modelfit",1,"make forced and SFM interfaces more consistent","""From [~rowen]:  {quote}  SimpleMeasurementTask.run and ForcedMeasurementTask.run now both take a source catalog, but the two use the opposite order for the first two arguments (one has the catalog first, the other has the exposure first)  {quote}"""
"DM-3456","Bug","Qserv",2,"Fix problems with talking from webserv to qserv","""Flask or sqlalchemy which are part of webserv are producing some extra queries that are confusing qserv. So basically, at the moment even the simplest query run via webserv that is directed to qserv fails."""
"DM-3455","Bug","meas_astrom",1,"ProcessImageTask.matchSources fails if using ANetAstrometryTask","""ProcessImageTask.matchSources fails when using ANetAstrometryTask with the following error:    This is probably a result of DM-2939. The basic problem is that the distortion context in ANetAstrometryTask should not be run at that point in processing. [~price] suggests that a simple clean fix is to make the distortion context a no-op if the WCS already contains distortion, if that works. This is what I will try first."""
"DM-3454","Bug","afw",0,"Odd error message in getDistortedWcs","""lsst.afw.image.utils.getDistortedWcs complains as follows if the provided exposure has no WCS:  """"exposure must have a WCS to use as an initial guess"""". It should not say anything about an initial guess. This is presumably a leftover from when the code was part of meas_astrom.    Thanks to [~price] for pointing this out."""
"DM-3453","Story","meas_astrom|pipe_tasks",1,"AstrometryTask.run return not consistent with ANetAstrometryTask","""ANetAstrometryTask.run returns matchMetadata but AstrometryTask.run returns matchMeta. The two must agree. It turns out that matchMeta is more widely used, so I'll standardize on that."""
"DM-3452","Story","Qserv",5,"Integrate pipelines with MySQL and Qserv","""Load data produced by pipelines into MySQL (on lsst10), and Qserv"""
"DM-3468","Story","afw",1,"drawing text to ds9 fails if size or the font family is set","""Commands like    silently fail.  The problem is that commands like    fail; you need to say {{font=times 12 normal}}"""
"DM-3463","Bug","meas_extensions_psfex",2,"psfex lapack symbols may collide with built in lapack","""On my Mac meas_extensions_psfex fails to build due to the numpy config test failing. """"import numpy"""" fails with:    Our best guess (see discussion in Data Management 2015-08-14 at approx. 1:57 PM Pacific time) is that the special lapack functions in psfex are colliding with the lapack that anaconda uses.    In case it helps I see this on OS X 10.9.5. I do not see it on lsst-dev."""
"DM-3462","Story","obs_decam",13,"Make obs_decam handle raw data ","""The current obs_decam expects instrument calibrated data from the community pipeline, i.e. it  requires matching instcal (Instrument Calibrated), dqmask (the associated mask file), and wtmap (weight map) data from the same visit.  This issue is to add functionality so that raw DECam images can be ingested into registry and retrieved by the data butler.     Practically, this will create new or expand existing sub-classes of CameraMapper and IngestTask.        A brief summary of changes:  - The unit test getRaw.py is updated and should pass, with DM-3196     - Working testdata_decam for the unit test is currently at lsst-dev /lsst8/testdata_decam and https://uofi.box.com/testdata-decam  - DecamInstcalMapper is renamed to DecamMapper, to reflect that Butler can also get """"raw"""" now besides """"instcal"""". Please update _mapper in your data repositories.  - To create a registry for raw data, run    - The default filetype is """"instcal"""" for ingestImagesDecam.py, so previous use for instcal stays.  """
"DM-3460","Bug","meas_base",1,"applyApCorr mis-handles missing data","""In ApplyApCorrTask.run the following lines do not behave as expected because get returns None if the data is missing, rather than raising an exception:  """
"DM-3470","Story","SUIT",5,"Install/deploy SUI web application at NCSA","""For summer 15 release,  we will deploya SUI web app on NCSA accessible to DM team.    - work with NCSA to have a server setup  - install necessary software packages  - install SUI software  - deploy the system and test """
"DM-3480","Story","Qserv",2,"Design SQL APIs for async queries","""Need SQL API for:   * submitting async query, note that we should be able to specify where the results are going / what is the format of the results   * retrieving status of async query   * retrieving results of async query   * retrieving partial results of async query while it is running  """
"DM-3493","Story","obs_subaru",1,"Fix crosstalk following ds9 interface changes","""crosstalk.py in obs_subaru uses ds9 without actually displaying anything, which causes trouble if display_ds9 is not setup."""
"DM-3492","Story","meas_astrom|obs_subaru",5,"Correct for distortion in matchOptimisticB astrometry matcher","""matchOptimisticB does not correct for distortion, although an estimate of the distortion is available.  We suspect that doing the matching on the celestial sphere might be ideal, but matching on a tangent plane has worked for HSC."""
"DM-3491","Bug","ip_diffim",1,"Update ip_diffim to use the new NO_DATA flag instead of EDGE","""In ip_diffImm some uses of EDGE were converted to or supplemented with NO_DATA, but others were not. This ticket handles the missing instances."""
"DM-3490","Story","afw",2,"Quick-and-dirty n-way spatial matching","""This issue will add limited N-way spatial matching of multiple catalogs with identical schemas, sufficient for measuring FY15 KPMs.  It will be a simple wrapper on our existing 2-way matching code in afw, and will not be intended for long term use (as it won't be an efficient algorithm or an ideal interrface)."""
"DM-3488","Story","Qserv",1,"Debug problem with large results set","""Query returning 2 billion rows causes problems for czar - czar is using nearly 16 GB or memory. Need to understand why RAM usage in czar is correlated with result size."""
"DM-3483","Improvement","meas_base",0.5,"Calibration transformation should not fail on negative flux","""Before database ingest, measured source fluxes are converted to magnitudes as per DM-2305. The default behaviour of {{afw::image::Calib}} is to throw when a negative flux is encountered, which derails the whole transformation procedure. Better is to return a NaN."""
"DM-3481","Story","Continuous Integration",2,"adapt sandbox-jenkins-demo to changes in jfryman/nginx 0.2.7","""Changes in the way  jfryman/nginx 0.2.7 handles tls cert files since 0.2.6 have run awful of selinux permissions issues."""
"DM-3506","Epic","Qserv",40,"W16 Support Dynamic CSS Metadata in Czar","""Czar needs to support dynamic CSS metadata. This epic involves reworking Facade and related code so that czar can have up to date CSS metadata (per query) instead of relying on static snapshots"""
"DM-3522","Bug","Qserv",3,"Releasing un-acquired resources bug","""Running a mix of queries: 75 low volume and 10 high volume that include near neighbor failed at some point with    {quote}  terminate called after throwing an instance of 'lsst::qserv::Bug'    what():  ChunkResource ChunkEntry::release: Error releasing un-acquired resource  {quote}    Stack trace:    {quote}  #0  0x00007fb6b0cce5e9 in raise () from /lib64/libc.so.6  Missing separate debuginfos, use: debuginfo-install expat-2.1.0-8.el7.x86_64 glibc-2.17-78.el7.x86_64 keyutils-libs-1.5.8-3.el7.x86_64 krb5-libs-1.12.2-14.el7.x86_64 libcom_err-1.42.9-7.el7.x86_64 libgcc-4.8.3-9.el7.x86_64 libicu-50.1.2-11.el7.x86_64 libselinux-2.2.2-6.el7.x86_64 libstdc++-4.8.3-9.el7.x86_64 nss-softokn-freebl-3.16.2.3-9.el7.x86_64 openssl-libs-1.0.1e-42.el7_1.9.x86_64 pcre-8.32-14.el7.x86_64 xz-libs-5.1.2-9alpha.el7.x86_64 zlib-1.2.7-13.el7.x86_64  (gdb) where  #0  0x00007fb6b0cce5e9 in raise () from /lib64/libc.so.6  #1  0x00007fb6b0ccfcf8 in abort () from /lib64/libc.so.6  #2  0x00007fb6b15d29b5 in __gnu_cxx::__verbose_terminate_handler() () from /lib64/libstdc++.so.6  #3  0x00007fb6b15d0926 in ?? () from /lib64/libstdc++.so.6  #4  0x00007fb6b15cf8e9 in ?? () from /lib64/libstdc++.so.6  #5  0x00007fb6b15d0554 in __gxx_personality_v0 () from /lib64/libstdc++.so.6  #6  0x00007fb6b1069913 in ?? () from /lib64/libgcc_s.so.1  #7  0x00007fb6b1069e47 in _Unwind_Resume () from /lib64/libgcc_s.so.1  #8  0x00007fb6ab554247 in lsst::qserv::wdb::ChunkResourceMgr::Impl::release (this=0x21d1cc0, i=...) at build/wdb/ChunkResource.cc:398  #9  0x00007fb6ab552696 in lsst::qserv::wdb::ChunkResource::~ChunkResource (this=0x7fb68a5f9b70, __in_chrg=<optimized out>)      at build/wdb/ChunkResource.cc:131  #10 0x00007fb6ab560f0f in lsst::qserv::wdb::QueryAction::Impl::_dispatchChannel (this=0x7fb65848c4d0) at build/wdb/QueryAction.cc:392  #11 0x00007fb6ab55f5ab in lsst::qserv::wdb::QueryAction::Impl::act (this=0x7fb65848c4d0) at build/wdb/QueryAction.cc:187  #12 0x00007fb6ab562084 in lsst::qserv::wdb::QueryAction::operator() (this=0x7fb658050548) at build/wdb/QueryAction.cc:450  #13 0x00007fb6ab544f46 in lsst::qserv::wcontrol::ForemanImpl::Runner::operator() (this=0x7fb67400fa20) at build/wcontrol/Foreman.cc:302  #14 0x00007fb6ab551cf0 in std::_Bind_simple<lsst::qserv::wcontrol::ForemanImpl::Runner ()>::_M_invoke<>(std::_Index_tuple<>) (      this=0x7fb67400fa20) at /usr/include/c++/4.8.2/functional:1732  #15 0x00007fb6ab551a8b in std::_Bind_simple<lsst::qserv::wcontrol::ForemanImpl::Runner ()>::operator()() (this=0x7fb67400fa20)      at /usr/include/c++/4.8.2/functional:1720  {quote}    Tail of log file from xrootd log:    {quote}  0821 19:08:58.530 [0x7fb68a6fb700] DEBUG GroupSched (build/wsched/GroupScheduler.cc:139) - _getNextTasks(1)>->->  0821 19:08:58.530 [0x7fb68a6fb700] DEBUG GroupSched (build/wsched/GroupScheduler.cc:151) - Returning 1 to launch  0821 19:08:58.530 [0x7fb68a6fb700] DEBUG GroupSched (build/wsched/GroupScheduler.cc:154) - _getNextTasks <<<<<  0821 19:08:58.530 [0x7fb68a6fb700] DEBUG ScanSched (build/wsched/ScanScheduler.cc:172) - _getNextTasks(29)>->->  0821 19:08:58.530 [0x7fb68a6fb700] DEBUG ScanSched (build/wsched/ChunkDisk.cc:199) - ChunkDisk busyness: yes  0821 19:08:58.530 [0x7fb68a6fb700] DEBUG ScanSched (build/wsched/ChunkDisk.cc:171) - ChunkDisk getNext: current= (scan=10436,  cached=8360,8259,) candidate=10301  0821 19:08:58.530 [0x7fb68a6fb700] DEBUG ScanSched (build/wsched/ChunkDisk.cc:184) - ChunkDisk denying task  0821 19:08:58.530 [0x7fb68a6fb700] DEBUG ScanSched (build/wsched/ScanScheduler.cc:196) - _getNextTasks <<<<<  0821 19:08:58.531 [0x7fb68a6fb700] INFO  root (build/xrdsvc/SsiSession.cc:120) - Enqueued TaskMsg for Resource(/chk/LSST/2732) in 0.001016 seconds  0821 19:08:58.531 [0x7fb6895f8700] DEBUG Foreman (build/wcontrol/Foreman.cc:175) - Registered runner 0x7fb66c141ab0  0821 19:08:58.531 [0x7fb6895f8700] DEBUG Foreman (build/wcontrol/Foreman.cc:209) - Started task Task: msg: session=434445 chunk=2732 db=LSST entry time= frag: q=SELECT o.deepSourceId,o.ra,o.decl,s.coord_ra,s.coord_decl,s.parent FROM LSST.Object_2732 AS o,LSST.Source_2732 AS s WHERE scisql_s2PtInBox(o.ra,o.decl,48.482655,-54.274507,48.555903,-54.196952)=1 AND scisql_s2PtInBox(s.coord_ra,s.coord_decl,48.482655,-54.274507,48.555903,-54.196952)=1 AND o.deepSourceId=s.objectId, sc= rt=r_4344458c9456ede5cbe0b5f42e1a1571d5dd73_2732_0   0821 19:08:58.531 [0x7fb6895f8700] INFO  Foreman (build/wcontrol/Foreman.cc:296) - Runner running Task: msg: session=434445 chunk=2732 db=LSST entry time= frag: q=SELECT o.deepSourceId,o.ra,o.decl,s.coord_ra,s.coord_decl,s.parent FROM LSST.Object_2732 AS o,LSST.Source_2732 AS s WHERE scisql_s2PtInBox(o.ra,o.decl,48.482655,-54.274507,48.555903,-54.196952)=1 AND scisql_s2PtInBox(s.coord_ra,s.coord_decl,48.482655,-54.274507,48.555903,-54.196952)=1 AND o.deepSourceId=s.objectId, sc= rt=r_4344458c9456ede5cbe0b5f42e1a1571d5dd73_2732_0   0821 19:08:58.531 [0x7fb6895f8700] INFO  Foreman (build/wdb/QueryAction.cc:177) - Exec in flight for Db = q_fd51ad249f62fb765e173d7b3cae5d94  0821 19:08:58.531 [0x7fb6895f8700] WARN  Foreman (build/wdb/QueryAction.cc:109) - QueryAction overriding dbName with LSST  0821 19:08:58.718 [0x7fb6a0d8e700] INFO  root (build/wdb/QueryAction.cc:261) - &&& _fillRows size=106  0821 19:08:58.718 [0x7fb6a0d8e700] INFO  root (build/wdb/QueryAction.cc:261) - &&& _fillRows size=210  0821 19:08:58.718 [0x7fb6a0d8e700] INFO  root (build/wdb/QueryAction.cc:261) - &&& _fillRows size=316    ...(thousands of _fillRows lines)    terminate called after throwing an instance of 'lsst::qserv::Bug'    what():  ChunkResource ChunkEntry::release: Error releasing un-acquired resource  {quote}  """
"DM-3555","Story","Qserv",1,"Ignore ""SELECT @@tx_isolation"" queries","""Looks like one of the queries we registered in webserv is: cursor.execute('SELECT @@tx_isolation') and that is bound to confuse Qserv. Need to suppress it at mysql proxy level."""
"DM-3546","Story","Design Documents",1,"Move LDM-151 to Sphinx/Read the Docs","""Move the LDM-151 (DM applications design document) to restructuredText (built with Sphinx) and published automatically via readthedocs.org.    See discussion at http://community.lsst.org/t/requesting-comments-for-design-documentation-format-for-dm/132?u=jsick    This is an experiment."""
"DM-3544","Epic","meas_astrom",20,"Cleanup of initial astrometry improvements","""The astrometry improvements are working, but some cleanup would be good to remove dependencies on A.net and to provide default reference catalog loaders."""
"DM-3558","Story","SUIT",8,"Experiment with Jupyter widget technology and Firefly Tools","""Based on DM-2047 work to date, investigate the feasibility of using the Jupyter widget interface to wrap up Firefly tools."""
"DM-3618","Bug","Qserv",1,"Fix bug related to restarting xrootd in wmgr","""Changes from DM-2930 are failing integration tests because wmgr is restarting xrootd and now we need to also restart mysqld if xrootd pid changes."""
"DM-3616","Story","Firefly",2,"Expose image XY readout at cursor point function in JavaScript API","""Expose image XY readout at cursor point function in JavaScript API"""
"DM-3615","Story","Firefly",5,"expose region overlay on image function through JavaScript API","""expose region overlay on image function through JavaScript API"""
"DM-3611","Story","Systems Engineering",3,"Prepare for Winter 2016 work on LSE-68","""Use a session at the LSST 2015 all-hands meeting to prepare for LSE-68 work in the Winter 2016 cycle."""
"DM-3610","Story","Systems Engineering",2,"CCB review and posting of final updated document","""Carry out the CCB review, respond to questions, support final implementation of updated document."""
"DM-3609","Epic","SUIT",8,"The Alert subscription system requirement gathering (F16)","""Solidify the requirement for the alert subscription system.     Nov. 2, 2016 XW    After much discussion with AP team and the re-plan exercise, the requirement for alert subscription has been identified as the following:  *use the API that AP team will provide to*    # provide a UI for user to specify the filters on alerts of their interests, the destination of the alert to be sent  # save the specification in a DB  # provide UI to allow users to make modification of the filters and destinations of alerts  # possibly to annotate the alerts and allow user to access the annotation    This will involve SLAC for DB, NCSA for user management  """
"DM-3608","Story","SUIT",1,"provide detailed information needed to DAX meta API","""SUIT needs certain specific information through DAX meta service when searching for meta data. For Example, what kind of table it is, does it have spatial index to search by position, which set of (ra, dec) columns is the primary one, etc?"""
"DM-3596","Epic","Firefly",40,"More bug fixes in Firefly JS code ","""Bug fixes and improvements for Firefly JS code  """
"DM-3593","Epic","Firefly",40,"Firefly support for pipeline visualization needs  (W16)","""Data products pipeline needs visualization capabilities for display. Firefly needs to have new capabilities to support it. """
"DM-3587","Epic","Firefly|SUIT",40,"Firefly infrastructure improvement to support new functions (W16)","""This epic will capture the necessary changes of Firefly infrastructure to support new functions needed. It does not include the changes caused by the the conversion from GWT infrastructure to pure JavaScript based system using React and FLUX platform. """
"DM-3653","Story","SUIT",1,"SUIT design document outline","""work with John Rector on SUIT design document outline"""
"DM-3652","Story","SUIT",1,"SUIT design document outline","""Work with Gregory on the SUIT design document outline    1.  Requirements flow down, making sure that we design the system satisfying the current requirements.  2.  Use cases collection. at least one typical use case in each major science theme  3.  Levels of different users  ** novice: treat the web portal as a archive to get some information, don't know much about LSST  ** novice expert: has some ideas of what special functions they would like, has some knowledge of LSST data  ** domain expert: knows LSST data very well and want some special functions ready to use  ** savvy expert: knows LSST data very well and like to use API to their own programming    4. functions for all different levels of users  5 system design   ** system diagram  ** details of the different parts  *** Firefly server  *** Firefly client  *** Firefly server extension  *** Firefly JavaScript API  *** Firefly Python API  *** Firefly Python API, Jupyter notebook, and other Python applications  *** workspace and level3 data  *** SUI web portal sketch, workflow  ** dependency on other capabilities of other institutes    6. development and test plan,  timeline  7. deployment plan                """
"DM-3651","Bug","pipe_tasks",2,"MakeDiscreteSkyMapRunner.__call__ mis-handled returning results","""{{MakeDiscreteSkyMapRunner.\_\_call\_\_}} will fail if {{self.doReturnResults}} is {{True}} due to trying to reference undefined variables. This is at least approximately a copy of a problem that was fixed in pipe_base {{TaskRunner}}.    {{MakeDiscreteSkyMapRunner.\_\_call\_\_}} should be fixed in a similar way, and (like {{TaskRunner}}) changed to return a pipe_base {{Struct}}.  """
"DM-3650","Story","Firefly",2,"on-going support to Camera team in UIUC","""Attend UIUC weekly meeting and give support as needed. """
"DM-3648","Story","SUIT",2,"SUIT design document outline","""SUI/T design document outline.  """
"DM-3646","Story","Systems Engineering",2,"LSE-72: OCS-CCS-DAQ-DM workshop, July 2015","""Work associated with Workshop IV in the series, held at NCSA July 8-10, 2015."""
"DM-3642","Epic","Systems Engineering",20,"Support OCS revision of LSE-70, LSE-209","""Support the OCS efforts to update LSE-70 and create a new associated document, LSE-209.  Getting current versions of these under change control will allow us to complete a round of work on LSE-72."""
"DM-3641","Epic","SUIT",40,"Firefly server side extensions using DM stack (F16)","""Design and implement a control system to extend Firefly server side capabilities using task in DM stack.  This will make it easier to use DM stack for customized data processing. """
"DM-3639","Story","Systems Engineering",2,"OCS-CCS-DAQ-DM teleconference, April 2015","""Prepare for and attend a half-day teleconference on OCS issues."""
"DM-3638","Bug","pex_config",1,"RangeField mis-handles max < min","""RangeField contains the following bit of code to handle the case that max < min:      This is broken because there is no swap function and if there was it could not work in-place like this. However, rather than replace this with the standard {{min, max = max, min}} I suggest we raise an exception. If max < min then this probably indicates some kind of error or sloppiness that should not be silently ignored. If we insist on swapping the values then at least we should print a warning.    The fact that this bug has never been reported strongly suggests that we never do set min > max and thus that an exception will be fine."""
"DM-3630","Story","ctrl_execute|ctrl_orca|meas_algorithms|meas_extensions_multiShapelet|meas_extensions_psfex|obs_cfht|obs_decam|obs_lsstSim|obs_sdss|obs_subaru|obs_test|pex_config|pipe_base",2,"Change root to config in config override files","""Implement RFC-62 by using {{config}} rather than {{root}} in config override files for the root of the config.    Note that I propose not modifying astrometry_net_data configs because those are numerous and hidden. They have their own special loader in LoadAstrometryNetObjectsTask._readIndexFiles which could easily be updated later. if desired. An obvious time to make such a transition would be when overhauling the way this data is unpersisted."""
"DM-3656","Bug","Qserv",1,"Data loader doesn't work for match tables","""qserv-data-loader.py fails to load match tables:   - it does not invoke the correct partitioner executable for them   - not all CSS parameters required for match tables are passed down to the CSS update code"""
"DM-3675","Story","QA",2,"Resourcing Verification runs","""  Identify required resources for Verification runs and communicate them to NCSA.   """
"DM-3670","Bug","obs_test",1,"obs_test needs to override map_camera and std_camera","""The Butler can't get a camera unless the map_camera and std_camera are defined correctly.  In most cases the camera can be built by the map_camera method.  In the case of obs_test, the camera is built in the constructor of the Mapper, so std_camera should just return the camera attribute."""
"DM-3667","Bug","psfex",0.5,"PSFEX does not build if PLplot is installed","""During the configure phase PSFEX checks for the presence of PLplot. If PLplot is found then the build fails (at least on a Mac using homebrew):      This particular error is caused by PSFEX using a deprecated PLplot API ({{plwid}}) that is not enabled by default and whose name is not translated to {{c_plwid}}. This PLplot change occurred in version 5.9.10 released in 2013. I assume upstream PSFEX has a fix for this.    Given that LSST does not need the PLplot functionality I think the simplest fix may well be to disable the test for PLplot in our version.    It seems likely that there will be a reasonable number of systems """"in the wild"""" who will have PLplot installed so I'm inclined to think that this should be a blocker for the v11.0 release.    If we are lucky people will have all upgraded their PLplot installs to v5.11.0 because in that version PLplot change the name of the library from {{libplplotd}} to {{libplplot}} and PSFEX has hard-wired the former rather than using pkg-config. This results in configure not finding PLplot. I don't think this eventuality is likely though.  """
"DM-3659","Story","Systems Engineering",1,"Initial discussions with Patrick Ingraham","""This story is a catch-all for preliminary conversations about LSE-140 with the new Calibration Instrumentation Scientist, Patrick Ingraham."""
"DM-3658","Story","Systems Engineering",3,"Discussions on LSE-75 with Telescope & Site personnel","""Pursue interactions with Telescope and Site personnel regarding LSE-75, and in particular the issues surrounding calibration data products for the wavefront and guider data analysis pipelines.    Covers work through the end of August 2015."""
"DM-3657","Story","Systems Engineering",2,"Create change request for LSE-75","""Create a change request for LSE-75, the TCS - to - DM ICD."""
"DM-3686","Bug","Qserv",1,"Fix PATH and compiler version detection in qserv scons","""In recently merged DM-3662 compiler version testing was done using OS tools with regular $PATH. This is inconsistent with other scons tools which reset PATH when executing actions.   We want to do two things:  - propagate PATH to the command execution  - Use scons tools to run """"$CXX --version"""" instead of OS tools to keep things consistent"""
"DM-3684","Epic","QA",40,"Release engineering Part Two","""This epic covers testing and co-ordination work associated with making  engineering and official releases, and code to support them.      [FE at 70%, JH at 20%, JS at 10%]"""
"DM-3679","Story","Developer Infrastructure",2,"Allow building/publishing components off branches other than master","""Support of xrootd within the stack is currently complicated by the fact that qserv depends on features that are not available on upstream master (only available on an upstream non-master branch).  Since we can currently only publish packages from master, this means that our lsst fork of xrootd cannot be a """"pure"""" fork -- we end up merging/rebasing from an upstream branch, then force-pushing the downstream master.  Upstream and downstream xrootd repos thus have completely different branch topologies, labels, etc., and history of master in the lsst fork is being continually rewritten to carry local patches forward.  The processes of both adopting upstream changes into the lsst fork and the pushing lsst changes back upstream are cumbersome, confusing, and labor intensive.    It is proposed that we extend our tools to allow publishing components from branches other than master.  This would allow us to have xrootd for example be a """"pure"""" fork of upstream -- we could then create our own branch based off any upstream branch, carry our downstream patches there, and release off of that.    This functionality could be used similarly for any of our current """"t&p"""" components where it would be convenient to track the upstream repo directly and/or carry changes in git instead of in an agglomerated patch file (e.g. when we might want to update frequently and/or contribute general purpose changes back upstream regularly with pr's, etc.)"""
"DM-3678","Story","meas_algorithms",1,"HSC backport: Standalone updates to star object selection","""This involves pulling over the following standalone (i.e. non-ticket) HSC commits:  [Updated star selection algorithm.|https://github.com/HyperSuprime-Cam/meas_algorithms/commit/071fcadc016908a10583c746f0a8e79df2a45ead]    [Appropriate config parameter for a unit test of testPsfDetermination.py.|https://github.com/HyperSuprime-Cam/meas_algorithms/commit/e73c5e447ac0b8a71926d3e78fec30aad4beee91]    [Remove HSC specific codes.|https://github.com/HyperSuprime-Cam/meas_algorithms/commit/15bb812578531766199e9a1ee41cc707fb3d9873]  (Note, the above reverts some unwanted camera-specific clauses added in the first commit.  May just squash them to only add the desired features)    [ObjectSizeStarSelector: push non-fatal errors to DEBUG level|https://github.com/HyperSuprime-Cam/meas_algorithms/commit/44f75bc60b41c5f77b323a8d9981048ef7e5f3c4]    [We don't use focal plane coordinates anywhere, and detector may be None|https://github.com/HyperSuprime-Cam/meas_algorithms/commit/4413db4610e4793727e591f395f5ad8cd0cb6030]    [Fixed axis labels|https://github.com/HyperSuprime-Cam/meas_algorithms/commit/67efacaccf8346fdfa1b450617aebabddb2b7ec0]    [Improved PSF debugging plots|https://github.com/HyperSuprime-Cam/meas_algorithms/commit/b1bc91ed1538607eb90e070881a82498fd551909]    [Worked on star selector|https://github.com/HyperSuprime-Cam/meas_algorithms/commit/6b36f4d757187d30142a7e026754a07ffeb8dea2]"""
"DM-3693","Story","obs_subaru|pipe_tasks",2,"HSC backport: allow photometric and astrometric calibrations to be required","""This is a port of the standalone changesets:  [calibrate: make astrometry failures non-fatal|https://github.com/HyperSuprime-Cam/pipe_tasks/commit/e9db5c0dcdca20e8f7ba71f24f8b797e71699352]  [fixup! calibrate: make astrometry failures non-fatal|https://github.com/HyperSuprime-Cam/pipe_tasks/commit/c2d89396923f9d589822c043ed8753647e70f3f6]  (the above is a fixup, so will likely be squashed)  [make failure to match sources non-fatal|https://github.com/HyperSuprime-Cam/pipe_tasks/commit/cf5724b852937cfcef1b71b7a372552011fda670]  [calibrate: restore original Wcs after initial astrometry solution|https://github.com/HyperSuprime-Cam/pipe_tasks/commit/ab6cb9e206d0456dc764c5ef78ac80ece937c610]  [move CalibrateTask from ProcessImageTask into ProcessCcdTask|https://github.com/HyperSuprime-Cam/pipe_tasks/commit/08a8ec029dd52ac55e47b707a6905df061a40506]  [processCoadd: set detection to use the declared variances|https://github.com/HyperSuprime-Cam/pipe_tasks/commit/9e8563fd8d630dad967786387b1f27b6bc7ee039]  [adapt to removal of CalibrateTask from ProcessImageTask in pipe_tasks|https://github.com/HyperSuprime-Cam/obs_subaru/commit/52733a7ab1731a15cbb93151851f57cec276f928]  and HSC tickets:  [HSC-1085: background not saved in processCcd|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1085] and  [HSC-1086: psf - catalog scatter is very large in some coadds|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1086]"""
"DM-3692","Story","pipe_tasks",1,"HSC backport: Allow for some fraction of PSF Candidates to be reserved from the fitting","""This is a port of the changesets from [HSC-966|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-966].    It provides the ability to reserve some fraction of PSF candidates from the PSF fitting in order to check for overfitting and do cross validation."""
"DM-3691","Story","obs_cfht",1,"CalibrateTask has outdated, incorrect code for handling aperture corrections","""The CFHT-specific CalibrateTask tries to apply aperture correction once just after measuring it (which is too early) and again later, at the right time. The error probably has no effect on the final results, but it is confusing and needlessly divergent from the standard CalibrateTask. The required changes are small. I plan to test by running [~boutigny]'s CFHT demo."""
"DM-3689","Story","Developer Infrastructure",0.5,"Slack notification of discourse activity","""It would be nice to have a hipchat channel with notifications of discourse activity.  As a power up, perhaps new topics under certain categories, I'm thinking specifically of DM Notifications, could generate posts to select general HC channels -- similar to how RFC notifications are currently handled.    A quick google search turns up this plugin for integration:    https://github.com/binaryage/discourse-hipchat-plugin"""
"DM-3707","Improvement","Qserv",2,"qserv scons - do not copy files to variant_dir","""Some people are not happy with our current scons setup which copies source files from source directories to variant_dir, it makes it harder to trace errors using tools like eclipse or debug code. Would be nice to get rid of the extra copy, but we still want to have separate build directory (variant_dir). It should be simple enough, I think, but will need some testing of course."""
"DM-3705","Improvement","ndarray",1,"Update ndarray to use current numpy API","""When we build software that uses SWIG and ndarray we get {{warning """"Using deprecated NumPy API}}. Please update ndarray so we are using the current API.    If in the interim you want to suppress the warnings, I suggest issuing a separate ticket for that. I have mixed feelings about suppressing the warnings. On the one hand false warnings do make it harder to spot real problems. On the other hand these warnings are not very numerous (building afw only results in 8 of them) and so are fairly easy to ignore."""
"DM-3702","Story","ip_diffim",40,"Assemble the report on DCR","""Everything learned through the literature search and project wide meeting should be synthesized into a single readable report that details the expected effects of DCR on difference imaging as well as possible mitigation techniques.    This may involve some preliminary analysis work to measure effectiveness of various techniques.    Note that I expect this to be two weeks of work for two people, thus the 40 story points.  I don't know how to assign a story to two people."""
"DM-3698","Story","pipe_base",1,"Replace --trace with --loglevel in pipe_base ArgumentParser","""Replace the --trace argument with an enhanced version of --loglevel that supports named values and numeric log levels (which are the negative of trace levels). This simplifies the interface for users and potentially reduces the log level/trace level confusion, though that won't fully happen until we finish replacing use of pex_logging Trace and Debug with Log.    This work was already done as part of DM-3532; it just needs to be copied with minor changes (since there are no named trace levels in pex_logging)."""
"DM-3694","Story","Developer Infrastructure",1,"Decrease buildbot  frequency","""Buildbot frequency is now down to two builds, one at 19:42 machine time (NCSA) and one at 1:42. This is to stop people needing buildbot runs to eups publish to have to wait before a CI build, since they are now done on[ https://ci.lsst.codes ]/ Jenkins.     """
"DM-3771","Story","Firefly|SUIT",5,"Resolve the issues accessing the newly populated tables","""There are several issues need to be resolved for the system to work properly. """
"DM-3770","Story","Firefly|SUIT",1,"build the SUI system on NCSA to use the right database and tables","""Due to the changes of the database and tables, the system has to be rebuilt."""
"DM-3769","Story","Firefly|SUIT",2,"access the database created and populated for Bremerton end-to-end system","""Collect the information for the tables populated for Bremerton end-to-end exercise. Use them in SUI/T so we can access them using the DAX API. """
"DM-3768","Epic","SUIT",8,"Resolve the issues found in the S15 end-to-end system exercise","""There are a few items we need to take care to finish the end-to-end system for S15. """
"DM-3763","Improvement","Developer Infrastructure",0,"Be friendlier to New Users on Discourse","""Please adjust New Users thresholds so that the following common use case on Discourse will work:    1. I have a question/thread I'm really interested in so I join.  2. I post answers, questions, and links.  I'm probably going to be heavily involved in this thread (it's why I bothered to create an account, after all).    The current defaults allow me only 3 replies, posting of 2 URLs, and no attachments.  I don't know what the exact values should be, but the current defaults don't seem to work for what would seem to me to be a pretty common use case."""
"DM-3749","Story","psfex",2,"Scons build of lapack_functions in PSFex fails if SCONSFLAGS are set","""The scons build system is unaware of extra flags which may be set in SCONSFLAGS environment variable, which are used from scons utils. This will cause the build to fail. The package needs to behave properly and build in the presence of these flags"""
"DM-3772","Bug","Qserv",0.5,"Fix compiler detection for non-default gcc/g++ compiler","""{{scons CXX=g+\+-4.4}} launches {{g\+\+-4.4 --version}} which returns {{g++-4.4 (Debian 4.4.7-2) 4.4.7}}. Nevertheless the {{-4.4}} is not supported by Qserv compiler detection tool. Support will be added here"""
"DM-3780","Story","Qserv|xrootd",1,"Rationalize lsst/xrootd repo and maintenance procedures","""The procedure for pulling/pushing xrootd changes from/to the upstream official xrootd repo is cumbersome, confusing, and error-prone.    Buildbot now has support for releasing packages from branches other than master.  Given this, we can now reasonably replace our lsst/xrootd repo with a fresh genuine fork (shared history) of upstream, then carry our lsst-specific work forward on a dev-branch.  This will make it much easier to track and contribute to the xrootd project moving forward.    Existing legacy branches and tags are to be migrated to the fresh fork, so historical builds will not be broken."""
"DM-3779","Story","Qserv",1,"clean up gcc and eclipse code analyzer warns","""We've been ignoring some accumulating warns in the qserv build for some time now.  Now that it is possible to develop qserv in eclipse, it would be useful to address warns and analyzer issues so that we can start to notice when new ones pop up."""
"DM-3778","Story","protobuf|Qserv",1,"Fix compiler warns in protobuf clients","""Google protobufs 2.6.1 includes a few unnecessary semicolons in some of its supplied header files; these generate a lot of compiler warnings when compiling client packages.    Proposed fix is to add a patch to our eups t&p protobufs package to remove the offending semicolons."""
"DM-3775","Story","skymap",1,"HSC backport: updates to tract and patch finding","""This is a port of the following HSC updates to how tracts and patches are found and listed given a set of coordinates.  These are all standalone commits (i.e. not associated with a ticket):  [Add findTract() and findTractPatchList() in ringsSkyMap.|https://github.com/HyperSuprime-Cam/skymap/commit/761e915dde25ce8ed5622c2d84b83793e9580fd7]  [move RingsSkyMap.findTractPatchList to BaseSkyMap.findClosestTractPatchlist|https://github.com/HyperSuprime-Cam/skymap/commit/56476142060bdb7d8c7fb59eacc383f0e0d5c85b]  [Small bug fix for RingsSkyMap.findTract().|https://github.com/HyperSuprime-Cam/skymap/commit/f202a7780ebb89166f03479d7447ace1555027c1]  [Add fast findTractPatchList() in RingsSkyMap.|https://github.com/HyperSuprime-Cam/skymap/commit/7e49c358501f95ce4c0e1aa8f48103a24391fc22]  [Fixed the problems regarding poles and RA wrap.|https://github.com/HyperSuprime-Cam/skymap/commit/841b0c9eda7462a7a4f182b7971d5e8e81478bfe]  [Add spaces around '+' and '-' to match LSST standard coding style.|https://github.com/HyperSuprime-Cam/skymap/commit/f7e2f036494afe382e653194c82bb15728c60fc3]"""
"DM-3774","Story","lsst_build",1,"lsst_build's default ref from repos.yaml support is broken when building multiple packages","""A problem with the default ref in {{repos.yaml}} support implemented in DM-3679 was discovered last Friday, shortly after deploying this feature to the production CI systems.    The default ref for {{xrootd}} was changed/overridden in {{repos.yaml}} to {{legacy/master}}.  This worked as expected (and as was tested) when setting {{xrootd}} as the sole {{lsstswBuild.sh}} product or when running {{rebuild}} by hand.  However, when building any package that pulled in {{xrootd}} as a recursive dependency, the {{master}} branch was being used (this case had not been manually tested)."""
"DM-3773","Story","ctrl_events",3,"add RUNID option to EventAppender","""A RUNID needs to be added as an option to EventAppender to allow event logging selectors to receive only events for a particular run."""
"DM-3792","Bug","obs_test|pipe_tasks",2,"obs_test data mis-assembled","""obs_test images are mis-assembled and need to be regenerated. This may affect some existing unit tests that rely on the data."""
"DM-3790","Story","Developer Infrastructure",0,"Top level product for obs_decam ","""We have an action to allow people to pull obs_decam and a working stack without including obs_decam in lsst_distrib. And we want to CI it.     The strawman plan is to make a new TLP for decam. SQuaRE will discuss. """
"DM-3808","Story","Developer Infrastructure",0.5,"Setup lsst_sphinx_kit package structure","""Setup the lsst_sphinx_kit package, including    * setup.py  * unit tests, tox and Travis CI  * README stub  * Sphinx stub and readthedocs"""
"DM-3804","Story","meas_base",2,"Fix order of arguments - run method of meas_base SingleFrameMeasurementTask","""In sfm.py on line 271, a comment indicates that some code is a temporary work around until the switch from meas_algorithms to meas_base is complete. This work is complete, so this temporary workaround should be removed, or if it is decided it should be kept, the comment should be removed. See https://github.com/lsst/meas_base/blob/tickets/DM-2915/python/lsst/meas/base/sfm.py#L271"""
"DM-3803","Improvement","Qserv",0.5,"Fix Qserv compiler warnings with clang","""Qserv triggers numerous warnings with clang on OS X. Full details are in the attached ticket, here we summarize the distinct warnings classes:    h5. Protobuf        h5. Qserv                                                            h5. OS X                h5. Xrootd                h5. boost    """
"DM-3800","Bug","pipe_tasks",2,"testProcessCcd.py computes values that are too different between MacOS and linux","""tests/testProcessCcd.py runs processCcd on visit 1 of obs_test's data repository. The result on MacOS is surprisingly different than on linux in at least one case: psfShape.getIxx() computes 2.71 on MacOS X and 2.65 on linux. Iyy and Ixy are likely different. It's worth checking all other computed values, as well. These differences likely indicate that something is wrong, e.g. in obs_test, processCcd, or the way the test runs processCcd.    This showed up as part of fixing DM-3792, but it is not clear if the changes on DM-3792 actually caused or increased the difference between MacOS and linux, or if the difference was always too large, but was masked by an intentionally generous tolerance in the unit test."""
"DM-3798","Bug","meas_deblender|meas_extensions_shapeHSM|obs_subaru",0.5,"Update flag names and config override files to current conventions","""The {{deblend.masked}} and {{deblend.blendedness}} flag names in {{meas_deblender}} need to be updated to use underscores instead of periods.  Various flag names in the {{examples}} scripts also need updating to the underscore and camelCase format.    A search for these flags throughout the database revealed a number of config files that need updating to current conventions.  These are also included here."""
"DM-3797","Story","Developer Infrastructure",1,"Enable SSL to community.lsst.org","""Enable SSL (https) for the Discourse site at community.lsst.org"""
"DM-3816","Story","obs_decam",1,"levels in DecamMapper.paf is not quite right","""When ccdnum is not given as part of the dataId, instead of iterating over it, an error like this happens        Likely a problem in policy/DecamMapper.paf"""
"DM-3850","Bug","Nebula OpenStack",2,"Nebula metadata service is intermittent","""Upon restarting one of my nebula instances (ktl-test), I noticed a failure in the logs:  {quote}  Sep 14 18:07:29 ktl-test cloud-init: 2015-09-14 18:07:29,157 - util.py[WARNING]: Failed fetching metadata from url http://169.254.169.254/latest/meta-data  {quote}    Attempting to retrieve that URL seems to randomly vary between succeeding, which returns:  {quote}  ami-id  ami-launch-index  ami-manifest-path  [...]  {quote}    and failing, which returns:  {quote}  <html>   <head>    <title>500 Internal Server Error</title>   </head>   <body>    <h1>500 Internal Server Error</h1>    Remote metadata server experienced an internal server error.<br /><br />         </body>  </html>  {quote}  These failures may be contributing to observed sporadic {{ssh}} key injection failures."""
"DM-3841","Epic","Systems Engineering",8,"LSE-75: Refine WCS and PSF requirements in W16","""Clarify the data format and precision requirements of the TCS (or other Telescope and Site components) on the reporting of WCS and PSF information by DM on a per-image basis.    Depends on the ability of the T&S group to engage with this subject.    Current PMCS deadline for Phase 3 readiness of LSE-75 is 29-Sep-2015."""
"DM-3840","Epic","Systems Engineering",8,"LSE-72: Phase 3 in X16","""Advance Phase 3 details as needed to eliminate obstacles to OCS and DM development during F16."""
"DM-3836","Story","Design Documents",2,"Migrate LDM-129 to new design docs platform","""Convert LDM-129 from Word to restructuredText and deploy onto readthedocs.org"""
"DM-3821","Bug","meas_modelfit",1,"Recent CModel bugfixes from HSC","""I've just fixed two rather critical bugs in the CModel code on the HSC side (they would have been introduced on the LSST side in the last transfer, DM-2977):   - The {{minInitialRadius}} configuration parameter had a default that is too small, causing many galaxies to be fit with point source models, leading to bad star/galaxy classifications.  This is HSC-1306.   - There was a simple but important algebra error in the uncertainty calculation, making the uncertainty a strong function of magnitude.  This is HSC-1313.    On the LSST side, the transfer should be quite simple; we'll have to rewrite a bit of code due to the difference in measurement frameworks, but there was very little to begin with (most of the effort in the HSC issues was in debugging)."""
"DM-3863","Story","Design Documents",2,"Web design fixes DM Design Documents on Sphinx/Read The Docs","""Solve fit-and-finish issues with the stock readthedocs.org Sphinx template when rendering DM design documents. Issues include:    * Sections need to be numbered and those numbers need to appear in TOC  * RTD's TOC does not properly collapse sub-topics  * Appropriate styling for document title and author list  * Wrapping the changelog table  * Adapt section references so that just the section number can be referenced, independently of the section number and title in combination  * Section labels given explicitly in the reST markup are different from the anchors that Sphinx gives to the {{<hN>}}tags; the former are simply divs inserted in the HTML.    The solutions may involve    # reconfiguring the Sphinx installation of individual documents  # forking the RTD HTML template, and/or  # developing extensions for Sphinx in {{sphinxkit}}."""
"DM-3860","Epic","Developer Infrastructure",20,"Communication Toolchain support","""This epic covers support of communication tools primarily used by DM  and/or supported by DM on behalf of other parts of the project - JIRA,  Discourse, Hipchat, etc     The source of this work is primarily driven by short-term user  requests, and so the outcome is timeboxed rather than planned.     [JS 50% FE 50%]  """
"DM-3898","Improvement","xrootd",0.5,"Fix xrootd compiler warnings with clang","""h5. Xrootd            """
"DM-3892","Story","Systems Engineering",3,"Review current version of LSE-78, prepare for LCR","""Do a comprehensive read-through of the previous released version of LSE-78.  Look for self-consistency and for consistency with the rest of the DM and overall system design.  Report issues to appropriate people."""
"DM-3887","Epic","Systems Engineering",8,"Review ICD flowdown to DMSR and design documents","""This epic will result in a plan for how DM will manage the ICD requirements and their relationship to LSE-61 (DMSR). This plan should make it easier for authors of design documents to understand which requirements are relevant."""
"DM-3912","Story","ctrl_events",0.5,"some ctrl_events tests execute outside of execution domain","""There are a couple of ctrl_events tests that attempt to execute outside of the valid domains acceptable by the tests, when they shouldn't be.  There's a check in place for tests to find this, but a couple of the tests do not have this check."""
"DM-3911","Story","daf_persistence|pex_config|pipe_base",1,"HSC backport: avoid I/O race conditions config write out","""This is a port of [HSC-1106|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1106]    When running tasks that write out config settings files ({{processCcd.py}}, for example), if multiple processes start simultaneously, an I/O race condition can occur in writing these files.  This is solved here by writing to temp files and then renaming them to the correct destination filename in a single operation.  Also, to avoid similar race conditions in the backup file creation (e.g. config.py~1, config.py~2, ...), a {{--no-backup-config}} option (to be used with --clobber-config) is added here to prevent the backup copies being made.  The outcome for this option is that the config that are still recorded are for the most recent run."""
"DM-3910","Story","Qserv",3,"Run and document multi-node test with docker","""In order to validate Docker setup on CC-IN2P3 cluster, it is required to launch some test on consistent data. S15 LargeScaleTest data doesn't seems to be compliant with latest Qserv version so running multi-node test would be interesting. Nevertheless the multi-node setup doesn't seems to be documented and, hence, is difficult to reproduce."""
"DM-3922","Story","Qserv",1,"Update multi-node setup documentation","""Workers in multi-node setup no longer require granting mysql permissions for test datasets since direct mysql connections are no longer used by the data loader."""
"DM-3926","Story","log",1,"Implement iostream-style formatting in log package","""Implement proposed in RFC-96 change to log macros. This ticket only covers defining new set of macros (LOGS() and friends) which use ostringstream for formatting messages. Migration of all clients and removal of LOGF macros will be done in separate ticket."""
"DM-3943","Bug","Qserv",1,"QMeta thread safety","""Initial QMeta implementation is not thread safe, it uses sql/mysql modules which also do not have any protection (there are some mutexes there but not used). Need an urgent fix to avoid crashes due to concurrent queries in czar."""
"DM-3940","Improvement","ip_diffim",0.5,"NaiveDipoleCentroid/NaiveDipoleFlux algorithms should not require centroid slot","""The {{NaiveDipoleCentroid}} and {{NaiveDipoleFlux}} algorithms in {{ip_diffim}} have members which are instances of {{meas::base::SafeCentroidExtractor}}. Due to the prerequisites that imposes, it is impossible to initialize these algorithms without first defining a {{centroid}} slot.    However, there is nothing in these algorithms which actually uses the {{SafeCentroidExtractor}} or any of the information stored in the slot; this seems to be an entirely arbitrary restriction which is likely a legacy of the port to the {{meas_base}} framework. We should remove the  use of {{SafeCentroidExtractor}} to simply the code and make it easier to run the test suite (since it will no longer be necessary to run a centroider)."""
"DM-3949","Story","Qserv",2,"Remove dependency on mysqldb in qserv","""Remove remaining dependencies on mysqldb in qserv.:      and use the sqlalchemy from db module instead."""
"DM-3947","Story","Qserv",0.5,"Remove dependency on mysqldb in wmgr","""Move remaining code that depends on mysqldb to db module"""
"DM-3957","Story","meas_modelfit",1,"Enable CModel in CalibrateTask prior to PhotoCal","""CModel needs to run in CalibrateTask before PhotoCal in order to compute aperture corrections, but it also needs a Calib objects as input, and that isn't available until after PhotoCal is run.    On the HSC side, we dealt with this by adding preliminary PhotoCal run before CModel is run, but we could also deal with it by removing the need for a Calib as input, at least in some situations."""
"DM-3951","Story","Qserv",3,"Remove qserv_objectId restrictor","""qserv_objectId restrictor can be replaced by the IN restrictor. This story involves checking if performance is acceptable if we use IN restrictor instead of qserv_objectId restictor, and if it is, doing the switch and removing the qserv_objectId restictor code."""
"DM-3971","Story","db",1,"Package sqlalchemy in eups","""Db module is expected to be used by science pipelines, and (per K-T, see qserv hipchat room) we have to package it through eups."""
"DM-3982","Bug","meas_astrom",0,"CalibrateTask is incompatible with older astrometry tasks","""[~lauren] and I recently discovered an incompatibility between {{CalibrateTask}}'s schema-handling and the older astrometry tasks, such as {{ANetAstrometryTask}} (the problem affects any astrometry task that utilizes its {{schema}} constructor argument).    The problem is that astrometry is called twice in {{CalibrateTask}}:   - Just before PSF estimation, in order to get matches to support {{CatalogStarSelector}}.  This call is passed {{sources1}}, a catalog containing only the initial, pre-PSF measurements.   - After the second measurement stage, to determine the {{Wcs}} and get matches to feed {{PhotoCal}}. This call is passed {{sources}}.    The problem is that {{sources.schema != sources1.schema}}, and the astrometry subtask is initialized with {{schema1 == sources1.schema}}.  So if the astrometry task needs to fields it added to the schema (the default {{AstrometryTask}} does not), it will likely fail in the second run, as it's being given a catalog that doesn't correspond to the schema it was initialized with.    Comments in the code indicate that there's a desire that future {{AstrometryTask}} s will not take a schema argument, and that would mean that they could be called repeatedly with different schemas (as we are doing).  I'm not sure that's viable; I think it'd probably be appropriate for {{AstrometryTask}} to set flags indicated the sources it's using (or considered using), as the other calibrate subtasks do.    Instead, I think we're probably best off creating two separate astrometry subtasks, each with a different schema, and using the appropriate subtask for each input/output catalog.    Clearly we need to come up with a better solution when in the upcoming {{CalibrateTask}} redesign; two subtasks is obviously clunky.  Whether this is high-priority before then depends on how much we're dependent on {{ANetAstrometryTask}} as a fallback option, and I haven't been following that conversation closely."""
"DM-3981","Story","Firefly",1,"Improve the performance for making the image plot","""Make FitsRead work better for multi-threads"""
"DM-3980","Story","Data Access|db",0.5,"Post SQLAlchemy-migration tweaks","""Implement some minor tweaks take came in late through PR comments, mostly related to sqlalchemy related migration"""
"DM-4003","Story","Qserv",2,"Replace zookeeper CSS with mysql","""To switch from QservAdmin to CssAccess interface in our Python tools we will need to replace zookeeper with mysql implementation because we do not have C++ KvInterface implementation for zookeeper."""
"DM-4002","Story","obs_test",0,"Add doc dir and main.dox to obs_test","""No obs_* packages have a doc dir. I suggest starting with obs_test since it is perhaps less obvious what it is used for than the others and in some ways acts as a template."""
"DM-3993","Bug","afw",0.5,"Display.dot origin swaps x and y","""Correcting for xy0 in {{dot}} currently does:  {code:hide-linenum}  r -= x0  c -= y0  {code}  which is backwards."""
"DM-3987","Story","meas_deblender",1,"remove unnecessary 'psf' arg to SourceDeblendTask.run()","""{{SourceDeblendTask.run}} takes both an {{Exposure}} and a {{Psf}}, even though it can get the latter from the former and always should."""
"DM-4009","Story","meas_base",3,"Allow FlagHandler to be used from Python","""The {{FlagHandler}} utility class makes it easier to manage the flags for a measurement algorithm, and using it also makes it possible to use the {{SafeCentroidExtractor}} and {{SafeShapeExtractor}} classes.  Unfortunately, its constructor requires arguments that can only be provided in C++.  A little extra Swig wrapper code should make it usable in Python as well."""
"DM-4014","Story","afw|meas_base|ndarray",1,"Replace boost::tuple with <tuple>","""Replace boost::tuple with <tuple>    This ticket will be completed as part of the DM bootcamp at UW."""
"DM-4021","Story","afw|daf_base|daf_persistence|sconsUtils|utils",2,"Replace boost::unordered_map with std::unordered_map","""DM boot camp tutorial.    """
"DM-4020","Bug","pipe_tasks",0,"Remove #!/usr/bin/env from pipe_tasks library code","""Many tasks in pipe_tasks start with #!/usr/bin/env..., yet are not executable."""
"DM-4022","Bug","obs_subaru|pipe_tasks",0.5,"forcedPhotCoadd.py fails on HSC data","""When trying to run {{forcedPhotCoadd.py}} on HSC data, I see the following error:        This is with the stack version 11.0+3 and {{obs_subaru}} 5.0.0.1-676-g4ae362c."""
"DM-4043","Story","jointcal",8,"update memory management in jointcal","""jointcal currently uses a combination of raw pointers and a custom reference-counted smart pointer class, {{CountedRef}} (similar to {{boost::intrusive_ptr}}).  The code needs to be modified to use a combination of {{shared_ptr}} (most code), {{unique_ptr}} local-scope variables and factory functions, and {{weak_ptr}} (at least some will be necessary to avoid cycles in some of the more complex data structures).  As part of this work, we'll also have to remove a lot of inheritance from {{RefCounted}}, which is part of the {{CountedRef}} implementation.    This ticket looks like it will require a lot of work, because we'll have to be careful about every conversion to avoid cycles and memory leaks.  Nevertheless, I think it will be necessary to do this conversion before attempting any other major refactoring, as I'm worried that having a newcomer make changes to the codebase without first making the memory management less fragile could be very dangerous."""
"DM-4036","Improvement","afw|geom|meas_base|meas_deblender|meas_extensions_photometryKron|meas_modelfit|Qserv|shapelet|utils",5,"Change from boost::math","""Most boost::math contents (not including pi) are now available in standard C++. Please convert the code accordingly.    In addition to the packages listed above, boost/math is used in """"partition"""" a package I don't recognize and not a component JIRA accepts."""
"DM-4071","Bug","meas_algorithms",0.5,"testPsfDetermination broken due to NumPy behaviour change","""Old NumPy behaviour (tested on 1.6.2):      New NumPy behaviour (1.10.0):      This breaks {{testPsfDeterminer}} and {{testPsfDeterminerSubimage}}, e.g.:  """
"DM-4065","Story","mysql",2,"Discuss with MySQL team","""This story captures issues/topics that we want to bring up with mysql team."""
"DM-4063","Bug","afw|coadd_utils|obs_lsstSim",1,"Support new casting requirements in NumPy 1.10","""The function imagesDiffer() in testUtils attempts to OR an array of unit16s (LHS) against an array of bools(RHS) {{valSkipMaskArr |= skipMaskArr}} and errors with message    preventing afw from building correctly. """
"DM-4078","Story","SUIT",2,"convert underscore to lodash","""lodash has become a superset of underscore, providing more consistent API behavior, more features, and more thorough documentation. We'd like to convert our underscore package dependencies to lodash while we have only ~20 calls to underscore functions"""
"DM-4076","Story","SUIT",2,"JavaScript code cleanup - remove unused packages","""Remove es6-promise, react-modal, other cleanup"""
"DM-4075","Story","SUIT",8,"Assemble eslint rules for JavaScript code quality control","""Review and assemble eslint rules, which enforce clean JavaScript and JSX code.    Code cleanup to avoid too many rule violations."""
"DM-4092","Story","Qserv|xrootd",0.5,"Update qserv for lastest xrootd","""Small API change in latest xrootd, requires a parallel change to qserv.  Paves the way for DM-2334"""
"DM-4087","Story","Firefly|SUIT",3,"Attend DM boot camp ","""Attend DM boot camp to learn more about DM stack, butler, and task. """
"DM-4086","Story","Firefly|SUIT",3,"Attend DM boot camp","""Attend DM boot camp to learn more about DM stack, butler, and task.     Most of the presentations are located at URL https://community.lsst.org/t/dm-boot-camp-announcement/249. Presentations like afw, eups, tasks, and butler are necessary to participate in LSST, so everyone on LSST must understand these concepts. Look at the list of presentations covering these topics and make sure your understand them. Some of the remaining talks go into more detail or cover more specialized topics. Those talks should be scanned to see if they are of interest to you."""
"DM-4085","Story","Firefly|SUIT",2,"Attend DM boot camp","""Attend DM boot camp to learn more about DM stack, butler, and task. """
"DM-4080","Story","ctrl_execute|ctrl_orca",8,"Shutdown mechanism doesn't work when logging process is disabled.","""If the logging mechanism is turned off in ctrl_execute, the ctrl_orca Logger doesn't get launched.  The current shutdown mechanism waits for the last logging message to be transmitted before shutting down so it doesn't kill off that process.   If the logger.launch config file option is set to false, this process never get launched and ctrl_orca hangs after the shutdown waiting for the message to arrive."""
"DM-4095","Improvement","skymap",1,"Please port showVisitSkyMap.py from HSC","""The HSC documentation at http://hsca.ipmu.jp/public/scripts/showVisitSkyMap.html includes a useful script for displaying the skymap and CCDs from a set of visits. It would be convenient if a version of this script was available in the LSST stack."""
"DM-4117","Story","Stack Documentation and UX",0.5,"Clean up lsst_stack_docs for preview","""Improve the presentation of the New docs overall:    # Add a Creative Commons license  # Remove stub documents from the presentation  # Put READMEs in all doc directories to explain what content will go in them  # Clean up and update the source installation guide to reflect 11_0"""
"DM-4105","Story","Qserv",1,"Update user documentation","""{{ORDER BY}}, {{objectId IN}} and {{objectId BETWEEN}} predicates support have been improved, this should be documented.    """
"DM-4104","Improvement","Stack Documentation and UX",0,"Document that <<= is deprecated","""Update our documentation to replace Image {{<<=}} pixel copy operator with {{[:] =}} for Python code and {{set(rhs)}} for C++ code (or whatever RFC-102 decides), with a note that {{<<=}} exists but is deprecated."""
"DM-4102","Improvement","afw|ip_diffim|meas_algorithms|meas_deblender|pipe_tasks",3,"Remove use of <<= from C++ code in our stack","""Replace usage of deprecated Image operator {{<<=}} in C++ code with {{assign(rhs, bbox=Box2I(), origin=PARENT)}} as per RFC-102    Switch from [:] to assign pixels in Python code where an image view is created for the sole purpose of assigning pixels (thus turning 2-4 lines of code to one and eliminating the need to make a view)."""
"DM-4100","Improvement","afw|display_ds9|ip_diffim|ip_isr|meas_algorithms|meas_astrom|meas_deblender|obs_lsstSim|obs_subaru|obs_test|pipe_tasks",2,"Replace use of image <<= with [:] in python code","""Replace all use of the afw image pixel copy operator {{<<=}} with {{\[:]}} in Python code.    See DM-4102 for the C++ version. These can be done independently."""
"DM-4098","Story","Developer Infrastructure",0.5,"Update Trust Level of all LSST DM Staff to Level 4 via the API","""It seems safe to update the Discourse trust level of all members of the LSSTDM group on community.lsst.org to Level 4 (full permissions). See https://meta.discourse.org/t/consequences-of-using-or-bypassing-trust-levels-for-company-organization-staff/34564?u=jsick    This should alleviate concerns that DM staff are being prevented from fully using the forum.    This ticket implements a small notebook to exercise the Discourse API to make this trust level migration possible."""
"DM-4133","Bug","afw",1,"Change type of LTV1/2 from int to float when writing afw images to FITS","""The LTV1/2 problem is originally my bug.  I used integer LTV1/2 in    whereas a more careful reading of the NOAO page [http://iraf.noao.edu/projects/ccdmosaic/imagedef/imagedef.html] introducing them includes floating point examples.    The fix is to cast the XY0 values to float.  I'm not sure if there'll be any side effects of fixing this, but if so they'll be obvious and trivial.  """
"DM-4129","Bug","daf_ingest",0.5,"Database connection problems in daf_ingest","""The DbAuth connection fallback in ingestCatalogTask passes the """"password"""" keyword argument to {{MySQLdb.connect}} instead of """"passwd"""", which fails. Also, the """"port"""" command line argument isn't marked as an integer, causing port strings to be passed down to MySQLdb. This results in a type error. """
"DM-4125","Bug","pipe_tasks",0.5,"pipe_tasks/examples/calibrateTask.py fails","""The self contained example calibrateTask.py in pipe_tasks/examples/ fails when attempting to set field """"coord"""" in refCat. Exact error message -         Note that {{wcs.pixelToSky(s.getCentroid())}} is set to {{Fk5Coord(15.007663073114244 * afwGeom.degrees, 1.0030133772819259 * afwGeom.degrees, 2000.0)}}"""
"DM-4143","Story","Stack Documentation and UX",3,"Demonstrate using Breathe for Python & C++ API reference in New Docs","""Demonstrate use of breathe for utilizing the existing Doxygen API documentation in the new Sphinx-based doc platform."""
"DM-4141","Improvement","pipe_base|pipe_drivers",1,"cmdLineTasks should provide proper unix return codes","""When a cmdLineTask fails it doesn't appear to return a non-0 exit code to the shell, making it hard to write shell scripts that chain commands together.    Please fix this.    E.g.  """
"DM-4137","Story","obs_decam",1,"Update DECam CCDs gain, read noise, and saturation values","""The values of DECam gain, read noise, and saturation value need to be updated.     This ticket is to update them in the Detector amplifier information, which is used in IsrTask.     Talked to Robert Gruendl. These values should take precedence over the values in the fits header. They seem stable and do not seem to vary with time.   """
"DM-4151","Story","afw",2,"Search for uses of current afw.wcs in the stack","""Search through the stack for all the uses of our Wcs implementation (Wcs, TanWcs, makeWcs, and any other hidden objects) and make a list of all of those uses (on Community for example). This list should note whether the usage is in C++ or python."""
"DM-4145","Story","Qserv",0.5,"Reduce scons output in qserv","""Yesterday AndyH expressed a valid concern that qserv prints too much info which makes it hard to find errors. By default scons prints whole command line for C++ compilation and linking which are quite long (~half screen depending on your screen size). Most of the time we don't need to see that, so it would be better to replace that with shorter messages like """"Compiling Something.cxx"""" and have an option to print full command with --verbose option."""
"DM-4165","Improvement","boost",0.5,"Take upstream boost 1.59 patch to squelch warnings for gcc 5.2.1","""Under gcc 5.2.1, use of boost 1.59.0 produces a torrent of compiler warns from within boost headers about use of deprecated std::auto_ptr (see https://svn.boost.org/trac/boost/ticket/11622).    A patch for this is already committed upstream in boost.  It is proposed that we take this patch into the lsst t&p in interim until the next official boost release."""
"DM-4160","Bug","meas_algorithms",1,"Unused variables in meas.algorithms.utils","""Pyflakes 1.0.0 reports:    In the best case, those variables are simply unnecessary, and they should be removed to simplify the code and avoid wasting time. Alternatively, it's possible that they ought to be used elsewhere in the calculation but have been omitted accidentally. Please establish this for each one, then either remove them or fix the rest of the code."""
"DM-4158","Story","pipe_tasks",3,"Allow configuring more statistical options for assembleCoadds.py ","""The assembleCoadd.py task has a configuration option doSigmaClip which chooses between MEAN and MEANCLIP. Please replace this with an option to specify the algorithm to be used. Note that afwMath.stringToStatisticsProperty can be used to convert a string to an enum value. In particular, this would allow me to specify a MEDIAN stack if desired (e.g. to make pretty RGB images)  """
"DM-4194","Bug","log",1,"Python LogHandler does not pass logger name to log4cxx","""Not sure how or why it happened, but presently Python LogHandler for lsst.log does not pass logger name to log4cxx layer and all messages from Python logging end in root logger. """
"DM-4202","Story","obs_subaru",1,"Revert temporary disabling of CModel in config override files","""Revert the temporary disabling of CModel that relates to a bug noted in DM-4033 that was causing too many failures to test that processCcd (etc.) would run all the way to completion (most of the other fixes/updates related to the initial disabling in the multiband tasks have now been completed in DM-2977 & DM-3821).     Relevant files:    """
"DM-4206","Bug","Qserv",2,"wmgr should delete database from inventory when dropping it","""When wmgr drops database it should also cleanup chunk inventory for that database.    """
"DM-4219","Story","Qserv",2,"Package capnproto for eups","""Prototype is now getting to the point where a wire-protocol package like capnproto or protobuf is needed.  capnproto is the new hotness, and we're probably going to want to migrate qserv from protobuf->capnproto at some point.    This task is to go ahead and get capnproto packaged and published for use in the replication prototype."""
"DM-4230","Story","ip_isr",2,"Port HSC-1355: Improved fringe subtraction","""[HSC-1355|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1355]: """"with this fix, we get much  better fringe subtraction""""."""
"DM-4229","Story","Qserv",3,"Identify candidate technology for secondary index","""Evaluate results of production-scale performance tests, both single and multiple host.  Identify the technology most likely to meet requirements, and estimate performance capability with respect to those requirements"""
"DM-4225","Story","Qserv",3,"Collect single-host performance data for secondary index","""Run production-scale (billions of entries) tests on different index options, collect performance statistics for allocation (CPU, memory) and for queries."""
"DM-4223","Story","ip_isr",1,"IsrTask calls removeFringe in FringeTask but the method does not exist","""The method {{removeFringe}} of {{FringeTask}} is called in {{IsrTask}} but there is no {{removeFringe}}.      Not sure if {{removeFringe}} was meant to be a place holder"""
"DM-4245","Story","SUIT",2,"Image Viewer memory leak","""When reloading the same 500MB RAFT image into an image viewer (see the script below), it was discovered that single node Firefy server with 3G memory runs out of memory after ~15 reloads    Test case: keep reloading the html file with the following Javascript, creating an image viewer with 500MB image:    function onFireflyLoaded() {          var iv2= firefly.makeImageViewer(""""plot"""");          iv2.plot({               """"Title""""      :""""Example FITS Image'"""",               """"ColorTable"""" :""""16"""",               """"RangeValues"""":firefly.serializeRangeValues(""""Sigma"""",-2,8,""""Linear""""),               """"URL""""        :""""http://localhost/demo/E000_RAFT_R01.fits""""});  }    Follow up:    The bug was traced to java.awt.image.BufferedImage objects not being evicted from VIS_SHARED_MEM cache.    Further search showed that java.awt.image.BufferedImage (along with java.io.BufferedInputStream) is in src/firefly/java/edu/caltech/ipac/firefly/server/cache/resources/ignore_sizeof.txt, which lists the classes that have to be ignored when calculating the size of cache.    Testing on single node server (VIS_SHARED_MEM cache is not replicated), using [host:port]/fftools/admin/status page:    BEFORE (java.awt.image.BufferedImage was commented out in ignore_sizeof.txt)    After 14 reloads:  Memory    - Used                      :      3.7G    - Max                       :     3.55G    - Max Free                  :    488.0M    - Free Active               :    488.0M    - Total Active              :     3.55G     Caches:    VIS_SHARED_MEM @327294449   Statistics     : [  Size:15  Expired:0  Evicted:0  Hits:246  Hit-Ratio:NaN  Heap-Size:1120MB  ]  OUT OF MEMORY on next reload    AFTER THE CHANGE (Commented java.awt.image.BufferedImage in ignore_sizeof.txt)    After 36 reloads:  Memory    - Used                      :   1672.9M    - Max                       :     3.55G    - Max Free                  :   1968.0M    - Free Active               :   1468.0M    - Total Active              :      3.6G    Caches:    VIS_SHARED_MEM @201164543   Statistics     : [  Size:3  Expired:0  Evicted:34  Hits:659  Hit-Ratio:NaN  Heap-Size:1398MB  ]    """
"DM-4239","Story","Qserv",5,"Identify Qserv areas affected by secondary index","""Evaluate Qserv software for the Czars and workers to identify where an interface to the secondary index will be required for efficient operation."""
"DM-4238","Story","obs_subaru",0.5,"Fix integer casting error in numpy version 1.10 in obs subaru","""Fix type casting in obs_subaru in lates numpy in obs_subaru"""
"DM-4237","Bug","Nebula OpenStack",2,"unable to upload images to nebula","""I seem to be unable to upload an image to neblua from a URL via either horizon or the nova cli client.  The request seems to queue briefly and then reports a status of {{killed}}. Eg    """
"DM-4236","Story","pipe_base",2,"Specify default output location for CmdLineTasks","""When neither {{\--output}} or {{\--rerun}} is specified as an argument to a {{CmdLineTask}}, any output from that task appears to be written back to the input repository. Note the use of the term """"appears"""": from a preliminary inspection of the code and documentation, it's not clear if this behaviour can be overridden e.g. by environment variables.    The HSC stack behaves differently, using {{$INPUT/rerun/$USER}} as a default output location. A [brief discussion|https://community.lsst.org/t/new-argument-parser-behavior-rerun-flag-introduction-discussion/345] suggests that this is the preferred behaviour.    Please update the LSST stack to match the HSC behaviour."""
"DM-4232","Story","ip_isr",5,"Variance is set after dark subtraction","""In the default {{IsrTask}}, the variance is currently set after dark subtraction.  This means that photon noise from the dark is not included in the variance plane, which is incorrect.  The variance should be set after bias subtraction and before dark subtraction.    [~hchiang2] also points out (DM-4191) that the {{AssembleCcdTask}} with default parameters requires amplifier images with variance planes, even though the variance cannot be set properly until after full-frame bias subtraction.  I believe that {{AssembleCcdTask}} only requires a variance plane in the amp images because it does an """"effective gain"""" calculation, but I suggest that this isn't very useful (an approximation of an approximation, and you're never going to use that information anyway because it's embedded in the variance plane with better fidelity).  I therefore suggest that this effective gain calculation be stripped out and that {{AssembleCcdTask}} not require variance planes."""
"DM-4259","Story","ip_diffim",5,"Create a set of tests (or update the current ones) to facilitate refactoring of dipole measurement","""This will create a test (not necessarily a unit test) that will simulate dipoles and measure them so that the measurement can be compared to truth values.  This may be simply refactoring the current tests.    This task should also include generating more generalizable utilities needed to create the dipoles and incorporating these and other test data into the stack so that they can be used in other studies."""
"DM-4256","Story","Stack Documentation and UX",1,"Sphinx support of sqr-001 technical note","""Support the distribution of a technical note SQR-001    - Remove oxford comma in author list (documenteer)  - Solve issue where title is repeated if the title is included in the restructured text document  - Solve issue where name of the HTML document is README.html"""
"DM-4252","Technical task","Developer Infrastructure",2,"Create GitLFS Technical Note","""Create a SQuaRE Technical Note describing the architecture of the GitLFS service implementation."""
"DM-4251","Story","Continuous Integration|obs_subaru",1,"Please include obs_subaru in CI","""{{obs_subaru}} should be included in the CI system."""
"DM-4266","Story","ip_isr|obs_lsstSim",8,"Should only read fringe data after checking the filter","""The fringe subtraction is not necessarily performed if {{doFringe}} is True. It is only if the filter of the raw exposure is listed in config fringe.filters.      Fringe data should not be read unless the filter is indicated. There are likely no such filter data and it would cause runtime errors.      Seems related to changes from RFC-26 and DM-1299. """
"DM-4264","Story","supertask",1,"SQuaRE supertask design meeting 2","""Hold a teleconference design discussion with members of the SQuaRE team.  """
"DM-4286","Story","QA",20,"Processing of DECAM COSMOS field - Part I","""This story covers work on the verification plan done in October.     The DECAM Cosmos field was selected, however DECAM ISR is not available so the starting point for now is Community Pipeline reduced data. Have put the data through processCcdDecam and makeCoaddTempExp but had a number of failures that we have so far not been able to pin down. A list of user experience issues is being collated and [~frossie] will generate Summer 16 cycle stories to address those that fall within SQuaRE's defined scope of activities.     Story closed to fit within month, but work is ongoing. """
"DM-4298","Improvement","Nebula OpenStack",2,"want equiv of m1.xlarge flavor with smaller disk","""I'd like to be able to build images with vcpus & ram from the {{m1.xlarge}} flavor that can be run on a {{m1.medium}} with it's smaller disk image, this would require a new flavor with 16GiB ram/8vcpus but only 40GiB of disk.  Something along the lines of:    {{openstack flavor create --ram 16384 --disk 40 --vcpus 8 ...}}    Is that possible?"""
"DM-4295","Story","Qserv",8,"Run and document multinode integration tests on Openstack+Docker","""Boot openstack machines using vagrant, then deploys docker images and finally launch multinodes tests.    FYI, lack of DNS on OpenStack Cloud cause problems, but a vagrant plugin seems to solve this."""
"DM-4305","Bug","pipe_tasks",1,"assembleCoadd broken","""A recent update to assembleCoadd to bring over changes to do clipped coadds breaks coadd generation.  There are two specific problems.    1. There is an infinite recursion because of SafeClipAssembleCoaddTask calling its own constructor in the \_\_init\_\_ method.  2. The overridden assemble method does not adhere to the original assemble call signature, so when the default run method is called by ParseAndRun, it raises an exception.    Additionally I find the flow fairly confusing as the overridden assemble method is called by the default run method which then calls the default assemble method on the parent class."""
"DM-4304","Story","SUIT",1,"Add unit testing into gradle build for Firefly's server-side code","""Add a test task to Firefly's common build script.  This can be used by any sub-project to run unit test.  Added unit testing to Jenkins continuous integration job to ensure new code does not break unit testing."""
"DM-4303","Story","lsstsw",3,"re-deploy lsstsw on Jenkins","""Pandas was added to the bin/deploy script in lsstsw to support  sims development.  This has already been merged to master in 4b1d1a0fa.  The ticket is to ask that lsstsw be redeployed so the sims team can build branches that use pandas."""
"DM-4301","Story","SUIT",8,"Convert banner and menu to react/flux","""Add flux data model to capture menu and banner information.  Convert banner and menu UI from gwt to react.  As part of this task, bring in Fetch API to simplify client/server interactions."""
"DM-4323","Story","afw|obs_subaru",1,"Replace fitsthumb in obs_subaru (port HSC-1196)","""{{fitsthumb}} is now obsolete; all the functionality we need is available in {{afw}}. Further, we want to drop it as a dependency to make the job of integrating {{obs_subaru}} with CI easier."""
"DM-4312","Story","Firefly",2,"Nov. on-going support to Camera team in UIUC","""Attend UIUC weekly meeting and give support as needed. """
"DM-4311","Story","Firefly",2,"Oct. on-going support to Camera team in UIUC","""Attend UIUC weekly meeting and give support as needed. """
"DM-4310","Bug","lsstDoxygen|sconsUtils|Stack Documentation and UX",1,"Missing Doxygen documentation","""As of [2015-11-10 02:53.26|https://lsst-web.ncsa.illinois.edu/doxygen/xlink_master_2015_11_10_02.53.27/] there were 19 """"mainpages in subpackages"""" available through Doxygen.    In the next build, [2015-11-10 21:16.19|https://lsst-web.ncsa.illinois.edu/doxygen/xlink_master_2015_11_10_21.16.19/], most of them have vanished and we only provide links for {{ndarray}} and {{lsst::skymap}}.    As of filing this issue, they were still missing from the [latest build|https://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/].    Please bring them back!"""
"DM-4307","Story","Continuous Integration",0.5,"Please add HSC tests to CI","""In DM-3663 we (= [~price]) provided an integration test for processing HSC data through the stack with the intention that it should be integrated with the CI system.    Having this test available and regularly run would be enormously helpful with the HSC port -- we've already run into problems which it could have helped us avoid (DM-4305)."""
"DM-4329","Improvement","coadd_utils",1,"Coadd_utils tests should run and skip if afwdata is missing","""Currently, the {{coadd_utils}} tests are completely skipped at the scons layer if afwdata can not be located. This is bad for two reasons:  1. Are there any tests that can be run even if afwdata is missing?.  2. When we switch to a proper test harness (e.g. DM-3901) an important metric is the number of tests executed compared with the number of tests skipped.  Each test file (or even each test) should determine itself whether it should be skipped based on afwdata availability. This should not be a global switch."""
"DM-4349","Story","SUIT",2,"Fix publishing script async issue and add additional release notes.","""Async command execution causes unpredictable and unreliable results.  Switches to synchronous where possible.  Also add additional description to the release notes."""
"DM-4347","Story","ImgServ",1,"dax_imgserv 2015_10.0 build error","""{{2015_10.0}} has a build error under a current {{lsstsw/bin/deploy}} environment.  Current speculation is that this is related to the conda version of numpy being upgraded to {{1.10.1}}."""
"DM-4344","Bug","pipe_tasks",0,"pipe_tasks 11.0-14-ga314014+5 fails a test on os/x 10.10.5","""Running    on my laptop running ox/x 10.10.5 results in a test failure:    """
"DM-4362","Story","supertask",8,"SuperTask phase 1 implementation","""This story represents the implementation of the first part of the SuperTask framework design,"""
"DM-4360","Bug","obs_subaru",0.5,"obs_subaru fails to compile after DM-3200","""Due to atypical calls in {{obs_subaru}}'s {{hsc/SConscript}} to run scripts in the {{bin}} directory, {{obs_subaru}} fails to compile after the changes made in DM-3200."""
"DM-4375","Story","obs_decam",2,"A slimmer testdata_decam","""Before this ticket, the files in {{testdata_decam}} are as they are downloaded from the archive.  Some are MEF, and the total is a bit big (1.2G).    I made a trimmed down version of {{testdata_decam}}, 109M and available here:  [https://github.com/hchiang2/testdata_decam.git]  I trimmed it down by only saving the primary HDU and one data HDU.  However the unit tests in {{getRaw.py}} become less meaningful and I am not sure if we really want to do this, because some complexities of DECam files are about the MEF. {{getRaw.py}} tests Butler retrieval of multiple dataset types, in particular tests if the correct HDU is retrieved.     Nonetheless, {{getRaw.py}} can pass  (with branch u/hfc/DM-4375 of obs_decam)    Note: the old testdata_decam still live on lsst-dev:/lsst8/testdata_decam/"""
"DM-4373","Story","meas_base",1,"HSC backport: Add tract conveniences","""This is a port of [HSC-715: Add tract conveniences|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-715].  Here is the original description:    {panel}  In regular HSC survey processing, we'll run with a """"rings"""" skymap to cover the entire survey area. meas_mosaic does not currently efficiently or conveniently iterate over tracts. For example:    Note the lack of a tract in the --id specifier  we want to iterate over all tracts. This is not currently possible. Instead, if we do not know the tract of interest (which the user should not be required to know), we have to iterate over all the tracts (e.g., tract=0..12345), but the user should not be required to know the number of tracts, and this is slow (and possibly memory-hungry: currently consuming 11GB on tiger3 just for 12 exposures).  We need an efficient mechanism to iterate over all tracts by not specifying any tract on the command-line.  {panel}    As this functionality was added specifically for {{meas_mosaic}}, it was going to be ported as part of DM-2674.  Due to a recent desire to use this functionality, this ticket will be ported here."""
"DM-4370","Story","obs_decam",0.5,"Migrate testdata for DECam from disk to git-lfs","""There is a package full with test data for the obs_decam.  It is an eups package currently, but not a git repository.  I would like to migrate that into our hosted git-lfs so the obs_decam package can be built by Jenkins.  [~jmatt] I'm hoping you would be willing to handle this for me.  If not I can find somebody else.  Thanks!"""
"DM-4367","Story","Algorithm Testing",3,"Fix bug and add unit tests for PsfShapeletApprox ","""We discovered during this Sprint that this plugin was giving us faulty values for all the models except for SingleGaussian.  I will fix that bug on this issue.    Obviously, a better unit test would have caught this.  I am adding a DoubleGaussian unit test, plus a test that the default models provide different results.  Also a timing test for all the models, as we do not really have enough information about the performance of the shapelet approximation.  """
"DM-4366","Story","obs_decam",5,"Improve overscan correction for DECam raw data","""Currently, the default overscan correction from IsrTask is used for processing DECam raw data. Overscan subtraction is done one amplifier at a time.     However, a bias jump occurs due to the simultaneous readout of the smaller ancillary CCDs on DECam, some images show discontinuity in the y direction across one amplifier, as in the example screen shot.     This ticket is to improve overscan correction for DECam data so to mitigate this discontinuity in the ISR processing.    Arrangement of CCDs on DECam: http://www.ctio.noao.edu/noao/sites/default/files/DECam/DECamPixelOrientation.png      h3. More details:  There are 6 backplanes in the readout system, shown by the colors in DECamPixelOrientation.png. In raw data files, the CCD's backplane is noted in the header keyword """"FPA"""".  Examination of some images suggests that science CCDs on orange and yellow backplanes show bias jump at 2098 pixels from the y readout. That is the y size of the focus CCDs.     h3. Actions:  For CCDs on the affected backplanes, divide the array into two pieces at the jump location, and do overscan correction on the upper and lower pieces separately.    """
"DM-4385","Improvement","utils",0,"Remove stringToAny from the utils package","""I accidentally left stringToAny in Utils.cc when implementing DM-2635, even though I removed it from Utils.h and it is not used anywhere. Remove it and mark RFC-47 Done."""
"DM-4383","Story","Qserv",2,"Avoid restarting czar when empty chunk list changes","""Currently czar caches empty chunk list after it reads the list from file. This complicates things when we need to update the list, integration test for example has to restart czar process after it loads new data to make sure that czar updates its cached list. Would be nice to have simpler mechanism to resetting cached list in czar without restarting it completely. It could be done via special query (abusing FLUSH for example) or via sending signal (problematic if czar runs remotely).    This can be potentially useful even after we replace empty chunk list file with some other mechanism as I expect that cache will stay around even for that."""
"DM-4381","Bug","Nebula OpenStack",2,"""SHUTOFF"" nebula instances consume core/ramIt  quota","""It appears that halted/shutoff instances have no effect on resource quota usage.  Eg:      """
"DM-4387","Bug","skymap",1,"Skymap fails tests on testFindTractPatchList","""When skymap is built and healpy is loaded, {{testFindTractPatchList}} fails with:    {quote}======================================================================  FAIL: Test findTractPatchList  ----------------------------------------------------------------------  Traceback (most recent call last):    File """"/Users/ctslater/lsstsw/build/skymap/tests/SkyMapTestCase.py"""", line 245, in testFindTractPatchList      self.assertClosestTractPatchList(skyMap, [tractInfo.getCtrCoord()], tractId)    File """"/Users/ctslater/lsstsw/build/skymap/tests/SkyMapTestCase.py"""", line 284, in assertClosestTractPatchList      tractPatchList = skyMap.findClosestTractPatchList(coordList)    File """"/Users/ctslater/lsstsw/build/skymap/python/lsst/skymap/baseSkyMap.py"""", line 146, in findClosestTractPatchList      tractInfo = self.findTract(coord)    File """"/Users/ctslater/lsstsw/build/skymap/python/lsst/skymap/healpixSkyMap.py"""", line 97, in findTract      index = healpy.ang2pix(self._nside, theta, phi, nest=self.config.nest)    File """"/Users/ctslater/lsstsw/stack/DarwinX86/healpy/1.8.1+12/lib/python/healpy-1.8.1-py2.7-macosx-10.5-x86_64.egg/healpy/pixelfunc.py"""", line 367, in ang2pix      check_theta_valid(theta)    File """"/Users/ctslater/lsstsw/stack/DarwinX86/healpy/1.8.1+12/lib/python/healpy-1.8.1-py2.7-macosx-10.5-x86_64.egg/healpy/pixelfunc.py"""", line 110, in check_theta_valid      assert (np.asarray(theta) >= 0).all() & (np.asarray(theta) <= np.pi + 1e-5).all(), """"Theta is defined between 0 and pi""""  AssertionError: Theta is defined between 0 and pi{quote}    This was missed during regular CI testing since healpy is not normally setup. """
"DM-4386","Story","obs_decam",1,"Clean up ProcessCcdDecam","""ProcessCcdDecam needs some cleanup:  * {{run}} method simply delegates to the base class  * {{propagateCalibFlags}} is a no-op (deliberately in {{cab69086}}, need to explore if the original problem still exists)  * The config overrides (in config/processCcdDecam.py):  ** Uses the catalog star selector, which isn't wise given the current heterogeneity of reference catalogs.  ** Sets the background {{undersampleStype}} to {{REDUCE_INTERP_ORDER}}, which is the default."""
"DM-4399","Story","ctrl_execute",1,"ctrl_execute test fails under El Capitan","""The test/testDagIdInfo.py because it runs a script from bin.src, rather than bin.   This test needs to be rewritten."""
"DM-4398","Bug","Qserv",1,"Fix regexp for gcc48","""DM-2622 inttoduced some regexes which raise exceptions when built with gcc48 (e.g. on centos7). gcc48 support for regexes is generally broken, so it's better to replace that with boost regexes."""
"DM-4396","Story","ctrl_execute",0.5,"ctrl_execute test fails to find test binary","""There's a test in ctrl_execute that exercises the bin/dagIdInfo.py test program.   Since the rewrite_shebang rewrites happen after the tests are executed, the test that looks for the bin/dagIdInfo.py binary fails, since it's not there before the tests execute."""
"DM-4395","Story","Qserv",1,"Update cmsd configuration for multi-node tests","""A particular cmsd configuration parameter prefixes a hardcoded path for QueryResource, which needs to be removed. This seems to appear only during multi-node tests."""
"DM-4391","Bug","pipe_tasks",0.5,"Update testCoadds.py to accommodate changes in DM-2915","""As of DM-2915, the config setting:    is set as a default for {{MeasureMergedCoaddSourcesTask}}.  However, this *CLIPPED* mask plane only exists if a given coadd was created using the newly implemented {{SafeClipAssembleCoaddTask}}.  If a coadd was built using {{AssembleCoaddTask}}, the *CLIPPED* mask plane is not present, so the above default must be overridden to exclude it when using {{MeasureMergedCoaddSourcesTask}}.  This is the case for the mock coadd that is assembled in the unittest code in {{testCoadds.py}}, so the config needs to be set for the test to run properly.    Note that the associated tests for {{SafeClipAssembleCoaddTask}} will be added as part of DM-4209."""
"DM-4402","Story","Qserv",8,"Experiment with light-weight SQL databases for secondary index","""Evaluate the use of light-weight SQL, such as InnoDB, TokuDB (now Kyoto Cabinet), or RocksDB to create and manage the secondary index."""
"DM-4410","Story","meas_algorithms|pipe_tasks",5,"Port detection task footprint growth changes from HSC","""In hsc the default behavior for the detection task is to updated footprints with a footprint which has been grown by the psf. This behavior needs to be ported to LSST, as some source records have footprints which are too small. When making this change, the new default needs to be overridden for the calibrateTask, as it needs the original size.    The port includes 8e9fb159a3227f848e0db1ecacf7819599f1c03b from meas_algorithms and 8bf0f4a44c924259d9eefbd109aadec7d839e0f2 from pipe_tasks"""
"DM-4408","Bug","afw",0.5,"HSC backport: fix memory leak in afw:geom:polygon","""This is a backport of a bug fix that got included as part of [HSC-1311|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1311].  It is not related to that issue in particular, so is being ported here as an isolated bug fix.    {panel}  Original commit message:  pprice@tiger-sumire:/tigress/pprice/hsc-1311/afw (tickets/HSC-1311=) $ git sub  commit 55ad42d37fd1346f8ebc11e4077366dff4eaa87b  Author: Paul Price <price@astro.princeton.edu>  Date:   Wed Oct 21 10:59:56 2015 -0400         imageLib: import polygonLib to prevent memory leak             When doing """"exposure.getInfo().getValidPolygon()"""", was getting:             swig/python detected a memory leak of type 'boost::shared_ptr< lsst::afw::geom::polygon::Polygon > *', no destructor found.             This was due to the polygonLib not being imported in imageLib.      Using polygonLib in imageLib then requires adding polygon.h to all      the swig interface files that use imageLib.i.      examples/testSpatialCellLib.i              | 1 +   python/lsst/afw/cameraGeom/cameraGeomLib.i | 1 +   python/lsst/afw/detection/detectionLib.i   | 1 +   python/lsst/afw/display/displayLib.i       | 1 +   python/lsst/afw/geom/polygon/Polygon.i     | 1 +   python/lsst/afw/image/imageLib.i           | 2 ++   python/lsst/afw/math/detail/detailLib.i    | 1 +   python/lsst/afw/math/mathLib.i             | 1 +   8 files changed, 9 insertions(+)  {panel}"""
"DM-4431","Epic","SUIT",40,"setup mechanism to measure the portal performance","""Setup the method to measure the query response time:   # query sent to the data provider from client (from portal to FF server, to data provider)   # result returns from data provider (FF server gets data, prepare the data for portal)   # result displayed in the client    Setup the method to measure image preparation in Firefly server:   * measure the time needed to prepare the image (generate the image in PNG or other suitable format) for client display.   * Track/identify the reasons if performance is not satisfactory   * Make plan for design/code change    Setup the method to measure image/plot renderingin Firefly client (portal):   * Measure the time needed to render the image after the data received by the client for display.   * Measure the time needed to generate the 2D plot after the data is received by the client   * Track/identify the reasons if the performance is not satisfactory   * Make plan for design/code change"""
"DM-4421","Story","ctrl_events",0.5,"faulty assumption about order dependency in ctrl_event unit tests","""A recent change to daf_base uncovered a couple of faulty tests in ctrl_events that incorrectly assumes the order in which assumed the order in which data in a PropertySet would be received.   We can't assume which order these values will be put into the property set, and therefore into the list retrieved from the Event object."""
"DM-4440","Story","Qserv",2,"Remove QSW_RESULTPATH and XROOTD_RUN_DIR if useless","""These parameters may be useless (see DM-4395). If yes they can be removed to simplify configuration procedure."""
"DM-4438","Story","Qserv",2,"Replace sed with stronger template engine in docker scripts","""Dockerfile are generated using templates and sed, this should be strengthened."""
"DM-4457","Story","Database",8,"Investigate MemSQL","""Take a look at the MemSQL distributed database."""
"DM-4454","Bug","meas_base",2,"Fix multiple patch catalog sorting for forcedPhotCcd.py","""{{forcedPhotCcd.py}} is currently broken due to the requirement of the {{lsst.afw.table.getChildren()}} function that the *SourceCatalog* is sorted by the parent key (i.e. {{lsst.afw.table.SourceTable.getParentKey()}}).  This occurs naturally in the case of *SourceCatalogs* produced by the detection and deblending tasks, but it may not be true when concatenating multiple such catalogs.  This is indeed the case for {{forcedPhotCcd.py}} as a given CCD can be overlapped by multiple patches, thus requiring a concatenation of the reference catalogs of all overlapping patches.    There two places in the running of {{forcedPhotCcd.py}} where calls to {{getChildren()}} can cause a failure: one in the {{subset()}} function in {{references.py}}, and the other in the {{run}} function of *SingleFrameMeasurementTask* in {{sfm.py}}."""
"DM-4451","Epic","Qserv",20,"F17 Qserv Disconnected Queries","""* Design and implement *basic* system for determining whether particular query is synchronous or asynchronous. The complete version will come through DM-1490. Note that this work is related to shared scans (e.g., we need to know what scans we have running)  * Design SQL API for starting and interacting with async queries.  * Modify Qserv to support async queries (starting, getting status, retrieving results)    Note, async queries are indirectly related to authentication (users should not see each other' async queries).    Deliverable: Qserv that accepts and executes queries asynchronously, and allows users to retrieve results."""
"DM-4443","Story","pipe_base",1,"Please document the --rerun option","""DM-3371 adds the {{--rerun}} option to command line tasks. The help for this option reads:  {quote}  rerun name: sets OUTPUT to ROOT/rerun/OUTPUT; optionally sets ROOT to ROOT/rerun/INPUT  {quote}  While essentially correct, that's not particularly helpful in understanding what's actually going on here. A motivation and description of this functionality is available in RFC-95: please ensure that, or some variation of it, is included in the stack documentation."""
"DM-4504","Story","SUIT",1,"FITS Visualizer porting: Image Select Panel/Dialog","""Converting the image select dialog/panel is a very big job and should be to be broken up into several tickets: Each ticket should reference this ticket as the base.    Panel includes the following:  * issa, 2mass, wise, dss, sdss tabs  * file upload tab, upload widget might have to be written  * url tab  * blank image tab  * target info reusable widget  * 3 color support - any panel should show for 3 times, for read, green, and blue in 3 color mode  * must be able to appear in a panel or dialog  * must add or modify a plot  * Allow to create version with most or less than the standard tabs. example - see existing wise 3 color or finder chart 3 color  * A plot might need to be tied to specific type of image select dialog, we need a way to tie a plotId to and non-standard image select panel."""
"DM-4503","Story","SUIT",5,"FITS Visualizer porting: selecting points of catalog from image view, showing selected points","""able to draw a rectangle on the image, and select the catalog entries overlaid on the image"""
"DM-4515","Story","obs_decam",5,"Flag out the glowing edges of DECam CCDs","""Pixels near the edges of the DECam CCDs are bigger/brighter and correcting them is not trivial. One way to move forward is to mask them out.      DESDM and CP mask 15 pixels on each edge.  The cut was later raised to 25 pixels, with the inner 10 pixels flagged as SUSPECT.  """
"DM-4511","Story","Stack Documentation and UX",2,"Improve reStructuredText documentation","""Enhance docs by covering    - Images as links  - Table spans  - Abbreviations  - :file: semantics, etc."""
"DM-4510","Improvement","lsstDoxygen",0.5,"makeDocs uses old style python","""{{makeDocs}} is written in python 2.4 style. This ticket is for updating it to python 2.7."""
"DM-4534","Improvement","Continuous Integration",1,"shellcheck linting of lsstsw bash scripts","""This issue is to recover a branch from DM-4113 that was not merged due to issues with installing shellcheck under travis."""
"DM-4529","Bug","Qserv",1,"Compilation errors from CLang (Apple LLVM 7.0) in XCode 7 on MacOSX","""Compiling on MacOSX Yosemite with XCode 7, a number of files fail compilation.  ----  {{core/modules/util/EventThread.h,cc}} fails because {{uint}} is used as a data type.  This is non-standard (though some compilers support it), and should be replaced with {{unsigned int}}.  ----  {{core/modules/wbase/SendChannel.h,cc}} fails because {{#include <functional>}} is missing.  ----  {{core/modules/wsched/ChunkState.cc}} fails because {{#include <iostream>}} is missing.  ----  {{build/qmeta/qmetaLib_wrap.cc}} (generated by SWIG) fails with many errors because the {{typedef unsigned long int uint64_t}} included in {{qmetaLib.i}} conflicts with MacOSX's typedef of it as {{unsigned long long}}."""
"DM-4523","Bug","Qserv",0.5,"Fix startup.py inside Docker container","""qserv tag should be replace with qserv_latest"""
"DM-4544","Story","butler",5,"Revisit short and long term plans for butler","""Revisit short and long term requirements and needs and capture it through stories."""
"DM-4556","Bug","Qserv",2,"Fix docker workflow","""Some issues where discovered while trying to package DM-2699 in Docker (for IN2P3 cluster deployment), they're fixed here.    - apt-get update times out: why?  - git clone then pull is too weak (if building the first clone fails, pull never occurs) => step merged  - eupspkg -er build creates lib/python in /qserv/stack/.../qserv/... and next install can't remove it for unknow reason => build and install merged."""
"DM-4596","Story","afw",1,"Remove deprecated versions of warpExposure and warpImage","""afw.math supports two templated variants of warpExposure and warpImage, one that takes a warping control and the other which does not. The latter have been deprecated for a long time and are no longer used. I think it is time to remove them."""
"DM-4591","Story","SUIT",3,"GWT conversion: System notifications","""This task is composed of:  - adding notification panel to the application  - convert server-side code to use messaging for notifications  - use messaging on client-side to handle notifications  - creating action, action creator, and reducing functions  - depends on DM-4578 Integrate websocket messaging into flux  """
"DM-4583","Story","SUIT",2,"SUIT: search returning images in a directory","""- Create a sample search processor, which returns images in a given directory.  - It should be using an external python task  - Update search form configuration to use this search processor to return image metadata"""
"DM-4582","Story","SUIT",8,"XY Plot View of a table (JS) - selection support","""Show/change selected/highlighted points. Ideally, this should be done without redrawing the whole plot. """
"DM-4580","Story","SUIT",8,"XY Plot view of a table (JS) - Toolbar","""Toolbar, which toggles plot options, selection and filter buttons    Extra:   - handling zoom from the toolbar rather than using built-in zoom  - ability to switch between histogram and scatter plot view"""
"DM-4576","Story","SUIT",8,"XY Scatter Plot (JS) ","""Implement basic scatter plot widget using react-highcharts library"""
"DM-4574","Story","SUIT",2,"Table (JS): text view","""This task is composed of:  - adding text view option to TablePanel"""
"DM-4572","Story","SUIT",5,"Table (JS): table options","""This task is composed of:  - adding table options panel to TablePanel.  - providing features:    - show/hide units in header    - show/hide columns, reset to defaults, etc    - page size"""
"DM-4564","Story","SUIT",20,"Convert basic table functionalities to JS.","""Task includes server-side json conversion, data modeling, and a simple React table for presentation."""
"DM-4603","Story","sconsUtils",0.5,"sconsUtils tests should depend on shebang target","""Some tests rely on code in the {{bin}} directory. Whilst these tests have been modified to use {{bin.src}} the general feeling is that the test code should be able to rely upon the {{shebang}} target having been executed before they are run."""
"DM-4617","Story","xrootd",5,"Send all chunk-queries to primary copy of the chunk","""We are planning to distribute chunks / replicas across worker nodes such that each node will have a mix of primary copies for some chunks, and backup copies for some chunks. While doing shared scan, we are going to always rely on the primary chunks (e.g., all queries that need a given chunk should be sent to the same machine so that we read that chunks only once on one node). This story involves tweaking xrootd to ensure we don't send chunk-queries to nodes hosting non-primary copies."""
"DM-4609","Story","partition",1,"Partition package should use the standard package layout","""The partition package does not build on OS X El Capitan because the package is not laid out in the standard manner and whilst {{sconsUtils}} is used most of the default behaviors are over-ridden. This means that fixes implemented for DM-3200 do not migrate over to {{partition}}. I think the best approach would be to reorganize the package so that it does build in the normal way."""
"DM-4631","Improvement","Middleware",5,"Create IDL pipeline workflow for DRP processing - processCcdDecam","""For the verification datasets work we need the ability to run a dataset all the way through DRP processing that takes advantage of many cores (orchestration), keeps track of successful and failed dataIDs, creates individual log files, and creates helpful QA plots/metrics/webpages.  Nidever will use his PHOTRED IDL workflow and rewrite it for the stack.  The first step is processCcdDecam."""
"DM-4652","Story","Continuous Integration",1,"CI debugging","""diagnosing build failures and refreshing build slaves"""
"DM-4648","Bug","Qserv",3,"Support sqlalchemy use with qserv","""When one tries to connect to qserv using sqlalchemy there is an exception generated currently:      The reason for that is that sqlalchemy generate few SELECT queries to figure out unicode support by the engine, and those selects are passed to qserv which cannot parse them. Here is the list of SELECTs which appears in proxy log:  """
"DM-4643","Story","SUIT",1,"Add utility function to handle client-side download requests.","""Create utility function to handle client-side download requests.  It needs to be done in a way that does not mess with history and current page state."""
"DM-4677","Story","Qserv",8,"Design Interfaces for Memory Management for Shared Scans","""Part of the shared scans involve memory management - a system that will be used by Qserv that will manage memory allocation / pin chunks in memory. This story involves designing the API between Qserv and the memory management system.  """
"DM-4667","Story","sphgeom",2,"Improve sphgeom documentation","""Per RFC-117, the sphgeom package needs decent overview documentation, linked from the top-level README.md. The doxygen output should also be reviewed."""
"DM-4656","Story","Stack Documentation and UX",5,"Port code style guidelines to new DM Developer Guide","""Verbatim port of DM Coding style guidelines to Sphinx doc platform from Confluence.    - https://confluence.lsstcorp.org/display/LDMDG/DM+Coding+Style+Policy  - https://confluence.lsstcorp.org/display/LDMDG/Python+Coding+Standard  - https://confluence.lsstcorp.org/pages/viewpage.action?pageId=16908666 and contents    Im unclear whether these pages should be included:    - https://confluence.lsstcorp.org/pages/viewpage.action?pageId=20283399 (C++ using)  - https://confluence.lsstcorp.org/pages/viewpage.action?pageId=20284190 (how to use C++ templates)  - https://confluence.lsstcorp.org/pages/viewpage.action?pageId=20283399 (C++11/14; which should seem to belong in the code style guide)    Any temptation to amend and update the style guideline content will be avoided."""
"DM-4688","Story","buildbot|SUIT",2,"Changed the implementation of HistogramProcessorTest due to the minor change about the algorithm in the HistogramProcessor","""In Histogram, when the data points fall on the bin edges,  the following rules are used:  #  For each bin, it contains the data points fall inside the bin and the data point fall on the left edge.  For example, if binSize=2, the bin[0] is in the range of [0,2].  The data value 0 is in bin[0] .  #  For each bin, the data point falls on the right edge is not included in the number point count. For example if binSize=2, the bin[0] is having the range of [0,2].  The data value 0 is in bin[0] but the data value 2 is not in the bin[0].  # For the last bin, the data points fall inside the bin or fall on the left or right bin are counted as the number of bin points.    The last rule is newly introduced.      """
"DM-4679","Epic","SUIT",40,"work with database team to exercise all the APIs for data access (F16)","""SUI will continue to work with database team to exercise all the APIs for data access. All known issues should be worked out in S16 cycle."""
"DM-4708","Story","lsst_dm_stack_demo",0.5,"Integrate astrometry test into SDSS demo lsst_dm_stack_demo","""Incorporate the astrometry test as an optional component in lsst_dm_stack_demo.    This is chosen because lsst_dm_stack_demo currently serves as the very loose stack validation and understanding how to do astrometric repeatibility testing in this demo will help explore how it would make sense to put in a fuller CFHT validation test of the DM stack."""
"DM-4706","Story","obs_cfht|Test Data",1,"Rerun and create a repository for CFHT astrometry test.","""Understand, re-rerun, and recreate clean version of [~boutigny] 's CFHT astrometry test for the astrometry RMS for two sample CFHT observations.  This test is on the NCSA machines in  /lsst8/boutigny/valid_cfht    Create a repository for this test with an eye toward it becoming integrated in a validation suite for the stack.        """
"DM-4705","Bug","qserv_testdata",1,"qdisp/testQDisp fails with mariadb","""Fabrice fried to build qserv with mariadb and it caused failure in one of the unit test: qdisp/testQDisp with the message:      Runnig it with GDB it' obvious that there is a problem with resource lifetime management in qdisp/testQDisp.cc. The problem is that XrdSsiSessionMock is destroyed sooner than other objects that use it.     One way to resolve this problem is to instantiate XrdSsiSessionMock earlier than other objects that use it (to reverse the order of destructors), possibly make it a global instance.    Big mystery here is how mariadb could trigger this interesting behavior and why did not we see this earlier."""
"DM-4704","Bug","Qserv",2,"Qserv integration tests fail on CentOS7 with gcc 4.8.5","""The version of gcc that ships with CentOS7, {{gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-4)}}, appears to miscompile the qserv worker source in a way that makes it impossible to actually run queries. Installing {{devtoolset-3-toolchain}} and {{devtoolset-3-perftools}} via {{yum}} to get gcc 4.9 resolves the issue."""
"DM-4711","Bug","obs_cfht",1,"Edit testdata_cfht to pass obs_cfht unit tests","""This ticket covers the first half of the issues in DM-2917.     {{testdata_cfht}} was left unedited while some past changes in {{obs_cfht}} {{MegacamMapper}} required coordinated changes.  The goal of this ticket is to simply pass the unit tests currently in {{obs_cfht}}.   """
"DM-4710","Story","ctrl_events",3,"host identification info needs to be part of log message","""The EventAppender needs to add host identification (host/process/id) information to the log message it transmits.   This was inadvertently left out."""
"DM-4716","Story","Science Pipelines",2,"Track down reason for slow performance when running many jobs of processCcdDEcam on bambam","""During the processing of the COSMOS data for the verification dataset work I ran many jobs of processCcdDecam.py on the new linux server, bambam.  The performance was very slow, 4x longer than running a single job at a time.  Figure out what is going on."""
"DM-4722","Story","Science Pipelines",3,"File tickets for list of stack deficiencies and suggested upgrades","""K-T suggested that I take my list of """"stack deficiencies and suggested improvements"""" [https://confluence.lsstcorp.org/display/SQRE/Stack+Deficiencies+and+Suggested+Upgrades] on confluence and (with Tim J.'s help) create tickets for each item (as much as possible) so that the work could be scheduled.  """
"DM-4728","Story","doxygen",1,"Doxygen package fails to build with flex 2.6","""To wit:        Builds fine using {{flex 2.5.35 Apple(flex-31)}}."""
"DM-4732","Story","obs_base",0,"butler parentSearch incorrectly returns '[]' instead of 'None' in one case.","""The contract for `daf.butlerUtils.CameraMapping.parentSearch` states that `None` will be returned if no matches are found.    But in one of the options  `            if os.path.realpath(pathPrefix) != os.path.realpath(root):`  the code says `return []` instead of `return None`.    This is then not caught properly by `daf.butlerUtils.mapping.map`, which was checking just for the return value `is not None`.      The behavior of parentSearch is clearly an error (it's againt the documentation for the function).    I would also suggest that `daf.butlerUtils.mapping.map` should check more robustly for `if newPath:` rather than `if newPath is not None:`.    Thus we explicitly set up this if/else to return `None` if `not paths` instead of `[]`.    """
"DM-4731","Story","pipe_tasks",2,"Add labels to qa analysis plots for better interpretation","""The plots output by the qa analysis script (see DM-4393) currently do not display any information regarding the selection/rejection criteria used in making the figures and computing the basic statistics.  This includes magnitude and clipping thresholds.  This information should be added to each plot such that the figures can be interpreted properly."""
"DM-4729","Story","afw",3,"HSC backport: Add functions to generate 'unpacked matches' in a Catalog","""The qa analysis script under development (see DM-4393) calls to HSC {{hscPipeBase}}'s [matches.py|https://github.com/HyperSuprime-Cam/hscPipeBase/blob/master/python/hsc/pipe/base/matches.py] which adds functions to generate """"unpacked matches"""" in a Catalog (and vice versa).  It will be ported into {{lsst.afw.table}}.    The port includes following HSC commits:  *Add functions to generate 'unpacked matches' in a Catalog.*  https://github.com/HyperSuprime-Cam/hscPipeBase/commit/210fcdc6e1d19219e2d9365adeefd9289b2e1186    *Adding check to prevent more obscure error.*  https://github.com/HyperSuprime-Cam/hscPipeBase/commit/344a96de741cd5aafb5e368f7fa59fa248305af5    *Some little error handling helps.*  https://github.com/HyperSuprime-Cam/hscPipeBase/commit/61cc053b873d42802581adff8cbbdb52a348879e  (from branch: {{stage-ncsa-3}})    *matches: add ArrayI to list of field types that require a size*  https://github.com/HyperSuprime-Cam/hscPipeBase/commit/d4ccd11d8afbcdd9cf0b35eba948cca4b5d09ba5  (from branch {{tickets/HSC-1228}})    Please also include a unittest."""
"DM-4734","Story","eups",0.5,"afw fails to build on a machine with many cores","""The afw package does not build reliably (if at all) on a linux box at UW (""""magneto"""", which has 32 cores and 128 Gb of RAM). The failure is that some unit tests fail with the following error:      For the record, /usr/include/bits/local_lim.h contains this:      It appears that the build system is trying to use too many threads when building afw, which presumably means it is trying to use too many cores. According to [~mjuric] the package responsible for this is {{eupspkg}}, and it tries to use all available cores.    A workaround suggested by [~mjuric] is to set environment variable {{EUPSPKG_NJOBS}} to the max number of cores wanted. However, I suggest we fix our build system so that setting this variable is unnecessary. I suggest we hard-code an upper limit for now, though fancier logic is certainly possible.    A related request is to document the environment variables that control our build system. I searched for {{NJOBS}} on confluence and found nothing."""
"DM-4753","Story","Qserv",1,"Cleanup location of anonymous namespaces","""we place anonymous namespace in two ways: (a), INSIDE lsst::qserv::<module> namespace, or (b) BEFORE. This story involves cleaning it up - move them to before lsst::qserv::<module>"""
"DM-4752","Story","sconsUtils",0.5,"Build on Mac very slow due to running fc-list","""Builds on MacOS 10.11 have been painfully slow (for instance 23 minutes to build {{afw}} instead of the more typical 12 minutes, 30 minutes to rebuild {{ip_diffim}}, 20 minutes to rebuild {{meas_astrom}}) and much of this time is spent running fc-list in 8 cores.    I suspect {{matplotlib}} is triggering this process, but I have not verified it.    I see this using lsstsw to build a fresh stack and with manual builds.    A workaround is to repeatedly kill {{fc-list}}, e.g. with this bash script:      I checked my fonts with Apple's Font Book and found a few dozen with """"minor errors"""" that I deleted, but nothing serious. I'm still seeing the problem."""
"DM-4759","Story","SUIT",8,"Port Data  set info converter achitechture","""defines various image data types, how to get them, groupings, artifacts.   I am not quite happy with how we did in in GWT so the design needs to be improved.  Must be less complex."""
"DM-4780","Bug","meas_extensions_shapeHSM",1,"meas_extensions_shapeHSM seems to be broken","""I have installed the meas_extensions_shapeHSM package together with galsim and tmv (I documented it at : https://github.com/DarkEnergyScienceCollaboration/ReprocessingTaskForce/wiki/Installing-the-LSST-DM-stack-and-the-related-packages#installing-meas_extensions_shapehsm) and tried to run it on CFHT cluster data.     My config file is the following:    {code:python}  import lsst.meas.extensions.shapeHSM  config.measurement.plugins.names |= [""""ext_shapeHSM_HsmShapeRegauss"""", """"ext_shapeHSM_HsmMoments"""",                                      """"ext_shapeHSM_HsmPsfMoments""""]  config.measurement.plugins['ext_shapeHSM_HsmShapeRegauss'].deblendNChild=''  config.measurement.slots.shape = """"ext_shapeHSM_HsmMoments""""    Traceback (most recent call last):    File """"/sps/lsst/Library/lsstsw/stack/Linux64/pipe_tasks/2015_10.0-10-g1170fd0/bin/measureCoaddSources.py"""", line 3, in <module>      MeasureMergedCoaddSourcesTask.parseAndRun()    File """"/sps/lsst/Library/lsstsw/stack/Linux64/pipe_base/2015_10.0-3-g24e103a/python/lsst/pipe/base/cmdLineTask.py"""", line 444, in parseAndRun      resultList = taskRunner.run(parsedCmd)    File """"/sps/lsst/Library/lsstsw/stack/Linux64/pipe_base/2015_10.0-3-g24e103a/python/lsst/pipe/base/cmdLineTask.py"""", line 192, in run      if self.precall(parsedCmd):    File """"/sps/lsst/Library/lsstsw/stack/Linux64/pipe_base/2015_10.0-3-g24e103a/python/lsst/pipe/base/cmdLineTask.py"""", line 279, in precall      task = self.makeTask(parsedCmd=parsedCmd)    File """"/sps/lsst/Library/lsstsw/stack/Linux64/pipe_base/2015_10.0-3-g24e103a/python/lsst/pipe/base/cmdLineTask.py"""", line 363, in makeTask      return self.TaskClass(config=self.config, log=self.log, butler=butler)    File """"/sps/lsst/Library/lsstsw/stack/Linux64/pipe_tasks/2015_10.0-10-g1170fd0/python/lsst/pipe/tasks/multiBand.py"""", line 530, in __init__      self.makeSubtask(""""measurement"""", schema=self.schema, algMetadata=self.algMetadata)    File """"/sps/lsst/Library/lsstsw/stack/Linux64/pipe_base/2015_10.0-3-g24e103a/python/lsst/pipe/base/task.py"""", line 255, in makeSubtask      subtask = configurableField.apply(name=name, parentTask=self, **keyArgs)    File """"/sps/lsst/Library/lsstsw/stack/Linux64/pex_config/2015_10.0-1-gc006da1/python/lsst/pex/config/configurableField.py"""", line 77, in apply      return self.target(*args, config=self.value, **kw)    File """"/sps/lsst/dev/lsstprod/clusters/my_packages/meas_base/python/lsst/meas/base/sfm.py"""", line 247, in __init__      self.initializePlugins(schema=self.schema)    File """"/sps/lsst/dev/lsstprod/clusters/my_packages/meas_base/python/lsst/meas/base/baseMeasurement.py"""", line 298, in initializePlugins      self.plugins[name] = PluginClass(config, name, metadata=self.algMetadata, **kwds)    File """"/sps/lsst/dev/lsstprod/clusters/my_packages/meas_base/python/lsst/meas/base/wrappers.py"""", line 15, in __init__      self.cpp = self.factory(config, name, schema, metadata)    File """"/sps/lsst/dev/lsstprod/clusters/my_packages/meas_base/python/lsst/meas/base/wrappers.py"""", line 223, in factory      return AlgClass(config.makeControl(), name, schema)    File """"/sps/lsst/dev/lsstprod/clusters/my_packages/meas_extensions_shapeHSM/python/lsst/meas/extensions/shapeHSM/hsmLib.py"""", line 964, in __init__      def __init__(self, *args, **kwargs): raise AttributeError(""""No constructor defined - class is abstract"""")  AttributeError: No constructor defined - class is abstract  {code}"""
"DM-4781","Bug","Qserv",2,"MariaDB does not work together with mysql-proxy","""We have switched to MAriaDB but there is one issue that complicates things - mysql client from mariadb fails to connect to mysql-proxy with an error:    so Fabrice had to find a workaround for our setup to use client from mysqlclient package instead. This workaround is not perfect and it complicates other things. Would be nice to make things work transparently for mariadb.    """
"DM-4782","Story","Developer Infrastructure",2,"JIRA project for the publication board","""The LSST Publication Board requests a JIRA project for managing its workload.       """
"DM-4785","Story","Database",2,"Update provenance in baseline schema","""Current provenance schema in baseline (cat/sql) is very old and no longer reflect latest thinking. This story involves bringing cat/sql up to data and replacing existing prv_* tables with tables we came up with in the epic."""
"DM-4794","Story","SUIT",2,"Write Zoom Options Popup","""Write the simple zoom options popup that is show when the user clicks zoom too fast or the zoom level exceeds  the maximum size.      activate this popup from visualize/ui/ZoomButton.jsx"""
"DM-4793","Story","Stack Documentation and UX",3,"Refactor prototype docs into Developer Guide and Science Pipelines doc projects","""Refactor [lsst_stack_docs|https://github.com/lsst-sqre/lsst_stack_docs] into two doc projects    - LSST DM Developer Guide that will be published to {{developer.lsst.io}}, and  - LSST Science Pipelines that will be published to {{pipelines.lsst.io}}"""
"DM-4789","Story","SUIT",8,"FITS Visualizer porting: Mouse Readout: part 3: Lock by click & 3 color support","""add toggle button that make the mouse readout lock to last position click on.  It will not longer update on move but by click  Include: 3 Color Support"""
"DM-4786","Story","Qserv",2,"Packge mysqlproxy 0.8.5","""See https://mariadb.atlassian.net/browse/MDEV-9389"""
"DM-4801","Story","lsst_dm_stack_demo",0.5,"Update the ground truth values in the lsst_dm_demo to reflect new defaults in deblending","""In DM-4410 default configuration options were changed such that footprints are now grown in the detection task, and the deblender is run by default. This breaks the lsst_dm_demo, as now the results of processing are slightly different. The short term solution as part of DM-4410 was to run the demo with the defaults overridden to be what they were prior to DM-4410. In the long term the values used in the compare script should be updated to reflect what would be generated with running processCcd with the stack defaults. """
"DM-4798","Story","pipe_tasks",1,"DetectCoaddSourcesTask.scaleVariance gets wrong result","""DetectCoaddSourcesTask.scaleVariance is used to adjust the variance plane in the coadd to match the observed variance in the image plane (necessary after warping because we've lost variance into covariance). The current implementation produces the wrong scaling in cases where the image has strongly variable variance (e.g., 10 inputs contributed to half the image, but only 1 input contributed to the other half) because it calculates the variance of the image and the mean of the variance separately so that clipping can affect different pixels.    Getting this scaling very wrong can make us dig into the dirt when detecting objects, with drastic implications for the resultant catalog.    This is a port of [HSC-1357|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1357] and [HSC-1383|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1383]."""
"DM-4806","Story","Database",2,"Test stack with mariadbclient","""Now that we switched Qserv to mariadb, it'd be good to switch the rest of the stack. This story involves trying out if things still work if we switch mysqlclient to mariadbclient."""
"DM-4825","Bug","pipe_tasks",1,"makeDiscreteSkymap has a default dataset of 'raw'","""The default dataset type for command line tasks is raw.  In the case MakeDiscreteSkyMapTask is asking the butler for calexp images.  This shouldn't be a problem, but in my case I have calexp images, but no raw images.  This causes the task to think there is no data to work on, so it exits."""
"DM-4824","Story","SUIT",1,"Clean up div and css layout on FitsDownloadDialog","""FitsDownload dialogs html and css is not quite right. Needs some clean up."""
"DM-4823","Story","SUIT",2,"Add Dropdowns to Vis toolbar","""Add the dropdown to the vis tool bar"""
"DM-4821","Story","meas_algorithms",1,"HSC backport: Remove interpolated background before detection to reduce junk sources","""This is a port of [HSC-1353|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1353] and [HSC-1360|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1360].    Descriptions from HSC:   {panel:title=HSC-1353}  We typically get a large number of junk detections around bright objects due to noise fluctuations in the elevated background. We can try to reduce the number of junk detections by adding an additional local background subtraction before object detection. We can then add this back in after detection of footprints and peaks.  {panel}  {panel:title=HSC-1360}  I forgot to set the useApprox=True for the background subtraction that runs before footprint and peak detection. This will then use the Chebyshev instead of the spline.  {panel}"""
"DM-4820","Improvement","obs_decam",1,"Improvement of raw data handling in DecamMapper","""Two minor improvements with better coding practice:  - Be more specific copying FITS header keywords. Avoid potential problems if unwelcome keywords appear in the header in the future. Suggested in the discussions in DM-4133.   - Reuse {{isr.getDefectListFromMask}} for converting defects. A more efficient method that uses the FootprintSet constructor with a Mask and a threshold has just been adopted in DM-4800.     Processing is not changed effectively.  """
"DM-4849","Improvement","Design Documents",1,"LDM-151 - comments from Jacek","""I am reading your https://github.com/lsst/LDM-151/blob/draft/DM_Applications_Design.tex, and I have some minor comments suggestions. I am going to add comments to this story to capture it. Feel free to apply to ignore :)"""
"DM-4847","Story","meas_algorithms|meas_deblender",3,"Add new blendedness metric","""[HSC-1316|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1316] shifts the calculation of blendedness from {{meas_deblender}} to {{meas_algorithms}} and defines a new blendedness metric in the process. Please port it."""
"DM-4842","Story","pipe_tasks",0.5,"Don't write HeavyFootprints in forced photometry","""There's no need to persist {{HeavyFootprint}}s while performing forced photometry since retrieving them is as simple as loading the _meas catalog.    This is a port of [HSC-1345|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1345]."""
"DM-4841","Story","pipe_tasks",1,"Use high S/N band as reference for multiband forced photometry","""We are currently choosing the priority band as the reference band for forced photometry as long as it has a peak in the priority band regardless of the S/N.  Please change this to pick the highest S/N band as the reference band when the priority band S/N is sufficiently low.    This is a port of [HSC-1349|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1349]."""
"DM-4835","Story","ctrl_pool",2,"Allow slurm to request total CPUs rather than nodes*processors.","""On some systems, we are asked to request a total number of tasks, rather than specify a combination of nodes and processors per node.    It also makes sense to use the SMP option this way.    This is a port of [HSC-1369|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1369]."""
"DM-4834","Story","obs_subaru",1,"Preliminaries for LSST vs HSC pipeline comparison through coadd processing","""This is the equivalent of DM-3942 but through coadd processing.    Relevant HSC tickets include:    * [HSC-1371|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1371]"""
"DM-4833","Story","obs_subaru",1,"Update configuration for Suprime-Cam","""The {{obs_subaru}} configuration for Suprime-Cam needs updating to match recent changes in the stack.    Port of [HSC-1372|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1372]."""
"DM-4831","Story","pipe_tasks",3,"Add bright object masks to pipeline outputs","""Given per-patch inputs providing     for each star to be masked, use this information to set:  * A bit in the mask plane for each affected pixel  * A flag in the source catalogues for each object that has a centroid lying within this mask area    This is a port of [HSC-1342|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1342] and [HSC-1381|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1381]."""
"DM-4858","Bug","afw",1,"imagesDiffer doesn't handle overflow for unsigned integers","""I'm seeing a test failure in afw's testTestMethods.py, apparently due to my numpy (1.8.2) treating images that differ by -1 as differing by 65535 in both {{numpy.allclose}} and array subtraction (which doesn't promote to an unsigned type).    Does this still cause problems in more recent versions of {{numpy}}?  If not, I imagine it's up to me to find a workaround for older versions if I want it fixed?    (assigning to [~rowen] for now, just because I know he originally wrote this test and I hope he might know more)"""
"DM-4856","Story","afw",2,"Add __setitem__ for columns in afw.table","""It's confusing to have to use an extra {{[:]}} to set a column in afw.table, and we can make that unnecessary if we override {{\_\_setitem\_\_}} as well as {{\_\_getitem\_\_}}."""
"DM-4850","Story","pipe_tasks",2,"Factor out duplicate setIsPrimaryFlag from MeasureMergedCoaddSourcesTask and ProcessCoaddTask","""{{MeasureMergedCoaddSourcesTask.setIsPrimaryFlag()}} and {{ProcessCoaddTask.setIsPrimaryFlag()}} are effectively the same code. Please split this out into a separate task which both of the above can call.    This is a (partial) port of [HSC-1112|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1112] and should include fixes from [HSC-1297|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1297]."""
"DM-4885","Story","qserv_testdata",5,"Improve/simplify multi-worker tests","""The idea is that our current integration test is using """"mono"""" configuration which is only useful for integration test but it's not used anywhere else. It would be more useful to have an integration test which is close to real setup, e.g. used more than one worker. It should still be possible to run the whole shebang on a single node though to keep it usable for regular development tasks."""
"DM-4882","Story","pipe_tasks",2,"base_Variance plugin generates errors in lsst_dm_stack_demo","""Since DM-4235 was merged, we see a bunch of messages along the lines of:    in the output from {{lsst_dm_stack_demo}}. (See e.g. [here|https://ci.lsst.codes/job/stack-os-matrix/label=centos-6/7482/console#console-section-3]). It's not fatal, but the warnings are disconcerting and could be indicative of a deeper problem."""
"DM-4878","Story","pipe_tasks",2,"Propagate flags from individual visit measurements to coadd measurements","""It is useful to be able to identify suitable PSF stars from a coadd catalogue. However, the PSF is not determined on the coadd, but from all the inputs. Add a mechanism for propagating flags from the input catalogues to the coadd catalogue indicating stars that were used for measuring the PSF.    Make the inclusion fraction threshold configurable so we can tweak it (so we only get stars that were consistently used for the PSF model; the threshold might be set it to 0 for """"or"""", 1 for """"all"""" and something in between for """"some"""").    Make the task sufficiently general that it can be used for propagating arbitrary flags.    This is a port of work carried out on [HSC-1052|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1052] and (part of) [HSC-1293|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1293]."""
"DM-4876","Story","QA",3,"Compile list of DM simulation needs for Andy Connolly","""Compile list of DM simulation needs over the next ~6 months to give to Andy Connolly (simulations lead)."""
"DM-4873","Story","meas_astrom",3,"Test the matchOptimisticB astrometric matcher","""The matchOptimisticB matcher fails on many visits of the bulge verification dataset.  This prompted a deeper investigation of the performance of the matcher.  Angelo and David developed a test script and discovered that the matcher works well with offsets of the two source catalogs of up to 80 arcsec, but fails beyond that.  This should be robust enough for nearly all datasets that the LSST stack will be used on."""
"DM-4867","Bug","scisql",2,"scisql build scripts are buggy ","""The scisql build script logic for MySQL/MariaDB version checking is broken on all platforms. There are also assumptions about shared library naming that do not hold on OS/X, which means that the deployment scripts are likely broken on all platforms other than Linux."""
"DM-4862","Story","SUIT",2,"Add point selection","""click and highlight a point.  Is on when mouse readout """"Lock by Click"""" is on. However, can me turned on externally by adding toolbar context menu options."""
"DM-4887","Story","meas_base",8,"Refactor measurement afterburners into a new plugin system","""Some of the operations we currently run as part of measurement (or would like to) share some features that make them a bit different from most plugin algorithms:   - They must be run after at least some other high-level plugins, and may be run after all of them.   - They do not require access to pixel data, as they derive their outputs entirely from other plugins' catalog outputs.   - They may require an aggregation stage of some sort to be run on the regular plugin output before they can be run.    Some examples include:   - Star/Galaxy classification (with training done after measurement and before classification).   - Applying aperture corrections (estimating the correction must be done first).   - BFD's P, Q, R statistics (requires a prior estimated from deep data).    We should move these algorithms to a new plugin system that's run by a new subtask, allowing these plugins to be run entirely separately from {{SingleFrameMeasurementTask}}.  This will simplify some of the currently contorted logic required to make S/G classification happen after aperture correction, while making room for hierarchical inference algorithms like BFD and Bayesian S/G classification in the future.    (We will not be able to support BFD immediately, as this will also require changes to our parallelization approach, but this will be a step in the right direction).    This work should *probably* be delayed until after the HSC merge and [~rowen]'s rewrite of {{ProcessCcdTask}} are complete, but it's conceivable that this refactoring could solve emergent problems there and be worth doing earlier as a result."""
"DM-4904","Bug","wcslib",2,"Buffer overrun in wcslib causes stack corruption","""The buffer 'msg' in wcsfix.c is used to report attempts by wcslib to re-format units found in fits files. It is allocated on the stack (in function 'unitfix') using a pre-processor macro defined size of 160 chars (set in wcserr.h). When attempting to run the function 'unitfix' in wcsfix, this buffer can overflow on some fits files (the raw files generated by HSC seem particularly prone to triggering this behavior) and results in the session being terminated on Ubuntu 14.04 as stack protection is turned on by default i.e. the stack crashes with a 'stack smashing detected' error. We have reported the bug to the creators of wcslib. As a temporary workaround, users affected by the bug should increase the default size of 'msg' by increasing WCSERR_MSG_LENGTH defined in wcserr.h      We are providing a small python example that demonstrates the problem. Run it as  python test.py <path to ci_hsc>/raw/<any fits file in this directory>    We are also providing a simple c program to demonstrate the bug. Compile it as  cc -fsanitize=address -g -I$WCSLIB_DIR/include/wcslib -o test test.c -L$WCSLIB_DIR/lib -lwcs (on Linux)  cc -fsanitize=address -g -L$WCSLIB_DIR/lib -lwcs -I$WCSLIB_DIR/include/wcslib -o test test.c (on Mac OS X)"""
"DM-4894","Story","Calibration Products Production",3,"Ingest DECam/CBP data into LSST stack","""[~mfisherlevine] will ingest the data taken in DM-4892 into the LSST stack. Initial experiments indicate problems with:    * Bias subtraction  * Flat fielding  * Bad pixel masks    These may already be remedied by work on {{obs_decam}}; if not, he will file stories and fix them."""
"DM-4893","Story","Stack Documentation and UX",2,"Write tutorial describing remote IPython + ds9 on lsst-dev","""[~mfisherlevine] recently figured out how to set up his system to run a remote IPython kernel on {{lsst-dev}} and interact with it from his laptop, including streaming image display from the remote system to a local instance of {{ds9}}.    He will write all this up so that others in the community can easily do the same."""
"DM-4921","Story","obs_subaru|sconsUtils",0.5,"Make obs_subaru build with OS X SIP","""Because of OS X SIP, {{obs_subaru}} fails to build on os x 10.11. In the {{hsc/SConscript}} file, the library environment variables need properly set, and scripts need to be delayed until the shebang rewriting occurs. """
"DM-4917","Story","SUIT",2,"Porting encodeURL of the java FitsDownlaodDialog code to javascript ","""When download an image,  the proper name needs to be resolved based on the URL and   the information about the image.  In Java code, it has the following three methods:      These method should be ported to javascript.  Thus, the javascript version of the FitsDownloadDialog will save the file in the same manner. """
"DM-4916","Story","obs_decam",3,"Test obs_decam with processed data","""Sometimes DECam-specific bugs only reveal in or affect the processed data. For example the bug of DM-4859 reveals in the {{postISRCCD}} products.  If the bugs are DECam-specific, some changes in {{obs_decam}} are likely needed.  It would be useful to have a more convenient way to test those changes. In this ticket I modify {{testdata_decam}} so that those data can be processed, and then allow wider options in the {{obs_decam}} unit tests.    I add {{testProcessCcd.py}} in {{obs_decam}} that runs {{processCcd.py}} with raw and calibration data in {{testdata_decam}}.  Besides a short sanity check, I add a test (testWcsPostIsr) that tests DM-4859. {{testWcsPostIsr}} fails without the DM-4859 fix, and passes with it.  """
"DM-4934","Story","Firefly",2,"on-going support to Camera team in visualization at UIUC","""Attend the weekly meeting and answer questions as needed"""
"DM-4933","Story","afw",1,"Create a utility function do do spherical geometry averaging","""I would like to calculate a correct average and RMS for a set of RA, Dec positions.    Neither [~jbosch] nor [~price] knew of an easy, simple function to do that that existed in the stack.  [~price] suggested:        That makes sense, but it's a bit unobvious (it's obvious how it works, but would likely never occur to someone that they should do it that way in the stack).    Pedantically it's also not the best way to do a mean while preserving precision, but I don't anticipate that to be an issue in practice.    Creating a function that did this would provide clarity.  I don't know where that function should live.    Note: I know how to do this in Astropy.  I'm intentionally not using astropy here.  But part of the astropy dependency discussion is likely """"how much are we otherwise rewriting in the LSST stack""""."""
"DM-4931","Bug","Qserv",2,"Qserv build fails on El Capitan with missing OpenSSL","""Qserv does not build on OS X El Capitan due to the absence of OpenSSL include files. Apple now only ship the OpenSSL library (for backwards compatibility reasons). Qserv only uses SSL in two places to calculate digests (MD5 and SHA). This functionality is available in the Apple CommonCrypto library. Qserv digest code needs to be taught how to use CommonCrypto."""
"DM-4929","Bug","Database",1,"Fix build of MariaDB on OS X El Capitan","""The current MariaDB EUPS package does not build on OS X El Capitan because OS X no longer ships with OpenSSL developer files. MariaDB has a build option to use a bundled SSL library in preference to OpenSSL but the logic for automatically switching to this version breaks when the Anaconda OpenSSL libraries are present."""
"DM-4926","Story","meas_base",8,"Centroids fall outside Footprints","""In DM-4882, we observed a number of centroids measured while running the {{lsst_dm_stack_demo}} routines fall outside their associated {{Footprints}}. This was seen with both the {{NaiveCentroid}} and the {{SdssCentroid}} centroiders.    For the purposes of DM-4882 we quieted the warnings arising from this, but we should investigate why this is happening and, if necessary, weed out small {{Footprints}} entirely."""
"DM-4940","Story","SUIT",2,"IRSA developer mentoring effort","""IRSA is contributing to Firefly development. We need to mentor the new developers."""
"DM-4939","Story","SUIT",2,"IRSA developer mentoring effort","""IRSA is contributing to the Firefly package development.  we need to put in time to mentor the developers. """
"DM-4938","Story","scisql",0.5,"Update scisql to v0.3.5","""In order to update MariaDB to v10.1.10 {{scisql}} needs to also be updated to deal with the hard-coded version checking. For the current version we get this error with the latest MariaDB:  """
"DM-4937","Bug","mysql|mysqlclient",0.5,"multiple CVEs relevant to mariadb 10.1.9 and mysql","""Multiple CVEs have been released this week for mysql & mariadb.  The current eups product for mariadb is bundling 10.1.9, which is affected.  Several of the CVEs do not yet provide details, which typically means they are """"really bad"""".    https://github.com/lsst/mariadb/blob/master/upstream/mariadb-10.1.9.tar.gz    https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0505  https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0546  https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0596  https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0597  https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0598  https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0600  https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0606  https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0608  https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0609  https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0616  https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-2047"""
"DM-4936","Story","ci_hsc",2,"Enable validateMatches in ci_hsc","""{{python/lsst/ci/hsc/validate.py}} in {{ci_hsc}} [says|https://github.com/lsst/ci_hsc/blob/69c7a62f675b8fb4164065d2c8c1621e296e40ad/python/lsst/ci/hsc/validate.py#L78]:  {code:python}      def validateMatches(self, dataId):          # XXX lsst.meas.astrom.readMatches is gone!          return  {code}  {{readMatches}} (or its successor) should be back in place as of DM-3633. Please enable this test."""
"DM-4957","Story","Validation",2,"Generate JSON output from validate_drp for inclusion in a test harness","""Generate JSON output from validate_drp for inclusion in a test harness.    Generate a file that summarizes the key metrics calculated by `validate_drp`.      Develop naming conventions that will make it easy to plug into the eventual harness being developed as part of DM-2050."""
"DM-4955","Story","Developer Infrastructure",1,"Update pyfits","""The final version of {{pyfits}} has just been released. This ticket covers updating to that version. This will be helpful in determining whether the migration to {{astropy.io.fits}} will be straightforward or complicated."""
"DM-4952","Story","pipe_base",2,"delegate argument parsing to CmdLineTask instances","""Command-line argument parsing of data IDs for {{CmdLineTask}} s is currently defined at the class level, which means that we cannot make data ID definitions dependent on task configuration.  That in turn requires custom {{processCcd}} scripts for cameras that start processing at a level other than """"raw"""" (SDSS, DECam with community pipeline ISR, possibly CFHT).    Instead, we should let {{CmdLineTask}} *instances* setup command-line parsing; after a {{CmdLineTask}} is constructed, it will have access to its final configuration tree, and can better choose how to parse its ID arguments.    I've assigned this to Process Middleware for now, since that's where it lives in the codebase, but it may make more sense to give this to [~rowen], [~price], or [~jbosch], just because we've already got enough familiarity with the code in question that we could do it quickly.  I'll leave that up to [~swinbank], [~krughoff], and [~mgelman2] to decide."""
"DM-4959","Story","ci_hsc",0.5,"ci_hsc fails to execute tasks from with SCons on OSX 10.11/SIP","""The {{ci_hsc}} package executes a number of command line tasks directly from SCons based on {{Command}} directives in a {{SConstruct}} file. On an OSX 10.11 system with SIP enabled, there are two distinct problems which prevent the necessary environment being propagated to the tasks:  * -The {{scons}} executable starts with a {{#!/usr/bin/env python}}. Running through {{/usr/bin/env}} strips {{DYLD_LIBRARY_PATH}} from the environment.- (duplicates DM-4954)  * SCons executes command using the [{{sh}} shell on posix systems|https://bitbucket.org/scons/scons/src/09e1f0326b7678d1248dab88b28b456fd7d6fb54/src/engine/SCons/Platform/posix.py?at=default&fileviewer=file-view-default#posix.py-105]. By default, that means {{/bin/sh}} on a Mac, which, again, will strip {{DYLD_LIBRARY_PATH}}.    Please make it possible to run {{ci_hsc}} on such a system."""
"DM-4961","Story","obs_subaru",0.5,"Obs_Subaru camera mapper has wrong deep_assembleCoadd_config","""When lsst switched to using SafeClipAssembleCoaddTask, the camera mapper for hsc was not updated accordingly. This causes ci_hsc to fail when it attempts to verify the config class type for the deep_coadd. Camera mapper should be updated accordingly"""
"DM-18241","Story","ts_management",3,"Create initial M1M3, M2 simulators","""Initial simulator support"""
"DM-17268","Story","ts_middleware",5,"SAL release 4 build and distribute","""Release new version"""
"DM-4993","Story","Firefly",2,"review of dependency on the third party packages","""We need to periodically review the status of the third party software packages that Firefly depends on. Making a plan to do upgrade if needed.   package.json lists out the dependencies Firefly has on the third party software. The attached file was last modified 2016-02-09.    package.json_version lists the current version of the third party packages, major changes were indicated by (M). The attached file was created on 2016-02-29.     bq.      """"babel""""     : """"5.8.34"""",                           6.5.2 (M)      """"history""""   : """"1.17.0"""",                           2.0.0 (M)      """"icepick""""   : """"0.2.0"""",                            1.1.0 (M)                """"react-highcharts"""": """"5.0.6"""",                      7.0.0 (M)      """"react-redux"""": """"3.1.2"""",                           4.4.0 (M)      """"react-split-pane"""": """"0.1.22"""",                     2.0.1 (M)      """"redux-thunk"""": """"0.1.0"""",                           1.0.3 (M)      """"redux-logger"""": """"1.0.9"""",                          2.6.1 (M)      """"validator"""" : """"4.5.0"""",                            5.1.0 (M)      """"chai"""": """"^2.3.0"""",                                 3.5.0 (M)      """"esprima-fb"""": """"^14001.1.0-dev-harmony-fb"""",        15001.1001.0-dev-harmony-fb (M)      """"babel-eslint""""      : """"^4.1.3"""",                   5.0.0 (M)      """"babel-loader""""      : """"^5.3.2"""",                   6.2.4 (M)      """"babel-plugin-react-transform"""": """"^1.1.0"""",         2.0.0 (M)      """"babel-runtime""""     : """"^5.8.20"""",                  6.6.0 (M)      """"eslint""""            : """"^1.10.3"""",                  2.2.0 (M)      """"eslint-config-airbnb"""": """"0.1.0"""",                  6.0.2 (M) works with eslint 2.2.0      """"eslint-plugin-react"""": """"^3.5.1"""",                  4.1.0 (M)  works with eslint 2.2.0      """"extract-text-webpack-plugin"""": """"^0.8.0"""",          1.0.1 (M)      """"html-webpack-plugin"""": """"^1.6.1"""",                  2.9.0 (M)      """"karma-sinon-chai"""": """"^0.3.0"""",                     1.2.0 (M)      """"redux-devtools""""    : """"^2.1.2"""",                   3.3.1 (M)      """"webpack"""": """"^1.8.2""""                               1.12.14, 2.1.0 beta4 (M)          """
"DM-4991","Bug","pipe_tasks",3,"Save algorithm metadata in multiband.py","""The various {{Tasks}} in {{multiband.py}} do not attach the {{self.algMetadata}} instance attribute to their output tables before writing them out, so we aren't actually saving information like which radii were used for apertures.    We should also make sure this feature is maintained in the processCcd.py rewrite."""
"DM-4983","Story","conda",3,"upstream patches/deps from conda-lsst","""Where ever possible, missing dep information and patches from conda-lsst should be upstreamed.  The patches have already been observed to cause builds to fail due to upstream changes."""
"DM-5005","Story","Validation",0.5,"Please trim config overrides in validate_drp","""validate_drp will test more of our code if it uses default config parameters wherever possible. To that effect I would like to ask you to eliminate all config overrides that are not essential and document the reasons for the remaining overrides.    For DECam there are no overrides that are different than the defaults, so the file can simply be emptied (for now).    For CFHT there are many overrides that are different, and an important question is whether the overrides in this package are better for CFHT data than the overrides in obs_cfht; if so, please move them to obs_cfht.    As a heads up: the default star selector is changing from """"secondMoment"""" to """"objectSize"""" in DM-4692 and I hope to allow that in validate_drp, since it works better and is better supported.    Sorry for the incorrect component, but validate_drp is not yet a supported component in JIRA (see DM-5004)"""
"DM-5002","Story","ci_hsc",2,"Make ci_hsc resumable","""if ci_hsc fails for any reason, (or is cancelled) it must start from the beginning of processing again. This is because of the use of functools.partial to generate dynamic function. These differ enough in their byte code that scons thinks each build has a new function definition passed to the env.command function. Using lambda would suffer from the same problem. This ticket should change how the function signature is calculated such that scons can be resumed.    This work does not prevent this from being used as a ci tool, as the .scons directory can be deleted which will force the whole SConstruct file to run again."""
"DM-4998","Bug","obs_subaru",2,"Fix rotation for isr in obs_subaru","""Approximately half of the HSC CCDs are rotated 180 deg with respect to the others.  Two others have 90 deg rotations and another two have 270 deg rotations (see [HSC CCD layout|http://www.naoj.org/Observing/Instruments/HSC/CCDPosition_20150804.png]) .  The raw images for the rotated CCDs thus need to be rotated to match the rotation of their associated calibration frames prior to applying the corrections.  This is accomplished by rotating the exposure using the *rotated* context manager function in {{obs_subaru}}'s *isr.py* and the *nQuarter* specification in the policy file for each CCD.  Currently, *rotated* uses {{afw}}'s *rotateImageBy90* (which apparently rotates in a counter-clockwise direction) to rotated the exposure by 4 - nQuarter turns.  This turns out to be the wrong rotation for the odd nQuarter CCDs as shown here:   !ccd100_nQuarter3.png|width=200!  top left = raw exposure as read in  top right = flatfield exposure as read in  bottom left = _incorrectly_ rotated raw exposure prior to flatfield correction"""
"DM-4996","Story","Validation",1,"Update validate_drp for El Capitan","""validate_drp does not work on El Capitan due to SIP (System Integrity Protection) stripping DYLD_LIBRARY_PATH from shell scripts. The simple fix is to add    near the top of the scripts."""
"DM-4995","Story","webserv",8,"Extend webserv API to pass security tokens","""Extend the [API|https://confluence.lsstcorp.org/display/DM/AP] to pass security tokens."""
"DM-5030","Improvement","Qserv",2,"Tests fail on Qserv on OS X El Capitan because of SIP","""OS X El Capitan introduced System Integrity Protection which leads to dangerous environment variables being stripped when executing trusted binaries. Since {{scons}} is launched using {{/usr/bin/env}} the tests that run do not get to see {{DYLD_LIBRARY_PATH}}. This causes them to fail.    The same fix that was applied to {{sconsUtils}} (copying the path information from {{LSST_LIBRARY_PATH}}) needs to be applied to the test execution code used by Qserv's private {{site_scons}} utility code."""
"DM-5026","Bug","db",1,"Fix dependencies for eups-packaged sqlalchemy","""Eups-packaged sqlalchemy lists {{mysqlclient}} as required dependency which is not really right. sqlalchemy does not directly depend on mysql client stuff, instead it determines at run time which python modules it needs to load depending on what exact driver client code is requesting (and {{mysqlclient}} does not actually provides python module so this dependency does not even make anything useful). So dependency on specific external package should be declared on client side and not in sqlalchemy, {{mysqlclient}} should be removed from sqlalchemy.table."""
"DM-5022","Improvement","Qserv",0.5,"Modernize python code in Qserv scons package","""The {{site_scons}} Python code is not using current project standards. For example, print is not a function, exceptions are not caught {{as e}}, {{map}} is called without storing the result and {{map/filter/lambda}} are used where list comprehensions would be clearer.    Most of these fixes are trivial with {{futurize}}."""
"DM-5018","Improvement","Developer Infrastructure|matplotlib",0.5,"Modernize version check scripts in matplotlib and numpy packages","""The version check scripts in the stub {{matplotlib}} and {{numpy}} eups packages use old Python conventions. They should be updated to work with 2.7+."""
"DM-5014","Improvement","ip_isr",1,"Set doRenorm default to False in AssembleCcdTask","""Change the default value of {{AssembleCcdConfig.doRenorm}} to {{False}} for the reasons given in RFC-157 and to implement that RFC."""
"DM-5013","Story","Stack Documentation and UX",5,"Convert Confluence DM Developer Guide to Sphinx (hack day) ","""This is a hack day sprint to convert all remaining content on https://confluence.lsstcorp.org/display/LDMDG to reStructuredText content in the Sphinx project at https://github.com/lsst-sqre/dm_dev_guide and published at http://developer.lsst.io.    The top priority for this sprint is to port all content into reST and have it tracked by Git.    h2. Sprint ground rules    # Before the sprint, clone {{https://github.com/lsst-sqre/dm_dev_guide.git}} and {{pip install -r requirements.txt}} in a Python 2.7 environment so that you can locally build the docs ({{make html}}).  # Claim a page from the list below by putting your name on it. Put a checkmark on the page when youve merged it to the ticket branch (see below).  # See http://developer.lsst.io/en/latest/docs/rst_styleguide.html for guidance on writing our style of reStructuredText. Pay attention to the [heading hierarchy|http://developer.lsst.io/en/latest/docs/rst_styleguide.html#sections] and [labelling for internal links|http://developer.lsst.io/en/latest/docs/rst_styleguide.html#internal-links-to-labels].  # If you use Pandoc to do an initial content conversion, you still need to go through the content line-by-line to standardize the reStructuredText. I personally recommend copy-and-pasting-and-formatting instead of using Pandoc.  # Your Git commit messages should include the URL of the original content from Confluence.  # Merge your work onto the {{tickets/DM-5013}} ticket branch. Rebase your personal work branch before merging. JSick is responsible for merging this ticket branch to {{master}}.  # Put a note at the top of the confluence page with the new URL; root is {{http://developer.lsst.io/en/latest/}}.    h2. Planned Developer Guide Table of Contents    Were improving the organization of DMs Developer Guide; there isnt a 1:1 mapping of Confluence pages to developer.lsst.io pages. Below is a proposed section organization and page structure. These sections can still be refactored based on discussion during the hack day.    h3. Getting Started  /getting-started/    *  *Onboarding Checklist* (Confluence: [Getting Started in DM|https://confluence.lsstcorp.org/display/LDMDG/Getting+Started+in+DM]). Id like this to eventually be a quick checklist of things a new developer should do. It should be both a list of accounts the dev needs to have created, and a list of important developer guide pages to read next. The NCSA-specific material should be spun out. [[~jsick]]  * *Communication Tools* (new + DM Confluence [Communication and Links|https://confluence.lsstcorp.org/display/DM/Communication+and+Links]). I see this as being an overview of what methods DM uses to communicate, and what method should be chosen for any circumstance.  * *Finding Code on GitHub* (new). This should point out all of the GitHub organizations that a developer might come across (DM and LSST-wide), and point out important repositories within each organization. Replaces the confluence page [LSST Code Repositories|https://confluence.lsstcorp.org/display/LDMDG/LSST+Code+Repositories]    h3. Processes  /processes/    *  *Team Culture and Conduct Standards* (confluence)  *  *DM Development Workflow with Git, GitHub, JIRA and Jenkins* (new & Confluence: [git development guidelines for LSST|https://confluence.lsstcorp.org/display/LDMDG/git+development+guidelines+for+LSST] + [Git Commit Best Practices|https://confluence.lsstcorp.org/display/LDMDG/Git+Commit+Best+Practices] + [DM Branching Policy|https://confluence.lsstcorp.org/display/LDMDG/DM+Branching+Policy])  *  *Discussion and Decision Making Process* (new & [confluence|https://confluence.lsstcorp.org/display/LDMDG/Discussion+and+Decision+Making+Process])  *  *DM Wiki Use* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/DM+Wiki+Use]) [[~swinbank]]  *  *Policy on Updating Doxygen* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Policy+on+Updating+Doxygen]); needs to be addressed with TCT. Inter-link with the developer workflow page. [[~jsick]] (were just re-pointing the Confluence page to the workflow document)  *  *Transferring Code Between Packages* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Transferring+Code+Between+Packages]) [[~swinbank]]  * -*Policy on Changing a Baseline Requirement*- ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Policy+on+Changing+a+Baseline+Requirement])  *  *Project Planning for Software Development* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Project+Planning+for+Software+Development]) [[~swinbank]]  *  *JIRA Agile Usage* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/JIRA+Agile+Usage]) [[~swinbank]]  * -*Technical/Control Account Manager Guide*- ([confluence|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=21397653]) (Do not port; see discussion below.)  * *Licensing* (new) Need a centralized page to discuss license and copyright policies; include boilerplate statements.    h3. Coding Guides  /coding/    *  *Introduction* and note on stringency language (confluence: [DM Coding Style Policy|https://confluence.lsstcorp.org/display/LDMDG/DM+Coding+Style+Policy])  *  *DM Python Style Guide* (confluence: [Python Coding Standard|https://confluence.lsstcorp.org/display/LDMDG/Python+Coding+Standard])  *  *DM C++ Style Guide* (confluence pages: [C++ Coding Standard|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=16908666] + [C++ General Recommendations|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=16908756] + [C++ Naming Conventions|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=16908685] + [C++ Files|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=16908674] + [C++ Statements|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=16908706] + [C++ Layout and Comments|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=16908737] + [Policy on use of C++11/14|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=20283399] + [On Using Using|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=20283856])  * Coding Style Linters (new; draft from confluence [C++ Coding Standards Compliance|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=20283861] and [Python Coding Standards Compliance|https://confluence.lsstcorp.org/display/LDMDG/Python+Coding+Standards+Compliance]  *  *Using C++ Templates* ([confluence|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=20284190]); this page needs to severely edited or re-written, however.  *  *Profiling* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Profiling|]). Also add a section Using Valgrind with Python' (new) [[~jsick]]  *  *Boost Usage* ([TRAC|https://dev.lsstcorp.org/trac/wiki/TCT/BoostUsageProposal]) [[~tjenness]]  *  *Software Unit Test Policy* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Software+Unit+Test+Policy]) [[~swinbank]]  *  *Unit Test Coverage Analysis* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Coverage+Analysis]) [[~swinbank]]  *  *Unit Testing Private C++ Functions* ([trac|https://dev.lsstcorp.org/trac/wiki/UnitTestingPrivateFunctions]) [[~swinbank]]    h3. Writing Docs  /docs/    * *Introduction* (new): Overview of DMs documentation needs; links resources on technical writing.  * *English Style Guide* (new): Supplement the [LSST Style Manual|https://www.lsstcorp.org/docushare/dsweb/Get/Document-13016/LSSTStyleManual.pdf] and provide English style guidance specific to DM. Capitalization of different heading levels; use of Chicago Manual of Style; a this, not that table of spelling and word choices.  *  *ReStructuredText Style Guide* (new)  *  *Documenting Stack Packages* (new)  *  *Documenting Python Code* (new)  *  *Documenting C++ Code* (confluence, adapted from [Documentation Standards|https://confluence.lsstcorp.org/display/LDMDG/Documentation+Standards]); needs improvement  *  *Writing Technotes* (new; port README from [lsst-technote-bootstrap|https://github.com/lsst-sqre/lsst-technote-bootstrap/blob/master/README.rst])    h3. Developer Tools  /tools/    *  *Git Setup and Best Practices* (new)  *  *Using Git Large File Storage (LFS) for Data Repositories* (new)  *  *JIRA Work Management Recipes* (new)  *  *Emacs Configuration* ([Confluence|https://confluence.lsstcorp.org/display/LDMDG/Emacs+Support+for+LSST+Development]). See DM-5045 for issue with Emacs config repo - [~jsick]  *  *Vim Configuration* ([Confluence|https://confluence.lsstcorp.org/display/LDMDG/Config+for+VIM]) - [~jsick]    h3. Developer Services  /services/    *  *NCSA Nebula OpenStack Guide* (Confluence: [User Guide|https://confluence.lsstcorp.org/display/LDMDG/NCSA+Nebula+OpenStack+User+Guide] + [Starting an Instance|https://confluence.lsstcorp.org/display/LDMDG/Introduction+to+Starting+a+Nebula+Instance] + [Using Snapshots|https://confluence.lsstcorp.org/display/LDMDG/Start+an+Instance+using+a+base+snapshot+with+the+LSST+Stack]. Add the [Vagrant instructions too from SQR-002|http://sqr-002.lsst.io]? [[~jsick]]  *  *Using lsst-dev* (Confluence: [notes Getting Started|https://confluence.lsstcorp.org/display/LDMDG/Getting+Started+in+DM] + [Developer Tools at NCSA|https://confluence.lsstcorp.org/display/LDMDG/Developer+Tools+at+NCSA]  *  *Using the Bulk Transfer Server at NCSA* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Using+the+Bulk+Transfer+Server+at+NCSA]) [[~jsick]]    h3. Build, Test, Release  /build-ci/    * *Eups for LSST Developers* (new) [[~swinbank]]  *  *The LSST Software Build Tool*  Using lsstsw and lsst-build' ([confluence|https://confluence.lsstcorp.org/display/LDMDG/The+LSST+Software+Build+Tool]); lsstsw and lsst-build documentation. [[~swinbank]]  * *Using DMs Jenkins for Continuous Integration* (new) [~frossie]   *  *Adding a New Package to the Build*([confluence|https://confluence.lsstcorp.org/display/LDMDG/Adding+a+new+package+to+the+build]) [[~swinbank]]  *  *Distributing Third-Party Packages with Eups* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Distributing+third-party+packages+with+EUPS]) [[~swinbank]]  *   *Triggering a Buildbot Build* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Triggering+a+Buildbot+Build]) [~frossie]  *  *Buildbot Errors FAQ* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Buildbot+FAQ+on+Errors]) [~frossie]  * * Buildbot configuration ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Buildbot+Configuration+and+Setup] [~frossie]    * *Creating a new DM Stack Release* ([confluence|https://confluence.lsstcorp.org/display/LDMDG/Creating+a+new+DM+Stack+Release]); though this page or a modern equivalent should probably belong with the software docs? [~frossie]    _A lot of work should go into this section._ Have something about Scons? Or maybe that belongs in the doc of each relevant software product.    h2. Leftover Confluence pages    h3. The following pages should be moved to a separate Confluence space run by NCSA:    * [NCSA Nebula OpenStack Issues|https://confluence.lsstcorp.org/display/LDMDG/NCSA+Nebula+OpenStack+Issues]  * [DM System Announcements|https://confluence.lsstcorp.org/display/LDMDG/DM+System+Announcements]  * [NCSA Development Servers|https://confluence.lsstcorp.org/display/LDMDG/DM+Development+Servers]    h3. The following pages are either not relevant, generally misplaced, or need to be updated/recalibrated:    * [Git Crash Course|https://confluence.lsstcorp.org/display/LDMDG/Git+Crash+Course]  * [Basic Git Operations|https://confluence.lsstcorp.org/display/LDMDG/Basic+Git+Operations]  * [Handling Git Push Problems|https://confluence.lsstcorp.org/display/LDMDG/Handling+Git+Push+Problems]  * [LSST Code Repositories|https://confluence.lsstcorp.org/display/LDMDG/LSST+Code+Repositories]; see the proposed Finding Code on GitHub page for a replacement.  * [Standards and Policies|https://confluence.lsstcorp.org/display/LDMDG/Standards+and+Policies]: this is a good TOC for the Confluence docs; but not longer needed for the new docs.  * [Documentation Guidelines|https://confluence.lsstcorp.org/display/LDMDG/Documentation+Guidelines]. Some of this could be re-purposed into an intro to the Writing Documentation section; some of this should go in a Processes' page.  * [DM Acknowledgements of Use|https://confluence.lsstcorp.org/display/LDMDG/DM+Acknowledgements+of+Use]: this probably belongs in documentation for the software projects that actually used this work."""
"DM-5052","Story","meas_astrom",2,"Design replacement for A.net index files","""We need a simple way to hold index files that will be easy to use and simple to set up."""
"DM-5050","Story","meas_base",1,"SingleFrameVariancePlugin takes variance of entire image","""{{SingleFrameVariancePlugin}} takes the median variance of the entire image, rather than within an aperture around the source of interest.  A {{Footprint}} is constructed with the aperture, but it is unused.    This means that this plugin takes an excessive amount of run time (255/400 sec in a recent run of processCcd on HSC {{visit=1248 ccd=49}} with DM-4692)."""
"DM-5086","Bug","meas_base|pipe_tasks",0.5,"Enable aperture correction on coadd processing","""Aperture corrections are now coadded, so we can enable aperture corrections in measurements done on coadds."""
"DM-5085","Improvement","lsstsw",0.5,"Please add a package that includes obs_decam, obs_cfht and all validation_data datasets","""It would be very helpful to have an lsstsw package that added all supported obs_* packages (certainly including obs_cfht and obs_decam, and I hope obs_subaru) and all validation_data_* packages. This could be something other than lsst_apps, but I'm not sure what to call it."""
"DM-5084","Bug","afw|pipe_tasks",1,"PropagateVisitFlags doesn't work with other pipeline components","""{{PropagateVisitFlags}}, which was recently ported over from HSC on DM-4878, doesn't work due to some inconsistencies with earlier packages/tasks:   - The default fields to transfer have new names: """"calib_psfCandidate"""" and """"calib_psfUsed""""   - We're not currently transferring these fields from icSrc to src, so those fields aren't present in src anyway.  I propose we just match against icSrc for now, since it has all of the fields we're concerned with.   - It makes a call to {{afw.table.ExposureCatalog.subsetContaining(Point, Wcs, bool)}}, which apparently exists in C++ but not in Python; I'll look into seeing which HSC commits may have been missed in that port."""
"DM-5095","Story","Stack Documentation and UX",0.5,"Redirect confluence based pages to new developer guide.","""Delete and apply redirects to all migrated pages in old Confluence-based Developer Guide"""
"DM-5094","Story","obs_subaru",3,"HSC backport: Set BAD mask for dead amps instead of SAT","""This is a port of [HSC-1095|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1095] and a leftover commit from [HSC-1231|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1231]: [isr: don't perform overscan subtraction on bad amps|https://github.com/HyperSuprime-Cam/obs_subaru/commit/d6fe6cf5c4ecadebd5a344d163e1f1e60137c7e4] (noted in DM-3942)."""
"DM-5107","Bug","obs_subaru",2,"Fix effective coordinates for defects in obs_subaru","""The defects as defined in {{obs_subaru}} (in the {{hsc/defects/20NN-NN-NN/defects.dat}} files) are defined in a coordinate system where pixel (0, 0) is the lower left pixel.  However, the LSST stack does not use this interpretation, preferring to maintain the coordinate system tied to the electronics.  As such, the defect positions are being misinterpreted for the rotated CCDs in HSC (see [HSC CCD layout|http://www.naoj.org/Observing/Instruments/HSC/CCDPosition_20150804.png]).  This needs to be remedied."""
"DM-5100","Story","Stack Documentation and UX",1,"Docs for ltd-keeper","""Create a documentation project within ltd-keeper that documents the RESTful API while it is being developed. This will allow the [SQR-006|http://sqr-006.lsst.io] technote to have a place to link to for detailed information."""
"DM-5125","Bug","Qserv",1,"qserv fails when it mixes mariadb and mariadbclient directories","""When I tried to run qserv-configure after installing qserv 2016_01-7-gbd0349f I got this error:      Running script configure/mysql.sh:      and         So it looks for mysqld in mariadbclient, the same directory as mysql_install_db script, mysql_install_db should be actually running from mariadb.  """
"DM-5122","Bug","Qserv",1,"LOAD DATA LOCAL does not work with mariadb","""After we un-messed mariadb-mysqlclient we see errors now when trying to run integration tests:      It looks like mariadb client by default disables LOCAL option for data loading and it needs to be explicitly enabled.  """
"DM-5121","Story","Validation",1,"Add multiple-filter capabilities to `validate_drp`","""Design and refactor `validate_drp` to produce results for multiple filters.    1. Decide on the syntax for the YAML configuration file that denotes the multiple filters.  E.g., which visit goes with what filter? (/)  2. Organize the running of multiple filters in `validate.run` to sequentially generate statistics and plots for each filter. (/)  3. Add a filter designation to the default output prefix. (/)    Note: matching objects *across* filters is out-of-scope for this ticket."""
"DM-5120","Story","Validation",5,"Add intelligence to `validate_drp` so it does ""A Reasonable Thing"" on an unknown output repo","""validate_drp current takes as input both a repository and a configuration file.  The configuration file contains information to construct the list of dataIds to analyze.    However, these dataIds could be extracted from the repo itself, in cases where the desired is to analyze the entire repo.      1.  Add a function that loads the set of dataIds from the repo. (/)  2.  Select reasonable defaults for the additional parameters specified in the config file. (/)  3.  Design how to handle multiple filters. (/)"""
"DM-5132","Bug","lsstsw|obs_subaru",1,"obs_subaru install with eups distrib fails","""Thus:    Please fix it."""
"DM-5130","Bug","ci_hsc|ip_isr|obs_cfht",0.5,"B-F correction breaks non-HSC custom ISR, ci_hsc","""The addition of brighter-fatter correction on DM-4837 breaks obs_cfht's custom ISR, since it slightly changes an internal ISR API by addding an argument that isn't expected by the obs_cfht version.  It also breaks ci_hsc, since the B-F kernel file isn't included in the calibrations packaged there.  """
"DM-5129","Story","SUIT",2,"Create InputField for generic use cases.","""Create a composable, validating InputField so it can use outside of the form/submit use-case."""
"DM-5147","Story","Validation",3,"Provide usable repos in {{validation_data_*}} packages.","""Re-interpreted ticket:  1. Provide already-initialized repositories in the `validation_data_cfht`, `validation_data_decam`, and `validation_data_hsc` packages alongside the raw data.  The goal is to allow both easy quick-start analyses as well as comparisons of output steps from processCcd.py and friends at each step of the processing. (/)  2. Add (Cfht,Decam,HSC).list files to provide for easy processing of the available dataIds in the example data. (/)  3. Update README files to explain available data.  (/)    [Original request:]  In validation_drp when I run examples/runXTest.sh I find that any data I had saved in CFHT or DECam is lost, even if I have carefully renamed it. This is very dangerous and I lost a lot of work due to it. At a bare minimum please do NOT touch any directories not named """"input"""" or """"output"""".    Lower priority requests that I hope you will consider:  - Have the the input repo be entirely contained in the validation_data_X packages, ready to use """"as is"""". That would simplify the use of those packages by other code. It would also simplify validate_drp, and it would just leave the output repo to generate (which already has a link back to the input repo).  - Have runXTest.sh accept a single argument: the path to the output. (The path to the input is not necessary if you implement the first suggestion)."""
"DM-5140","Story","Qserv",0.5,"Move luaxmlrpc to lsst-dm/legacy-","""We no longer need luaxmlrpc because we run czar inside proxy. We should move it to lsst-dm/legacy-, and remove mentioning it in readme."""
"DM-5139","Improvement","Developer Infrastructure",0.5,"Update apr and apr_util","""{{apr}} and {{apr-util}} are outdated and lagging behind the versions on RHEL6. They should be updated as agreed in RFC-76."""
"DM-5135","Story","ci_hsc|obs_subaru|Validation",2,"Make ci_hsc buildable by Jenkins","""1. Make sure {{ci_hsc}} is buildable by {{lsstsw}} / {{lsst_build}}  (/)  2. Add {{ci_hsc}} to lsstsw/etc/repos.yaml so that one can request that Jenkins builds it.  (/)  3. Verify that the test in {{ci_hsc}} fails on known broken tags and passes on known successful tags. (/)    No dependencies will be added to {{lsst_sims}} or {{lsst_distib}}.  This is meant to provide the ability to request that Jenkins do these builds and to fail if something has broken them.    This will later be expanded to new packages {{ci_cfht}}, {{ci_decam}}, and {{ci_sim}}.    The key goal is to make sure one hasn't broken obs_ packages in their butler interface or in their processCcd    Additional Notes and Thoughts from HipChat Discussion  [~ktl]  Sounds good to me; we might have an """"lsst_ci"""" top-level metapackage depending on all of them which is what Jenkins would run regularly.     If the goal is to test obs_ packages, then my first instinct would be to put that in the obs_ package.  Longer term goal to test the stack with different precursor datasets.  If this is testing obs_ packages on a slower cadence than the built-in tests, it's OK for that to be a separate package.    [~jbosch]  Eventually, I think we need to run a CI dataset for each camera, then run some camera generic tests on each of those, then run some camera-specific tests on each of those.So we don't want to go too far down a road in which all tests are camera-specific, but maybe we don't have a choice until we have some better unifying framework for them.  I've certainly been putting some checks in {{ci_hsc}} that would be valid for all other cameras, if we had a CI package for them that went through to coadd processing."""
"DM-5159","Improvement","Validation",1,"Please use angle and Coord where possible","""validate_drp would be easier to follow and safer if it took advantage of lsst.afw.geom.Angle and lsst.afw.coord.IcrsCoord. For instance {{averageRaDecFromCat}} could return an IcrsCoord and positionRms could use coord1.angularSeparation(coord2) and handle wraparound and other effects simply and safely."""
"DM-5156","Story","Stack Documentation and UX|utils",0.5,"Please document MemoryTestCase","""{{lsst.utils.tests.MemoryTestCase}} is used extensively throughout our test suite, but it is lacking in documentation and it's not clear under what circumstances its use is required or encouraged. Please add appropriate documentation to the [Software Unit Test Policy |http://developer.lsst.io/en/latest/coding/unit_test_policy.html].    See also [this thread on clo|https://community.lsst.org/t/what-is-the-policy-for-using-lsst-utils-tests-memorytestcase]."""
"DM-5161","Improvement","pipe_tasks",1,"HSC backport: Support a full background model when detecting cosmic rays","""This is a port of the following two standalone HSC commits:    [Support a full background model when detecting cosmic rays|https://github.com/HyperSuprime-Cam/pipe_tasks/commit/3bae328e0fff4b2a02267e97cc1e53b5bbe431cb]    [Fixed cosmicRay() in RepairTask for the case background is subtracted.|https://github.com/HyperSuprime-Cam/pipe_tasks/commit/2cdb7c606270d84c7a05baf9949ff5724463fa6b]    """
"DM-5169","Story","Stack Documentation and UX",8,"Fastly API interactions for LSST the Docs","""Using Fastlys API, have ltd-keeper setup new builds and editions:    - Add {{Surrogate-Key}} to headers of objects uploaded to S3 (happens on ltd-mason side)  - Configure Varnish to serve specific bucket directories as specific domains (DM-4951 has added Route 53 interactions to ltd-keeper)  - Purge content when editions switch or content is deleted.    DM-5167 is covering non-API driven work to configure fastly.    See https://www.hashicorp.com/blog/serving-static-sites-with-fastly.html for a write-up on serving static site via fastly. See also http://sqr-006.lsst.io for an overview of LSST the Docs."""
"DM-5164","Improvement","daf_persistence",2,"Tests in daf_persistence should skip properly","""Some of the tests in {{daf_persistence}} have a couple of problems that cause difficulties with modern test frameworks:  # unittest is not being used at all in some cases  # Skipping is done with a print and a {{sys.exit}}    They need to be modernized."""
"DM-5187","Story","Qserv",3,"Set Qserv master in env variable for Docker containers","""This would allow use of pre-configured container on all clusters, indeed the only parameter which currently change in cluster install is master fqdn.  See http://xrootd.org/doc/dev42/Syntax_config.htm  and  """
"DM-5182","Story","SUIT",8,"Hook up help system","""We need to help system like we have in GWT."""
"DM-5179","Bug","Developer Infrastructure|lsstsw",0.5,"miniconda2 eups package fails to install on OS X","""The {{miniconda2}} eups package attempts to install the relevant conda packages by downloading a list from the {{lsstsw}} repository. This fails for the same reason that {{lsstsw}} fails in DM-5178 in that the list of packages is not OS-specific. This means that {{newinstall.sh}} does not work any more on OS X."""
"DM-5204","Bug","Qserv",1,"Remove remaining LOGF macros from qserv","""There are still few cases of LOGF macros in qserv, have to replace them all."""
"DM-5202","Story","log",1,"Remove LOGF macros from log package","""We have removed all uses of LOGF macros from qserv and as far as I know no other clients use those macros. It's time to clean up log package itself from those macros."""
"DM-5200","Story","Nebula OpenStack",1,"instance I/O errors","""The kernel dmesg for Instance {{bbfd7458-6dd6-4412-a8ba-8d417c3df56b}} has started reporting thousands of block I/O errors and these are starting to trickle up as a filesystem I/O errors.  I suspect this is likely a hypervisor I/O issue.        """
"DM-5198","Story","SUIT",8,"FITS Visualizer porting: Statistics - part 2 - drawing overlay & 3 color support","""drawing overlay 3 Color Support"""
"DM-5197","Story","meas_modelfit",8,"Test and robustify shapelet PSF approximations","""The CModel code ported from HSC only works as well as the ShapeletPsfApproximation algorithm that runs before it, but we've switched on the LSST side to a more flexible algorithm that isn't as nearly as battle-tested as what's been running on the HSC side, and there are some concerning indications from [~pgee]'s work that it can be catastrophically slow on some reasonable PSFs.  On this issue, I'll run it on some real HSC data and try to improve it, even if that means reducing the flexibility back to what was on the HSC side in some ways."""
"DM-5196","Story","Nebula OpenStack",1,"swift API availability?","""The downtime announcement email for {{Nebula unavailable Feb 9-10}} mentioned a """"roadmap"""" for swift.  I have checked and post maintenance, there is not a swift endpoint available in the catalog.  Is there a time line for availability?"""
"DM-5206","Story","afw",0.5,"Please do not write garbage to the FITS EQUINOX","""The equinox is not relevant when dealing with ICRS coordinates.    When {{afw}} manipulates {{Wcs}} objects, it simply doesn't bother initializing the {{equinox}} field of its {{_wcsInfo}} struct when dealing with an ICRS system.    When {{afw}} persists the {{Wcs}} to FITS, it blindly writes whatever happens to be in that uninitialized field to the FITS header. Thus, we end up with something like:    This should be no problem, since, per the [FITS standard|http://fits.gsfc.nasa.gov/standard30/fits_standard30aa.pdf] (page 30), the {{EQUINOX}} is """"not applicable"""" if they {{RADESYS}} is {{ICRS}}. The reader should thus ignore this value.    However, [SAOimage DS9|http://ds9.si.edu] version 7.4.1 (the latest release at time of writing) does _not_ ignore the {{EQUINOX}}. Rather, it refuses to handle the WCS for the image. Note that version 7.3 of DS9 does not seem to have the same issue.    While this does seem to be a bug in DS9, it's easy enough to work around by simply not writing {{EQUINOX}}."""
"DM-5265","Story","obs_decam",0.5,"Turn on bias-jump fix for all CCDs ","""The overscan fix to handle bias jump in an amplifier done in DM-4366 introduced a new config parameter {{overscanBiasJumpBKP}}, and the fix is applied for CCDs on the backplanes specified in {{overscanBiasJumpBKP}}.  Previously, the default is to only fix CCDs on backplanes next to the focus chips. But [~mfisherlevine] also see the bias jump features in other CCDs.  It would make more sense to turn it on for all CCDs by default. """
"DM-5264","Bug","Developer Infrastructure|lsst_build",1,"Modernize python in lsst_build","""The python in {{lsst_build}} uses old-style print and exception handling. These should be updated to the current standard."""
"DM-5252","Story","Validation",2,"Base ""bright star"" cut on S/N instead of magnitudes","""The astrometry histogram generated by validateDrp.py conflates astrometric and photometric calibration because it uses magnitude for brightness, and this relies on the accuracy of the photometric calibration. [~ctslater] suggests (and I agree) that brightness should be based on signal to noise ratio, thus making the astrometry histogram independent of photometric calibration.  """
"DM-5251","Bug","Developer Infrastructure|eups|lsst_build|lsstsw|sconsUtils",1,"lsstsw breakage with spaces in paths","""There are still some issues relating to using {{lsstsw}} to build the stack when spaces are in the path to the {{$LSSTSW}} location. This is a fine thing to sort out on Rodeo Day..."""
"DM-5247","Bug","meas_base|meas_extensions_shapeHSM",2,"Segfault in shapeHSM centroid extractor","""[~boutigny] reports a segfault in {{meas_extenstions_shapeHSM}}. He provides the following backtrace:      See the discussion at DM-4780."""
"DM-5275","Story","jointcal",2,"make floating point exception handling cross-platform (or remove it)","""jointcal currently has a couple of trapfpe() functions that wrap feenableexcept, which doesn't exist on OSX. Were these an important part of error handling in meas_simastrom, or can I just remove them?"""
"DM-5298","Story","ip_diffim",8,"Document simple simulator","""Document the simple simulator produced in DM-4899.  This will also involve some refactoring and adding unit tests to make it usable by others in the group."""
"DM-5291","Story","Stack Documentation and UX",1,"Docker-ready configuration system for LTD Keeper","""To deploy LTD Keeper in a Docker container (DM-5194), its best practice to handle all configurations through environment variables. In DM-4950, LTD Keeper was configured through files for test and dev/deployment profiles. What we should do is continue to allow hard-coded configurations for test and dev environments, but have a third fully fledged configuration environment thats driven entirely by environment variables.    The environment variables should allow fine grained configuration (for example, to turn off calls to individual external services for testing).    This should also resolve how to deal with Google Container Engine/Kubernetes auth flow works with environment variables, config files, and profiles."""
"DM-5290","Story","SUIT",2,"Add z-index for dialogs components","""Some of the outside modules that we have brought in have a z-index.  We need to make sure that our dialog components stay on top of them."""
"DM-5289","Story","obs_subaru",5,"Port HSC obs_subaru changesets to LSST","""We identified in DM-5162 several changesets that still need to be ported from HSC to LSST:    * 8948917de4579e032c7bbb2c8316014446e3841b: config: add astrometry filter map for HSC narrow-band filters  * 69d35a890234e37c1142ddbeff43e62fe36e6c45: Set radius for flux.naive, adjust comment for flux.sinc  * 8ea54d10f5ae56f8b6f244bca76d5796ae015216: config: disable sigma clipping in coadd assembly  * 8d2f4a02d0d668fc82e853b633444d8e0fe80010: config: reduce coadd subregionSize  * e36bd1b4410812ca314f50c01f899d92acc0e7a5: config: set pixelScale for jacobian correction  * Remove processCcdOnsiteDb.py, processStack.py  * Rename stacker.py to coaddDriver.py or whatever Nate chooses in DM-3369  * 49e9f5dcf16490f6be6438b89b17911a0cd35fb2: Fixed obvious errors caused by introducing VignetteConfig  * 8948917de4579e032c7bbb2c8316014446e3841b: config: add astrometry filter map for HSC narrow-band filters  * daa43eeac46e8708de6f37feeb5d5d16a3caca11: HscMapper: set unit exposure time for dark  * 77ff7c89d56bed94bca4f320f839dbd20fbab641: Set BAD mask for dead amps instead of SAT    We also noticed the following need to be done:    * Forced photometry configuration (CCDs and Coadds)  * Sanitize config of OBS_SUBARU_DIR (use getPackageDir)  * multiband config files need """"root"""" --> """"config""""  * No astrometry in measureCoaddSources  * Narrow bands missing from priority list  * detectCoaddSources removed from multiband  * Move filterMap from config/processCcd.py into own file"""
"DM-5288","Story","meas_base|obs_cfht|obs_decam|obs_lsstSim|obs_sdss|obs_subaru|pipe_tasks",3,"Port HSC pipe_tasks changesets to LSST","""We identified in DM-5162 some changesets that still need to be ported from HSC to LSST:    * 31ab5f02f7722650ad0a0eb4e2f7f8b3e0073366, 0c9a4a06bfb34ed26c72109131ef9f4a8c8f237a: multiBand: save background-subtracted coadd as deepCoadd_calexp  * e99e140feafe28e6f034143e8ee2ae58e9a9358d: Rejig interface for DetectCoaddSourcesTask to provide non-dataRef-centric API  * 829ee0cdd605ed027af1fada4446b715d9a5180d: multiband: activate sky objects  * MeasureMergedCoaddSources.doMatchSources defaults to False  * ProcessImageConfig.doWriteHeavyFootprintsInSources defaults to False ?  * 56666e8feba6893ac95fd4982d3e0daf6baf2d34: WcsSelectImagesTask: catch imagePoly is None    We also noticed some differences:    * * CalibrateConfig.setDefaults doesn't call parent  * CalibrateTask.run isn't returning apCorrMap  * reserveFraction=-1 instead of 0.2  """
"DM-5287","Story","ip_isr",1,"Port HSC ip_isr changesets to LSST","""We identified in DM-5162 some changesets that still need to be ported from HSC to LSST:    * f1cee734998f1faf86c02af42ea599b077847eeb: IsrTask: allow fallback to a different filter when loading calibrations  * 89cd629bb8e1a72a545176311b1ef659358d95af: saturationDetection: apply to overscan as well as image  """
"DM-5286","Story","meas_deblender",1,"Port HSC meas_deblender changesets to LSST","""We identified in DM-5162 a few changesets that still need to be ported from HSC to LSST:    * a8cf6c22df14494d6dcf2d7354c695cba9506301: Clarify tiny footprint limit  * 624790aa63a38fb7a328ebc21abfd1b10503aa26: config: change default strayFluxRule  * db7d705de93b43a5f32f771c716b1c5c7368d124: consolidate failed peak logic and downgrade warning    We also identified a few differences that should be resolved:  * clipStrayFluxFraction defaults to 0.01 for LSST, 0.001 for HSC  * Stray file, src/Baseline.cc.orig, on LSST side  """
"DM-5284","Story","meas_base",3,"Port HSC meas_extensions_simpleShape package to LSST","""HSC uses a package, meas_extensions_simpleShape, which needs to be ported to LSST.  The package is used for basic shape measurements for determining focus, and also serves as a simple guide for writing measurement plugins."""
"DM-5283","Story","obs_base",2,"Port HSC daf_butlerUtils changesets to LSST","""We identified in DM-5162 several changesets that still need to be ported from HSC to LSST:    * daee24edba01b01a0412df7f9b4cf70be5b10860: CameraMapper: allow a default filter name to be provided  * e3fee95d6a1850dd2309d3ebe4e3ef3ffe38eef0: CameraMapper: normalize path names, and remove leading double slash  * 476b6ddccd9d0cceb2b89ca34bee7d0fdcd70694: preserve timestamps in cameraMapper.backup()  * b2491ef60e5e23afa7d9f0297f257e694aa1af35: Only attempt to update Wcs if it's available  * 9f62bcce588fa9abc8e1e44ff2f0275e5230f629: Registry: hold registry cache for a single thread only (HSC-1035)  * 412f03b95b7a5e82003ab33a61bd43adbf465188: Registry: use a pool of registries to avoid having too many open files"""
"DM-5281","Story","shapelet|skymap",0.5,"Port HSC skymap, shapelet changesets to LSST","""We identified in DM-5162 some changesets that still need to be ported from HSC to LSST:    * skymap:  ** f83f71718eac5307d575d3113ee3757a63a16de2: Set vertex list in ExplicitTractInfo.    * shapelet:  ** bb928df3fc2fafe5183e0d075da19994f0af4fc7: Let the value to normalize to be specified in [Multi]ShapeletFunction  """
"DM-5279","Bug","ctrl_events",1,"arrays not properly transmitted","""Sending a property set with an array as one of the entries only passes the last element of the array."""
"DM-5277","Story","Continuous Integration",3,"replace buildbot with jenkins job(s)","""Removing buildbot and replacing it with jenkins would provide a number of benefits    * one less dashboard for developers to know about / interact with  * one less system for SQRE to maintain  * lessening the cost of refactoring the CI drivers scripts as synchronized updates to two CI system configurations would no longer be necessary    It should also be easy to go one step further and try to eliminate the need for developers to manually log into the {{lsstsw}} account on {{lsst-dev}} to publish eups distrib packages. """
"DM-5312","Story","Qserv",5,"Additional vertical partitioning tests","""Test potential improvements in many-vertical-shards test (20,50) run-times with query optimizer settings."""
"DM-5302","Story","Continuous Integration",5,"manage jenkins core + plugin versions","""There have been a couple of issues that have arisen when deploying test instances vs updating an existing instance due to slight differences between plugin versions.  This would be avoided by putting all plugin versions under change control.    Including:  * The versions of all jenkins components need to be explicitly specified  * The stored job {{config.xml}}'s should be updated to reflect plugin version changes  * The hipchat notification configuration should be updated to fix breakage caused by the production core/plugin update earlier this week  """
"DM-5324","Epic","Firefly|SUIT",100,"Convert GWT code to pure JavaScript (X16, part2, basic)","""Continue to work on the GWT code conversion to JavaScript."""
"DM-5321","Improvement","meas_base",0.5,"MeasureApCorrTask should use slot_CalibFlux as default ref flux","""{{MeasureApCorrTask}} uses """"base_CircularApertureFlux_17_0"""" as its default reference flux. It should use """"slot_CalibFlux"""" instead.    Also check obs_sdss packages for overrides that can be removed; obs_sdss certainly has one in {{config/processCcdTask.py}}"""
"DM-5320","Story","obs_subaru|pipe_tasks",2,"Make Bright Object Masks compatible with all cameras","""Currently all of the logic that goes into using bright object masks falls into obs_subaru and pipe_tasks. This ticket should move parts (such as the bright object mask class) out of obs_subaru, into a camera agnostic location. The work should also duplicate relevant camera configurations and parameter overrides in the other camera packages. Bright object masks were originally introduced in DM-4831"""
"DM-5319","Bug","mariadb",1,"Fix mariadb CI","""patch package is missing in docker container used by travis-CI."""
"DM-5355","Bug","meas_algorithms",0.5,"meas_algorithms uses packages that are not listed in table file","""{{meas_algorithms}} directly uses the following packages not expressed in the table file:  * Minuit2  * daf_persistence  * daf_base  * pex_config  * pex_exceptions  * pex_policy  """
"DM-5351","Story","Systems Engineering",1,"Create change request for LSE-140","""Deliverable: change request and document diffs for LSE-140"""
"DM-5350","Story","Systems Engineering",2,"Establish goals and create EA framework for LSE-140 update","""Deliverable: together with [~pingraham], identify the changes needed and develop initial content in EA."""
"DM-5349","Epic","Systems Engineering",5,"Revise LSE-140 to account for recent changes to calibration instrumentation","""Produce a revision of LSE-140, the DM - to - auxiliary instrumentation ICD, taking into account recent changes to the calibration instrumentation."""
"DM-5348","Story","obs_decam|obs_sdss|pipe_tasks",2,"Get rid of ProcessCcdSdssTask and ProcessCcdDecamTask","""Update {{ProcessCcdTask}} so that it can be used with different datasete types as appropriate for the ISR task. This will allow us to get rid of obs-specific variants {{ProcessCcdSdssTask}} and {{ProcessCcdDecamTask}}    The plan is to change {{ProcessCcdTask}} as follows:  - set {{doMakeDataRefList=False}} in the call to {{add_id_argument}}  - get the dataset type from the ISR task (default to """"raw"""") and set it in data container  - make the dataRef list by calling {{makeDataRefList}} on the data container    Question for DECam folks: do you want two executable scripts for DECam (one that processes data from the community pipeline and one that performs ISR)? Or do you prefer one exectutable (in which case you switch between performing ISR and reading the output of the community pipeline output by retargeting the ISR task)? If you prefer one binary, then which should be the default: perform ISR or read the output of the community pipeline?"""
"DM-5336","Bug","Qserv",1,"Fix minor issues in docker procedure","""- params.sh was missing at configuration  - startup.py wasn't importing correctly module """"utils""""  - remove unused parameters in params.sh"""
"DM-5359","Story","supertask",1,"Update DMTN-002 to reflect last changes","""Need to update documentation with latest changes on {{pipe_base}}, {{pipe_supertask}} and {{pipe_flow}}"""
"DM-5356","Story","meas_modelfit",8,"Test consistency of Shear Measurements with different Psfs","""DM-1136 was done with a single Psf, partly to avoid some of the problems we found with PsfShapeletApprox.  In this issue, I will look at consistency of the measurement for different Psfs."""
"DM-5364","Story","SUIT",8,"Image Select Panel: Support add or modify of plot","""previously the image select panel would only modify a plot.  Now give it the ability to add a plot."""
"DM-5372","Story","ci_hsc|obs_cfht|obs_decam",1,"Fix obs_* packages and ci tests broken by DM-4683","""The butler changes in DM-4683, in particular the removal of {{.mapper}} from the interface exposed by a {{Butler}} object, broken {{obs_cfht}}, {{obs_decam}}, and {{ci_hsc}}.    This issue will fix those changes, and search for additional broken things.    This work is proceeding in conjunction with DM-5370 to test that the CI system, e.g. {{lsst_ci}}, is sensitive to these breakages and fixes."""
"DM-5370","Story","Continuous Integration",1,"Create lsst_ci package as a continuous integration build target","""Create an {{lsst_ci}} package to be built for the continuous integration testing.    Plan:  1. Create empty package that has dependencies on {{obs_cfht}}, {{obs_decam}}, {{obs_subaru}}, {{testdata_cfht}}, {{testdata_decam}}, {{testdata_subaru}}. (/)  2.  Ensure above builds. (/)  3.  Add {{obs_lsstSim}} and ensure that it builds. (/)    The following were moved to DM-5381:  [ [~tjenness] : How can I get strikethrough to work in the following list?]  3. Add dependencies on {{validation_data_cfht}} and {{validation_data_decam}}, and {{validate_drp}}.  4. Run CFHT, DECam quick examples in {{validate_drp}}.  5. Test for successful running of the above examples.  Fail and trigger Jenkins FAILURE message if these examples fail.  6. Check performance of CFHT, DECam runs against reference numbers.  Fail if there is a significant regression.  7. Decide how to include {{ci_hsc}}, which currently can take at least 30 minutes to process the image data.--"""
"DM-5390","Story","SUIT",2,"JavaScript loading/caching plan","""We need to ensure that the latest version of the application(javascript) is loaded. Conditions: 1. once loaded, it should be cached by the browser. 2. name of the script has to be a static, so it can be referenced by api user. 3. it also has to load dependencies(gwt scripts) after the main script is loaded.  To do this, we created a tiny firefly_loader.js script whose role is to load the main script and then its dependencies. firefly_loader.js is configured to never cache so that the latest main script is always picked up. The main script is appended with a unique hash on every build.  This ensures that the browser will pick up the new script the very first time, and then cache it for future use. """
"DM-5385","Story","pipe_tasks",1,"calib_psfReserved is only defined when candidate reservation is activated","""The schema should in general not be a function of whether particular features are enabled or disabled so that users can have confidence looking for columns.  However, {{MeasurePsfTask}} only creates the {{calib_psfReserved}} column when {{reserveFraction > 0}}.  This causes warnings when attempting to propagate flags from calibration catalogs to deep catalogs."""
"DM-5384","Story","meas_base",3,"Port SdssShape changes from HSC meas_algorithms to LSST meas_base","""In porting {{meas_algorithm}} changes from HSC to LSST, modifications to the {{SdssShape}} algorithm were discovered. These changes should be transferred to LSST."""
"DM-5406","Improvement","pipe_tasks",1,"Require fields listed in icSourceFieldsToCopy to be present","""{{CalibrateTask}} presently treats config field {{icSourceFieldsToCopy}} as a list of fields to copy *if present*. This was required because one of the standard fields to copy was usually missing. However, [~price] fixed that problem in DM-5385. Now we can raise an exception if any field listed is missing (though I propose to continue ignoring {{icSourceFieldsToCopy}} if isSourceCatalog is not provided)."""
"DM-5402","Story","Qserv",3,"Make cluster deployment scripts more generic and enable ccqserv100...124","""These scripts will be improved (i.e. more genericity) and integrated inside Qserv code. Qserv will be deployed on ccqserv100 to ccqserv125"""
"DM-5394","Bug","boost|Third Party Software",2,"Investigate boost compiler warnings and update boost to v1.60","""As reported in comments in DM-1304 clang now triggers many warnings with Boost v1.59:    v1.60 is the current version so we should see if these warnings have been fixed in that version."""
"DM-5392","Story","butler|daf_persistence",1,"Please stop leaving repoCfg.yaml files around","""After a recent change to {{daf_persistence}} and possibly other packages I'm finding that many packages leave {{repoCfg.yaml}} files lying around after they run unit tests.    I'm not sure what is best to do about these files. If they are temporary, as I am guessing, then I think we need some way to clean them up when the tests that generated them have run. If they are intended to be permanent (which would be surprising for auto-generated files) then they should probably be committed?    I hope we can do better than adding them to .gitignore."""
"DM-5421","Story","pipe_base",2,"Add --show history option to cmdLineTask","""{{pex_config}} is able to report where a config parameter is set.  Please add a command line option {{--show history=config.parameter.name}} to the cmdLineTask parser.    The implementation will probably want to use something like:  {code:python}  import lsst.pex.config.history as pch  pch.Color.colorize(False)  print pch.format(config.calibrate.astrometry.solver, """"matchingRadius"""")  {code}  """
"DM-5419","Bug","ci_hsc",1,"ci_hsc fails test requiring >95% of PSF stars to be stars on the coadd","""Since the first week of March 2016, ci_hsc fails its test that requires that >95% of the PSF stars be identified as stars in the coadd.  I suspect this is related to the DM-4692 merge.    Here is a sample job that fails:  https://ci.lsst.codes/job/stack-os-matrix/9084/label=centos-6/console    The relevant snippet of the failure is:        This is the test that fails    https://github.com/lsst/ci_hsc/blob/74303a818eb5049a2015b5e885df2781053748c9/python/lsst/ci/hsc/validate.py#L169      Note that the assertion failure messages is a bit confusing.  It should say  """"Fewer than 95% of the sources used to build the PSF are classified as stars on the coadd."""""""
"DM-5416","Epic","Developer Infrastructure",8,"Ci Deploy and Distribution Improvements part IV","""This is a bucket epic for ongoing improvements to the CI system"""
"DM-5410","Bug","obs_decam",1,"DecamIngestTask is mis-calling openRegistry","""`DecamIngestTask` is mis-calling `lsst.pipe.tasks.RegistryTask`. Line 59:      {{openRegistry}} is expecting a directory name, not a butler object for the first argument    Thanks to [~wmwood-vasey] for diagnosing this."""
"DM-5431","Story","Algorithm Testing",5,"Changes to galaxy_shear_experiments Python code","""This ticket describes changes which were made to the test runner and analysis scripts during the Dec 2015 - Feb 2016 period.  Most of these changes were made as a part of moving to a large computing cluster, where both the units of work and the output file organization had to be changed to make parallelization possible.    The large number of tests run during this period and the need to more efficiently analyze and compare also introduced some changed to the analysis and plot modules.    Since these changes do not pertain to any single test (though many were done during Dm-1136), I have put them on a separate ticket."""
"DM-5428","Bug","meas_algorithms",2,"ObjectSizeStarSelector can produce numpy warnings","""`ObjectSizeStarSelector` can produce the following numpy warning:     This occurs at the following point in the code:    where `func` has been assigned to `numpy.mean`. When I have seen this occur I have found that `dist` is an array of `nan`    I suggest that the star selector handle this situation more gracefully, e.g. by reporting an appropriate exception or handling the data in an appropriate way. If logging a message would be helpful, then please do that (and if RFC-154 is adopted, a log will be available).    One way to reproduce this is to run `tests/testProcessCcd.py` in `pipe_tasks`. However, I often see it when running `processCcd.py` on other data, as well."""
"DM-5427","Story","meas_base",2,"SingleFrameVariancePlugin can give numpy warnings","""SingleFrameVariancePlugin can produce the following numpy warning, with no hint as to where the problem is coming from:    I tracked it down by adding the following code to the calling code:      It would be nice if the measurement plugin handled this situation more gracefully, such as turning the warning into an exception or testing for it and handling it.    One way to reproduce this problem is to run {{tests/testProcessCcd.py}} in {{pipe_tasks}}. However, it is commonly seen when running {{processCcd}} on other data, as well."""
"DM-5424","Story","pipe_tasks",2,"Switch PropagateVisitFlags to use src instead of icSrc","""On DM-5084 [~jbosch] switched PropagateVisitFlags to match against icSrc instead of src because we weren't yet matching `icSrc` to `src` in ProcessCcdTask.  That's now been done on DM-4692, so we can revert this.    After doing so, please verify with ci_hsc that this is working, as that's where the only test of this feature lives."""
"DM-5435","Story","Developer Infrastructure",3,"Provide a shared stack on lsst-dev & other relevant systems","""Following the discussion in RFC-156, ensure that a documented, fast, easy to initialize shared stack is available for developers to use on shared systems, certainly to include {{lsst-dev}}."""
"DM-5449","Epic","SUIT",100,"Convert GWT code to pure JavaScript (F16)","""The remaining work for converting GWT code to pure JavaScript"""
"DM-5448","Story","meas_extensions_ngmix",3,"Familiarization with ngmix codebase","""Download the ngmix codebase from https://github.com/esheldon/ngmix. Install it and its dependencies in the same environment as the LSST stack. Experiment with using it and understanding how it works"""
"DM-5447","Story","meas_modelfit|Requirements Documents",8,"Write technical note describing galaxy shear fitting experiments","""Through S15 (DM-1108) and W16 (DM-3561), [~pgee] has conducted a large-scale investigation into galaxy shear fitting. Please summarize the motivation, methodology and results of this study as a [technical note|http://sqr-000.lsst.io/en/master/]."""
"DM-5463","Improvement","pipe_tasks",1,"Don't restore the mask in CharacterizeImageTask.characterize","""CharacterizeImageTask.characterize presently restores the mask from a deep copy for each iteration of the loop to compute PSF. This is unnecessary because repair and detection both clear the relevant mask planes before setting new values."""
"DM-5502","Story","afw",5,"Collect usage of header metadata","""Collect a comprehensive set of exposure oriented metadata used by science code.  This should also include metadata that is not currently needed but that could be utilized in the future.  In practice, I suspect this will involve looking for all calls to PropertySet.get since that is how FITS header metadata is currently passed around."""
"DM-5501","Epic","afw",100,"Solve the metadata sanitization problem","""Applications need access to visit specific metadata: e.g. pointing, airmass, exposure length.  This information is typically carried around in a FITS header, but there are no conventions on spelling or even necessarily units of these metadata key, value pairs.  There needs to be a easy to use metadata sanitization process that allows data from many different systems to present a standardized interface to observation metadata to the algorithm code."""
"DM-5499","Story","Design Documents",2,"Coordinate completion of functional breakdowns","""Coordinate the creation of a new version of LDM-148 incorporating DPS-WG-generated functional breakdowns."""
"DM-5498","Story","Design Documents",2,"Coordinate completion of operations concepts","""Coordinate the creation of a new version of LDM-230 incorporating DPS-WG-generated operations concepts."""
"DM-5496","Story","Design Documents",2,"Develop functional breakdown for Data Access Center Processing System","""Write sections that can be incorporated into LDM-148 describing the functional breakdown of the Data Access Center Processing System, including, for each major element:  * overall function  * inputs, outputs, and control interfaces  * components used  * descriptions of functions to be performed    (Story points are for KTL drafting and initial contributions)"""
"DM-5495","Story","Design Documents",2,"Develop functional breakdown for Data Backbone","""Write sections that can be incorporated into LDM-148 describing the functional breakdown of the Data Backbone, including, for each major element:  * overall function  * inputs, outputs, and control interfaces  * components used  * descriptions of functions to be performed    (Story points are for KTL drafting and initial contributions)"""
"DM-5494","Story","Design Documents",2,"Develop functional breakdown for Batch Processing System","""Write sections that can be incorporated into LDM-148 describing the functional breakdown of the Batch Processing System, including, for each major element:  * overall function  * inputs, outputs, and control interfaces  * components used  * descriptions of functions to be performed    (Story points are for KTL drafting and initial contributions)"""
"DM-5493","Story","Design Documents",3,"Develop functional breakdown for Observation Processing System","""Write sections that can be incorporated into LDM-148 describing the functional breakdown of the Observation Processing System, including, for each major element:  * overall function  * inputs, outputs, and control interfaces  * components used  * descriptions of functions to be performed    (Story points are for KTL drafting and initial contributions)"""
"DM-5492","Story","Design Documents",3,"Develop operations concept for Data Access Processing System","""Develop a ConOps document that can be included as appropriate sections of LDM-230 describing the Data Access Processing System that manages L3 computing in and interfaces to the Data Access Center, specifying automated operations sequences, how human intervention can occur, and processes to handle changes and updates.    (Story points are for KTL drafting and initial contributions)"""
"DM-5491","Story","Design Documents",3,"Develop operations concept for Data Backbone","""Develop a ConOps document that can be included as appropriate sections of LDM-230 describing the Data Backbone that contains, manages, and provides access to the Science Data Archive, specifying automated operations sequences, how human intervention can occur, and processes to handle changes and updates.    (Story points are for KTL drafting and initial contributions)"""
"DM-5490","Story","Design Documents",3,"Develop operations concept for Batch Processing System","""Develop a ConOps document that can be included as appropriate sections of LDM-230 describing the batch processing environment, specifying automated operations sequences, how human intervention can occur, and processes to handle changes and updates.    (Story points are for KTL drafting and initial contributions)"""
"DM-5489","Story","SUIT",1,"improvement of the north/east arrow on image","""make the compass sticky when scroll the image"""
"DM-5488","Story","SUIT",8,"Field group updates","""After some work we have realized that the following needs to be done to field groups:    * Tabs group should have a field group smart wrapper component  * field group needs to reinit on id change   * remove mixin, use Higher-Order Components instead  * support a function for a value, this function will return a value or a promise  * hidden fields - init field group with key/value object  * Sub-field groups? study only, unless it is easy to implement.  * maintain an option to keep unmount field value available  * determine if InitValue needs to be passed around  * passing fieldState around too much  * find reason for react warning every time popup is raised  * look at promise code make sure it is working the way we think  * if practical, remove all export default    FieldGroupConnector.It is the high order component that replaces the mixin.   FieldGroupUtils.js:  (~line 33): The field value would be a function on the file upload case. Therefore the upload does not activate until validation. In the upload case the function would return a promise. However, It could return a value or an object with a value and a valid status. Now the value key of a field can contain a promise or function or primitive. The function can return a primitive, a promise, or an object with primitive and status.    fftools.js lines 102-158 you can see my experimenting with taking out the connector. It works fine and does eliminate one of the warning messages.    """
"DM-5487","Story","Design Documents",2,"Revise operations concept for Observation Processing System","""Turn the L1 ConOps document into appropriate sections of LDM-230, specifying automated operations sequences, how human intervention can occur, and processes to handle changes and updates.     (Story points are for KTL drafting and initial contributions)"""
"DM-5486","Story","QA",2,"Work on putting together page of ""tips and tricks for using the stack""","""Due to the incomplete state of the stack documentation and tutorials, I decided to write down various """"tips and tricks"""" for using the stack as I learn them.  https://confluence.lsstcorp.org/display/SQRE/Tips+and+Tricks+for+using+the+Stack"""
"DM-5485","Story","QA",2,"Work on plan to test specific algorithmic components of the stack","""After working on a script to test the astrometric matcher, I decided to put together a plan to run similar tests on our algorithmic code.  The rough plan is here:  https://confluence.lsstcorp.org/display/SQRE/Stack+Testing+Plan"""
"DM-5484","Bug","obs_sdss",0.5,"SdssMapper.paf has wrong python type for processCcd_config","""[~npease] reports that {{Sdssmapper.paf}} has the wrong python data type for the dataset {{processCcd_config}}: it is {{lsst.obs.sdss.processCcdSdss.ProcessCcdSdssConfig}} instead of {{lsst.pipe.tasks.processCcd.ProcessCcdConfig}}"""
"DM-5483","Story","QA",5,"Work on script to test the astrometric matcher","""We encouraged astrometric matching problems for the Bulge verification dataset.  Therefore, I wrote a script that tests the matcher by systematically shifting the coordinates of one sets of the data to see if the matcher still works.  It worked well until ~80 arcsec."""
"DM-5482","Story","QA",5,"Write presentation on verification datasets for AAS","""Prepared and gave a talk at the NSF booth at the Florida AAS meeting on the progress of the verification datasets effort."""
"DM-5480","Story","QA",20,"Processing of COSMOS data - Part II","""Continued work on processing and QA work on the COSMOS verification dataset.  Running processCcDecam, making diagnostic plots, and nvestigating the results.  Most recently I've  reprocessed the COSMOS data through processCcdDecam using SDSS as the astrometric and photometric reference catalog and am redoing the QA work on those results."""
"DM-5479","Story","QA",5,"Wrote script to print the names of all visits that overlap a patch","""In order to finish the IDL workflow module for makeCoaddTempExp I needed a program to say which visits overlap a given path.  That's what this script does."""
"DM-5478","Story","QA",20,"Write script to derive and collate QA metrics from data repository of processed data","""I wrote a python script using stack components to derive QA metrics and collate other QA-relevant information for a data repository of processed data.  This is currently output to a CSV file that can be loaded into a SQL database."""
"DM-5474","Bug","obs_subaru",1,"Bugs in obs_subaru found by PyFlakes","""I ran pyflakes on the code in obs_subaru and found a few bugs (beyond a few trivial ones that I am fixing as part of DM-5462)    {{ingest.py}} has undefined name {{day0}}    {{ccdTesting.py}} has at least three undefined variables: {{x}}, {{y}} and {{vig}} in the following:      {{crosstalkYagi.py}} has many undefined names, starting with {{makeList}}, {{estimateCoeffs}}"""
"DM-5473","Bug","ci_hsc",1,"Jenkins/ci_hsc failure: 'base_PixelFlags_flag_clipped' already present in schema","""Since 15 March, the {{ci_hsc}} build in Jenkins has been failing as follows:        Please fix it."""
"DM-5472","Story","meas_mosaic",3,"Update meas_mosaic for compatibility with new single frame processing","""Following [recent changes to single frame processing|https://community.lsst.org/t/backward-incompatible-changes-to-processccdtask-and-subtasks/581], {{icSrc}} no longer includes celestial coordinates and {{icMatch}} is no longer being written. {{meas_mosaic}} requires this information. Provide a work-around."""
"DM-5553","Bug","Firefly|SUIT",8,"Z-scale stretch for image display","""The z-scale stretch in current system is different from the one in OPS"""
"DM-5552","Story","SUIT",2,"Add renderer option to js table","""TablePanel and BasicTable now accept optional renderers.  For each column, you can set a custom renderer for the header, cell, or both.  Also, created several commonly used renderer for images, links, and input field."""
"DM-5542","Bug","afw",0.5,"AFW rgb.py has undefined variable that breaks a test in some situations","""The {{rgb.py}} test is failing for me with current AFW master:      {{Tempfile}} is definitely only used in line 313. It was introduced with commit c9864f49.    I'm not entirely sure how this is not picked up by Jenkins as the test will run if matplotlib and scipy are installed and Jenkins does have those.    """
"DM-5530","Epic","Firefly",40,"Documentation of Firefly functions and API (F16)","""We are concentrating on the coding in X16. This epic will be capture the effort to write the document for using Firefly functions and API. """
"DM-5515","Story","Developer Infrastructure",1,"prepare Slack RFC","""    https://jira.lsstcorp.org/browse/RFC-140"""
"DM-5568","Story","Systems Engineering",2,"CCB review of LCR-603 (LSE-74)","""Review LCR-603, """"LSE-74 document revision"""""""
"DM-5567","Story","Systems Engineering",2,"CCB review of LCR-567 (LSE-70) and LCR-568 (LSE-209)","""Review the LSE-70 and LSE-209 drafts submitted with change requests LCR-567 and LCR-568 in January 2016."""
"DM-5566","Story","Systems Engineering",3,"Review of LSE-70 and LSE-209 drafts, September 2015","""Arrange, prepare for, and attend a joint call with the Camera team to review the end-of-summer-2015 drafts of LSE-70 and LSE-209 from the OCS group."""
"DM-5565","Story","Systems Engineering",1,"Participate in December 2015 OCS-subsystems teleconference (LSE-74)","""Prepare for, attend, and follow up on the OCS-subsystems teleconference on December 9, 2015. This story covers work related to LSE-74; LSE-70 and LSE-209 work was also done under a separate epic."""
"DM-5564","Story","Systems Engineering",2,"Participate in December 2015 OCS-subsystems teleconference (LSE-70, LSE-209)","""Prepare for, attend, and follow up on the OCS-subsystems teleconference on December 9, 2015. This story covers work related to LSE-70 and LSE-209; LSE-74 work was also done under a separate epic."""
"DM-5563","Story","Systems Engineering",1,"Participate in November 2015 OCS-subsystems teleconference (LSE-74)","""Prepare for, attend, and follow up on the OCS-subsystems teleconference on November 11, 2015.  This story covers work related to LSE-74; LSE-70 and LSE-209 work was also done under a separate epic."""
"DM-5560","Story","Systems Engineering",2,"Participate in October 2015 OCS-subsystems teleconference","""Prepare for, attend, and follow up on the OCS-subsystems teleconference on October 8, 2015."""
"DM-5582","Story","Systems Engineering",3,"Support LCR-385","""Support getting LCR-385 against LSE-78 through the CCB."""
"DM-5580","Story","Systems Engineering",2,"Docgen draft from EA content for LSE-140","""Create a docgen from the LSE-140 content in Enterprise Architect."""
"DM-5591","Epic","SUIT",40,"Archive in a box v1 (F16)","""Several times we were asked a question about Firefly: Great software. How could I use it for my data now?     This epic capture the preparation work in Firefly for its final version of """"Archive in a box"""". The work is also needed to improve the user experience in using Firefly.     8/1/2017  Future related work will be captured in stories of  epic DM-10853. """
"DM-5590","Bug","afw",1,"Fix afw build issues with recent clang","""{{afw}} fails to build with recent versions of clang:      and issues with statistics.i so far, more errors may turn up as these are cleared.    These problems are apparent with {{Apple LLVM version 7.3.0 (clang-703.0.29)}} (as shipped with the latest release of XCode, hence this now becoming an issue) and {{clang version 3.8.0 (branches/release_38 262722)}} (a recent release from LLVM; note that Apple uses its own versioning scheme). {{clang version 3.7.1 (tags/RELEASE_371/final)}} is not affected."""
"DM-5586","Bug","obs_decam",3,"Fix obs_decam butler level","""There is a bug in {{obs_decam/policy/DecamMapper.paf}}, causing some butler features for the """"visit"""" level or above working incorrectly. The {{hdu}} key is irrelevant for the visit level or above, but wasn't included in the policy file.    Because of this bug, the {{DemoTask}} in {{ctrl_pool}} (ctrlPoolDemo.py) runs incorrectly with DECam data. It incorrectly treats dataRef with different {{hdu}}s as they are from different visits, hence reads each ccd image multiple times (61 times for one visit with 61 hdu). Instead, each ccd image should be read once.        Besides fixing the policy file, I also added an optional test that only runs if {{testdata_decam}} is set up. The part with level=""""visit"""" in the test fails without the ticket changes in the policy.    (p.s. The raw data file in {{testdata_decam}} is modified and has only 2 hdus.) """
"DM-5585","Story","Developer Infrastructure|Stack Documentation and UX",5,"SQuaRE Communication and Publication Platforms Document and Presentation - Clone","""This is a clone of DM-5581 tracking [~frossie]'s SPs"""
"DM-5595","Bug","daf_persistence|mariadb|mariadbclient",1,"daf_persistence build failure on OSX","""I see the following build failure in {{daf_persistence}} on OSX 10.11:      This happens with the current master ({{3484020}} at time of writing), but also with a recent weekly ({{3878625}}). """
"DM-5594","Bug","Qserv",5,"Fix qserv service timeout issue","""After Qserv services have been running over ~couple of days, new queries fail and can also lead to a crash. Investigate and implement a solution."""
"DM-5593","Story","butler",1,"fix issue where butler repository search returns list for single item","""Backwards compatible behavior is that when butler returns a single item, it is NOT in a list. A recent change (when the Repository class was added) broke this behavior.     Change it back so that if an operation in repository would return a list with a  single item, it pulls it from the list.    Note this is only related to the case where a repository's parentJoin field is set to 'outer' and since no one is using this yet (they should not be, anyway) then the point is moot.     """
"DM-5633","Story","obs_decam",3,"Add data products and config in obs_decam for multi-band processing","""Add necessary data products and default config in order to run forcedPhotCcd, coaddDriverTask, and multiBandDriverTask with DECam data. """
"DM-5607","Story","butler",1,"check & correct comparison operators in daf_persistence and daf_butlerUtils","""per comments in DM-5593, an incorrect comparison operator was found, that used {{is}} instead of {{==}} in a string comparison (e.g. {{var is 'left'}} which is incorrect, it should be {{var == 'left'}}.  This needs to be corrected in {{Repository}} (see DM-5593 for details), and the rest of daf_persistence and daf_butlerUtils should be checked for correct use of is vs. ==."""
"DM-5635","Bug","meas_base",1,"not flagged NaN in sdssCentroid","""In some rare cases base_SdssCentroid_x(y)Sigma can be NaN while base_SdssCentroid_flag is False"""
"DM-5643","Story","daf_base",2,"add method to convert Property[Set,List] to nested dict","""In interfacing with AstroPy it'd be useful to easily convert PropertySet and PropertyList to nested dict and OrderedDict (respectively), converting elements with multiple values to lists in the process."""
"DM-5641","Story","afw",1,"finish up afw.table to astropy.table view support","""At an LSST/AstroPy summit hack session, we've put together a functional system for viewing afw.table objects as astropy.table objects on branch u/jbosch/astropy-tables of afw and https://github.com/astropy/astropy/pull/4740.    Before merging, we should add support for """"object"""" columns for subclasses to hold e.g. Footprints in SourceCatalog, and add some documentation.  We may also want to add a convenience method to return an astropy.table.Table directly."""
"DM-5659","Story","SUIT",3,"multiple dialog are not working well together","""When several dialogs are up together.  The most recently click one should be one top. When table are in the dialogs such a fits header view. The scroll bars will go over other dialogs. This needs some though and work.  Another thing- when a message dialog is show because of a dialog error. It should center on the dialog.  Update- I don't think I will do the error centering now.  I am going to leave that and see if it is a real problem."""
"DM-5689","Story","SUIT",2,"Table needs to fire another action when data completely loaded","""When the data for a table is completely loaded fire another action such as TABLE_NEW_LOADED_DONE. This way the xyplots and the image overlays know to go fetch the data.    4/22/2026 from the pull request:  added new action TABLE_NEW_LOADED to table; fired when table is completely loaded.  added table error handling.  fix active table not updating after an active tab is removed."""
"DM-5686","Story","meas_algorithms|meas_astrom|pipe_tasks",2,"Accommodate pixel padding when unpersisting reference catalog matches","""The reference object loader in {{meas_algorithm}}'s *loadReferenceObjects.py* grows the bbox by the config parameter pixelMargin:  doc = """"Padding to add to 4 all edges of the bounding box (pixels)"""" . This is set to 50 by default but is not reflected by the radius parameter set in the metadata, so some matches may reside outside the circle searched within this radius. This increase needs to be reflected in the radius set in the metadata fed into {{joinMatchListWithCatalog()}}.  """
"DM-5681","Story","pipe_tasks",2,"Provide single-visit processing capability as required by HSC","""In DM-3368, we provided a means of running multiple processCcd tasks across an exposure, but without performing global calibration etc as provided by HSC's ProcessExposureTask.    Please augment this with whatever additional capability is required to enable HSC data release processing."""
"DM-5675","Story","meas_extensions_shapeHSM|obs_subaru",0.5,"Cannot enable shapeHSM because RegistryField fails validation","""When running ci_hsc after setting-up the meas_extensions_shapeHSM, meas_extensions_photometryKron and dependencies using setup -v -r . in the respective cloned folders, I get    Find out why this is happening and find a fix  """
"DM-5664","Story","meas_extensions_psfex",1,"Delete or document and test config/psfex.py","""The file {{config/psfex.py}} has no documentation and is bit rotting. If you feel it should be kept then please document it and add a simple unit test that loads it and runs data using it. If it is not needed, then please get rid of it."""
"DM-5663","Story","meas_extensions_psfex|obs_subaru",2,"Config override fixes needed due to new star selector","""As of DM-5532 a few config files need updating to not refer to star selector config fields as registries (not ones run by our normal CI, which is how I missed this)."""
"DM-5660","Story","Validation",5,"Add motivated model fits to validate_drp  photometric and astrometric scatter/repeatability analysis and plots","""Implement well-motivated theoretical fits to the astrometric and photometric performance measurements based on derivations from LSST Overview paper.  http://arxiv.org/pdf/0805.2366v4.pdf    Photometric errors described by  Eq. 5  sigma_rand^2 = (0.039 - gamma) * x + gamma * x^2  [mag^2]  where x = 10^(0.4*(m-m_5))    Eq. 4  sigma_1^2 = sigma_sys^2 + sigma_rand^2    Astrometric Errors   error = C * theta / SNR    Based on helpful comments from [~zivezic]    {quote}  I think eq. 5 from the overview paper (with gamma = 0.039 and m5 = 24.35; the former I assumed and the latter I got from the value of your  analytic fit that gives err=0.2 mag) would be a much better fit than the adopted function for mag < 21 (and it is derived from first principles).  Actually, if you fit for the systematic term (eq. 4) and gamma and m5, it would be a nice check whether there is any weird behavior in  analyzed data (and you get the limiting depth, m5, even if you dont go all the way to the faint end).     Similarly, for the astrometric random errors, wed expect        error = C * theta / SNR,    where theta is the seeing (or a fit parameter), SNR is the photometric SNR (i.e. 1/err in mag), and C ~ 1 (empirically, and 0.6 for the idealized maximum likelihood solution and gaussian seeing).   {quote}"""
"DM-5703","Story","afw",8,"Evaluate performance of AST/GWCS over a range of numbers of pixels","""Once we have a composite distortion model from DM-5701, evaluate the performance of AST and GWCS over a range of numbers of pixels, likely from ~100 through full-CCD (4k^2).    As part of this process, we will try to determine whether there is a way to efficiently warp images/postage stamps using python-only models in GWCS and whether bottlenecks could be worked around via optimizations in cython."""
"DM-5702","Story","afw",8,"Create a new model in AST/GWCS to represent a complex distortion","""Using lessons learned from DM-5701, create a more complex distortion model that cannot be represented from the basic models in GWCS or AST. A good example for this might be a rapidly varying sinusoidal tree-ring-like function that is not well represented by the standard polynomial basis functions. This will test our ability to extend each framework with new models that have not yet been decided on.    Once completed, we could plug this back into the composite model in DM-5701."""
"DM-5695","Story","Science Pipelines",8,"Implement simple 1D DCR correction on simulated data","""Nate Lust wrote a simple DCR correction recipe that runs in 1D in an ipython notebook. This ticket is to re-write the notebook in python modules that can be run on StarFast simulated images prior to image differencing. For this ticket, the simulated images will be 2D, but DCR will be purely along the x or y pixel grid, allowing columns or rows of pixels to be treated separately in 1D."""
"DM-5694","Story","Science Pipelines",2,"Run StarFast simulated images through diffim","""Determine the metadata and dependencies needed to fully process two images simulated with StarFast through diffim. """
"DM-5726","Story","Firefly|SUIT",2,"attend the weekly meeting with UIUC camera team (May 2016)","""Tatiana will attend the weekly meeting. Xiuqin and Gregory also attends when needed. """
"DM-5723","Story","SUIT",2,"make sure table can be resized properly","""Test table to make sure it can be resized under a variety of layout."""
"DM-5720","Story","Project Management tools",2,"JIRA fixes","""This tracks SPs spent on JIRA requests. """
"DM-5734","Story","SUIT",1,"Fix the issues in the server side and the client side introduced by FitsHeaderViewer 's work","""*  The testing data """"table_data.tbl"""" in the testing tree was accidentally moved.  It should be added back so that IpactTableTest.java can run.    * The request in JsontableUtil was mistakenly moved out from the tableModel by the the line   * .  The meta can be null but the request is not null, the request should be put into the TableModel.     """
"DM-5729","Bug","pex_config",0.5,"Config.loadFromStream suppresses NameError","""Within a config override file being executed via {{Config.load}} or {{Config.loadFromStream}}, using a variable that hasn't been defined results in a {{NameError}} exception, but this is silently suppressed and the user has no idea the following overrides have not been executed."""
"DM-5748","Improvement","Third Party Software",1,"Upgrade mpi4py to latest upstream","""[mpi4py|https://bitbucket.org/mpi4py/] version 2.0 was released in October 2015 with a number of changes. We should upgrade. When upgrading, we should check whether it contains a proper fix for DM-5409 and, if not, file a bug report upstream.    This issue should not be addressed until we have proper test coverage on code which uses mpi4py (DM-3845)."""
"DM-5773","Story","Firefly",2,"Firefly API plan and decision","""We need a plan for  all the Firefly APIs development in the new React/Redux based JS framework, including JS API and Python API.    - Backward compatibility  - Syntax format for JS API  - Syntax format for Python API  - Schedule     - convert the existing API first     - list of new ones to be added, when    """
"DM-5771","Story","Calibration Products Production",2,"Update config files","""DM-46921 and DM-5348 changed ProcessCcd to the point where past config files are no longer valid as stuff has moved a lot (see https://community.lsst.org/t/backward-incompatible-changes-to-processccdtask-and-subtasks/581)    This ticket is to go through past configs and create a new config file to reproduce the reductions done, or at least make something sensible come out the end of processCcd"""
"DM-5770","Story","Calibration Products Production",2,"Investigate image processing for feature enhancement","""Whilst looking at an individual spot from the CBP on DECam I noticed a weird feature, and upon further investigation, several more, though these were very hard to see.    This ticket is to investigate what image processing techniques will make these hard-to-see features pop out so that they can be examined more closely."""
"DM-5769","Story","Calibration Products Production",2,"Write spot visualisation snippets","""Write some snippets to aide in the processing and visualisation of the CBP data/analysis.    Essentially, write some helper functions that you can throw sections of images at to help look at the shape of the CBP spots, as ds9 isn't great ideal this.    Some nice features would be:    A function that takes a list of images or arrays, and plots them side-by-side, which provides some intelligent options for the stretches, and optionally stretches each image as is best for it, or ties them all to be the same. This would be as 2D colour plots.    A function that takes part of an image and displays it as a colour-graded surface.    A function that takes part of an image and displays it as a 3D bar-chart (as in ROOT, but without using ROOT because there is already enough evil in the world)"""
"DM-5767","Story","Calibration Products Production",1,"Create custom basic coaddition code","""Create script to do the following:  * Takes a list of DECam exposure numbers  * for each CCD, loads the corresponding calexps  * creates a naive pixel-by-pixel coadd of the underlying images  * Possibly either ANDs or ORs the masks (though perhaps not necessary)  * Either sums the expusure time info from the headers, or averages them, depending on whether the images were normalised to exposure times or not  * write the corresponding images out as coadded fits"""
"DM-5765","Improvement","sconsUtils",1,"Remove unneeded imports in SConstruct","""There's an outstanding pull request from an external contributor (Miguel de Val-Borro) [here|https://github.com/lsst/sconsUtils/pull/9] that makes some minor improvements to sconsUtils by cleaning up the imports. Somebody should review and (if appropriate) merge it. (Or, at least, reply to our community!)"""
"DM-5763","Story","SUIT",3,"XYPlot: decimation options","""User needs to be able to control number of bins and bin size."""
"DM-5760","Story","SUIT",2,"XYPlot needs to be expandable","""Make XYPlot expandable"""
"DM-5757","Story","SUIT",1,"FitsHeader's resize and sorting","""DM-4494 has merged to the dev.  However, there are still two issues remained:  * Resize the popup with tabs does not work  * Sorting is depending on the BasicTable's sorting"""
"DM-5756","Improvement","Developer Infrastructure|partition|Third Party Software",2,"Update Scons to v2.5.0","""Scons 2.5.0 came out over the weekend. There were many fixes to the dependency determination code. The next version of Scons is intended to be 3.0 which will be the first version to support Python 3. Since we fully intend to switch to Python 3.0 in the summer it is prudent for us to ensuer that 2.5.0 works fine before switching to 3.0.0 so that we do not get confused as to why there is breakage in jumping straight to 3.0.0."""
"DM-5775","Story","SUIT",0.5,"Change the TabPanel.jsx and TabPanel.css's properties to allow its children can be resizable","""When an outside container is resizable (using css properties: resize: 'both', overflow: 'auto'...), in order for the child inside the container to be resizable, the child has to specify its height and width properties using percentage format (height: 90%, width:100%).   When the TabPanel is used, the table is put on TabPanel.  The table needs to access the size information of the outside container, ie,, the grandparent's width and height. The TabPanel has to pass the height and width to its child component.  Without specifying the height and width in the TabPanel, by default, the auto is used.  When the width (height) is auto, it allows to use the child's width (height).  However, the child replies on the parent to provide such information.  When this circular relations occur, the default size of the child is used.  That is why the table component forever has 75px when it was put in the TabPanel.  To be able to resize with the outside (root) contains all the ancestors of the component have to specify the width and height explicitly. """
"DM-5784","Story","SUIT",8,"Port region serializer and data structures from GWT","""The region serializer in: firefly/src/firefly/java/edu/caltech/ipac/util  * RegionFactory.java    Region container data structures files in : firefly/src/firefly/java/edu/caltech/ipac/util/dd    * ContainsOptions.java  * Global.java  * RegionFileElement.java  * RegParseException.java  * Region.java  * RegionAnnulus.java  * RegionBox.java  * RegionBoxAnnulus.java  * RegionCsys.java  * RegionDimension.java  * RegionEllipse.java  * RegionEllipseAnnulus.java  * RegionFont.java  * RegionLines.java  * RegionOptions.java  * RegionPoint.java  * RegionText.java  * RegionValue.java      Note - do not port CoordException, there are other ways to do this."""
"DM-5782","Story","Developer Infrastructure",1,"Include obs_cfht, obs_decam in lsst-dev shared stack","""The shared stack on {{lsst-dev}} provided in DM-5435 does not contain the {{obs_cfht}} or {{obs_decam}} camera packages. Please add them."""
"DM-5791","Story","pipe_tasks",1,"Why is doSelectUnresolved an argument?","""The {{run}} method in the {{PhotoCalTask}} has an argument that selects whether to use the extendedness parameter to select objects for photometric calibration.  This is a good idea, but it should be configurable, I think. """
"DM-5794","Story","SUIT",8,"Image Visualizer: Support image and drawing layer subgrouping","""This will give user finer control of turning on/off the catalog overlays on one image, a group of images, or all the displayed images. """
"DM-5793","Story","SUIT",8,"FITS Visualizer porting: Convert  Mask support","""* convert the make support from GWT  * Make a temporary dialog to control it  * Add python/JS API supporty"""
"DM-5799","Story","Firefly",8,"Asinh stretch algorithm corerction","""in DM-2634, the Asinh stretch algorithm  was implemented, but the behavior was not quite right. We need to figure out the issue and make it right. One possibility is that the understanding the relationship  of zero point  and black point, maximum point and white point. """
"DM-5797","Bug","meas_algorithms",2,"Using 'CONSTANT' for background subtraction fails","""Running processCcd (on a DECam file) with the following in the config file:        fails, and throws the following:    """
"DM-5816","Story","SUIT",2,"Investigate behavior of Firefly and stretches for images with negative pixel values","""Based on a discussion in the Tea Time HipChat room today, this is a """"note to ourselves"""" to take a look at the behavior of Firefly when visualizing images with negative flux values.    This is important for difference imaging and is therefore highly relevant to both LSST and ZTF (if ZTF difference images become visible through Firefly at some point).    The behavior of the asinh stretch, in particular, should be looked at."""
"DM-5810","Story","pipe_tasks",1,"Update imageDifferenceTask to cast template ids and use ObjectSizeStarSelector","""A couple recent changes to the stack break imageDifferenceTask.     Requires updates to only a few lines.     While I'm updating it to reflect the star selector API, I'm also changing the default star selector from SecondMoment to ObjectSizeStarSelector (which I learned today is what the stack has been using by default for a while). """
"DM-5803","Story","SUIT",2,"fetchUrl is not handling post requests correctly.","""Parameters are not sent to the server when requests are posted via fetchUrl."""
"DM-5821","Bug","ci_hsc",3,"Intermittent fault building ci_hsc through Jenkins","""Occasionally (see e.g. [here|https://ci.lsst.codes/job/stack-os-matrix/label=centos-7/10437//console] and [here|https://ci.lsst.codes/job/stack-os-matrix/label=centos-6/9594//console]) the {{ci_hsc}} job in Jenkins fails, reporting:    The fault seems to be intermittent. Please fix it."""
"DM-5819","Story","Validation",2,"Incorporate Price suggestions to make `validate_drp` faster","""Increase the loading and processing speed of {{validate_drp}} following suggestions by [~price]    1. Don't read in footprints  Pass {{flags=lsst.afw.table.SOURCE_IO_NO_FOOTPRINTS}} to {{butler.get}}    2. Work on speed of calculation of RMS and other expensive quantities.  Current suggestions:  a. {{calcRmsDistances}}  b. {{multiMatch}}  c. {{matchVisitComputeDistance}}  d. Consider boolean indexing in {{afw}}'s {{multiMatch.py}}      Note that while this ticket will involve work to reduce the memory footprint of the processing, it will not cover work to re-architect things to enable efficient processing beyond the memory on one node."""
"DM-5823","Story","SUIT",0.5,"ECL_B1950 coordinate was not defined correctly","""The CoordSys.js defined ECL_B1950 incorrectly.  When I was testing WebGrid, the grid lines for  Ecliptic B1950 were not right.  Looked further, it was caused by wrong equinox value in its definition."""
"DM-5822","Bug","afw",2,"Afw fails unit test for convolve depending on compiler optimisation level","""On OSX 10.11.4 with Apple LLVM version 7.3.0 (clang-703.0.29) afw fails {{test/convolve.py}} with the following error when either {{-O0}} or {{-O1}} is enabled but works fine for {{-O2}} and {{-O3}}.    {code:bash}  tests/convolve.py    .....FF/Users/pschella/Development/lsst/code/afw/python/lsst/afw/image/testUtils.py:283: RuntimeWarning: invalid value encountered in isnan    nan0 = np.isnan(filledArr0)  /Users/pschella/Development/lsst/lsstsw/miniconda/lib/python2.7/site-packages/numpy/lib/ufunclike.py:113: RuntimeWarning: invalid value encountered in isinf    nx.logical_and(nx.isinf(x), ~nx.signbit(x), y)  /Users/pschella/Development/lsst/lsstsw/miniconda/lib/python2.7/site-packages/numpy/lib/ufunclike.py:176: RuntimeWarning: invalid value encountered in isinf    nx.logical_and(nx.isinf(x), nx.signbit(x), y)  F.F...  ======================================================================  FAIL: testSpatiallyVaryingAnalyticConvolve (__main__.ConvolveTestCase)  Test in-place convolution with a spatially varying AnalyticKernel  ----------------------------------------------------------------------  Traceback (most recent call last):    File """"tests/convolve.py"""", line 437, in testSpatiallyVaryingAnalyticConvolve      rtol = rtol)    File """"tests/convolve.py"""", line 290, in runStdTest      self.runBasicConvolveEdgeTest(kernel, kernelDescr)    File """"tests/convolve.py"""", line 317, in runBasicConvolveEdgeTest      doVariance = True, rtol=0, atol=0, msg=msg)    File """"/Users/pschella/Development/lsst/code/afw/python/lsst/afw/image/testUtils.py"""", line 201, in assertMaskedImagesNearlyEqual      testCase.fail(""""%s: %s"""" % (msg, """"; """".join(errStrList)))  AssertionError: basicConvolve(MaskedImage, kernel=Spatially Varying Gaussian Analytic Kernel using brute force) wrote to edge pixels: image planes differ: maxDiff=1.09176e+38 at position (73, 18); value=-1.09176e+38 vs. 2825.0; NaNs differ    ======================================================================  FAIL: testSpatiallyVaryingDeltaFunctionLinearCombination (__main__.ConvolveTestCase)  Test convolution with a spatially varying LinearCombinationKernel of delta function basis kernels.  ----------------------------------------------------------------------  Traceback (most recent call last):    File """"tests/convolve.py"""", line 556, in testSpatiallyVaryingDeltaFunctionLinearCombination      rtol = rtol)    File """"tests/convolve.py"""", line 290, in runStdTest      self.runBasicConvolveEdgeTest(kernel, kernelDescr)    File """"tests/convolve.py"""", line 317, in runBasicConvolveEdgeTest      doVariance = True, rtol=0, atol=0, msg=msg)    File """"/Users/pschella/Development/lsst/code/afw/python/lsst/afw/image/testUtils.py"""", line 201, in assertMaskedImagesNearlyEqual      testCase.fail(""""%s: %s"""" % (msg, """"; """".join(errStrList)))  AssertionError: basicConvolve(MaskedImage, kernel=Spatially varying LinearCombinationKernel of delta function kernels using brute force) wrote to edge pixels: image planes differ: maxDiff=9.06659e+36 at position (75, 29); value=9.06659e+36 vs. 2865.0    ======================================================================  FAIL: testSpatiallyVaryingGaussianLinerCombination (__main__.ConvolveTestCase)  Test convolution with a spatially varying LinearCombinationKernel of two Gaussian basis kernels.  ----------------------------------------------------------------------  Traceback (most recent call last):    File """"tests/convolve.py"""", line 523, in testSpatiallyVaryingGaussianLinerCombination      rtol = rtol)    File """"tests/convolve.py"""", line 290, in runStdTest      self.runBasicConvolveEdgeTest(kernel, kernelDescr)    File """"tests/convolve.py"""", line 317, in runBasicConvolveEdgeTest      doVariance = True, rtol=0, atol=0, msg=msg)    File """"/Users/pschella/Development/lsst/code/afw/python/lsst/afw/image/testUtils.py"""", line 201, in assertMaskedImagesNearlyEqual      testCase.fail(""""%s: %s"""" % (msg, """"; """".join(errStrList)))  AssertionError: basicConvolve(MaskedImage, kernel=Spatially Varying Gaussian Analytic Kernel with 3 basis kernels convolved using brute force) wrote to edge pixels: image planes differ: maxDiff=1.22472e+38 at position (74, 3); value=-1.22472e+38 vs. 2878.0; NaNs differ    ======================================================================  FAIL: testTicket873 (__main__.ConvolveTestCase)  Demonstrate ticket 873: convolution of a MaskedImage with a spatially varying  ----------------------------------------------------------------------  Traceback (most recent call last):    File """"tests/convolve.py"""", line 623, in testTicket873      rtol = rtol)    File """"tests/convolve.py"""", line 290, in runStdTest      self.runBasicConvolveEdgeTest(kernel, kernelDescr)    File """"tests/convolve.py"""", line 317, in runBasicConvolveEdgeTest      doVariance = True, rtol=0, atol=0, msg=msg)    File """"/Users/pschella/Development/lsst/code/afw/python/lsst/afw/image/testUtils.py"""", line 201, in assertMaskedImagesNearlyEqual      testCase.fail(""""%s: %s"""" % (msg, """"; """".join(errStrList)))  AssertionError: basicConvolve(MaskedImage, kernel=Spatially varying LinearCombinationKernel of basis kernels with low covariance, using brute force) wrote to edge pixels: image planes differ: maxDiff=3.19374e+38 at position (1, 46); value=3.19374e+38 vs. 2774.0    ----------------------------------------------------------------------  Ran 13 tests in 43.252s    FAILED (failures=4)  The following tests failed:  /Users/pschella/Development/lsst/code/afw/tests/.tests/convolve.py.failed  1 tests failed  scons: *** [checkTestStatus] Error 1  scons: building terminated because of errors.  {code}"""
"DM-5838","Story","Firefly",0,"3-color image label change","""When generating 3-color image, the label for the image display should 'Project 3-color', i.e.   WISE 3-color, 2MASS 3-color ...  """
"DM-5837","Story","ctrl_pool|pipe_drivers",2,"Document pipe_drivers","""Please provide a minimal level of documentation for {{pipe_drivers}}, to include:    * A {{doc}} directory with the usual content so that docstrings get generated by Doxygen;  * A package overview;  * All docstrings should be appropriate for parsing by Doxygen (ie, should start with {{""""""""""""!}} where necessary)."""
"DM-5835","Story","SUIT",2,"Prepare a draft of the SUIT deployment timeline","""Prepare a draft schedule, with some detail for 2016-2017, for deployments of the SUIT into (test) production, including the datasets that will be served."""
"DM-5832","Epic","Systems Engineering",2,"LSE-140 post-CCB implementation","""Following CCB approval of LSE-140, perform minor document work required for full implementation (application of standard cover page, change log, etc.)."""
"DM-5830","Story","SUIT",3,"Level 3 requirements flowdown","""Document the flowdown of Level 3-related requirements from SRD, LSR, OSS, and DMSR."""
"DM-5829","Story","SUIT",2,"Create outline of Level 3 ConOps","""Create an outline of the sections of the Level 3 ConOps document"""
"DM-5841","Story","Nebula OpenStack",1,"unable to list nebula lsst project users","""Currently, [with some difficulty] it is possible to discover the {{user_id}} that created an instance (might be possible for other resources as well) but it is not possible to map this back to a username / person.  This can make it difficult to 'self police' instances.    The administrative API endpoints are not publicly accessible and I doubt any end user has the appropriate permission. """
"DM-5840","Story","Nebula OpenStack",1,"instance limit low vs available cores","""The LSST project is currently at 81/100 instances but there are over 200 cores unused.  Is it possible to increase the instance limit or are we being encouraged to use large instance flavors?"""
"DM-5839","Story","Nebula OpenStack",1,"horizon console interface broken","""It appears that at some point in the last few months the horizon console interface has stopped working.  I am still able to access the console log output via the API/CLI."""
"DM-5854","Story","SUIT",1,"Java array index out of bound error in VisSeverCommand.java","""The class FileFluxCmdJson in VisServerCommand.java is calling       However, when the mouse is outside the image, the VisServerOps.getFileFlux(fahAry, pt) returns:    It is fine for a single band.  However, for 2 or 3 bands, the for loop below caused the index out of bound error because res is an array of length=1 and the expected res is an array of length=no of bands.      Thus,  res\[cnt++\] caused array index out of bound error.     To fix this issue, the for loop is changed as below:      When the mouse is outside the image, the res returns a new String\[\]\{PlotState.NO_CONTEXT\}, it is added to the JSONObject only once.  """
"DM-5849","Story","SUIT",2,"Investigate Ginga and Glueviz visualization tools","""Ginga and Glue (glueviz) are community visualization tools in Python. Become familiar with the capabilities of both, thinking from the point of view of using Firefly for the display but using Python for many other things."""
"DM-5848","Story","SUIT",2,"Investigate Jupyter internals, interactive widgets","""In preparation for linking Jupyter notebooks with Firefly and other SUIT components, read Jupyter documentation. Learn how to build a sample widget or interactive dashboard in the Jupyter framework"""
"DM-5847","Bug","Developer Infrastructure",2,"libxml build issue with mpich on OS X","""On OS X with Xcode installed {{mpich}} fails to build because it can not locate the libxml include files:      with {{pkg-config}} 0.29.1 installed. The problem is that {{configure}} determines that {{libxml-2.0}} is available and is installed into {{/usr}} with a CFLAGS of {{-I/usr/include/libxml2}}. {{configure}} does not itself test whether those parameters are reasonable. With Xcode there are no files installed into {{/usr/include}} and {{clang}} knows to look in specific SDK locations. When {{mpich}} builds it assumes that {{libxml2}} can be found but fails to find it.    Strangely, {{pkg-config}} v0.28 does not seem to be able to find {{libxml-2.0}} so there is no issue.    One solution is to install the Command Line Tools but it might be more portable to attempt to disable {{libxml2}}.  """
"DM-5870","Bug","obs_subaru|testdata_subaru",0.5,"Update testdata_subaru to support calib changes","""Merging DM-5124 broke obs_subaru because the test data in testdata_subaru wasn't updated.  Fix it."""
"DM-5859","Story","SUIT",2,"Table: Add keyboard navigation","""- Added arrow up/down to move between rows.  - Added page up/down to move between pages.    - Fixed table loading mask not showing  - Fixed PagingBar rendering more than it should  - Fixed annoying StandardView missing unique key warning"""
"DM-5883","Story","obs_decam",1,"Include more information in DECam registry","""obs_decam originally included 'object' and 'proposal' fields in the registry but these were removed at some point.  Putting them back would allow users to more easily select data.    I also suggest surveying the headers for additional useful fields."""
"DM-5898","Bug","Developer Infrastructure",1,"Python EUPS package can use $PYTHON","""The {{python}} eups package has a script that checks that the python being used is version 2.7. This script can optionally check {{$PYTHON}} rather than the python in the path but I am confused as to what that test is going to do for us. The problem is that {{sconsUtils}} uses {{python}} and most of the shebangs use {{/bin/env python}} (although shebang rewriting on all platforms could help with that). I think the check script should have the {{$PYTHON}} support removed due to excessive confusion.    It would also help if the check script worked with python 3 so that the wrong python could be caught."""
"DM-5893","Story","Stack Documentation and UX",0.5,"LSST the Docs Fastly should redirect /en/latest/ to /","""Previously we deployed documentation on Read the Docs. By default, Read the Docs would show the master version of documentation on """"/en/latest/"""". Many links with that endpoint may already exist. We should configure Fastly to redirect such paths to """"/""""."""
"DM-5889","Story","sconsUtils",0.5,"Suppress gcc warnings about ""unused local typedefs""","""We should add {{\-Wno\-unused\-local\-typedefs}} to our gcc options.  This cleans up the build significantly, because there's a flood of warnings of this type coming from boost.  If we suppress those, it might become possible to notice warnings that we care about."""
"DM-5887","Story","Continuous Integration",0.5,"lsstswBuild.sh --print-fail flag broken","""The {{--print-fail}} flag appears to broken for at least some failure modes.    https://github.com/lsst-sqre/buildbot-scripts/blob/master/lsstswBuild.sh#L145    Eg.    https://ci.lsst.codes/job/stack-os-matrix/label=centos-6/10673//console"""
"DM-5885","Story","Qserv",3,"Create a JSON file for monitoring stack","""Create a JSON or YAML file with:    - Qserv version  - libraries/deps version  - other idea welcome    This will interesting """"GROUP BY"""" in monitoring tool (performance for each Qserv or xrootd version for example)"""
"DM-5915","Story","afw",8,"Decide how to rework afw:Wcs guts with AST","""Following the to-be-written recommendation for DM-4157, we plan to rework the guts of afw:Wcs to use AST. We need to decide how afw:Wcs will use AST, whether as a wrapper or as a complete replacement with AST.    The product is a design"""
"DM-5911","Improvement","obs_base",1,"Fix circular references in Mapper objects","""Whilst running tests with pytest and the new file descriptor leak checker it became clear that Mapper objects were not freeing their resources when they were deleted. In particular, the registry objects remained and the associated sqlite database files were opened. This led to pytest running out of file descriptors when large test suites were being executed.    The problem turns out to be the dynamically created map functions. These are created as functions (not bound methods) attached to an instance. Since they are not bound methods the instance object (self) has to be passed in to closure. This leads to self containing a reference to a function that contains a reference to self and this prevents the Mapper from ever being garbage collected (leading to all the resources being retained).    A short term fix is pass the mappers into the closures using {{weakref}}.    Eventually it would be nice to consistently make the {{map_}} items bound methods rather than attaching them as functions but that is beyond the scope of this ticket."""
"DM-5904","Story","obs_subaru",2,"Create focus script","""In DM-3368, we stripped out the focus calculation since it's not camera-generic, and the scatter/gather isn't necessary for general processing.  We need to reinstate the focus calculation in its own scatter/gather script."""
"DM-5900","Improvement","Developer Infrastructure",0.5,"Create psutil EUPS package","""Add the python {{psutil}} package to the stack as {{python_psutil}}."""
"DM-5899","Story","obs_decam",0,"Support LSST-produced calibs","""obs_decam currently uses a {{%(path)s\[%(ccdnum)d\]}} template for its calibs (bias, dark, flat, fringe).  This is desirable in order to support calibs provided from external sources (e.g., NOAO).  However, our calib construction code does not support such a path ({{path}} cannot be inferred for new data, and we can't write MEFs from multiple processes).  We believe the best path forward is to split the {{DecamMapper}} into two mappers, one supporting calibs from external sources and one supporting calibs we construct ourselves.  The alternative is to copy the external calibs to match a template like {{BIAS/%(date)s/BIAS-%(date)s-%(ccdnum)02d.fits}}, which means breaking apart the MEFs.    I suggest also moving the defects into the obs_decam package because they're required for use, small and we don't have code to regenerate them."""
"DM-5935","Story","Developer Infrastructure",1,"Package Astropy for the stack","""Once RFC-178 is adopted Astropy needs to be packaged in an EUPS container. Given the complexity of Astropy dependencies the packaging will be done as for {{numpy}} and {{scipy}} by checking that Astropy is available (v1.1 will be the minimum version)."""
"DM-5934","Story","Stack Documentation and UX",1,"Update developer guide with Astropy guidance","""Once RFC-178 is adopted the developer guide has to be updated to include guidance as to how Astropy can be used in the stack (similar to how Boost is documented)."""
"DM-5933","Story","jointcal",2,"Replace jointcal.StarSelector with meas_algorithms.starSelector","""jointcal has its own custom star selector. This should be removed and replaced with a star selector based on meas_algorithms.starSelector. A good choice might be meas_algorithms.objectSizeStarSelector."""
"DM-5927","Story","Nebula OpenStack",2,"API errors when trying to start up multiple instances","""I am attempting to start up 20 {{m1.medium}} instances without floating IPs to take available of the new instance cap from DM-5840.  This consistently fails after starting a few instances with an HTTP 403.        Of the instances that do manage to start, most end up in an error state with.            """
"DM-5926","Story","Nebula OpenStack",1,"networking in strange state for newly created instances","""When starting a new instance, occasionally something strange seems to happen with the  network setup.  The instance will come up but is inaccessible (icmp, ssh). When this happens, the console log shows that a DHCP address was obtained and cloud-init injected ssh-keys, so it isn't a total network setup failure.    I have seen this happen a few times in the last couple of weeks but I can't reliably reproduce it.  I'm wondering if neutron is logging anything interesting when this happens.    This failure mode happened  again a few minutes ago with 7adffa82-7221-454c-acfe-5f21cdd34ea8.  Which I killed and recreated as instance b6f64981-099b-46e5-a27e-e3694372f447 with the same private IP address.   The new instance is accessible as expected."""
"DM-5922","Story","afw",8,"Rework camera geometry to use the replacement for XYTransform","""As part of overhauling XYTransform we will likely need to replace the way we describe the transformations supported by camera geometry and {{Detector}}. This is likely to include a new way of describing the coordinate frames (e.g. {{PIXEL}}. {{FOCAL_PLANE}} and {{PUPIL}}).    If we adopt AST (as seems likely) then these frames will be AST {{Frames}}, the transforms will be AST {{Mappings}} and the collection described by {{Camera}} and {{Detector}} will be one or more AST {{FrameSets}}.    An RFC for the redesigned API for camera geometry will be required and this ticket is to implement the resulting design."""
"DM-5921","Bug","ci_hsc",0.5,"Clarify how to work with ci_hsc's astrometry_net_data","""ci_hsc's {{README.rst}} contains [a note|https://github.com/lsst/ci_hsc/blob/87b6ecb1cc0157cac8dafb356520f49f971bb1ec/README.rst#reference-catalog] on declaring & setting up the included reference catalogue data.    I believe this was rendered obsolete by DM-5135, which automatically sets up the reference catalogue when ci_hsc itself is set up. Attempting to follow the documentation therefore produces confusing warning messages, and may break things.    Please check if my understanding is correct and, if so, fix the documentation."""
"DM-5941","Story","Nebula OpenStack",2,"Private network not available across all instances","""I'm setting up an ELK system. Part of that is an Elasticsearch system. When I bring up the system the private network is bisected. I attempted creating a security group, in case that was a problem but it didn't help. Note that the work around is to create security groups or use a firewall and use floating ips. This is far from ideal. I think the right solution is to use the private network.    Example:    First section {{p-es-1}} {{p-es-3}} {{p-es-k}}    {code:bash}  vagrant@es-1:~$ ifconfig  ens3      Link encap:Ethernet  HWaddr fa:16:3e:47:28:a7            inet addr:10.0.42.30  Bcast:10.0.42.255  Mask:255.255.255.0            inet6 addr: fe80::f816:3eff:fe47:28a7/64 Scope:Link            UP BROADCAST RUNNING MULTICAST  MTU:1454  Metric:1            RX packets:363265 errors:0 dropped:0 overruns:0 frame:0            TX packets:304215 errors:0 dropped:0 overruns:0 carrier:0            collisions:0 txqueuelen:1000            RX bytes:95396177 (95.3 MB)  TX bytes:238466304 (238.4 MB)    lo        Link encap:Local Loopback            inet addr:127.0.0.1  Mask:255.0.0.0            inet6 addr: ::1/128 Scope:Host            UP LOOPBACK RUNNING  MTU:65536  Metric:1            RX packets:850 errors:0 dropped:0 overruns:0 frame:0            TX packets:850 errors:0 dropped:0 overruns:0 carrier:0            collisions:0 txqueuelen:1            RX bytes:138411 (138.4 KB)  TX bytes:138411 (138.4 KB)    vagrant@es-1:~$ ping 10.0.42.32  PING 10.0.42.32 (10.0.42.32) 56(84) bytes of data.  64 bytes from 10.0.42.32: icmp_seq=1 ttl=64 time=0.284 ms  64 bytes from 10.0.42.32: icmp_seq=2 ttl=64 time=0.266 ms  64 bytes from 10.0.42.32: icmp_seq=3 ttl=64 time=0.265 ms  64 bytes from 10.0.42.32: icmp_seq=4 ttl=64 time=0.302 ms  ^C  --- 10.0.42.32 ping statistics ---  4 packets transmitted, 4 received, 0% packet loss, time 2998ms  rtt min/avg/max/mdev = 0.265/0.279/0.302/0.019 ms  vagrant@es-1:~$ ping 10.0.42.34  PING 10.0.42.34 (10.0.42.34) 56(84) bytes of data.  64 bytes from 10.0.42.34: icmp_seq=1 ttl=64 time=0.333 ms  64 bytes from 10.0.42.34: icmp_seq=2 ttl=64 time=0.325 ms  64 bytes from 10.0.42.34: icmp_seq=3 ttl=64 time=0.322 ms  64 bytes from 10.0.42.34: icmp_seq=4 ttl=64 time=0.319 ms  ^C  --- 10.0.42.34 ping statistics ---  4 packets transmitted, 4 received, 0% packet loss, time 2998ms  rtt min/avg/max/mdev = 0.319/0.324/0.333/0.022 ms  vagrant@es-1:~$ ping 10.0.42.31  PING 10.0.42.31 (10.0.42.31) 56(84) bytes of data.  From 10.0.42.30 icmp_seq=1 Destination Host Unreachable  From 10.0.42.30 icmp_seq=2 Destination Host Unreachable  From 10.0.42.30 icmp_seq=3 Destination Host Unreachable  ^C  --- 10.0.42.31 ping statistics ---  4 packets transmitted, 0 received, +3 errors, 100% packet loss, time 3017ms  pipe 3  vagrant@es-1:~$ ping 10.0.42.33  PING 10.0.42.33 (10.0.42.33) 56(84) bytes of data.  From 10.0.42.30 icmp_seq=1 Destination Host Unreachable  From 10.0.42.30 icmp_seq=2 Destination Host Unreachable  From 10.0.42.30 icmp_seq=3 Destination Host Unreachable  ^C  --- 10.0.42.33 ping statistics ---  4 packets transmitted, 0 received, +3 errors, 100% packet loss, time 3008ms  pipe 3  vagrant@es-1:~$ ping 10.0.42.35  PING 10.0.42.35 (10.0.42.35) 56(84) bytes of data.  From 10.0.42.30 icmp_seq=1 Destination Host Unreachable  From 10.0.42.30 icmp_seq=2 Destination Host Unreachable  From 10.0.42.30 icmp_seq=3 Destination Host Unreachable  ^C  --- 10.0.42.35 ping statistics ---  5 packets transmitted, 0 received, +3 errors, 100% packet loss, time 3999ms  pipe 3      This can be reproduced by sourcing your OpenStack credentials and running this [{{Vagrantfile}}|https://gist.github.com/jmatt/7b6eb6a042c4e63531d40d1a68069f33]. Use {{vagrant ssh p-es-1}} to connect to the {{p-es-1}} instance.  """
"DM-5940","Story","SUIT",8,"Create new build based on the converted firefly code.","""- remove all of the gwt code except for a few remaining files.  - create separate build for the new firefly viewer, leaving the old fftools as it was before the JS conversion.  - repackage files as needed moving forward."""
"DM-5939","Bug","afw",0.5,"Pre-release versions of matplotlib 2.0 break afw unit tests","""In the afw rgb unit test, testWriteStarsLegacyAPI checks to make sure that a file name with an unknown extension raises a value error. In current version of matplotlib, saving a file with an unknown extension causes this error:      In matplotlib 2.0 prerelease the file is saved as a png when an unknown extension is specified. Since the write call success the unit test fails as it is expecting a failure.     If nothing depends on this behavior, the unit test should probably be removed."""
"DM-5936","Bug","afw",0.5,"Make afw rgb unit test PEP440 compliant for matplotlib check","""If a user has a version of matplotlib installed from a git clone, the afw rgb unit test fails at the matplotlib version check. The versioning scheme for this type of install is determined by pep 440. Make the unit test properly handle this type of version comparison."""
"DM-5973","Story","Developer Infrastructure",5,"Update developer guide with pytest guidance","""Now that DM-5561 explains how to migrate to pytest compatibility the developer guide must be updated to state how to use pytest in unittests."""
"DM-5979","Story","pex_logging|pipe_base|utils",2," tests in testArgumentParser.py fail Jenkins run-rebuild on nfs","""(1) {{testOutputs}} fails because paths are compared literally  Jenkins run-rebuild #139 failed with pipe_base  https://ci.lsst.codes/job/run-rebuild/139//console      Please make the comparison more robust.     (2) File descriptor leaks  Jenkins run-rebuild #138 failed with pipe_base  https://ci.lsst.codes/job/run-rebuild/138//console        This test passes on local disk.  """
"DM-5986","Story","SUIT",3,"Use sagas in place of side-effects in chart-related controllers ","""Replace side-effects with saga and clean-up chart related controllers (TableStats, XYPlot and Histogram)."""
"DM-6051","Story","ci_hsc",2,"Add extendedness vs. star selector test to single-visit validation in ci_hsc","""ci_hsc has a test that verifies that extendedness as measured on coadds broadly agrees with the star selection done for PSF estimation on individual frames.  This tests a bunch of stuff, including aperture corrections on the coadds and propagation of flags from visits to coadds.    It doesn't test that aperture correction vs. extendedness logic is correct in processCcd.py, but just copying this test to the appropriate validation function in ci_hsc should do the trick.  This is currently broken, but should be fixed in DM-5877."""
"DM-6050","Story","SUIT",2,"Table caching optimizations","""We need to avoid duplicate requests which result from minor differences in TableRequest parameters, which are not used to get data.  For example, loading catalog table, which triggers table statistics, and then getting an XY plot, results in 3 requests, returning identical data.    1. RequestClass=ServerRequest; *tbl_id=tbl_id-1;* UserTargetWorldPt=10.68479;41.26906;EQ_J2000;m31;ned; SearchMethod=Cone; catalog=wise_allwise_p3as_psd; RequestedDataSet=wise_allwise_p3as_psd; radius=200; use=catalog_overlay; catalogProject=WISE    2. RequestClass=ServerRequest;RequestedDataSet=wise_allwise_p3as_psd; catalog=wise_allwise_p3as_psd; use=catalog_overlay; UserTargetWorldPt=10.68479;41.26906;EQ_J2000;m31;ned; catalogProject=WISE; radius=200; SearchMethod=Cone    3. RequestClass=ServerRequest; *tbl_id=xyplot-tbl_id-1;* catalog=wise_allwise_p3as_psd; use=catalog_overlay; UserTargetWorldPt=10.68479;41.26906;EQ_J2000;m31;ned; SearchMethod=Cone; RequestedDataSet=wise_allwise_p3as_psd; catalogProject=WISE; radius=200; *decimate=decimate=ra,dec,10000,1,,,,*    The difference between 1 and 2 is tbl_id parameter. The difference between 2 and 3 is tbl_id and decimate parameters. As well as the order of the parameters. None of which change the catalog search result.    Test Case: Test Searches, Test catalog, AllWISE Source, radius=200"""
"DM-6048","Story","Validation",3,"Bundle up more HSC data for validate_drp","""We would like to include a larger set of HSC data for validation.  I tested this while in Tucson.  My working dir was {{/tigress/pprice/frossie}}.  The raw and processed data should be stuffed into validation_data_hsc"""
"DM-6045","Bug","afw|pipe_tasks",2,"Nominal PSF required by processCcd","""After the processCcd refactor, non-sky images, or, in general, images for which an initial PSF estimate cannot be made, cause {{ProcessCcdTask}} to fail if {{config.doCalibrate=True}}.    To work around this, I put a dirty hack at line 157 of my {{processCcd.py}}:    to ensure that there would always be kind of PSF. This should be redone in a way that someone who knows what they're doing approves of."""
"DM-6044","Improvement","meas_algorithms",0,"Add LoadReferenceObjectsTask to task documentation page","""The documentation for {{LoadReferenceObjectsTask}} should show up on the task documentation page, despite its being an abstract base class."""
"DM-6041","Story","SUIT",1,"Functional use cases for light curve ","""Work with Vandana Desai (IRSA) to tabulate science use cases for tools. Then transform the science use cases to functional use cases (""""this is how we want the tool/interface to behave"""").    This work is  to identify common functional and scientific use cases between PTF/ZTF and LSST to inform LSST on how the SUIT web portal might be organized for user interaction with LSST data. """
"DM-6037","Story","obs_monocam",3,"Reduce sky data from USNO monocam run","""Using the master calibs produced in DM-6036, push all the monocam data through processCcd.    Others will run sanity checks on the output (initial astrometry & photometry). From there I believe people will look at using the data to test jointcal & sim_astrom etc, but this ticket just related to the initial reduction.    As more data comes in from the 2nd telescope, a little further hacking may be necessary to keep everything running. Some of this will likely be hacky or need one-off solutions/header modification, hence the higher-than-normal number of story points assigned to what one might expect to be an hour-long job."""
"DM-6036","Story","obs_monocam",2,"Produce and ingest master calibs for USNO monocam data.","""Use the construct*.py scripts added to pipe_drivers to produce temporally relevant master biases, darks, flats (and fringe frames?) for the recent USNO observing with monocam.    A small amount of hacking will be required due to the fact that the current ingestion model assumes that each CCD frame has a USNO counterpart which tells about the telescope pointing etc, but the bias frames do not have these.    Once the master calibs are produced, get them ingested."""
"DM-6030","Story","Calibration Products Production",8,"Investigate possibilty of cosmic ray muons (etc) for precision gain calibration","""In the era of CBPs, we care about absolute system throughput, and thus need to accurately know the gain of amplifiers in the CCDs.    Initially, this can be done by lab-based Fe55 characterisation (modulo the non-linearity, though that itself will need to be need to be characterised and corrected for), but changes in the relative gains of the various amplifiers need to be monitored, and this must be done in a way that is not degenerate with the optical transmission in any way.    Theoretically it should be possible to use cosmic ray muon tracks, and tracks from radioisotope contamination of the glass/dewar, to measure the (change in the) relative gains of the amplifiers.    Early work has shown that this does work in principle, but this ticket is for some further effort to see whether this method can provide the necessary accuracy given the amount of data available remains to be seen.    This ticket would normally need to be significantly more points, but as it builds on earlier work, it can, at least for initial results, be done quite cheaply.    Initial investigation will inform further work, which will be carried out in S17 as DM-8276."""
"DM-6029","Story","SUIT",1,"Error message is not shown","""The error message is not showing consistently when mouse is over tha exclamation icon."""
"DM-6028","Story","SUIT",2,"Validation is not performed on unchanged fields","""Currently, validation is performed only if a field has changed. We need to be able to validate all fields on form submit.    The issue is not limited to initial (ex. empty) value being invalid. The invalid message is lost when a field is unmounted/re-mounted.    You can test the following way:  - http://localhost:8080/firefly/;a=layout.showDropDown?view=AnyDataSetSearch  - Open chart settings, enter 1000 into X/Y ratio - the field is shown as invalid  - Switch to histogram and back, the invalid message is gone, the field appears to be valid    Another test case is Example Dialog tab 'X 3', 'X 3'  tab test field initial value 88 is invalid (it should be between 22 and 23), but it appears valid. """
"DM-6026","Story","SUIT",2,"Make it possible to distinguish TABLE_NEW_LOADED actions triggered by sort","""It would be beneficial to have in the TABLE_NEW_LOADED payload a  trigger field, which would differentiate actions triggered by sort (where  data do not change, only their order) or filter from other loads. We don't  need to reload table statistics or histogram on sort. But we do need to to  reload them on filter.      created TABLE_SORT action to distinguish sorting from filtering.  sorting should not reload xyplot nor catalog overlay.    Also:  - disable history when in api mode.  - ensure tableMeta.source reflects the file on the server.  - fix TablePanelOptions not resetting columns selection.  - remove 'Fits Data' tab when no images available.  - fix 'Coverage' appearing when it should."""
"DM-6022","Story","SUIT",3,"Lazy load related chart data on table data update","""When new table data received, the related chart data should be updated only for the components on display. Hidden components' data should be lazily updated when a component becomes visible."""
"DM-6054","Story","supertask",2,"Minor updates in suptertask from following DMTN-002","""Some examples in the DMTN-002 seem slightly out of date.    Update supertask documentation and code to catch up with some recent developments in the stack. """
"DM-6067","Epic","butler",40,"S17 Butler DB storage","""Initial implementation to be read-only, DB -> in-memory AFWTable.  DB connection info to reside in repository config.  Query substitution elements to be taken from data id."""
"DM-6063","Story","pipe_tasks",1,"Fix how aperture correction is applied","""[~lauren] committed a fix Jan 15 to how aperture correction is applied that I accidentally lost when refactoring in DM-4692. https://github.com/lsst/pipe_tasks/commit/d904e3d188698b4f57bf3dad1516b0bf201078f5 Restore the fix.    The need for this fix suggests a design flaw in measurement that will be fixed as part of DM-5877"""
"DM-6078","Bug","meas_base",2,"Aperture correction fails to measure a correction for the final plugin in the list and reports misleading errors","""Since the refactoring of DM-4692, runs of *processCcd.py* detail the following in their logs:    {code:title=With base_PsfFlux and base_GaussianFlux plugins registered}  processCcd.charImage.detectAndMeasure.measureApCorr WARNING: Only 0 sources for calculation of aperture correction for 'base_PsfFlux'; setting to 1.0  processCcd.charImage.detectAndMeasure.measurement: Measuring 65 sources (65 parents, 0 children)   processCcd.charImage.detectAndMeasure.measurement.applyApCorr: Applying aperture corrections to 1 flux fields  processCcd.charImage.detectAndMeasure.measurement.applyApCorr: Use naive flux sigma computation  ...  processCcd.calibrate.detectAndMeasure.measurement.applyApCorr: Applying aperture corrections to 2 flux fields  processCcd.calibrate.detectAndMeasure.measurement.applyApCorr: Use naive flux sigma computation  processCcd.calibrate.detectAndMeasure.measurement.applyApCorr WARNING: Could not find base_GaussianFlux_flux or base_GaussianFlux_fluxSigma in apCorrMap      I can confirm that for the latter, running HSC data with the fix on DM-6063, the aperture corrections are being measured and applied for the PsfFlux and GaussianFlux measurements, but NOT for the KronFlux measurements.      Looking at the output from the current """"expected"""" values for the {{lsst_dm_stack_demo}} we see that there is an offset in the Psf-Gaussian fluxes, implying the Gaussian fluxes are not being measured (and hence not applied):  !demo_current.png|width=500!    From this I conclude that the aperture corrections are indeed being measured for all but the final entry in the plugin list.  This implies that the report of """"Only 0 sources for calculation of aperture correction for 'xxx_xxFlux'; setting to 1.0"""" is incorrect for all but the final plugin measurement.    The demo previously successfully calculated aperture corrections and, after the logic fix of DM-4836, applied them in the correct order:  !demo_previous.png|width=500!    The sources of these issues and fixes for them are the goal of this issue."""
"DM-6077","Improvement","meas_algorithms",1,"Change PSF determiners into tasks","""PSF determiners are already configurables, and some benefit from having a log. Take the logical next step and make them instances of {{lsst.pipe.base.Task}}."""
"DM-6075","Improvement","pipe_base|pipe_tasks",2,"Document the need for abstract base tasks for tasks","""As part of RFC-183 document the fact that variant tasks should have a common abstract base class that defines the API. If we add future tasks that we feel are likely to have variants, then we should create an abstract base class.    Candidates include star selectors, PSF determiners and ISR tasks.    Note that this applies to tasks LSST provides in its stack, not to variants users produce and other obscure one-off code.    Also document the desire that tasks with anticipated many variants, such as star selectors, and PSF determiners should be in registries. This explicitly excludes tasks such as ISR where only one task is likely to be useful for a given set of data.  """
"DM-6074","Improvement","pipe_base",2,"Add RegistryField support to Task.makeSubtask","""As part of implementing RFC-183 add support for tasks specified in {{lsst.pex.config.RegistryField}} to {{lsst.pipe.base.Task.makeSubtask}}  """
"DM-6100","Bug","afw",0.5,"afw/tests/rgb.py fails due to .ttf files","""afw/tests/rgb.py fails for me with the below error. We likely shouldn't be trying to track system resources like fonts, as we don't have any control over them.    """
"DM-6084","Story","meas_algorithms",0,"meas_algorithms cannot be built with XCode 7.2.1","""The LSST stack fails to build on OS X 10.10 """"Yosemite"""" using XCode 7.2.1, the last version that is compatible with that operating system. I have attached a build log from [~wmwood-vasey].    [~smonkewitz] suggests trying the following (HipChat UW DM room, 2016-05-12 18:12 Pacific): in BinnedWcs.h change:    to:      with the following explanation (HipChat SQuaRE room 2016-05-12  18:26 Pacific):    {{enable_shared_from_this}} usually holds a {{weak_ptr}} to this internally, and the first {{shared_ptr}} to manage an instance is assigned to the internal {{weak_ref}}. It looks to me like this particular version of the STL only allows {{std::shared_ptr<A>}} to be assigned to a {{weak_ptr<B>}} if {{A}} is implicitly convertible to {{B}}. In this case the first {{shared_ptr}} to manage the {{BinnedWcs}} is a {{shared_ptr<Wcs>}}, and I think a static cast is required to get from {{Wcs *}} to {{BinnedWcs *}}, so the compiler barfs."""
"DM-6083","Story","SUIT",1,"Enable websocket client to pickup channel parameter from url","""send websocket channel information via url.  keep channel information on browser reload.    This is needed for Firefly Python API and external (when Firefly viewer is invoked trough URL) API.  """
"DM-6082","Improvement","Stack Documentation and UX",1,"Add Sublime Text configuration tips to Developer Documentation","""[~rowen] and [~Parejkoj] have some good tips about setting up Sublime Text.  [~jsick] suggested that we add these configuration tips to the Developer Documentation.    http://developer.lsst.io/en/latest/#part-tools    Both want to include info about recommended packages, but also the linter configurations to support the DM styles.    I paste in here various helpful parts from the HipChat Software Development room discussion of this.  Both verbatim, and summarized.    1. Install {{Package Control}}    2. Packages:  {{Git}}, {{GitGutter}}, {{SideBarEnhancements}}, {{SublimeLinter}}, {{SublimeLinter-flake8}}, {{SublimeLinter-html-tidy}}, {{SumNumbers}}, {{Gist}}, {{BracketHighlighter}}, {{TrailingSpaces}}, {{Trimmer}}, {{OmniMarkupPreviewer}}, {{ReStructuredTextImproved}}, {{MarkDown Editing}}, {{Colorsublime}}    3. Themes:  {{Sunburst}} color scheme    * VIM users:  {{Vintageous}}  + Mac OS X configuration:  {{defaults write com.sublimetext.3 ApplePressAndHoldEnabled -bool false}}  so that holding down 'j' moves downward.  Note that {{Vintageous}} is not a complete implementation of {{vim}}, but it at least allows enough basics so that one doesn't go crazy switching back and forth.    link the {{subl}} command to {{/usr/local/bin}}     Quick Tips:  """"option-select (to select blocks) and select something then cmd-D are both extremely useful for modifying lots of things at once.""""    """"Similarly, ctrl-shift-up/down arrow.""""    """"cmd-click on multiple lines to have multiple synchronized cursors""""    Configurations:  1. [~rowen]'s SublimeText Preferences file: https://jira.lsstcorp.org/secure/attachment/27846/Preferences.sublime-settings  2. Configuration {{flake8}} so that it works in the linting can take a bit of work if {{flake8}} isn't in your default path.  See SublimeLinter.sublime-settings attachment for [~rowen]'s configuration: https://jira.lsstcorp.org/secure/attachment/27845/SublimeLinter.sublime-settings    The above are useful, but we'll need someone to detail the linter stuff more."""
"DM-6112","Story","meas_extensions_photometryKron",0.5,"Provide minimal documentation for meas_extensions_photometryKron","""Please provide a minimal level of documentation for meas_extensions_photometryKron, to include:  * A doc directory with the usual content so that docstrings get generated by Doxygen;  * A package overview;  * All docstrings should be appropriate for parsing by Doxygen (ie, should start with {{""""""""""""!}} where necessary).  """
"DM-6111","Story","Stack Documentation and UX",1,"Browsers should cache editions for a shorter time period than Fastly","""Currently we set {{Cache-Control: max-age=31536000}} so that Fastly caches uploads from LTD Mason for a year on its POPs. This has the side-effect of also having browsers potentially cache documentation on the client for up to a year. In practice, browsers churn through their cache space more quickly, but I've noticed that Safari has no cap on its cache space, and therefore can hold onto pages for a long time.    The solution is to set a {{Surrogate-Control}} max age to 1 year, and have {{Cache-Control: max-age=0, private, must-revalidate}}. This will be done on LTD Keeper during the copy phase of a build into an edition (since it is reasonable for a client to cache a build forever), but then give us the flexibility to update an edition instantly.    In the future we may want a more nuanced solution where CSS and JavaScript, for example, are cached longer on the browser."""
"DM-6128","Story","SUIT",1,"Expanded view not doing fit/fill consistently ","""Expanded view not doing fit/fill consistently. Sometimes is seems to fit/fill and resize it correctly, other times it stays at the zoom level.  It should always fit/fill and change zoom level with resize when in expanded mode. (unless zoom type is FORCE_STANDARD)."""
"DM-6127","Story","ngmix",1,"ngmix has no license","""ngmix does not have a license, which means we shouldn't distribute it. Work with Erin Sheldon to see if he is willing to add one."""
"DM-6126","Story","Developer Infrastructure|stack release",1,"LSST's version of Astrometry.net doesn't build on Ubuntu 16.04","""Reproduced building on Ubuntu 16.04.    https://groups.google.com/forum/#!topic/astrometry/aDCjhfMYhpE    The current version (0.67) does build successfully standalone.    These two patches fix 0.5.0:  https://github.com/dstndstn/astrometry.net/commit/7ded70917d7cf1efa1d3af6d0da8b336ebbf9d92.diff and https://github.com/dstndstn/astrometry.net/commit/7c65b3cefc4f33c59af90c1a40b5f246002cdf28.diff  Though only the first one is needed, I believe the second one is part of the build already."""
"DM-6139","Story","SUIT",2,"Change server side hardcopy code to work better with the non-GWT call","""The server hard to make a hard copy now takes a StaticDrawInfo object.  We want to use only a region array.  Change the server side to support this."""
"DM-6138","Story","SUIT",2,"Change Fields groups to handle other actions better","""The fields group can be out of sync with actions if they are trying to use store data when that actual value is changes.  This is a classic side-effect issue.  It can be solved with sagas.    Our current example.  The color panels updating from the plot when the activePlotId changes.    More to do:  * field groups need a sega to more effective respond to out side actions  * the dispatchChangeFieldGroup needs better, more documented parameters  * update multiple fields at the same time.  * should we have the field group support reset to init state? probably not, but look into it.  * change init values?  * Check example dialog and see if the large/smaller example is validating correctly."""
"DM-6133","Bug","lsst_distrib",1,"mpi4py does not compile under Yosemite due to hardcoded MACOSX_DEPLOYMENT_TARGET","""{{mpi4py}} build on Yosemite (Mac OS X 10.10) fails with       For details see attached build log.    The {{MACOSX_DEPLOYMENT_TARGET}} is being set in {{ups/eupspkg.cfg.sh}}        What is it that is supposed to be setting {{MACOSX_DEPLOYMENT_TARGET}}?  And why is it not set at the time when {{ups/eupspkg.cfg.sh}} is run, but is set to 10.10 by the time the actually compilation is done?   """
"DM-6151","Story","ip_isr",1,"Failure to fail when fallbackFilterName is None","""When no {{fallbackFilterName}} is set, we can get a confusing error message when failing to load a calib:    This is unrelated to the calib load failure, and merely reflects the fact that {{fallbackFilterName=None}}."""
"DM-6149","Story","Qserv",2,"Reduce memory utilization in mysql proxy","""Jon is trying to run tests with large result which kills proxy/czar because it runs out of virtual memory. Would be nice to reduce memory use and find a way not to keep query result in memory."""
"DM-6147","Improvement","ip_isr",5,"Set SUSPECT mask in ISR task and make saturation a double","""Implement RFC-190 and mask suspect pixels:    Add {{selectLevel}} to {{lsst.afw.cameraGeom.AmpInfoCatalog}}, as a double, and add support for it to {{lsst.ip.isr.IsrTask}}, analogously to masking saturation: iif {{suspectLevel}} is not {{nan}} then set the {{SUSPECT}} flag for pixels above the suspect level.    Also change the type of {{saturation}} in the {{AmpInfoCatalog}} from {{int}} to {{double}}, so that the existing test for {{nan}} actually works"""
"DM-6166","Improvement","afw",3,"Time AST and compare to our WCS code","""Time TAN-SIP for our code and for AST, in order to get a sense of the performance impact of switching to AST for our WCS implementation."""
"DM-6188","Story","Design Documents",3,"First draft of overview (""vision"") document","""See https://dmtn-016.lsst.io"""
"DM-6185","Epic","jointcal",100,"Get jointcal running on minimum data","""It is very important for other teams to have a version of jointcal running to remove the sensitivity on the errors in astrometric reference catalogs.  The suggestion is to get jointcal running with CFHT, HSC, DECam and lsstSim."""
"DM-6180","Epic","Requirements Documents",40,"Update LSE-61 requirements and traceability","""With the updates to DPDD and LDM-151 in the early part of F16, there is a need to update LSE-61 (DMSR) such that it can directly trace requirements from OSS+DPDD through LSE-61 and down to implementation LDM documents.    This will require substantial rewrites of many of the existing requirements and possible addition of new requirements. It may also be necessary to add annotations to DPDD and other LDM documents to provide traceability anchors for DMSR.    The outcome of this epic is a new baselined DMSR approved by CCB."""
"DM-6179","Epic","Developer Infrastructure",40,"Support Python 3 migration","""Support the migration of the DM code to Python 3. This includes writing transition documentation, integration of a new scons, migrating a handful of low-level packages and liaising with the teams on their packages.    The final outcome of this epic is that everything would be in place for the migration at the August All Hands meeting."""
"DM-6177","Story","qserv_testdata",2,"Increase memory locked amount in container","""In order to lock memory, the memory locking limit within the container for the qserv worker needs to be raised. My understanding is the container uses whatever is the host setting so the limit has to be set for the container user and whatever the user is inside the container. The particular limits is:    memorylocked 64 kbytes    notice that by default it's 64K. That needs to be raised to say 75% of the real machine size. I wouldn't make it unlimited as a memlock mistake may crash the whole machine. The limits are specified in """"/etc/security/limits.conf"""". You will know that you are successul when you ssh into the container as the qserv worker user and the """"limit"""" command tell you have can lock lots of memory.    We would also set the CAP_IPC_LOCK privilege but setting the soft/hard limit above should be good enough. So, let's start with that. """
"DM-6261","Story","Design Documents",1,"Cleanup and standardize DRP background matching, coaddition, and diffim diagrams","""DM-6256 will produce rough diagrams that will require cleanup and standardization.    [~ctslater] has made some suggestions for the current diagram that I'll implement on this issue, so I'm assigning it back to me.  I'll also go ahead and integrate his updated DRP overview diagram (currently on Confluence) into LDM-151 here.  """
"DM-6251","Story","Design Documents",2,"Convert DRP Top-Level Diagram to standard conventions","""DM-6248 adds a large, complex diagram that will need to be cleaned up and converted to use the same conventions and colors as other diagrams in LDM-151."""
"DM-6248","Story","Design Documents",2,"DRP Top-Level Diagram and Descriptions, Draft 1","""Insert the content from the DRP Data Flow diagram on Confluence into LDM-151, adjusting it to the outline developed on DM-6247."""
"DM-6247","Story","Design Documents",2,"DRP Outline for LDM-151","""Write outline for Data Release Production section of LDM-151, using the DRP Data Flow diagram as the organizing principle."""
"DM-6246","Bug","obs_cfht",0.5,"Vertical overscan off by one again","""In DM-5524 [~price] fixed the vertical overscan by directly editing the amp info catalogs, but didn't mark the camera generating code as bad. In DM-6147 I regenerated the files, reintroducing the problem. The problem seems to be a subtle bug in the camera generating code. Rather than try to fix it, I'll convert the fixed catalogs directly and mark the generating code as broken. [~price] will issue an RFC that suggests a better way to handle generating amp info and once that is dealt with we can come up with a more permanent fix (e.g. delete the generating code or fix it)."""
"DM-6239","Story","SUIT",2,"The grid labels are not placed in the right position when the coordinate is Ecliptic coordianates","""The algorithm to calculate the label position does not work well for the Ecliptic coordinate system.  The algorithm needs to be modified to work for all the coordinates."""
"DM-6224","Epic","butler",40,"F16 Butler Repository Refactor","""Per KT, the parent/peer repository relationship scheme was not an exact fit for what we need. We discussed and decided that butler should manage its own input and output repositories. Also discussed with KT and Gregory was the ability to select inputs by 'tagging' repositories. The design discussion with the larger group is captured in RFC-184."""
"DM-6209","Epic","Developer Infrastructure",8,"Ad-hoc developer requests","""This is a bucket epic for ad-hoc developer requests that cannot be postponed till the next planning cycle. In the event that it is underutilised for this purpose, it will be assigned to technical debt DM-5850"""
"DM-6208","Epic","Developer Infrastructure",8,"SQuaRE services disaster recovery","""This is a timeboxed effort to test and improve backups and disaster recovery for SQuaRE services. It is unlikely to be sufficient in itself.     Delivered: daily snapshots of git repos in lsst, lsst-dm and lsst-sqre orgs, with a progressive roll-off retention policy. Git-LFS repos are not currently serviced by this strategy, work on this will be scheduled at a later date.   """
"DM-6206","Epic","Developer Infrastructure",8,"CI Improvements: Jenkins 2 upgrade etc","""This epic covers a timeboxed maintainance of the Jenkins-based CI system, including the Jenkins 2 upgrade as well as the required updates to the Jenkins-puppet module. It also may include work done as part of DM-6204 brought over to the apps CI service.     Highlights:     - Jenkins 2 upgrade in production at ci.lsst.codes    - Improvements releases as part of the widely used puppet Jenkins module https://github.com/jenkinsci/puppet-jenkins        """
"DM-6199","Epic","Developer Infrastructure|Stack Documentation and UX",20,"Stack API documentation ","""Stack API Doc generation -> pipelines.lsst.io    Deliverables:     * a proof of concept of a CI-driven API doc build  * documentation content planning"""
"DM-6288","Story","SUIT",3,"Chart options display","""Make chart options """"in-place"""" popup, similar to table options for consistent look. It will also alleviate resizing, because the chart size won't need to change when options are open."""
"DM-6281","Epic","Firefly",100,"More visualization features in S17","""New features for visualization in Firefly: error-bars in 2D scatter plot, allow user to control symbol size and shapes for overlaid objects, histogram improvement, density plot improvements."""
"DM-6280","Story","SUIT",1,"The labels in HMS formate are wrong in WebGrid","""The labels in HMS format no longer show hh:mm:ss anymore.  The porting introduced the bug.  """
"DM-6306","Improvement","utils",1,"Executable test in utils needs to test an executable","""In DM-4036 all the test binaries were removed as no longer being needed. This had the unfortunate side effect that the {{testExecutables.py}} test no longer tests anything. This ticket will be used for adding a test file."""
"DM-6297","Story","afw",5,"Wrap afw::detection with pybind11","""The generated wrappers will live parallel to the Swig wrappers. This ticket only covers the C++ wrappers themselves, not the Python layer on top (which will continue to use the old wrappers) all work will stay on a separate branch and will not be merged to master until DM-8467 is complete.    The tests included in this ticket are:  # {color:#14892c}testExposureTable.py{color}  # {color:#14892c}testFootprint1.py{color}  # {color:#14892c}testFootprint2.py{color}  # {color:#14892c}testFootprintEllipse.py{color}  # {color:#14892c}testFootprintMergeCatalog.py{color}  # {color:#14892c}testGaussianPsf.py{color}  # {color:#14892c}testHeavyFootprint.py{color}  # {color:#14892c}testRgb.py{color}  # {color:#14892c}testTicket2019.py{color}"""
"DM-6294","Story","afw",8,"Add support for pybind11 to build system","""Add pybind11 as third party package to the stack. Update sconsUtils to support building with pybind11. Use daf_base DateTime to demonstrate that this works."""
"DM-18251","Story","ts_management",2,"Old T&S Epic carried over from old JIRA project - no longer valid","""Old T&S Epic carried over from old JIRA project - no longer valid"""
"DM-6326","Story","Stack Documentation and UX",0.5,"reST roles for mock code references","""Add mock code reference roles so that authors can add semantics to their writing without attempting to make actual references to API documentation that does not _yet_ exist. Covers all roles in the Python domain, and supports tilde syntax for collapsing the namespace."""
"DM-6325","Improvement","afw",0.5,"Replace BOOST_STATIC_ASSERT with static_assert","""Replace BOOST_STATIC_ASSERT with static_assert from C++11."""
"DM-6323","Story","Developer Infrastructure",8,"Lead Python 3 migration at All Hands Meeting","""* Prepare for all hands meeting.  * Present plan to developers.  * Advise developers doing migration.  * Contribute fixes as required."""
"DM-6322","Story","base",2,"Port base package to Python 3","""Ensure that {{base}} works with Python 3."""
"DM-6320","Story","utils",2,"Port utils to Python 3","""Ensure that the {{utils}} package will work with Python 3."""
"DM-6319","Story","sconsUtils",3,"Adjust sconsUtils to query python on path for executable location","""{{sconsUtils}} has to be modified to ensure it works with Python 3. Additionally SWIG calls might need to be changed to trigger Python 3 mode."""
"DM-6317","Story","Stack Documentation and UX",2,"Update developer guide to include Python 3","""Update the developer guide to indicate that Python 3 must be supported and that code must run on Python 2.7 and 3.    This ticket will reference the tech note delivered as part of DM-6315. Writing extensive user documentation on the {{future}} package is beyond the scope of this ticket."""
"DM-6316","Story","Developer Infrastructure",1,"Update newinstall.sh to support Python 3","""{{newinstall.sh}} currently insists on installing and checking for python 2.7. This needs to be changed to allow Python 3.    Requires {{sconsUtils}} works with Python 3 as the {{lsst}} EUPS package is installed as part of {{newinstall.sh}}."""
"DM-6314","Story","Developer Infrastructure|lsstsw",5,"Port lsstsw to Python 3","""Get {{lsstsw}} working with Python 3:  * Update the {{deploy}} script to allow a Python 3 python to be installed and modify the version checking code.  * Demonstrate that {{lsstsw}} {{rebuild}} will successfully build and install a third-party non-Scons package."""
"DM-6313","Story","Developer Infrastructure",1,"Create miniconda3 EUPS package","""{{newinstall.sh}} currently installs miniconda via EUPS. To replicate that functionality in Python3 we need to create a {{miniconda3}} package. This package should be almost identical to {{miniconda2}}.    Requires that {{lsstsw}} first be updated to support python 3."""
"DM-6309","Story","Design Documents",1,"Update LDM-151 with SDQA Skeleton and Outline","""1. Update the LDM-151 draft with the SDQA Skeleton from the DMLT + SciPipelines working group discussions of May 16-20.  Implement as bullet points in a semi-coherent list. (/)    2. Clean up list. (/)"""
"DM-6328","Story","QA",8,"add hsc driver script to validate_drp","""Add an equivalent of {{examples/runChftTest.sh}} to {{validate_drp}} to process {{validation_data_hsc}}."""
"DM-6348","Story","Design Documents",20,"Write Calibration Products Production section of LDM-151","""Write photometric calibration pipeline section of LDM-151"""
"DM-6346","Story","Stack Documentation and UX",3,"User installation and operation instructions for conda ","""Create documentation for the Stack conda binaries created in DM-5415 as part of the Science Pipelines documentation"""
"DM-6392","Story","Design Documents",1,"Text on variability characterization for LDM-151","""Expand the variability characterization algorithmic section of LDM-151."""
"DM-6383","Story","Science Pipelines",2,"Use template DCR images for image differencing","""DM-6382 creates template images of a field at arbitrary airmasses, which can be used to match the template airmass to the science image precisely to mitigate Differential Chromatic Refraction in image differencing. This ticket is to determine the best method to supply the new templates to image differencing, which may be simply to create a new exposure and ingest/process the template as though it were a real observation."""
"DM-6378","Story","Science Pipelines",2,"Persist output of simple DCR correction","""DM-5695 will create transfer matrices stored as numpy arrays. This ticket extends that work to determine a useful format and write functionality to persist those arrays."""
"DM-6375","Epic","Firefly|SUIT",40,"New image visualization functions (F16)","""TO support the pipeline QA and build the first web portal, there will be new functions need to be developed.  This epic is to collect those functions."""
"DM-6373","Story","Design Documents",1,"Improve skeleton for LDM-151 Algorithmic Components","""For all subsections in  Algorithms Components owned by [~jbosch]:   - Provide enough bullet points to capture scope.   - Add bullet points for subtly difficult aspects of components.   - Add extra level subsubsubsection level for Measurement.   - Create matrix of measurement algorithms and contexts.  """
"DM-6368","Story","Developer Infrastructure",0.5,"Adjust version check of EUPS python package to allow v3","""To enable Python 3 support of the stack the EUPS {{python}} stub package needs to allow Python 3.    """
"DM-6437","Story","SUIT",8,"Convert GWT projection and Coorindate Conversion routine to JavaScript","""convert Booth's projection code and Judy Bennet's coordinate conversion routines to pure javascript  """
"DM-6459","Story","butler",20,"productize ""Repository Refactor""","""After RFC-184 is closed: implement, unit tests, review, document, submit.    When this story closes, I think RFC-184 status is supposed to be changed from Adopted to Implemented."""
"DM-6458","Story","Design Documents",20,"Expand skeleton in LDM-151","""We need to flesh out the skeleton text to contain full descriptions of the algorithms and pipelines we expect the baseline design to use."""
"DM-6457","Story","butler",20,"Design and RFC for Repository Refactor","""Drive the RFC for Repo Refactor to completion (this includes a lot of design work)"""
"DM-6474","Story","meas_algorithms",2,"Restore star selector registry","""Restore the registry for star selectors that was lost in DM-5532, now that tasks in registries can be used as subtasks.    Also use the registry where appropriate."""
"DM-6473","Story","SUIT",8,"Possible image related issues in firefly viewer","""Image Meta Data tab  * images cannot be remove, but in expanded mode, it can.  * selecting image no longer highlight table.  the reverse works fine.  * visualize/saga/ImageMetaDataWatcher.js:272 returns -1.  * when a non-meta table is selected, images are shown, but not the toolbar.  * after table is removed, images are still there.    image external api does not mix well with firefly viewer.  * firefly viewer uses 'triViewImages viewer_id while api has no viewer_id.  as a result, images loaded by api will be lost once table or other searched data are returned.    * catalog overlay are drawn outside of the images.    more issues:    - -It's possible to select distance tool and then area selection. First drag would define area selection, all the following line. A click would be defining a 0 length line, even if point selection is enabled.- _moved to_ DM-6656  """
"DM-6494","Improvement","obs_base",0.5,"Better error messages from the camera mapper when a template cannot be formatted","""The CameraMapper produces a very unhelpful traceback if it cannot format a template string with the provided data ID dict. For example:      It is unclear what string was being formatted with what data, making the problem difficult to diagnose and correct.    I suggest changing line 732 of CameraMapper.py from:    to something like the following:      Here are the last few lines of the same traceback after applying this change:      A bit wordy, but it is much easier to figure out what went wrong.    I have stumbled across this problem twice in the last few weeks, so I consider this change fairly important. The first time it was caused by a defective format string in a paf file. This time I'm not yet sure what is causing it, but at least I have something to go on."""
"DM-6490","Story","pipe_tasks",8,"Investigate calibration zeropoint offset between HSC vs. LSST processCcd.py runs","""As reported in DM-4730, while the scatter between single frame processing measurements of the same dataset on the HSC vs. LSST stacks is quite good (rms = 0.009 mag between Gaussian fluxes, for example, in the figure shown on that ticket), there is a clear offset (0.0166 mag in the figure shown) in the zeropoint between the two stacks (it is systematic, i.e. no trend with magnitude).  The cause may well be due to slight differences in the reference stars selected for calibration.  We also speculated about differences in slot definitions used in the calibrations steps (e.g. for aperture corrections, psfex, etc...), so I have rerun visit 1322 through both stacks having forced all apertures used in calibration to be the same, namely a circular aperture of 12 pixels measured using the sinc algorithm (as opposed to """"naive"""").  I have attached the *processCcd.py* config files for the two runs so my settings can be reproduced.    Also of note, I am using a {{meas_algorithms}} branch on the HSC stack with the following commit:        I attach some of the figures comparing the PSF fluxes from these runs which compare the output of the two stacks having matched the two src catalogs.  There are two sets: 1) having adjusted the flux for each source to the zeropoint calculated in the calibration and stored as *FLUXMAG0* 2) having adjusted the flux for all sources to a common zeropoint (zp=33.0, chosen to roughly match the calibrated zp).  Note that my figures do include aperture corrections (in DM-5301, many of the plots show fluxes pre-aperture correction).  I have also included plots that directly compare the aperture corrections applied (difference in mag units).  Finally, I also include plots comparing the 12 pixel circular aperture mags (i.e. to which no apCorr is added).    Clearly, the zeropoint determined in the calibration of the two stacks differs between the two stacks and, in particular, there seem to be some very problematic CCDs where the differences are particularly significant (~0.05 mag, and not always in the same direction).  Please investigate the source of this discrepancy."""
"DM-6497","Story","Qserv|qserv_testdata",3,"Assist IN2P3 engineer in loading DC2013 data sample","""Bogdan Vulpescu, IN2P3 engineer, tried to load DC2013 data sample. Fabrice help was required to install Qserv in multi-nodes and understand data-loading system.    Some issues have been found and will be reported in future tickets:    - a script to publish loaded data (i.e. insert db name in qservw_worker.Dbs) would be useful  - mysql client might break proxy if option are not provided correctly (a bug report will be available soon)"""
"DM-6519","Bug","meas_algorithms|meas_astrom|pipe_tasks",0.5,"Temp local background broken","""The temp local background feature has been broken and needs to be fixed."""
"DM-6516","Story","SUIT",20,"Convert footprint support","""Convert the footprint support from the GWT code"""
"DM-6514","Bug","ip_isr",1,"Minor fixes to linearization","""DM-5462 added linearization to {{IsrTask}} but had a few loose ends which this ticket aims to correct:  - I intended to enable linearization by default, but somehow lost that change.  - I intended to update obs_test to use null linearization, but I forgot and the previous item meant I didn't catch the omission  - It turns out that the butler data proxy object will not work with functors (attempting to call the retrieved item results in an error, rather than resolving the proxy). This is easily worked around by using immediate=True when retrieving linearizers. This didn't show up until DM-6356 because obs_decam is the only camera that uses linearization lookup tables, and obs_subaru avoids the problem by not returning a proxy.  """
"DM-6533","Story","Design Documents",2,"LDM-151 adjustments","""Adding text to LDM-151 where appropriate, working around the structure defined by Jim et al."""
"DM-6542","Story","SUIT",3,"Prevent external viewer from popup blockers.","""Currently, when external viewer launched, it is blocked by pop-up blockers. Need to change polling logic to a pushed solution so the 'launch' action can happen immediately. """
"DM-6566","Improvement","afw|meas_algorithms",1,"Make updateSourceCoords and updateRefCentroids more visible","""Implement RFC-197 to make updateSourceCoords and updateRefCentroids more visible"""
"DM-6569","Improvement","meas_algorithms",1,"Remove the extra init method from the SourceDetectionTask","""SourceDetectionTask defines both {{init(self, schema=None, **kwds)}} and {{\_\_init\_\_(self, schema=None, **kwds)}}. The first exists purely because of a Doxygen bug that makes {{\copydoc \_\_init\_\_}} fail. However,     works. Remove the non-dunder init method and update the documentation with  ."""
"DM-6592","Story","Firefly",8,"enable subMenu in the menu list","""We want to have a subMenu component in the Firefly so we could group some of the actions together by putting them into subMenu.        Added submenu capability to drop down menu. Submenu can be nested to multiple levels.  Also, implemented ticket DM-14515 to place project footprints into submenu.  You can test this by loading any image, then select {{Overlay Markers}} to see drop down with submenu."""
"DM-6590","Story","Firefly",2,"Collection of small bugs and look and feel issues","""1. In the color stretch dialog:  (in chrome Version 50.0.2661.102 (64-bit) on my Mac OSX 10.9.5)      * the asinh beta and powerLaw Gamma input field do not  look like part of the input fields group. Too much white space in between.      * When clicked on the Z scale option when the asinh and powerLaw types selected, the min and max values overlapped with the option choice. """
"DM-6608","Story","Stack Documentation and UX",1,"Finalize v12 Pipelines release documentation","""Add the release announcement and finalize other documentation details in pipelines.lsst.io for the v12 release."""
"DM-6601","Story","obs_subaru",0.5,"Port change to EXP-ID handling","""From [HSC-1409|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1409]:  {quote}  Due to an operational reason (to meet the requirement of Subaru FITS dictionary), the definition of EXP-ID is soon to be changed in the data acquisition side.  In the new definition, EXP-ID is set to 'HSCE%08d' where the letter 'E' is fixed as requested in the dictionary, and the number part corresponds to exactly the same number as our familiar 'visit'.  obs_subaru:ingest.py needs to be updated to include this rule.  The data taken with this change so far are:  HSCA07441200--HSCA07441757  HSCA90925200--HSCA90929557  {quote}    The change made as part of HSC-1409 introduces a new code path for the updated data, while old data continue to be supported with the old code path."""
"DM-6630","Story","pipe_tasks",2,"Support ingesting reference catalogs from FITS files","""Support a means of ingesting index reference catalogs from FITS tables (e.g. SDSS catalogs)."""
"DM-6627","Story","jointcal",1,"Fix base_* stuff in CcdImage.cc","""CcdImage.cc currently has hard-coded a bunch of {{getSchema().find(""""base_blah"""").key}} things. These should either be replaced with """"slot_*"""", config.blahName, or dealt with at a higher level (e.g. not loading all those values directly inside of ccdImage::LoadCatalog).    Once this is done, we should delete the comments at the top of the file."""
"DM-6620","Story","meas_astrom",0.5,"Cannot instantiate LoadAstrometryNetObjectsTask without Config object","""One should be able to create a LoadAstrometryNetObjectsTask without passing a Config object, if one only wants the default configuration. Currently it raises TypeError:        If the config object really is a kwarg, it should default None and create a default config, so that one doesn't have to do, e.g.:    """
"DM-6617","Story","SUIT",2,"Catalog Search Panel bugs","""from pull request DM-6500:  https://github.com/Caltech-IPAC/firefly/pull/102  * 2MASS All-Sky 'Read Me!' link in Catalog Search panel points to http://localhost:8080/irsaviewer/Q'http://hades.ipac.caltech.edu/applications/Gator/GatorAid/irsa/scan.html'E * -If you search m31 2MASS scan info catalog (4th catalog in the list), then bring back catalog panel, the first catalog is highlighted, but if you search, you'll notice that you are still searching 2MASS scan info.-"""
"DM-6614","Story","meas_extensions_photometryKron",1,"Include Kron parameters in algorithm metadata","""The Kron code doesn't set the algorithm metadata.  E.g.    """
"DM-6613","Bug","afw",2,"Typo in afw/display/interface.py","""There's a typo in interface.py;  the patch is  """
"DM-6612","Story","obs_subaru|pipe_tasks",2,"Make HSC processing without bright object catalogs easier","""obs_subaru enables bright object masks by default, as that's desirable for HSC production runs.      However, when HSC data is processed without bright object masks available (as will happen in most GO observations and development use), multiBandDriver.py will fail because the BRIGHT_OBJECT mask plane is not present but the base_PixelFlags algorithm is configured to make use of it. This is confusing, and it also requires the definition of a configuration file to fix the problem because base_PixelFlags cannot be configured directly on the command-line.    Some possibilities for fixing this:   - Add the BRIGHT_OBJECT mask plane in AssembleCoadd if doMaskBrightObjects is True but the external catalog is not found.  This will make the PixelFlags operation a silent no-op.   - Allow configuration options to allow PixelFlags algorithm to silently skip some flags if the appropriate masks are not available.    I am sure there are other options as well.  """
"DM-6638","Story","Stack Documentation and UX",0.5,"LTD Keeper: Auto slug for edition paths deals with underscores","""Had a bug where {{utils.auto_slugify_edition}} did not replace underscores with a dash, and therefore failed {{utils.validate_path_slug}}. This created a silent breaked where a branch like {{u/rowen/r12_patch1}} did not get an edition created for it.    This ticket adds this replacement code and adds a test for such a case."""
"DM-6635","Bug","pipe_tasks",1,"Typo in CoaddSrcTransformTask","""[~price] points out  a typo [in {{CoaddSrcTransformTask}}|https://github.com/lsst/pipe_tasks/blob/0eef0fd518098cc25c66bfff40f53ccca9058431/python/lsst/pipe/tasks/transformMeasurement.py#L263]: {{self}} should not be repeated."""
"DM-6633","Bug","obs_subaru",1,"HSC ISR configuration file is applied to ProcessCcdTask, not IsrTask","""{{obs_subaru/config/hsc/isr.py}} has its config options specified relative to {{ProcessCcdTask}}'s config hierarchy, not {{IsrTask}}'s.  This allows the ISR task to be retargeted in this file, but it will prevent {{IsrTask}} from being run as a {{CmdLineTask}} directly.    ISR Task retargeting should be moved to {{config/processCcd.py}}, allowing the {{config/isr.py}} level to be moved to the appropriate level."""
"DM-6631","Bug","pipe_tasks",3,"Single-frame processing tasks are no longer usable without a Butler","""Adding a butler argument to the constructor signatures for {{CharacterizeImageTask}}, {{CalibrateTask}}, and {{ProcessCcdTask}} makes these tasks difficult to use without a butler.    The fix is to make the butler argument optional (with a default of None), while adding another argument that allows a fully-constructed reference object loader to be provided directly instead.    This is closely related to DM-6597, which has the opposite problem: pipe_drivers' {{SingleFrameDriverTask}} doesn't take a butler argument, but it needs to in order to provide one to {{ProcessCcdTask}}.    I have a fix for this just about ready, but I'd like to add some unit tests that verify we can run all of these tasks both from the command-line and directly before calling it complete."""
"DM-6661","Bug","pex_config",0.5,"ConfigDictField says ""Inequality in keys for..."" even if I give 2 same configurations","""From [HSC-1401|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1401]:  {quote}  config.py:  {code:python}  from lsst.meas.photocal.colorterms import ColortermGroupConfig    for key in ['i', 'i2', 'y', 'r', 'N1', 'N2', 'N3', 'z']:      root.calibrate.photocal.colorterms.library[key] = ColortermGroupConfig.fromValues({}){code}    This comamnd line  {code:bash}  rm -fr output ; for i in {1..2} ; do processCcd.py ./HSC --output output -C config.py  ; done  {code}  raises following error    {quote}"""
"DM-6660","Bug","meas_algorithms",0.5,"CR finder does not care about XY0 of input image","""Port of [HSC-1391|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1391]:  {quote}  The current version of CR finder does not care about XY0 of the input image and when I try to run CR finder on warped (difference) image, PSF cannot be properly extracted.  {quote}  and:  {quote}  I have noticed that the center of warped image is a gap between CCDs and PSF estimation there will fail. So get PSF without specifying the position is good enough. PSF class will select the best position.  {quote}"""
"DM-6657","Story","SUIT",1,"ffApi XYplot related issues found by irsa integration","""* default  symbol size, shape,and color setting is different from that of original version.  * no XY Plot Options pop-out windows  *  the plot displays non-ascii characters on the panel (for example:  Fit  )  * miss Filter Dialog on the plot panel comparing with the original version.  *  does not accept default column names for the plot."""
"DM-6653","Story","SUIT",0.5,"implement the active target","""When a dialog such as catalog search is displayed, it should be able to pick up the active target or the coordinates from a highlighted row in a table. Please, implement the mechanism that will automatically pick up those coordinates and pre-fill the search form for you."""
"DM-6652","Story","obs_monocam",2,"Remove database hack","""DM-5988 introduced a hack in reading the raw files: we use a database to cache metadata from the shutter files and update the camera files at read time.  The camera files have now been """"sanitised"""" (updated with the appropriate metadata), and it's time to remove the hack.    [~mfisherlevine] writes:  {quote}  Data is on lsst-dev in:    /nfs/lsst2/photocalData/data/monocam/sanitised9/1m3/1m3    Raw calibs are in:    /nfs/lsst2/photocalData/data/monocam/sanitised9/1m3/calibs    Regarding what I want: everything to be the same, but with a normal ingest, i.e. no splicing, just taking everything that is needed from one set of files. Some points to note:    * should be able to ingest all the raws and calibs files, and register their OBJECT types to allow processing with these as ids (inc. pipe_drivers scripts)  * pipe_drivers master calib scripts should still run (and their outputs still be ingestable)  * processCcd should run  {quote}"""
"DM-6651","Improvement","meas_algorithms|pipe_tasks",2,"Move new reference loader so meas_astrom can use it and perform some cleanup","""The new reference object loader code lives in pipe_tasks, which means it cannot be directly used by code in meas_astrom. This will hamper separating astrometry.net out of meas_astrom, because unit tests need reference catalogs and meas_astrom cannot depend on pipe_tasks.    Also, I'd like to take a cleanup pass on the module names, so the new code is easier to find, and improve the unit tests."""
"DM-6647","Story","pipe_tasks",2,"Adapt qa analysis script to apply corrections measured by meas_mosaic","""DM-2674 involves getting HSC's {{meas_mosaic}} working with the LSST stack.  This issue consists of adapting the analysis.py script of DM-4393 & DM-4730 to (optionally) apply the astrometric and photometric solutions derived running {{meas_mosaic}} to the individual visits before comparison.  This is useful in general and is specifically useful in comparing the {{meas_mosaic}} results between the HSC and LSST stacks."""
"DM-6701","Story","supertask",2,"Specify requirements for SuperTask extensions ","""Specify requirements for SuperTask extensions according to the use cases and architecture."""
"DM-6663","Story","SUIT",2,"Study iPlant as a potential candidate for workspace implementation","""in 2015 iPlant was rebranded to CyVerse  (http://www.cyverse.org/) with a revised mandate to serve all life sciences.  CyVerse's  Data Store is based on technology iRODS (http://irods.org/).   CYVerse's Atmosphere provides a managing portal for users's VM instances and data spaces called volume. The instance and volume is tied under a project.     There are other tools and UIs under CyVerse. Data Store and Atmosphere are very close to what we wanted  for LSST workspace.  It provides many VM instance images preconfigured for life sciences domain-specific tasks. We could definitely learn from this if LSST provides the VM for its users.  LSST could supply instance images with specific astronomical tools preconfigured.      Deciding if the CyVerse could be used as LSST workspace implementation will need much more study and discussion with other teams involved in workspace design and implementation.     The direction we are going with Jupyter Notebook and JupyterHub most likely preclude us from using CyVerse directly.   """
"DM-6718","Bug","afw",2,"afw table and record should have useful str() and repr()","""To see the contents of an afw table in python, you have to do something like  which is totally not discoverable and returns a dict which doesn't print well. Much more useful would be for str() on a record to produce a pretty-printed list of the contents, and str() on a table to produce some nicely formatted summary (like a numpy recarray does, only printing a few things separated """"..."""" for large tables).    I'm not sure what the best repr() output would be (certainly for a Record it should be a full dump of the contents), but currently table.repr()==table.str(), which is equally unhelpful.    Maybe this will come """"for free"""" when we get astropy.table views, but it makes exploring the contents of a table a pain right now."""
"DM-6785","Story","meas_base",5,"Port parent/child measurement from HSC","""The deblender sometimes gets into trouble with cluster galaxies, and the deblended fluxes aren't accurate.  In that case it helps to have measurements on the image without any deblending having been performed.  This is a feature used in HSC's mid-2016 production run afterburner, ticket [HSC-1400|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1400].  This feature should be ported for use in LSST."""
"DM-6784","Story","meas_algorithms|meas_extensions_photometryKron",5,"Port meas_extensions_convolved from HSC","""HSC has a new measurement extension: meas_extensions_convolved.  This performs aperture photometry with the PSF degraded to nominated seeings (similar to how galaxy photometry is commonly done these days).    Relevant HSC tickets are [HSC-1395|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1395] and [HSC-1408|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1408]."""
"DM-6824","Story","meas_astrom",2,"Use meas.algorithms.astrometrySourceSelector in measOptimisticB","""Now that there is a working astrometrySourceSelector (just merged in meas_algorithms from DM-5933), we should get matchOptimisticB working with it. This would entail replacing matchOptimisticB.SourceInfo with AstrometrySourceSelectorTask and tweaking the latter to do whatever matchOptimisticB needs, and removing SourceInfo."""
"DM-6823","Story","Stack Documentation and UX",2,"Add new boilerplate to introduction of SQR-012","""SQR-012 provides details of how the new unittests should be written, but it only gives an example of the old testing boilerplate in the introduction. It would be very helpful to have the first thing a reader sees be the new, correct, boilerplate, so they can immediately drop it into a new testing file."""
"DM-6788","Story","meas_extensions_ngmix",2,"Document meas_extensions_ngmix","""meas_extensions_ngmix has no useful documentation, not even a {{doc}} directory. Add some.    This should include at least an overview of the package contents, a description of its capabilities, and instructions on enabling it within the meas_base framework. The package should have a README."""
"DM-6833","Improvement","SUIT",1,"add 'placeholder' attribute to the input element","""An attribute called placholder is available in html element <input> to give a hint to the user of what can be entered. The placeholder text must not contain carriage returns or line-feeds.      Add it as proptype to <inputfield> component."""
"DM-6832","Story","utils",2,"Wrap utils with pybind11","""Split off from DM-6302."""
"DM-6831","Story","base",2,"Wrap base with pybind11","""Split off from DM-6302."""
"DM-6858","Story","obs_base",2,"Mapper tests require modification when new datasets are added","""[~price] [recommends|https://community.lsst.org/t/centrally-defined-butler-datasets/841] a new way to define datasets common to all cameras in daf_butlerUtils, but modifying these yaml files require explicit lists of datasets to be modified in tests/cameraMapper.py.    If these tests are still useful, they need to depend on a minimal set of dataset definitions instead of the real ones."""
"DM-6857","Improvement","meas_algorithms",0.5,"Document that the catalog returned from star selectors is a view","""Star selectors return a catalog whose records are shallow copies of the input catalog records. Document the shallow copy aspect. This is important for two reasons:  - The user should know  - Implementers must be told this, because if the records are deep copies then the code that sets a flag for stars will not set a flag in the input catalog, which loses most of the point of setting that flag."""
"DM-6886","Bug","meas_modelfit",1,"forcedPhotCoadd.py fails on CFHT data due to a CModel bug","""Hello,    forcedPhotCoadd fails while running on CFHT data due to a CModel bug. Here is an example on the error message that we get:        Adding the following lines in cmodel.py (in CModelForcedPlugin.measure, before the call to self.algorithm.measure) allows to go around the problem for the time being, which seems to arise for null value of the number of pixel in a given footprint:    """
"DM-6910","Story","SUIT",3,"Tab panel issues","""There are several issues with tab titles:  - Sometimes we don't want them to be resized at all (like in Images panel since the tabs are all fixed at begining)  - When titles are resized, their size is proportional to the length of the title, use fixed-size tab length instead to make sure no tab is too long.    Please add other tab panel issues here."""
"DM-6909","Story","SUIT",2,"Filtering from expanded mode cancels expanded mode","""When a table is filtered from the expanded mode, the layout is changed back to unexpanded.    It looks like the issue is more general: table actions trigger layout changes, which are not always right. For example, TABLE_REMOVE action while in a dropdown makes the  dropdown to get closed. I've traced it to FireflyLayoutManager.js:layoutManager generator function.    Test sequence in firefly:   - When a table is loaded, open """"Charts"""" dropdown, select Col link for X, then select Col link for Y. (At this point the previous table is removed).  - TABLE_REMOVE action on the second click triggers dropdown to go away.   """
"DM-6905","Story","Qserv",2,"Locate the test dataset for PDAC","""Locate and evaluate a dataset of SDSS Stripe82 which is going to be used for testing the prototype DAC."""
"DM-6903","Story","skymap",0.5,"Add an option to label ccd serial number on the showVisitSkyMap.py plot ","""(actual assignee: Samuel Piehl)     Sometimes it is useful to know where the CCDs are on the plot. Add an option to label the CCD numbers. """
"DM-6916","Story","Stack Documentation and UX",0.5,"Documenteer seeds Git revision date and branch name if not present in metadata.yaml","""If {{last_revised}} and {{version}} are not present in metadata.yaml, then the Git commit date and branch name should be used while building metadata instead.    Also updates lsst-technote-bootstrap to take advantage of automated metadata for new projects."""
"DM-6914","Bug","Developer Infrastructure",1,"git-lfs.lsst.codes certificate is expired","""Per reports on hipchat, the tls certifcate on git-lfs.lsst.codes was not upgraded to the new *.lsst.codes cert.        """
"DM-6923","Story","meas_astrom",1,"Apply distortion when searching for astrometric reference objects","""While investigating DM-6529 I found that LSST generally finds fewer reference objects than HSC when doing astrometry.  For the CCDs on the edge of the focal plane the number of stars was typically very low causing frequent failures.  I found that in the HSC code, there is a distortion being applied that shifts the exposure bounding box when getting objects from the reference catalog.  This distortion is not being applied in the LSST code."""
"DM-6922","Bug","Qserv",2,"Upgrade to new stack install procedure for containers","""LSST stack install has evolved: https://pipelines.lsst.io/install/newinstall.html#  Release container creation script needs to be update.  Latest Docker version will be tested, as [~bvan] reported cmd line options have changed."""
"DM-6929","Story","SUIT",8,"Image Viewer: Support circular selection","""Support circular selection by choosing a point and dragging the mouse across the image. The callbacks and functions supported for rectangular selection should be also supported for circular selection.    (Circular region selection is a part of Paul O'Connor's visualization wish list and is a long promised feature.)        Copied from GitHub(XW 1/18/18)    This development includes,   * adding circular selection support for area selection.   * change select area icon on the tool bar from on/off button to a on/off button with dropdown selection at off state. The dropdown list supports the selection for 'rectangular selection', 'elliptical section' (circular area).   * add stats calculation for circular area selection on both rotated and non-rotated images.   * fix stats calculation for rectangular area selection on rotated image case.   * update 'select catalog' and 'filter catalog' functions for circular area selection.    Test:   - Do image selection:   1. Click 'select area' icon (on 'off' state) to get selection dropdown list,   2. Select either 'rectangular selection' or 'elliptical selection' (this will move the 'select area' icon into 'on' state) and draw a selected area by choosing a point over the image and dragging the mouse across the image.         3. Click 'select area' icon to move it back to 'off' state to remove the selected area.        4. Select one of the extension buttons for 'crop', 'stats', 'zoom', or 'recenter' while either 'rectangular selection' or 'elliptical selection' is selected.   - Repeat the steps by rotating the image first.     - Do catalog selection next:   repeat the 'select area' steps done as image selection, and select one of the extension buttons for 'crop', 'stats', 'select mark data', 'filter', 'zoom' or 'recenter' while either 'rectangular selection' or 'elliptical selection' is selected."""
"DM-6949","Bug","SUIT",1,"Firefly has problem to render in other browsers than Chrome","""Couple of problem using Firefly in  Safari:  * the components appears blank,    in Firefox:   * image and xyplot are not aligned (Gator).    The alignment can be reproduced in my Chrome and Safari.  Search parameters: ALLWISE source catalog, m81 100arcsec.   """
"DM-6945","Story","Design Documents",8,"Add text to algorithmic components sections in LDM-151","""While [~swinbank] has commented that the outlines are probably good enough for planning work (and I thnk that's broadly true), the lack of text in the algorithmic components section did occasionally lead to some misunderstandings in [~rhl]'s first review pass, so I think I should flesh that out with text sooner rather than later.    In this issue, I'll stick to sections that no one else has added text for, but eventually I'll also need to work with [~krughoff] and perhaps others to ensure that section has a consistent level of detail and focus."""
"DM-6969","Story","pipe_tasks",2,"Fixes to LoadIndexedReferenceObjects","""Bug fixes for using the new {{LoadIndexedReferenceObjectTask}} and its associated components."""
"DM-6968","Story","Developer Infrastructure",1,"create a shared stack on NFS for use with  the current local condor pool","""It is well known that building, setting up a stack, and interactive devel work with those operations on NFS has performance issues.  Hence the official shared stack on lsstdev uses /ssd .    However,  a shared stack on NFS is useful and adequate for one important  use case --   users need a stack that can be used for small productions on the local condor pool currently available  on lsstdev.   For this use case multiple """"source""""/""""setups"""" on a node/against the file system  can be avoidable by using a script to directly declare the environment.  run_orca /ctrl_orca supports this feature.       While GPFS is coming soon, there is expected to be a transition period of 2-3 months and so the NFS file system and a stack on it can serve users for an interim period.   If building a shared stack on NFS is not a heavy labor, we think it is worth the effort for this interim period, and as such make this request for a shared stack on NFS. """
"DM-6974","Bug","obs_lsstSim",1,"Type of IngestIndexedReferenceTask_config wrong in obs_ paf files","""In DM-6651 I moved the new HTM indexed reference catalog code from pipe_tasks to meas_algorithms, but didn't do a complete job. The type of IngestIndexedReferenceTask_config in obs_ paf files still must be updated."""
"DM-6972","Story","Qserv",1,"Fix Qserv install doc and scripts for new newinstall.sh","""Update qserv install docs per new info at https://pipelines.lsst.io/install/newinstall.html"""
"DM-6981","Story","afw",1,"Add column setters for Flag types in catalogs","""It should be possible to set Flag columns with bool arrays or scalar values.    This should just be a matter of adding a {{set}} overload or two around line 100 of {{specializations.i}}."""
"DM-6979","Epic","Firefly",20,"Firefly strategy response to RFC-193 (f17)","""RFC-193 has been adopted.   """"we propose to replace the current World Coordinate System handling and XYTransform code in the LSST stack with Starlink AST, using a new API that is under development in DM-3874 (that API will have its own RFC). """"     How does Firefly respond to this and display images as accurately as possible?   """
"DM-6978","Story","Qserv",2,"Update qserv for changes in Log interface","""DM-6521 improved Log class interface by replacing some static methods with non-static. Qserv is currently using couple of static methods which were retained in Log class for the duration of this migration. Once updated log package is released update qserv code to use new non-static methods and remove static methods from Log class after that."""
"DM-6976","Story","Firefly",1,"watch for Highcharts update ","""There is an issue in the density plot for displaying the legends. Highcharts does not support the setting of the symbol size in the legends. So when the symbol size is too small or too large, the legends are not displayed.     We don't want to do too much workaround currently. This ticket is to watch for the Highcharts update. """
"DM-6996","Story","SUIT",20,"produce a draft document of SUIT requirements","""After combing through the current SUIT requirements, we feel that we need to re-organize and re-write the SUIT requirements to be in-line with SUIT vision document.    This story will be producing the first draft of the rewrite. """
"DM-6989","Bug","ctrl_events|log",3,"ctrl_events/tests/EventAppenderTest.py fails Jenkins run-rebuild","""ctrl_events/tests/EventAppenderTest.py started failing on Jenkins """"run-rebuild"""" last night:   https://ci.lsst.codes/job/run-rebuild/354//console    All test cases in EventAppenderTest.py did run and pass, but it failed with a Segmentation fault in the end.     Jenkins """"run-rebuild"""" uses a stack on NFS on lsst-dev (/nfs/home/lsstsw).  The same test passes on regular Jenkins (stack-os-matrix).      """
"DM-6987","Story","butler",2,"Write up a description of Composite Datasets based on input from KT","""Write a description of composite datasets as I understand them based on the email KT sent on May 20 (attached), and on conversation I had with KT and Fritz on July 20."""
"DM-6984","Story","cat|daf_persistence|obs_base",2,"Suggest logging migration in daf_persistence and daf_butlerUtils","""Use lsst::log instead of pex::logging in daf_persistence and daf_butlerUtils"""
"DM-6983","Story","ci_hsc",1,"ci_hsc failure: AttributeError: 'Butler' object has no attribute 'repository'","""Following [~npease]'s [recent changes to the Butler|https://community.lsst.org/t/im-checking-in-butler-changes-related-to-rfc-184/959], ci_hsc is failing as follows:        See e.g. https://ci.lsst.codes/job/stack-os-matrix/13274/compiler=gcc,label=centos-7,python=py2/console.    Please fix it. """
"DM-6982","Story","meas_extensions_psfex",1,"Fix oversampling settings in psfex","""The current settings in psfex will only turn on oversampling only if the seeing is < 0.5"""", even if you have configured it do oversampling. This needs to be changed so that everything is determined by the config parameters.    We have also seen on HSC data that oversampling in general does not work well in psfex.  We need to change the current configuration which does 2x oversampling to just use the native pixel scale."""
"DM-6999","Story","pipe_base|pipe_tasks",8,"Use lsst::log in pipe_base and pipe_tasks","""Per RFC-203, switch Task's logs from using pex.logging to lsst.log in pipe_base and pipe_tasks (stage 2)  This implements the main idea of RFC-203 and migrate the logging framework used in the task framework."""
"DM-6998","Story","utils",3,"Problems with MemoryTest ordering","""{{MemoryTestCase}} (or a derivative thereof) must be run as the last of all tests in a module in order to properly catch leaks.    [Our documentation|https://developer.lsst.io/coding/python_testing.html#memory-and-file-descriptor-leak-testing] implies, and [SQR-012 states|https://sqr-012.lsst.io/#memory-test], that this can be achieved by listing it as the last test case in the file.    This works for py.test, but not when using plain old unittest: the latter does not, so far as I can see, guarantee any sort of ordering as a matter of principle, and, in practice, it sorts things lexicographically (it uses whatever order it gets from running {{dir()}} on the test module, and I don't *think* that's guaranteed to be anything in particular).    For example, consider [{{testAstrometrySourceSelector.py}}|https://github.com/lsst/meas_algorithms/blob/master/tests/testAstrometrySourceSelector.py]. I made the following change to introduce a memory leak:        Py.test catches it:      But simply running the test suite does not:      Rename the test case:      And boom:      Based on a very quick check, I think [sconsUtils runs tests by simply invoking {{python}}|https://github.com/lsst/sconsUtils/blob/f9763768d999cefa4c26b9f3418c28394dfb38df/python/lsst/sconsUtils/tests.py#L133], and I'm pretty sure that this is hard-wired into the muscle memory of many developers. In these cases, memory tests written following current guidelines won't be being properly executed.    """
"DM-7008","Story","boost",0.5,"Check boost.python building with Python 3","""We may want to disable boost.python in the build. There are hints that there are problems with python3.5."""
"DM-7019","Story","SUIT",3,"Setup standalone Firefly build using IPAC github","""Modify the existing Firefly-Standalone build in Jenkins to use IPAC's github.  Make sure github auto-releases still works."""
"DM-7018","Story","SUIT",2,"Firefly distribution build","""We need to support regular Firefly distribution builds (with bundled tomcat server),  similar to the builds we did in lsst firefly repository before the conversion.    This is to get Camera team started with new API."""
"DM-7016","Story","SUIT",2,"Big image not showing working message when the load","""This is a problem with uploads, large image loads, and Atlas.   When a big image is loading the user does  not get feedback.  The problem is the the UI is not creating the ImageViewer soon enough."""
"DM-7014","Story","SUIT",2,"Memory cache leak in firefly server","""The visualization system is not update the memory accounting for the caching system."""
"DM-7010","Story","sconsUtils",0.5,"Builds should be optimised by default","""By default, our builds are not optimised ({{-O0}}), which requires everyone who doesn't want to wait until the heat death of the universe to set {{SCONSFLAGS=""""opt=3""""}}, but other packages that are built with scons may not recognise this.  This default is also contrary to the standard practise for open-source software, which is that by default builds are optimised.  I will change the default optimisation level to {{opt=3}} from the current {{opt=0}}.  I will also add support for {{-Og}}.    This change was approved in RFC-202."""
"DM-7028","Story","daf_base",0.5,"Port daf_base to Python 3","""Changes necessary to get daf_base to work with Python 3."""
"DM-7027","Story","SUIT",1,"Region issues","""There are several region issues I have found when comparing old and new API:  (1, 2, 3, 7, 8 are implemented in DM-7147, 4, 5, 6 are implemented in DM-7190)    1. The default coordinate system when """"pure numbers"""" are used should be pixel positions on the original image.     The [spec](http://ds9.si.edu/doc/ref/region.html) says the following:   """"...the default system is implicitly assumed to be PHYSICAL. In practice this means that for IMAGE and PHYSICAL systems, pure numbers are pixels.""""  'If no coordinate system is specified, PHYSICAL is assumed.'    More explanation can be found [here](http://hea-www.harvard.edu/RD/funtools/regcoords.html)    2. PHYSICAL coordinate system does not mean screen pixels. The question is whether we can always use image pixels.    _If wcs is """"physical"""", WCS is the pixel coordinate system of the original image, which may be different from the pixel coordinate system of the current image, if the current image is the result of an imcopy or other geometric transformation operation. In the """"physical"""" coordinate system the ltv, ltm and the axis attribute parameters wtype, axtype, units, label, and format may be edited, but the FITS parameters crval, crpix, and cd cannot_. [reference](http://stsdas.stsci.edu/cgi-bin/gethelp.cgi?wcsedit)    3. When used in API, the actions are dispatched one after another. For example, dispatchCreateRegionLayer might be issued before image plot has finished loading. Can we make regionCreateLayerActionCreator wait for image with plotId to finish loading?     More details: If I create a region layer with a few regions in image coordinates right after firefly.showImage, two errors are loaded to console:   doOnAppReady: uncaught TypeError: Cannot read property 'getImageCoords' of null(),   RegionFactory:602: Uncaught (in promise) TypeError: Cannot read property 'getImageCoords' of null()    4. When a region is selected, yellow dashed line appears around it. On zoom the line does not change color.    5. Can not add empty region. Line 124 of the test script.    6. Can not add or delete regions after the first one. (Load test script, click Show Regions, then Add Region, line 121 of the test script) When there is one region in the layer and you are adding another region with a different position but everything else the same, the added region is perceived to be the same.    7. It's possible to select regions only in in the first region layer added. In the other layer, you can sometimes see the selection blinking, but it does not stay.    8. If region format is wrong, for example  'image; box 40 400 72 72 # color=blue' instead of  'image; box 40 400 72 72 0 # color=blue',   the region is silently ignored, no warning or error is logged to console.    9. We need region selection action to support callbacks on region selection. (Currently the selected region is """"calculated internally based on the distance between the region and  mouse readout.)"""
"DM-7021","Story","pex_exceptions",1,"Update pex_exceptions to support Python 3","""{{pex_exceptions}} needs to be updated to support Python 3."""
"DM-7048","Story","butler",1,"validate_drp is failing because it's accessing butler internals that have changed","""need to change obs_decam's ingest task to use the newer class hierarchy to get the root of the butler's single repository. (longer term there should be a butler API for this or the task should get the value of root from somewhere else)"""
"DM-7047","Story","pex_config",1,"Port pex_config to Python 3","""Work involved in ensuring that pex_config passes all tests on Python 3 and legacy Python."""
"DM-7044","Story","pipe_tasks",3,"Additional constraints on reference band selection for multiband","""Reference band selection currently depends on the configured band priority order, with exceptions made for sources with low signal-to-noise in the high priority bands.  [HSC-1411|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1411] points out that some additional qualifications, such as success for major measurements (e.g., CModel and Kron), would be helpful."""
"DM-7043","Story","QA",5,"Update SQuaSH database model and JSON API with concepts from validate_drp measurement API","""In DM-6629, a new measurement API was introduced into validate_drp that established a JSON data model for metrics, specifications of metrics, measurements, and general blob datasets. The intent of that work is to enable rich plots in the SQUASH dashboard, with access to data behind measurements. The new data model also clarifies the subtleties of metric specifications (filter dependence, and dependence on other specifications). This ticket will incorporate validate_drps new data model into the SQUASH database and API.    Also related to DM-7041, which will update the post-qa tool that submits validate_drp json to the SQUASH API."""
"DM-7040","Story","meas_algorithms|meas_extensions_psfex",2,"Stars selected by starSelector change when number of cores varies","""Sogo Mineo writes in [HSC-1414|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1414]:  {quote}  See the following lines:    meas_algorithms/HSC-4.0.0/python/lsst/meas/algorithms/objectSizeStarSelector.py:466  in ObjectSizeStarSelector.selectStars():      In reduceFrames, these lines set the width of psfCandidate to be 21  for the first time the execution reaches there.    When the first CCD image has been processed, the worker process  continues to process another CCD image, and the execution reaches  here again.  This time, psfCandidate.getWidth() is 41, because  psfexPsfDeterminer has set it to be 41, and the value has been  retained because the width is a static member.  And so, for the second  CCD image, the width of psfCandidate is not 21 but 41.    Since psfCandidates are widened, stars positioned at edges of images  are rejected.  It results in a smaller number of PSF candidates than expected.    Only CCD images that are initially given to the worker processes  are processed with psfCandidate.getWidth() == 21. The other CCD images are  processed with psfCandidate.getWidth() == 41.  When the number of SMP cores changes, CCD images are processed with different  parameters.    The change in the number of PSF candidates results in different Psf, a different  result of image repair, and different catalogs.  {quote}    The line numbers are different on the LSST side because of refactoring (objectSizeStarSelector.py:466 has moved to starSelector.py:148), but the bug is still present.  The main problem appears to be that the {{PsfCandidate}} elements are {{static}}, are being set in both the star selector and the PSF determiner and one of those is conditional on what the value is.  I will investigate moving the {{static}} class variables to instance variables --- the desired size appears to vary by context, so it shouldn't be a class variable."""
"DM-7039","Story","afw",5,"Familiarization with Footprint redesign","""Familiarize yourself with the RFC-37 driven Footprint redesign. Start thinking about ideas for how you could implement it and what the transition plan from the current Footprints might be.    A great outcome would be to propose a set of stories which would tackle the new Footprint development effort.    A good outcome would not be to have the stories ready to go, but to be well prepared for a discussion with [~jbosch] & [~swinbank] where we'll come up with some stories as a group."""
"DM-7031","Story","Design Documents",2,"Assign initial responsibilities in LDM-151","""Assign first thoughts on responsibilities to all software primitives and algorithmic components. This is my take. Simon will have his own take."""
"DM-7058","Epic","jointcal",20,"Generate useful plots of jointcal results (I)","""JointcalTestBase currently generates a few different plots (old vs. new WCS quiver and heat maps, relative and absolute RMS histogram) to summarize the fitting results. After showing these to people and some discussion, we came up with a number of other plots that would be very useful to help understand the fitted WCS that jointcal produces. Since figuring out how to produce some of these plots may be tricky, or may be best done after the new WCS system is in place, I'm making separate stories for them.    It also would be good to have an external plotting framework that lives outside the tests."""
"DM-7050","Story","Stack Documentation and UX",5,"LTD Keeper: Use Google Cloud Platform SQL","""Currently LTD Keeper uses a sqlite DB. This ticket will migrate that DB to Googles Cloud Platforms managed SQL. This solution provides automatic backups, and provides flexibility to run multiple ltd-keeper pods. Googles SQL makes sense since LTD Keeper is run on Google Cloud Platform."""
"DM-7070","Story","jointcal",1,"Move consts from top of Associations.cc into JointcalConfig","""There are three values at the top of Associations.cc under a TODO comment that should be lifted up into JointcalConfig so they can be configured at runtime. It would be good to try to add tests to check different values for them (and possibly just remove usnoMatchCut)."""
"DM-7069","Story","daf_persistence",1,"Port daf_persistence to Python 3","""Work relating to getting daf_persistence to run on python 3. Includes some code modernization."""
"DM-7067","Story","jointcal",0.5,"Break joincal's link to upstream lsst_france repo","""lsst/jointcal is still linked to the upstream repo at lsst_france. I believe all the relevant changes have been ported. It's time to break that upstream link, so that pull requests can be made in a more obvious fashion."""
"DM-7066","Story","pex_logging",1,"Port pex_logging to Python 3","""Work required to get pex_logging working on python 3. Will also include some package cleanups."""
"DM-7091","Epic","Qserv",20,"F16 Qserv Release Mgmt","""Developer work to support the monthly and end-of-cycle qserv releases.  Includes compiling release notes, updating package dependencies, updating installation docs, minor fixes in support of new compilers, etc."""
"DM-7090","Story","SUIT",2,"IrsaViewer catalog panel, labels and input fields moved as you type","""Catalog search panel in IrsaViewer, the target panel label, feedback, and input box are jumping as input is being typed.  Their position should be fixed."""
"DM-7080","Story","doxygen|Stack Documentation and UX",0.5,"Doxygen isn't updating","""The current build of our Doxygen documentation, as displayed at https://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/index.html, is labelled """"Generated on Mon Jun 27 2016 03:52:22 for LSSTApplications"""". At time of writing, that's more than a month ago. Important additions to the documentations made during the last month are missing.  """
"DM-7106","Story","Qserv",13,"PDAC Qserv Deploy","""Configure cluster and adapt scripts and methodology as necessary to support qserv deploy on the PDAC cluster at NCSA, as is currently done at IN2P3.  """
"DM-7104","Story","Qserv",8,"support PDAC Qserv deploy","""Support John in adapting scripts and methodology as necessary to support qserv deploy on the PDAC cluster at NCSA, as is currently done at IN2P3.  """
"DM-7095","Story","Stack Documentation and UX",3,"Pilot Sphinx/Breath/Doxygen-generated API docs for daf_base","""Since daf_base is low in the dependency tree and dominated by C++ APIs, it is an excellent candidate for exploring Sphinx-based package documenation for C++ with breathe and doxygen. We will also see how astropys automodsumm sphinx extension works with SWIGd Python APIs.    This prototype will build upon the system developed in DM-7094.    Lessons from this prototype will be fed into a """"Pipelines Documentation Implementation Planning"""" tech note in a follow-up ticket."""
"DM-7093","Improvement","daf_base",0.5,"Remove unused inPlace argument from PropertyList","""In DM-1972 [~ktl] says:  {quote}  It looks like we don't actually use the inPlace argument to the PropertyList add and set methods anywhere in the stack besides the daf_base unit tests. I think it was originally put in to accommodate the addition of COMMENT and HISTORY items that might want to be placed at the end of the PropertyList instead of grouped together, but the implementation actually still groups all of these items together, just at the end of the list instead of where they were. If this is not actually useful, the argument could be removed and SWIG presumably appeased.  {quote}  This removal is no longer needed to appease SWIG but the code can usefully be removed and a test branch for this was created as part of DM-1972. This ticket will be used for the actual removal.  """
"DM-7119","Story","Firefly|SUIT",1,"revise the Firefly README file","""Issues to think/discuss (in README)  # mention of Firefly Tools  # mention of viewer, plot  (for image display)  # testing data location     """
"DM-7117","Bug","meas_astrom|pipe_tasks",1,"measureCoaddSources fails with ""RuntimeError: Unable to match sources""","""Running measureCoaddSources.py, I'm getting a {{RuntimeError: Unable to match sources}}.  The patch I'm running on doesn't have a lot of pixels illuminated, so it's not surprising that there would be no matches, but that fact shouldn't cause the operation to fail.  The behaviour of the matcher has changed in this respect: before the refactoring of astrometry, {{AstrometryTask.useKnownWcs}} would not raise an exception, but log an error and return an empty list of matches (it successfully matched zero sources, which might be cause for concern).    I think we should fix the matcher to return an empty list (as it did previously), but perhaps a case can be made that measureCoaddSources should catch the exception and continue.  I think that's wrong because measureCoaddSources would have {{matches = None}} rather than an empty list, which communicates something different (""""I have no knowledge of matches"""" vs """"I tried to match and there's nothing""""); and measureCoaddSources shouldn't simply set {{matches = \[\]}} because it's not its responsibility to guess a type for what its subtask returns (breaks encapsulation)."""
"DM-7116","Bug","SUIT",2,"Drawing layers dialog title is not updated with context image mission","""Before migration, layers dialog title included mission name such as for example:  """"Layers- IRIS: 25"""".    Now the dialog title is a fixed string:   """"Drawing Layers"""".    Make the title aware of the active image with the mission name since we know about it. """
"DM-7114","Bug","galsim",0.5,"Guard against assertion failure","""measureCoaddSources can hit an assertion failure in GalSim:      This is due to GalSim using asserts rather than throwing an exception.  We fixed this on the HSC side ({{7a73869}}), but it didn't come over because we're using GalSim as a dependency rather than sucking it into the package.    I thought I reported this upstream at one point..."""
"DM-7138","Story","ndarray",0.5,"Port ndarray to Python 3","""I just tried to build LSST ndarray on Python 3 and it does not work. It's all going wrong as {{include/ndarray/swig}} seems to not be compiling.    That API changed in Python 3 and it probably should be {{PyBytes_AsString}}.    http://stackoverflow.com/questions/22487780/what-do-i-use-instead-of-pystring-asstring-when-loading-a-python-module-in-3-3#22491037    """
"DM-7137","Bug","utils",2,"utils raDecStr delimiters are untested and don't work","""In working on DM-6320 I noticed that there do not seem to be any tests for the {{decStrToDeg}} and related functions. When I added the following test:  {code:python}     def testDecStrToDegDelim(self):          deg = lsstutils.decStrToDeg(""""+15_00_00.00"""", """"_"""")          self.assertAlmostEqual(deg, 15.0, 6)    Failed to parse +15_00_00.00 as a declination with delimiter '_' and regex '([\d]+)_(\d+)_([\d\.]+)'    Please add some tests. Alternatively, we could remove the delimiter option completely.    It might also be worth removing the code duplication in the RA and Dec variants."""
"DM-7134","Bug","pipe_drivers",0.5,"singleFrameDriver is only running with a single process","""singleFrameDriver.py is only using a single process.  The problem appears to be the change to use a {{ButlerInitializedTaskRunner}}, which doesn't inherit from {{BatchTaskRunner}}."""
"DM-7150","Story","utils",1,"Configure a default log for tests ","""The default configurations such as format and levels are different between {{lsst.pex.logging}} and {{lsst.log}}. With DM-6999 logs of command line tasks are changed from {{lsst.pex.logging}} to {{lsst.log}}.  For running command line tasks, logs are configured in {{pipe_base}}.      Based on RFC-203, another main use case is debug logging by running unit tests. In this case, log are not (and cannot be) configured in {{pipe_base}} command line interface.  This ticket adds a default configuration in {{lsst.utils.tests}} so the default logs will look more similar to what they have been with pex.logging when running unit tests. Developers can put customized configuration in each unit test (after DM-6999).   """
"DM-7152","Story","afw",1,"Port afw to Python 3","""Work required to allow AFW to work on Python 3."""
"DM-7166","Story","Firefly|SUIT",0,"Add new controller to react when table/xy-plot is clicked to display the observed image","""Create new controller to deal with actions on LC or periodogram or phase folded curve table and xy-plot:  * on row changed,  * on plot highlight.    On both actions, as time changed, the image should be updated in the image grid view with the new single exposure from the dedicated search processor (see DM-7164)    Note: Take into consideration that a user could select a different flux column     Fixed in DM-7167."""
"DM-7159","Story","Firefly|IRSA|SUIT",8,"Create a Light-curve viewer prototype to display time dependent dataset and compute periodogram","""The prototype could be considered as a sort of IRSAViewer for handling LC objects / Time dependent dataset, with extra feature that would enable the existing relationship between catalog and image, in particular for WISE, PTF, which could be a reference to single-epoch image (IBE referenced URL typically).    For each observation a corresponding image should be retrieved and placed in a grid (image vs time) either in the same LC object (table) or separately.   One could expect that any LC data-point (time point) would be pointing to an image (single-epoch, exposure) taken from a dataset (image axis would be a 3rd dimension or a 3rd view of LC).  LC should display LC object as following views:  * X-Y plot (typically flux vs time)  * Table  * Images (corresponding image dataset single exposure at a particular time)  The high-level requirements are:  # Easily plot light curve  # Compute Period using Lomb-Scargle   # Display folded Light Curve and Periodogram   # Link Light Curve Points with Single-Epoch Images  # Download Cutouts and Light Curves    In order to create the Light curve viewer prototype, we need to *create a skeleton app to start adding the tri-views* (Upper: plot, Bottom left: table, bottom-right: grid image): (DM-7406)  * Should handle single (one position) LC (table & plot flux or magnitud vs. time, tipically 'mjd')  ** For the prototype it will be a fixed table given  * Image of the single exposure to be displayed at least single page mode  * Should display input for computing a periodogram (the result of an API call)  ** Power spectrum (Power vs log(period) ) as table and xyplot  ** Peaks as a table (Power vs. period)  ** Period (first Period in peak table) as a field (editable), tipically in days.    In order to connect table/plot to single exposure image, be able to compute periodogram and plot based on the table focused, we need a 2 new UI components, 3 new searches and 2 new controllers (tickets will be created separately and added here):      1. UI components:    * To handle the algorithm input parameters to compute periodogram  (DM-7160)  * To handle the period input (DM-7161)    2. Processors:    whether it is in one search processor or in different one, we need to have the following task processor:    * One to deal with API to compute periodogram that will result at least in 2 tables (periodogram and peaks table, + extra output parameters fi needed) (DM-7162)  * one for getting the image cutout (single exposure) (DM-7164)  * one to build the phase folded curve based on (DM-7165)  ** Original table searched  ** Period whether it comes from the API result or any other changes from user afterward    3. Controllers:  * For image to change on row or xy plot curve clicked (DM-7166)  * For plotting chart based on the type of the table (power vs period, or LC or phase folded) (DM-7167)  """
"DM-7157","Bug","daf_persistence",2,"Test order in daf_persistence can cause some tests to skip","""If all tests are run from py.test as:    The {{DbStorage_?.py}} tests skip. If they are run without {{DbAuth.py}} running they run and pass. Something in {{DbAuth.py}} is causing the availability test to fail."""
"DM-7156","Bug","daf_persistence",1,"Linter errors in daf_persistence","""Running {{flake8}} on {{daf_persistence}} as part of DM-7069 I find two real errors.    # in {{butler.py}} the {{key}} argument was removed from {{queryMetadata}} in commit 3a169f but it is still documented as being there and is still used inside the function.  # {{mapper.py}} refers to class {{RepositoryMapperCfg}} but that class is not seemingly defined anywhere.  """
"DM-7182","Story","L1 Database",8,"Discuss L1 database requirements (continuing)","""There are few things that are not yet very well understood in the L1 database access from AP. I need to meet with pipeline people at LSST2016 and try to clarify all of them The list of questions will be added below."""
"DM-7180","Bug","meas_algorithms",1,"Port HSC aperture correction fix","""Port [HSC-1416|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1416] to prevent {{ZeroDivisionError}} in {{MeasureApCorrTask}}."""
"DM-7179","Bug","sconsUtils",1,"sconsUtils reads SConscript files in alphabetical order","""I have made the deeply embarrassing discovery that I knowingly made sconsUtils' reading of SConstruct files discovered in subdirectories ordered alphabetically, and considered this okay because """"include < lib < python < test"""".  This needs to be made user-configurable, probably via a keyword argument to {{sconsUtils.scripts.BasicSConstruct}}."""
"DM-7177","Story","afw",8,"Document interface for new Footprints class","""Create a technote and a community posting on the new Footprints class to both document the new api, and explain the differences with the old class."""
"DM-7172","Story","afw",3,"Implement SpanSet overlap tests","""Implement testing for overlapping spans in SpanSets"""
"DM-7171","Story","afw",5,"Document interface for SpanSets class","""Write up a brief technote describing the new SpanSet interface, both things such as functions etc, and descriptions about how it is expected to be used in the future, and made available through python. This will give others a chance to express their needs opinions for span sets while the development is still ongoing"""
"DM-7170","Story","afw",3,"Implement Interface for SpanSets","""Building off the work done in RFC-37, design a interface for a collection of sets to be called SpanSet. This should encompass most of what currently exists in afw footprints, but contain more topological set functionality."""
"DM-7168","Bug","Qserv",2,"Fix Qserv CI build w.r.t xrootd upgrade","""Qserv can't build using xrootd version tagged """"qserv-dev"""":    """
"DM-7196","Story","Firefly|IRSA|SUIT",1,"Make a design document explaining the light-curve core server-side functions","""We need a design schema document to identify and describe the core functions that will be commonly used by the Light-curve viewer as well as the inputs and outputs on:  - getting the single exposure image  - compute and getting a phase folded curve  - compute and getting periodogram  - getting the peaks table    Those functions will be used by the processors DM-7162, DM-7164, DM-7165 via one or several Firefly 'search' processor.  Would be also helpful to add the description on the expected table format and content that the (future) NexSci API will offer."""
"DM-7195","Story","Firefly|IRSA|SUIT",2,"Add a download feature to get the single exposure cutout from a LC","""The LC viewer need an extra download button to get all the cutout from the light-curve table.  The output can be a tar/zip file, or it can be also the wget (curl) scripts to download them if too many images."""
"DM-7192","Bug","Firefly|IRSA",2,"replaced image of the coverage is gone after expand mode","""do a catalog search, then do an image search to replace coverage image by another image (say WISE), then go in expand mode and back, the image is replaced back to the initial coverage image"""
"DM-7190","Story","Firefly",2,"Fix region bugs related to zoom selected region, add empty region layer and add/remove more regions","""This one is made to include some issues report in DM-7027 (issues 4, 5, 6):    4. When a region is selected, yellow dashed line appears around it. On zoom the line does not change color.  5. Can not add empty region. Line 124 of the test script.  6. Can not add or delete regions after the first one. (Load test script, click Show Regions, then Add Region, line 121 of the test script) When there is one region in the layer and you are adding another region with a different position but everything else the same, the added region is perceived to be the same."""
"DM-7212","Bug","Firefly",0,"The feature 'lock-by-click' in the readout panel doesn't work","""The feature 'lock-by-click' in the readout panel doesn't work, when checked, the readout doesn't display any value from any image click."""
"DM-7208","Story","Qserv",0.5,"Minor fixes for issues flagged by Eclipse codan","""Fix a few minor errors that were flagged by the Eclipse Neon C++ code analyzer."""
"DM-7207","Story","afw",8,"Modify afw tests to support pytest","""This ticket is for the work of migrating the AFW tests such that they run with the py.test test runner."""
"DM-7206","Story","Design Documents",2,"LDM-151 review meeting, 2016-08-08","""Prepare materials for and participate in the meeting."""
"DM-7205","Story","Design Documents",2,"LDM-151 review meeting, 2016-08-08","""Prepare materials for and participate in the meeting."""
"DM-7204","Story","Design Documents",2,"LDM-151 review meeting, 2016-08-08","""Prepare materials for and participate in the meeting."""
"DM-7203","Story","Design Documents",2,"LDM-151 review meeting, 2016-08-08","""Prepare materials for and participate in the meeting."""
"DM-7199","Improvement","afw",2,"afwTable's .getX()/.getY() do not appear in dir()","""On a SourceCatalog, I can call {{cat.getX()}} or {{cat.getY()}} to return an array of pixel coordinates, but neither of these functions appear in {{dir(cat)}}. This breaks introspection and makes it difficult to know what other such magic functions exist (e.g., I can't tell if there is an equivalent for ra/dec)."""
"DM-7221","Bug","afw",1,"TUNIT header is not uniformly applied to columns in FITS table output from afw.table","""In looking at the Source table outputs (SRC*.fits files) in the validation_data_hsc repository, we noticed that the headers are not consistently applied in the FITS files generated by afw.table output.  In particular, the TUNIT keywords are missing for the coord_ra and coord_dec columns, making it difficult for a client to determine that the columns are persisted in units of radians, especially since the FITS convention is for the default units for angles to be degrees.    {quote}KEYWORD:   TUNITn  REFERENCE: FITS Standard   STATUS:    reserved  HDU:       table  VALUE:     string  COMMENT:   column units  DEFINITION: The value field shall contain a character string describing  the physical units in which the quantity in field n, after any  application of TSCALn and TZEROn, is expressed.   The units of all FITS  header keyword values, with the exception of measurements of angles,  should conform with the recommendations in the IAU Style Manual. For  angular measurements given as floating point values and specified with  reserved keywords, degrees are the recommended units (with the units,  if specified, given as 'deg').{quote}    http://heasarc.gsfc.nasa.gov/docs/fcg/standard_dict.html    Accepting that we are not conforming to that convention, the proper value for TUNITn is """"rad"""" for data in units of radians.    While much access to afw.table-produced files will be through the afw.table interfaces, where this issue is irrelevant as long as round-tripping is successful, for exploratory and debugging purposes it is very useful to be able to access the file contents with standard tools.    In addition, if the FITS tables produced from afw.table are to be used as the input to the database ingest, providing units for all columns will assist the database system in providing and validating correct column metadata to its clients, whether through VO standards or other means."""
"DM-7214","Bug","Qserv",2,"Replace docker_spy by hostfile management","""docker_spy is broken and breaks travis CI. It is now replace with raw hostfile management, simpler and more robust"""
"DM-7225","Story","Firefly|SUIT",20,"File upload function","""Develop a file upload function:  - upload FITS, VOtable, IPAC table, CSV file,  ...  - distinguish file type  - list multiple extensions of FITS, to know the type (image or table) of each extension  - display header information of each extension or the data accordingly  """
"DM-7239","Bug","Firefly",2,"Any table update ('reset', sorting..) will also reset image options","""When table is updated after sorting or clicking on 'reset' option, the image is reset to default option. If you have a different color stretch/scale or zoom, the image gets reset to initial values loosing the operations applied.    Updates:    This is the case with coverage image only.  On every table update, it will re-calculate the coverage, then redraw it with default options.  Prior to conversion, coverage image also reset its options when it does a redraw.  However, it only does a redraw when the catalog data have changed, like when filter is applied.   """
"DM-7250","Story","display_ds9",1,"Adapt display_ds9 to py3","""Follow the steps in the [LSST 2016 presentation|https://project.lsst.org/meetings/lsst2016/sites/lsst.org.meetings.lsst2016/files/201608-LSST2016-py3.pdf] by [~tjenness] to update the Python code in the {{display_ds9}} package. This will be a learning exercise to prepare for updating {{display_firefly}} for SUIT."""
"DM-7268","Bug","pipe_tasks",1,"Record source measurement time in the metadata","""Currently the measurement of sources in {{processCcd.py}} and {{imageDifference.py}} is not wrapped by {{pipeBase.timeMethod}}, and thus the metadata does not record this processing time. Adding this wrapper will improve our ability to track processing speed improvements."""
"DM-7267","Improvement","utils",1,"Add array equality helpers to TestCase","""afw.math added equality helper method, e.g. {{assertImageEqual}}, that just call the appropriate NearlyEqual method with tolerance of 0. It would be good to have equivalent """"assertArrayEqual"""" and """"assertArrayNotEqual"""" methods that wrap assertClose, which has some useful functionality (e.g. plotting) beyond what numpy.testing.allClose provides."""
"DM-7260","Story","cat",1,"Modify cat package to support python3","""LSST2016 DM hack session for updating LSST code to support python3.  Instructions: https://project.lsst.org/meetings/lsst2016/sites/lsst.org.meetings.lsst2016/files/201608-LSST2016-py3.pdf  """
"DM-7259","Story","Continuous Integration",1,"jenkins user listing and per user builds is unreliable",""" I'm seeing some odd behavior with /asynchPeople/ only listing a small number of the actual users.  The list keeps refreshing itself with a different partial list.  Possibly related, /user/<userid> isn't listing all builds for a users, in some cases, it lists no builds at all for users which should have 100s"""
"DM-7253","Story","db",1,"Modify db package to support python3","""LSST2016 DM hack session for updating LSST code to support python3.    Instructions: https://project.lsst.org/meetings/lsst2016/sites/lsst.org.meetings.lsst2016/files/201608-LSST2016-py3.pdf"""
"DM-7280","Bug","Firefly|IRSA",2,"Atlas: table scrambled values when few columns are selected","""Atlas table has inconsistent values when a few columns are selected.  Please fix. (Not happening in Gator btw)"""
"DM-7279","Bug","Firefly",0.5,"Firefly table and xy plot 'reset' should returned default values","""'reset' button before migration returned the initial default values, not the previous applied values.  Please, restore function so 'reset' feature would give back the initial default values.    For example, if table starts with 'show units', 50 rows per page, clicking 'reset' button should give back this values if user changed them before."""
"DM-7275","Bug","Firefly",1,"Image expand mode had name of image at top left whereas migrated image view has ""Tiled View""","""Before migration, expanded single image had the name on top left corner.    The current migrated view says 'Tiled View' which is not correct with the view itself. Please, add correct information of the expanded mode and/or the image name."""
"DM-7274","Bug","Firefly|IRSA",1,"Although the table shows more than 1 position, xy plot displays 1 single datapoint","""In IRSAViewer and Gator/Atlas:  one single point is shown in XY Plot (RA vs. DEC) despite the fact that the table contains more points (see attached snapshot)    Step to reproduce from IRSAViewer (external viewer from Atlas) or from Gator itself: Do a catalog search 'm82' on AllWise around 100 arcsec.  """
"DM-7273","Bug","Firefly",1,"Smaller readout switch to bigger one unexpectedly","""Either in firefly demo page or in Gator, the small readout switch unexpectedly into the exanded bigger readout.    Please, check that the readout size and information layout should stay constant consistently.     (I could duplicate it but there is no clear pattern step by step to reproduce, but definitively i could see readout switching back and forth - maybe related to 'lock-by-click' problem)"""
"DM-7271","Story","SUIT",2,"Change default format for float and double to %g","""DM-7271: table enhancements    * do not apply default data format  * introduce optional display format  * add """"AUTO"""" and """"NONE"""" as format keywords.  * for fits table, set display format to """"%.9g"""" for double type.  * add support for TDISPn fits table header  * remove condition so temp files will not get written into source directory    When reading fits table, set display format to """"%.9g"""" for double if TDISPn is not given."""
"DM-7309","Story","obs_cfht",1,"Port obs_cfht to Python 3","""This ticket covers the work required to get obs_cfht working with Python 3."""
"DM-7299","Story","Third Party Software",0,"Check lmfit works with Python 3","""lmfit is meant to work with Python 3 but this needs to be checked. Some code in the tree does not work with Python 3 but it is possible that this code is not used by LSST."""
"DM-7295","Story","Third Party Software",2,"Get astrometry.net that works with Python 3","""The current release of astrometry.net does not support Python 3. Upstream needs to be fixed."""
"DM-7314","Story","Developer Infrastructure",1,"Odd Jenkins failure","""A Python 3 Jenkins build failed with a very unusual log full of """"#"""" and no clear idea of what went wrong.    https://ci.lsst.codes/job/stack-os-matrix/label=centos-7,python=py3/14730//consoleFull"""
"DM-7317","Bug","Firefly",2,"Log scale doesn't work with sample table attached","""When using the attached sample ipac table with 2 columns 'period' and 'power' from 'Data Sets: Catalogs & Images' dialog (firefly viewer), the XY-plot display correctly the data 'period' vs. 'period.     Changing Y axis to plot 'power' column and selecting 'log' scale, the axis disappear and nothing seems to be converted in log scale.    An error message can be seen in the console related to highchart.js:  highcharts.js:15 Uncaught Highcharts error #10: www.highcharts.com/errors/10P @ highcharts.js:15setTickInterval @ highcharts.js:16setScale @ highcharts.js:17(anonymous function) @ highcharts.js:18each @ highcharts.js:8setSize @ highcharts.js:18shouldComponentUpdate @ XYPlot.jsx:350updateComponent @     Please, investigate why and fix.  Thanks!"""
"DM-7338","Bug","butler|pipe_drivers",2,"Fix-up any code that uses butler.repository","""See https://community.lsst.org/t/access-to-root-in-butler/991  When running constructBias.py in lsst_apps w_2016_34 I get the error:  AttributeError in map: 'Butler' object has no attribute 'repository'  The source of the error is probably  https://github.com/lsst/pipe_drivers/blob/master/python/lsst/pipe/drivers/constructCalibs.py#L585  All code that uses butler.repository should be fixed. If that's too much work possibly the ticket could get changed to fix constructCalibs only for now."""
"DM-7336","Bug","Firefly",2,"Rotation of image display bug","""The rotation of a z-scale log stretched  or north-up image operation fails and changes the stretch. The image becomes black/white.   That doesn't happen with linear stretch btw.   It looks like a server -side problem.    Step to reproduce:  Either by searching from Spitzer GOALS images or just uploading the attached FITS file, then stretch on 'z-scale log', then rotate (45deg). The stretch changes. Same for north-up operation."""
"DM-7332","Story","meas_extensions_simpleShape",0.5,"Modify meas_extensions_simpleShape tests to support pytest","""This ticket is for the work of migrating the meas_extensions_simpleShape tests such that they run with the py.test test runner.  """
"DM-7329","Story","meas_extensions_photometryKron",0.5,"Modify meas_extensions_photometryKron tests to support pytest","""This ticket is for the work of migrating the meas_extensions_photometryKron tests such that they run with the py.test test runner."""
"DM-7328","Story","QA",0.5,"Port validate_drp to Python 3","""This ports {{validate_drp}} to Python 2+3 compatibility.    (Note that the work is still against the {{u/sqre/measurement-api}} integration branch until we can coordinate the coordinate the deployment with SQUASH.)"""
"DM-7327","Story","Third Party Software",1,"Check ngmix works on Python 3","""Check that {{ngmix}} works on python 3."""
"DM-7326","Story","Firefly",2,"Adapt FireflyClient (renamed to firefly_client.py) to Python 3","""The stack is being adapted to work with Python 3 as well as Python 2. Following the guide from LSST2016 for porting packages to Python 3, adapt the FireflyClient API. This will allow afw.display to work with Firefly in a Python 3 stack."""
"DM-7325","Story","meas_extensions_ngmix",1,"Port meas_extensions_ngmix to Python 3","""Work associated with adding support for Python 3 to {{meas_extensions_ngmix}}."""
"DM-7324","Story","ci_hsc",1,"Port ci_hsc to Python 3","""Work associated with ensuring that {{ci_hsc}} works with Python 3."""
"DM-7358","Story","meas_modelfit",0.5,"Modify meas_modelfit tests to support pytest","""This ticket is for the work of migrating the meas_modelfit tests such that they run with the py.test test runner."""
"DM-7356","Epic","ap",20,"Run test on prototype alert distribution and report on results","""Tests are defined in DM-7355, but should be done in a staged way to increase the complexity of the system to test scaling.  Not all test scenarios need to be tested with each configuration.    A scheme like the following could work:  # Test 1: Mac with single server, 189 prodcuers  #* 1 consumer  #* 10 consumers  #* 100 consumers  # Test 2: Mac with 3 servers, 189 producers  #* 1 consumer  #* 10 consumers  #* 100 consumers  # Test 3: on big Nebula virtual machine with single server, 189 producers  #* 1 consumer  #* 10 consumers  #* 100 consumers  # Test 4: on one Nebula virtual machine with 3 servers, 189 producers  #* 1 consumer  #* 10 consumers  #* 100 consumers  # Test 5: 3 Nebula virtual machines  #* 189 producers within Nebula: 1, 10 and 100 consumers internal to Nebula  #* 189 external producers: 1, 10, 100, and N consumers both internal and external to Nebula    Product will be a DMTN on the results of using Kafka as the backend technology for supporting the internal alert distribution system."""
"DM-7355","Epic","ap",20,"Provide a set of parameters to measure and contexts to test","""The tests will have clearly defined measurements and failure modes.  We will need a tool for monitoring all the parameters.    Example system params to measure:  * latency and throughput  * CPU usage  * mem usage  * network I/O  * disk I/O    Example distribution system tests:  * Kafka node goes down  * Vary rampup of producers  * Vary message size  * Vary message block size  * Vary number of consumers    Result will be a list of system parameters to monitor, a list of distribution system tests, and a tool to do the monitoring."""
"DM-7352","Epic","ap",20,"Prepare for testing the candidate technology for the alert distribution system","""In order to test out the suggested candidate technology for alert distribution within the LSST system (Kafka) several activities need to be carried out.    1. Perform a literature review of relevant documents: Kafka paper and Comet paper at least  2. Answer relevant questions for setting up testing: e.g.  * What are topics used for?  * What partition sizes are optimal?  * Time scales for tests?    Product will be a short writeup of the literature review and any questions that came up and were resolved.  """
"DM-7350","Story","ip_diffim",1,"Cleanup ip_diffim's afwData test skipping","""There are a number of {{if not self.defDataDir: print(""""skipping""""); return}} blocks in the ip_diffim tests that should be converted to {{@unittest.skipIf}} decorators. Otherwise, those tests may silently not be run, which is bad."""
"DM-7347","Story","meas_deblender",0.5,"Modify meas_deblender tests to support pytest","""This ticket is for the work of migrating the meas_deblender tests such that they run with the py.test test runner."""
"DM-7341","Story","utils",1,"Handle lsst.utils.tests dependency better in testExecutables.py","""The {{testExecutables.py}} script that allows py.test to run executable unittests requires lsst.utils.tests. Several packages such as sphgeom explicitly avoid making lsst.utils a dependency. Hence {{testExecutables.py}} is unable to reside inside the {{sphgeom}} package and {{py.test}} is unable to run the executable unittests for now. Figure out which is better:    # Make sphgeom depend on lsst.utils  # Remove the lsst.utils dependency from testExecutables.py"""
"DM-7386","Bug","Developer Infrastructure|lsstsw",0.5,"Jenkins/lsstsw no longer seems to build optional dependencies in all cases","""If I ask Jenkins (or {{lsstsw}}) to build {{skymap}} the optional dependency of {{healpy}} is not included in the build. If I try to build {{afw}} it does include the optional dependencies of {{pyfits}}, {{matplotlib}} and {{afwdata}}. {{pipe_base}} does bring in its optional dependencies as well.    I haven't worked out what is """"special"""" about {{skymap}}.    For an example Jenkins build: https://ci.lsst.codes/job/stack-os-matrix/label=centos-7,python=py3/14837//console    Table file:    """
"DM-7384","Improvement","obs_lsstSim",0.5,"Modify obs_lsstSim to support py.test","""Migrate the {{obs_lsstSim}} tests such that they run with the {{py.test}} test runner.  """
"DM-7379","Bug","ip_diffim",1,"random seed not run in command line test","""In the conversion of ip_diffim to pytest a random.seed was moved to inside the setup_module function as opposed to the seUp method. When run from the command line (for example using Jenkins) this test can fail."""
"DM-7376","Bug","ip_diffim",8,"Failure to identify location of clear supernova in a subtraction","""I've run a subtraction of two images, one with a clear supernova (SNR~100), the other taken a year later.  The supernova shows up very clearly, but does not get properly identified by the object detection and measurement.    If run with {{config.doMerge=False}} then I get the first attachment, which shows the identification of a footprint in which the SN is found, but the X, Y position are set to be the presumably the first object that went in to the footprint.  It's not re-centered at the SN.    If I run with {{config.doMerge=True}}, then I get the third attachment, in which I believe the SN has been subsumed into the larger object of the dipole at the galaxy center.    Some notes  1. There is significant galaxy background (that's what I wanted to do the subtraction).  This changes the noise properties and, from my understanding of a discussion on Hipchat, breaks assumptions made by the de-correlation step.  2. These images are from a NIR detector, so they are created from a sequence of raw images in a grid dither pattern, which have been processed and combined to make these final images.  This means that the noise varies significantly across the image, from the center which is covered by all raw images, to the corners which are each just covered by one.     To recreate on lsst-dev.ncsa.illinois.edu:    Set up the LSST stack + some custom branches in {{pipe_tasks}}, {{ip_diffim}}, {{obs_file}}:          If you're testing for yourself, you may wish to change the output repo to your own cusomt repo so we don't accidentally confuse each other with various runs.    The active parts of {{diffimconfig.py}} are        For a quick start, the following will display the images:    """
"DM-7372","Story","Design Documents",1,"Add information on milestone relationships to DMTN-020","""Per [this discussion of LDM-472|https://github.com/lsst/LDM-472/commit/5ad5f731463cb0b17f8919c6d6016e63441b0a2e#commitcomment-18628148], please add material to DMTN-020 about relationships between milestones."""
"DM-7392","Story","Design Documents",1,"More LDM-151 Review Updates","""Implement changes identified in walking through the Algorithmic Components and Software Primitives sections with [~swinbank] and [~krughoff]."""
"DM-7387","Story","obs_decam",0.5,"Modify obs_decam to support py.test","""Migrate the {{obs_decam}} tests to support py.test"""
"DM-7405","Story","Firefly",8,"Add VOTable support when uploading table ","""Uploading a votable result from simple cone search is not currently supported.    We should provide VOTable xml file as part of the format supported by table upload.    Make sure that it handle also VOTable with BINARY2 encoding (attached sample from Gaia DR1)."""
"DM-7433","Story","processFile",2,"Create test case for processFile","""Add a testing suite to {{processFile}}.  Specifically create a simple test case that verifies that {{processFile.py}} runs on a known set of test data.    Optionally create simple additional tests if any occur.    Implementation Plan  1. This test data will be from {{afwdata}}, as this adds minimal dependencies.  See https://community.lsst.org/t/should-i-take-example-test-files-from-afwdata-or-obs-test-to-write-a-test-case-for-processfile/1101/2 for a bit of discussion.  2. The dependency on {{afwdata}} will be {{setupOptional}}.  A user shouldn't have to download {{afwdata}} just to run {{processfile}}, but we will want to run this test as part of our regular Jenkins builds and CI efforts to make sure things don't get broken.    Tests of performance against a known standard will be deferred to the {{lsst_ci}} package.    """
"DM-7429","Story","Stack Documentation and UX",0.5,"Publish LSE-163 to LSST the Docs","""The treatment will be a static HTML landing page, similar to ldm-151.lsst.io"""
"DM-7425","Story","pipe_supertask",1,"Port pipe_supertask to Python 3","""Work for porting {{pipe_supertask}} to Python 3."""
"DM-7424","Story","Design Documents",1,"Rework joint photometric calibration in LDM-151","""The current text in LDM-151 for joint calibration (by [~pyoachim]) mostly concerns global calibration, but references to it in the DRP pipelines section assume we'll use Gaia for global calibration.    I'll try to resolve that discrepancy with minimal modification on this issue, and then ask [~zivezic] and [~rhl] to review.  """
"DM-7419","Story","Data Access",0.5,"Port dax_webservcommon to Python 3","""Work related to porting {{dax_webservcommon}} to Python 3."""
"DM-7418","Story","Data Access",0.5,"Port dax_webserv to Python 3","""Work related to porting {{dax_webserv}} to Python 3."""
"DM-7417","Story","Data Access",0.5,"Port dax_metaserv to Python 3","""Work related to porting {{dax_metaserv}} to Python 3."""
"DM-7416","Story","Data Access",2,"Port dax_imgserv to Python 3","""Work related to porting {{dax_imgserv}} to Python 3."""
"DM-7415","Story","Data Access",0.5,"Port dax_dbserv to Python 3","""Work related to porting {{dax_dbserv}} to Python 3."""
"DM-7456","Story","ap",2,"Scale up Kafka alert consumers","""Use Docker compose or something similar to easily scale up from one Kafka alert consumer to N consumers."""
"DM-7455","Story","ap",5,"Scale up Kafka alert producers","""Figure out how to use Docker compose or something similar to easily scale up from one producer to 189 producers, one per CCD."""
"DM-7450","Story","Stack Documentation and UX",0.5,"Update coding standard to reflect non-executable tests (RFC-215)","""Following the discussion at RFC-215, we need to update the developer guide to reflect that python tests should not be executable, nor have a shabang at the top. This is probably a few sentences to the python [testing portion|https://developer.lsst.io/coding/python_testing.html] part of the dev. guide, possibly in a new subsection at the end."""
"DM-7448","Bug","Firefly",1,"Table reset unset option 'Show unit' initially set","""Reset feature works ok as expected unless if the table is created with 'show unit' option checked initially reset button will unset the option when it shouldn't changed it.  Please investigate and fix.    The problem can be shown in the table with filters and units on by default here:  http://localhost:8080/firefly/demo/ffapi-highlevel-test.html"""
"DM-7447","Story","Science Pipelines",2,"Run DCR template generation on real data","""The DCR template generation code has been developed and tested using simulated data. It would be informative to try running it on real data to identify new issues and see if it works."""
"DM-7445","Story","Science Pipelines",8,"DCR template generation speed improvements","""The current DCR template generation code takes approximately 30s per pixel on a single core to run. This code needs to be optimized to run much faster."""
"DM-7444","Story","jointcal",8,"Improve jointcal plotting backend","""While working on the jointcal quiver plots, etc. I made all the plots with the default, interactive, backend. Now that I need to use larger datasets on lsst-dev, interactive mode won't work, but would be useful to keep as an option. I had started to convert to using Agg during the All Hands Meeting, but got stuck on some strange interactions with quiver.    This story is to capture the work I started on it, and to finish cleaning up that code. It might even be worth lifting the plotting code out of the tests, now that they're becoming more complicated. It would be useful to be able to generate these plots during non-testing jointcal runs.    This might be a good opportunity to develop the """"unified plotting abstraction layer"""" described in DM-5790."""
"DM-7442","Story","Science Pipelines",8,"Write unit tests for DCR template generation code","""DM-5697 and DM-6249 created code that generates DCR-matched template images for image subtraction. These functions should have unit tests."""
"DM-7437","Bug","Qserv",2,"Fix eupspkg command for qserv containers","""A bug was introduced during DM-6444. Fix is provided here."""
"DM-7436","Story","Qserv",2,"Cleanup in admin/tools","""Remove obsolete files and directories and update documentation.  See:  - admin/tools/cluster/  - admin/tools/*"""
"DM-7470","Bug","Firefly",1,"Firefly viewer (and IRSAVIewer) shows an extra coverage tab when doing a catalog search","""Once the viewer shows an image search or externally calling the viewer to expand an image previously displayed, it will display a coverage image (extra tab) after doing a catalog search.    In IRSAVIewer, this is inconsistent with previous flow and appearance, a catalog search expect to return and overlaid on top of the previously image displayed. Coverage shouldn't appear if an image is already loaded and a search catalog is triggered.    Plus, when the user get rid off the catalog, the image left is the selected image (could be the added coverage image).    At some point, this was working as before but the flow had changed.  Please, restore the way it was before, no coverage after doing a catalog search when an image is already loaded from image search or pushed externally to the viewer."""
"DM-7465","Story","Requirements Documents",20,"Add requirement annotations to DPDD","""When linking items in DPDD to requirements and design documents, we need to provide anchor links that can be referenced outside of DPDD and which are guaranteed not to change. Section numbers and """"item 5 in list on page 3"""" are not acceptable anchors. Explicit numbers will be assigned as margin notes to requirements-like items in DPDD."""
"DM-7464","Story","Firefly",2,"Repackage Firefly Python API in its own pip-installable repository","""After a discussion between [~gpdf], [~xiuqin] and [~shupe], there is a strong rationale for separating the FireflyClient API into its own repository (not combined with widgets):  * FireflyClient has very few dependencies, while {{firefly_widgets}} already depends on Astropy and more dependencies may be added.  * FireflyClient is pure Python, while {{firefly_widgets}} includes both Javascript and Python.    The proposal is to move FireflyClient out of the {{firefly}} repository and into its own repository {{firefly_client}}. -Within this repository, FireflyClient needs to be packaged to be pip-installable via {{pip install firefly_client}}.-    -To conform to Python module naming conventions, the module needs to be all lower-case, so that the users will import the class with something like {{from firefly_client import FireflyClient}} after it has been installed.-    Examples of using the Python API could be included in an {{examples}} subdirectory in this repository."""
"DM-7461","Story","afw",0.5,"afw test suite fails in the absence of afwdata","""Running a fresh build of afw master on os x fails on two unit tests. One is in testExecutables.py and is related to not finding AFWData. On my system AFWData is not installed and the test should be skipped, but is still run. The other is DM-7474."""
"DM-7460","Bug","Firefly|SUIT",2,"No help link/anchor option XY-plot component","""Table component has an option to add a link to onlinehelp for table documentation.  Xy-plot is missing this feature and need an anchor to link to xy-plot help dcumentation.    Please add to the API a way to pass a help-id property and add an anchor in the toolbar.  """
"DM-7458","Bug","ip_diffim",2,"Cannot add base_GaussianFlux to the list of default plugins in DipoleFitTask.","""The DipoleFitTask plugin in ip_diffim currently registers a number of default measurement tasks. However, if base_GaussianFlux is registered, the following error is produced:    Alias for 'slot_Shape_flag' must be defined before initializing 'base_GaussianFlux' plugin. {0}  lsst::pex::exceptions::LogicError: 'Alias for 'slot_Shape_flag' must be defined before initializing 'base_GaussianFlux' plugin.'    Track this down and fix it so that we can add base_GaussianFlux to the default list."""
"DM-7494","Story","ImgServ",8,"PDAC imgserv Butler configuration",""" Address butler configuration for imgserv to it can access calexps within PDAC  """
"DM-7492","Story","ImgServ",8,"Load calexps into PDAC","""Igor has located calexps, and begun work to stage them to NCSA.  Figure out final location in PDAC needed to support imgserv, transfer images there, and drop duplicates."""
"DM-7512","Epic","obs_cfht|obs_decam|obs_lsstSim|obs_sdss|obs_subaru|obs_test",40,"obs packages need a unified test framework","""The various obs* package test cases should derive from a set of parent TestCases, so that they all trivially have the same testing functionality. obs_decam has more tests written for it than most of the other packages, but most of those tests could be lifted into some higher package, with the obs_decam test looking like, e.g.        with all of the test* methods living {{obs_test_helper.tests.IdTestCase}}. This is just a sketch of a design, but I think it would both simplify deploying new obs packages and allow us to almost trivially improve testing coverage in the existing packages."""
"DM-7511","Story","SUIT",2,"Firefly API JSDoc build in Jekins","""We need to add JSDoc generation in Jekins build and bundle it in the firefly.war file when we make Firefly release.  """
"DM-7510","Story","obs_subaru",0.5,"Add support for HSC-R2 filter","""Port of [HSC-1419|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1419]."""
"DM-7509","Bug","log|obs_sdss",2,"Logging system sensitive to %s in string","""There are two bugs in the log package:    log.info(""""%s"""") results in:    this is because Log._log is defined with this line:    and in this case args is an empty tuple. A trivial fix is to replace this with:      However, doing so exposes another bug. The following will segfault:    This is because Log.log is extended in logLib.i as follows:    and the version of Log.log it calls expects additional format arguments. In general the log package seems to use {{logMsg}} when no {{%s}} formatting is wanted, and {{log}} when such formatting is wanted, so I propose to fix this using:      In addition, this requires the first fix to be changed to call {{logMsg}} instead of {{log}}"""
"DM-7504","Story","meas_deblender",1,"Compile list of missing or inadequate deblender functionality","""As part of DM-3622, we aim to make the single-band deblender equal to """"the state of the art"""". What does this mean in practice? Compile a list of features we need to add (the SDSS anti-shredding algorithm is the canonical example; are there others?) and pathological behaviour that we need to fix. Ensure they're all programmed into the epic as stories."""
"DM-7503","Story","meas_deblender",2,"Discuss deblender requirements with stakeholders","""Chat with stakeholders in the deblender (at least RHL, Jim Bosch) to get a better feeling for their vision of how it should be developed in the future. Understand the architectural requirements for multi-band deblending."""
"DM-7521","Bug","Firefly|IRSA|SUIT",1,"Add image feature in the image viewer toolbar is inconsistent when single image","""The toolbar of the image viewer shows a button to add or replace an image ('plot').    The option 'Create new plot' doesn't work when the viewer shows a single image without the 'grid'/'single' image expand mode toolbar (that happen for example in Gator but can be seen in demo page higher level API test).    The lock image feature is also not needed when only one image is shown.    The toolbar is different in Gator in OPS than it is in the migrated version. Please check the inconsistency and fix the toolbar.    9/7/2016  Xiuqin WU  After discussion today, the decision is to make the """"Create new plot"""" option work  when the """"Add image"""" icon (the one with + sign)   in both the normal mode and expanded mode.   Leave the lock icon as is. """
"DM-7520","Bug","Firefly",2,"XY plot is not shown after closing one of the catalog tab","""When 2 or more catalog search result tables are shown, the XY-plot displays the table selected. If one click on another tab, the xy-plot refresh and gets updated correctly plotting the table datapoints automatically.    If the user close the table, the next table gets focused and one expect to see the xy-plot to be updated.     The xy-plot doesn't refresh and shows empty grey background.    Please, investigate and fix."""
"DM-7518","Story","log",2,"Wrap log package with pybind11 instead of swig","""The {{log}} package was recently added as a future replacement for {{pex_logging}}.  Wrap this package with pybind11 instead of swig."""
"DM-7523","Bug","obs_sdss",1,"obs_sdss test should not print outside of test","""In DM-7346 the {{testSelectSdssImages.py}} test was modified to skip if a server was unavailable but the reason for the lack of availability was printed to standard error at the module level. This print is not captured by pytest (it only captures test output). The reason has to be moved inside the skip message."""
"DM-7538","Story","meas_modelfit",1,"CModel is producing SingularTransformException","""This is running on private data because I haven't yet found a public example that produces the problem.  The particular data set may be specialised, but we shouldn't be so chatty in any case.    """
"DM-7535","Story","Firefly|SUIT",1,"list the JS source files that need JSDoc generated for JS API","""Please make a list of JS source files that need JSDoc content updated in order to generate the JSDoc for Firefly JS API.     The update of all the source files will be separate tasks. """
"DM-7533","Bug","meas_astrom",1,"astrometry_net log is not controllable from the command line interface","""The external logs from astrometry_net (https://github.com/dstndstn/astrometry.net) is now passed through to {{lsst.log}} with the logger name """"meas.astrom.astrometry_net"""". But unlike other internal logger components, the astrometry_net log is not controllable from the command line intercae.  I suspect a bug in [this commit|https://github.com/lsst/meas_astrom/commit/bf568b1853fdd4f49e4fbae7f2fc731a15dc76aa].  """
"DM-7532","Story","Developer Infrastructure",0.5,"Add ""disallow if False:"" note to developer docs","""This is the implementation ticket for RFC-205.    The suggested additional text is given below, which probably best fits as a subsection of section 10 of the python style guide:    Code must not be placed inside `if False:` or `if True:` blocks, nor left commented out. If one has debugging code or if one is undecided about which particular implementation to use, such code must be placed inside a """"named"""" `if` statement. Such blocks may have a comment describing the conditions under which said code can be removed (e.g. completion of a ticket, a particular date). For example, for code that will likely be removed in the future, once testing is completed:        Such debugging flags should usually be lifted up into the method's keyword arguments to allow users to decide which branch to run. For example:        or, using [lsstDebug|https://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/base_debug.html], which can be controlled as part of a commandline task:    """
"DM-7531","Story","Continuous Integration",0.5,"Jenkins is no longer displaying test failure output","""At some point in the past week or so failures from Jenkins have stopped making available the output of test {{.failed}} files or the output of the {{_build.log}} file. This makes is almost impossible to work out why Jenkins failed.    Examples: https://ci.lsst.codes/job/stack-os-matrix/label=centos-6,python=py2/15505//console and from last week: https://ci.lsst.codes/job/stack-os-matrix/label=centos-6,python=py2/15194//console"""
"DM-7526","Bug","Stack Documentation and UX",0.5,"Python Coding Standard Copy Edits","""Content from DM-5456 has some missing words that existed during drafts. It seems that these were lost by a Git rebase. This ticket will fix this issues."""
"DM-7555","Epic","Developer Infrastructure",8,"Ad-hoc developer requests Part II","""This is a bucket epic for ad-hoc developer requests that cannot be postponed till the next planning cycle. In the event that it is underutilised for this purpose, it will be assigned to technical debt DM-5850"""
"DM-7553","Story","Qserv|xrootd",1,"Merge XRootD plugin link changes from upstream and adapt Qserv","""Changes to plugin linking have been made upstream in XRootD (plugins now to link against import library).  This ticket is to update the lsst-dev XRootD branch from upstream and make the necessary parallel change to the Qserv build scripts."""
"DM-7549","Bug","afw",3,"afw:testGaussianProcess has an intermittent test failure","""Sometimes the {{afw}} test {{testGausisianProcess.py}} can fail:      This is a very rare failure. It ran 102 times on my laptop before it stopped with this failure. So far we have only seen reports of this failure on Python 3.  """
"DM-7548","Story","ctrl_pool|ip_isr",5,"constructBias.py crashes with errors about log","""[~aritter] got this error when running {{constructBias.py}}. It seems {{pipe_drivers}} needs changes following the logging framework transition in {{pipe_base}}.       """
"DM-7547","Story","Firefly|SUIT",2,"Remove the extra column on far right-hand side of a table when no description is available","""An empty column seems to be visible on the right-hand side of a table when no description is available in option panel of the XY-plot column setting, table option and fits header table."""
"DM-7546","Story","Developer Infrastructure",1,"create a shared stack in GPFS for Verification Cluster ","""   Analogous to the work of   DM-6968 for NFS, we request a shared stack within the GPFS file system for  lsst-dev7 and the Verification Cluster (48 nodes, 1152 cores).       The familiar NFS home directories are available on the front end system lsst-dev7, but are not mounted on the compute nodes of the Verification Cluster.  As such, the NFS stack of DM-6968 is not usable for computation on the Verification Cluster.    Initial testing shows computation against a stack in GPFS can execute at least 300+ simultaneous tasks/pipelines without significant slowdown, suggesting a wide range of work can be performed with a stack in the shared GPFS space on the >~ 1000 cores of the Verification Cluster.    The suggested location for the GPFS stack  is under  /software/lsstsw , reachable on lsst-dev7 (i.e., the build of the stack would be done on lsst-dev7, running CentOS 7.2.1511 ).    The /software space is considered a location where various reference software stacks might be made available to the team.    In addition to /software/lsstsw , the 'lsstsw' user does have a 'GPFS home' directory /gpfs/fs0/home/lsstsw  that could also be used, though the organization offered by /software appears preferable.    (The 'lsstsw' user  would continue to have a home directory in NFS for the time being, with an eventual transition to that on GPFS. )"""
"DM-7543","Bug","Firefly",1,"Change background and text color in image toolbar and label (left)","""compared to before migration, a blue background and transparent icon toolbar appears on top of the image viewer.    Blue background and zoom number is not readable enough. The color is not consistent with the rest of the application neither.    Change blue to same transparency as the toolbar icon (right hand) or change to black on white if doesn't improve.    """
"DM-7542","Story","Stack Documentation and UX",0.5,"Renew TLS certificate for community.lsst.org (2016)","""Renew *.lsst.org certificate and install on community.lsst.org. Procedure at https://meta.discourse.org/t/allowing-ssl-https-for-your-discourse-docker-setup/13847"""
"DM-7539","Bug","Requirements Documents",0.5,"""Docstrings SHOULD NOT be preceded or followed by a blank line"" needs update","""The nicely updated Python style guide version 6.0 has a small error in """"Docstrings SHOULD NOT be preceded or followed by a blank line"""". It's a nice simple rule, and one I followed for years, but autopep8 adds a blank line after the doc string for a class, so apparently PEP8 has slightly different requirements.    I hope fixing this won't require an RFC."""
"DM-7578","Story","obs_test",8,"Create obs_base and make obs_test work with it","""To support broad testing of obs packages, with minimal configuration, we will add an {{obs_base}} package that all obs packages will depend on. It will contain a test suite for them to derive from, plus frameworks for other modules (e.g. {{makeSomeCameraRepository.py}}).    {{obs_test}} will be the demo for how this new module works. Implementation details will be worked out along the way."""
"DM-7576","Story","ip_diffim",2,"Set default detection threshold to 5.0-sigma if decorrelation is turned on","""The current logic to set detection.thresholdValue to 5.0 if doDecorrelation == True is set in setDefaults(), and so never runs. This block needs to be moved elsewhere (doValidate, perhaps?) so that it runs correctly."""
"DM-7567","Story","butler",1,"Butler Repository fails to import mapper module","""when a mapper is specified to the butler as a dot-delimited string (i.e. the module is part of the mapper specification), the importer fails. For example if you use     The module that contains the CameraMapper ({{lsst.daf.persistence}}) should be imported, not the module+class name."""
"DM-7563","Story","Design Documents",8,"Produce straw-man plan for DRP","""Using the    - Understanding developed in DM-7561;  - Dependency map developed in DM-7557;  - Responsibility assignments developed in DM-7031;  - Rough resource requirements developed in DM-7032, DM-7034;  - Tooling decided in DM-7559;    develop an outline of a plan for Data Release Production.  """
"DM-7562","Story","Design Documents",1,"Take part in 2016-09-08 planning meeting","""Participate in the meeting called by [~mjuric]:    {quote}          Just confirming well meet for an initial planning meeting tomorrow at 10am PT. Roughly, the goal is to make sure were on the same page on the principles for the deployment plan you guys have    started developing, and to begin putting together a Gantt chart and milestones for what we believe thePipelines groups will deliver (and need) based on what we know is in LDM-151.  {quote}"""
"DM-7561","Story","Design Documents",5,"Audit Data Release Production section of LDM-151","""Detailed read-through of the CPP section of LDM-151. Identify areas of uncertainty, resolve them with stakeholders (ie, [~jbosch], at least initially). Make copious notes."""
"DM-7560","Story","Design Documents",5,"Audit Calibration Products Pipeline section of LDM-151","""Detailed read-through of the CPP section of LDM-151. Identify areas of uncertainty, resolve them with stakeholders (ie, [~mfisherlevine], at least initially). Make copious notes."""
"DM-7558","Story","Design Documents",3,"Create dependency map for Calibration Products Production","""Identify the relationships that the Calibration Products Pipeline have with other parts of LDM-151 (chiefly algorithmic components) and with external deliverables, and record these appropriately."""
"DM-7584","Bug","afw|Stack Documentation and UX",0.5,"Fix missing code lines in doxygen page on using masked image locators","""The doxygen page   https://lsst-web.ncsa.illinois.edu/doxygen/xlink_master_2015_11_10_02.53.27/masked_image_locators.html  describes how to use image locators to move around images. Unfortunately, the page is missing the actual code lines that are being discussed. Fix the broken/missing code lines on this page."""
"DM-7586","Story","Continuous Integration",0.5,"add lsst_py3 job to jenkins","""The new {{lsst_py3}} metapackage enumerates eups products known to be compatible with python3.  A new dedicated jenkins job has been requested to catch regressions."""
"DM-7595","Story","IRSA",0,"Extra column doesn't appear in the header description when saving ipac table","""Add attribute to the extra phase column so a comment or some description appears in the ipac table header when is saved by the user if possible    NOTE: this ticket is combined with DM-7594."""
"DM-7594","Bug","IRSA",2,"Extra phase column is displayed with too few precision","""DM-7165 allow to add an extra column ('phase') to the raw LC table, which result in the phase folded table.    This is done using DataType object.     When the result is shown in table view, the display format is '0.0' which is not enough.    The phase column should be displayed as double precision with at least 8 significant digits    Also, add attribute to the extra phase column so a comment or some description appears in the ipac table header when is saved by the user if possible."""
"DM-7593","Story","IRSA",1,"Make use of the phase folded code","""Now that DM-7165 is done, use the code in the LC handler to complete the processor added [DM-7162]"""
"DM-7590","Story","SUIT",2,"SUIT vision document","""SUIT vision document work, review, revision, and submission for approval by TCT. """
"DM-7588","Story","Third Party Software",2,"Update MPICH","""Version 3.2 of MPICH fails multiple tests on OS X and does not integrate well with mpi4py. Presently the newer 3.3a development version performs better and when the stable version 3.3 is released we should upgrade the stack."""
"DM-7587","Improvement","daf_base",3,"Add timesys argument to DateTime constructor to toString (implement RFC-219)","""Implement RFC-219 as follows:    - DateTime(string, timescale) with """"Z"""" required for UTC and forbidden for TAI. Ideally forbid """"23:59:60"""" leap seconds for TAI as well.  - DateTime.toString(timescale) with """"Z"""" produced for UTC and not for TAI.    Require the timescale argument, unless it proves to be a major headache by affecting too much code, in which case default to UTC for backwards compatibility.    Additional tests that verify that """"23:59:60"""" strings are not produced by toString(TAI) at actual leap seconds."""
"DM-7610","Story","SUIT",1,"Implement Target Panel resolve option  (ned then simbad or simbad then ned)","""We have not implement the target panel resolve option.  When is there in the search panels now are dummy ui components."""
"DM-7608","Improvement","obs_sdss",0,"testSelectSdssImages.py broken: ""noConnectionStr"" not defined","""A recent change to testSelectSdssImages.py broke the test for those who could connect to the database. The symptom is:    and is self descriptive. I have a fix ready to go."""
"DM-7604","Story","cat",1,"file() in lsst.cat should be open()","""The lsst.cat package has a reference to file(), which is not supported in Python 3.  Updating this to use open()."""
"DM-7630","Story","Firefly",2,"Dispaly ""null"" when a value ""null"" is in the data","""Allow null values to display as """"null"""", currently a value of null is left blank. """
"DM-7629","Story","Data Access",1,"Modernize dax_metaserv to support pytest","""Support pytest."""
"DM-7626","Story","Data Access",0.5,"Modernize dax_webservcommon tests to work with pytest","""Support pytest."""
"DM-7622","Bug","daf_base",2,"DateTime rejects an acceptable date","""The following fails for reasons I do not understand:      The error is:    and comes from this code:    """
"DM-7615","Story","shapelet",1,"Update tests in shapelet to support pytest","""The tests in {{shapelet}} need to be modernized to support pytest and to drop {{suite}}."""
"DM-7614","Story","coadd_chisquared",0,"Support pytest in coadd_chisquared tests","""Modernize the test file to be compatible with pytest."""
"DM-7652","Story","meas_astrom",1,"Replace usage of execfile in astrometryNetDataConfig.py","""{{astrometryNetDataConfig.py}} gained a {{from past.builtins import execfile}} during the python3 conversion. We should replace this with a more modern syntax."""
"DM-7651","Improvement","Stack Documentation and UX",1,"Clarify in dm_dev_guide that SSH keys must be in one-line format","""The [instructions for using public-key authentication with lsst-dev|https://developer.lsst.io/services/lsst-dev.html#lsst-dev-ssh-keys] assume the user has OpenSSH. While this does not prevent users from translating the instructions to their own SSH software, it does cause a confusing bug if the user isn't aware that OpenSSH (or, specifically, the {{~/.ssh/authorized_keys}} file) only accepts one-line keys and not the more common multi-line PEM format.    I propose that a note be added to the end of """"1. Generate a key pair"""" warning non-OpenSSH users to make sure their public key is in the one-line format."""
"DM-7655","Bug","Firefly",3,"The region with semicolon inside text property is not displayed","""Region description is not parsed well in case there is character ';' contained in 'text', 'tag' (the property which has text string value). """
"DM-7662","Story","Stack Documentation and UX",1,"Prepare and deliver a documentation/technical writing talk at the invitation of NCSA.","""The talk is archived at https://zenodo.org/record/153867#.V92VODvsXPg and was given on September 12, 2016."""
"DM-7665","Story","SUIT",2,"plan to choose the context background image for LSST data","""As we search and display the LSST sources/objects, the SUIT should be able to choose a sensible background image to overlay the sources/objects on.     We need to come up with a strategy and the potential images to choose from at different stages:  *  PDAC v1 (end of F16): Current method that Firefly employs to choose. Depending on size needed, it will pick one from 2MASS, WISE, SDSS, IRAS.   * PDAC v2 (end of S17)  * Ready ComCAM  """
"DM-7681","Story","SUIT",2,"Begin the documentaiton process of visualization","""Begin the visualization documentation process.  This is the first step of probably much more documentation.  However, some needs to be put into jsdocs soon so this ticket should be that documentation."""
"DM-7679","Bug","xrootd",1,"XrdSsiClient library compilation error with gcc -v 6.2 in Ubuntu 16.10","""[~speckins] tried building qserv under Ubuntu 16.10, which ships with gcc -v 6.2 . I was able to reproduce the error with cmake on the xrdssi branch as follows:    """
"DM-7677","Story","obs_cfht|obs_decam|obs_lsstSim|obs_sdss|obs_subaru|obs_test",3,"Create RFC documents for changes to Mapper.paf files","""In DM-7049, an set of datasets were moved from the HSC mapper to daf_butlerUtils.  These are in exposures.yaml and datasets.yaml, and are now available to all cameraMapper subclasses (provided that there is an exposures or datasets section in their own Mapper.paf file.)    An RFC will be published for each Mapper describing possible additional changes:    1.  Additional cleanup is required in each of the obs_*/policy/*Mapper.paf files to fully implement this move.  Datasets which are not consistent with the new """"shared"""" datasets need to be altered before they can be removed, but carefully, so as not to disturb the code which utilizes the mapper.    2.  Identify datasets in each mappers which have the same function as a shared dataset, but a different name.  If possible, these should be renamed and made consistent with the shared dataset.    3.  Attempt discover datasets which are no longer in use and could be deleted."""
"DM-7676","Bug","lsstsw",1,"lsof used by setup.csh not always in /usr/sbin","""The {{setup.csh}} script uses {{/usr/sbin/lsof}} to detect the location of the script if indirectly sourced.  On a stock Ubuntu 14.04 system (which is not an officially supported platform but on which the stack works otherwise), it appears that this utility is installed as {{/usr/bin/lsof}} instead.  Making this usage slightly more generic should help improve portability."""
"DM-7674","Story","Stack Documentation and UX",0.5,"New workflow for onboarding DM members into community.lsst.org groups","""Previously we made every T/CAM a community.lsst.org admin so that they could add their team members to the LSST and LSSTDM groups to access private community categories.    Discourse now has the concept of Group owners, who can add/remove members from individual groups.    Id like to limit the number of people with Admin credentials since it poses a security risk; especially considering our responsibility to support private Science Collaboration categories.    This ticket will update community configurationg and Developer Guide documentation to implement this."""
"DM-7669","Story","afw",2,"Remove GPU warping, convolution, and support code","""Implement RFC-224."""
"DM-7668","Story","meas_algorithms",2,"Remove shapelet code from meas_algorithms","""Implement RFC-223."""
"DM-7691","Story","Developer Infrastructure",0.5,"Shared stack in NFS /lsst4 shows error at initialization","""The NFS stack created in DM-6968 today shows an error upon initialization :        This may be occurring due to the existence of a lock and .lockDir :        Could this be investigated ?                  Greg   """
"DM-7687","Story","pipe_analysis",1,"Split HSC comparison/QA script into separate package","""Currently, it lives as all the scripts starting with {{hsc}} in branch {{u/lauren/working}} of {{pipe_tasks:bin.src}}. These should all move to a new package in the lsst-dm organization."""
"DM-7702","Bug","Firefly",0.5,"stretch dropdown feature is currently broken","""The stretch feature is broken.    The log shown are related to getRangeValues error:    Uncaught TypeError: (0 , _PlotViewUtil.primePlot)(...).plotState.getRangeValues is not a function    Please investigate and fix. Thanks."""
"DM-7701","Story","ndarray",1,"conda-lsst ndarray test failure","""The conda-lsst build log for the test failure can be found here:    https://gist.github.com/jmatt/dcb6ce8312aac1ff81cbb923703d8430    """
"DM-7700","Bug","Firefly|IRSA",2,"Atlas table filtering doesn't work properly","""Atlas result page is using Firefly table component but couple of problems have been detected:    - Filtering the table doesn't work properly.    Step to reproduce:  Go to http://irsawebdev1.ipac.caltech.edu/applications/Atlas, do a search on SEIP.  Then try to filter 'Instruments' column on 'mips'. The result is wrong. I see 'IRAC' rows.    """
"DM-7694","Story","butler",1,"Restore a couple of datasets from DM-7049","""DM-7049 removed at least one dataset which might be in use.    Restore any doubtful datasets to the Mappers and move them to the DM-7677 RFC.  """
"DM-7693","Story","ctrl_orca",2,"fix premature merge of previous ctrl_orca ticket","""When I went to look for the pull for ctrl_orca on Monday for ticket DM-7183, I didn't see one;I made changes to the """"is True"""", """"is False"""", and list(keys()) issues, and then didn't look again on Tuesday when I saw the """"Review complete"""", so I thought it had been done, which is was not.   This is to look at those issue and fix them."""
"DM-7716","Bug","pipe_drivers",0.5,"Fix dataset lookup in multibandDriver.py","""{{MultibandDriver}} builds a patch reference list by checking for the existence of {{self.config.coaddName + """"Coadd""""}}.  However, when coadd assembly is performed by running {{coaddDriver}}, this coadd is not persisted in favor of only persisting the updated calexp version.  Thus, currently {{MultibandDriver}} ends up with and empty patch list and exits quietly.  The existence check should be on the {{self.config.coaddName + """"Coadd_calexp""""}}."""
"DM-7710","Story","afw",1,"afw.display.makeMosaic doesn't understand self.images","""The routine makeMosaic doesn't work if you pass in a list of images (as opposed to appending images to self)  """
"DM-7706","Story","SUIT",3,"Fix issues related to tomcat8 and ipv6. Also add firefly.war into firefly release page.","""- Fix duplicate nom.tam.fits classes during build  - Add preferIPv4Stack to tomcat env.  - Add firefly.war to Firefly Standalone release page."""
"DM-7726","Story","ctrl_stats",1,"Fix MySQL Incorrect date time value warning in ctrl_stats","""in Mysql 5.7, the warning    /home/srp/lsstsw27/lsstsw/stack/Linux64/cat/12.1.rc1-3-g00b8a9c+1/python/lsst/cat/MySQLBase.py:158: Warning: Incorrect datetime value: '0000-00-00 00:00:00' for column 'executionStartTime' at row 1    is emitted.    This is because of a change in MySQL 5.7 about how '0000-00-00 00:00:00"""" dates are handled."""
"DM-7725","Bug","meas_deblender",0.5,"Fix missing lsst.log update and build dependencies","""There was one missed instance of updating to the new {{lsst.log}} system and the remaining {{pex_logging}} dependencies are not reflected in the {{ups/}} table and cfg files (but are being pulled in by {{meas_algorithms}})."""
"DM-7745","Bug","daf_base",1,"enum constants in daf_base.DateTime can cause confusion","""Whilst looking at DM-7742 I started to wonder why the {{DateTime}} constructor did not complain when it was given an MJD time system instead of a UTC time scale.    It seems we have two issues with {{DateTime}} that can lead to subtle bugs not being caught:    # Both the TimeScale and DateSystem enums share values in Python land. This means that in Python you can pass in an MJD but C++ will treat it as UTC. We should ensure that both these enums convert to different sets of integers in Python so that we can trap system/scale confusion.  # The DateTime constructor does not check all cases. It assumes that if the scale is not  TT or TAI then the user probably meant UTC. The code in DateTime should never use an {{else}} to assume UTC but should always check and trigger and exception if the value is not recognized.    """
"DM-7741","Bug","meas_astrom",1,"Missed incompatible logging changes in Python + migrate meas_astrom","""Since DM-6999, Python codes using Task/CmdLineTask are converted to use {{lsst.log}} instead of {{lsst.pex.logging}}.  Codes like {{self.log.log(self.log.WARN, """"messages"""")}} should be changed to {{self.log.warn(""""messages"""")}} because that API is no longer supported. Many places need such changes but were missed.  This ticket is to go through the Python codes of pipe_\*, ip_\*, meas_\* and obs_\* and correct them. """
"DM-7739","Improvement","SUIT",1,"Docstring improvements in Firefly Python API","""The docstrings for FireflyClient are very helpful overall. That said, I found myself tripping over a few items that could be clarified for users.    In add_mask:  * It would be helpful to mirror the order of the parameters with the function signature, i.e. in the Parameters section, please list bit_number first and then image_number.  * Please indicate that image_number is zero-based, e.g. for a file of image, mask, variance, the user will want to specify image_number=1.    In show_fits:  * Under additional_params, it would be helpful to note that the user can supply MultiImageIdx to display a particular image extension from the file, and that this is a zero-based index. (The link to parameters does not list MultiImageIdx btw.)"""
"DM-7738","Story","obs_decam",0.5,"Remove outdated instructions in obs_decam README","""{{obs_decam}} README has outdated information, leading to confusion like [this|https://community.lsst.org/t/error-of-using-obs-decam/1181/1]. Remove the outdated instructions to avoid confusion. For example, {{processCcdDecam.py}} is no longer used since DM-4692 (https://community.lsst.org/t/backward-incompatible-changes-to-processccdtask-and-subtasks/581) """
"DM-7769","Bug","pipe_tasks",1,"duplicate imports in CharacterizeImageTask","""A few duplicate imports snuck into CharacterizeImageTask in a recent change.    It's a one-liner to fix. However, pep8 also picked up the fact that lines 565-569 are indented too far. Might as well fix that as well and run flake8 on all python code."""
"DM-7765","Story","SUIT",2,"Rendering region text on PNG ","""The region text defined with  region object (not text region) is not shown on PNG.   """
"DM-7762","Story","SUIT",20,"Understand PDAC data base enough to determine the queries we need to do.","""This story involves understanding the data we need to access for the PDAC UI.     * Understand the two applications we want to make for the PDAC: general catalog search and light curve viewer  * Understand the data base searches we need to do.  * Analyze the tables and data we need for the two applications.  * Come up with example select statements for each search.  * Try to make the the related DAX URL for each search. (We might need to make a second ticket to really work this last issue)  * Get some example fits files and put the into firefly_test_data    The scope grew and more work in documenting the difference of qserv_* functions and scisql_* functions. """
"DM-7760","Bug","SUIT",0.5,"WCS match does not work right when the images are not initially locked","""WCS match is not working immediately when the images start out as not locked. It requires a second uncheck and check to make it work.    Bug was found with following description below.  This ticket fixes the WCS matching part of the problem.      The rotation not centering is another problem that I can't quite repeat but is probably not related to WCS-match. We have other work for the rotation (DM-7336) that might help.      -----------------------------------------------------------    1. Go to the Spitzer Enhanced Imaging Products:    http://irsawebdev1.ipac.caltech.edu/data/SPITZER/Enhanced/SEIP/    2. Try the last example, CGCG 036-024, with size = 0.1 and images must cover coordinate checked.    3. In the results, I cannot seem to sort by distance. However, I can now   filter by wavelength. Filter wavelength = 24 and type of data = science.   Only 2 results should remain. Send both to the IRSA Viewer.    4. On the second image, zoom in 6x and center target in display. Click WCS Match.    Nothing happens. (I waited 6 minutes.)    5. Turn WCS Match off and on again. It works.    6. Turn WCS Match off. Rotate the second image using 30 degrees.    The target moves off the display instead of just rotating.    7. Recenter the target.    Works.    8. Click WCS Match on again.    The first image target goes off the screen instead of just rotating.    9. Click on the first image, and recenter target.    Works."""
"DM-7756","Story","pipe_drivers",0.5,"Port pipe_drivers to Python 3","""{{pipe_drivers}} needs to be converted to python 3."""
"DM-7754","Story","log|log4cxx",1,"Can't use simple afwImage primitives without explicitly initialising log4cxx","""This simple script:      generates the error:  {quote}  log4cxx: No appender could be found for logger (afw.image.Mask).  log4cxx: Please initialize the log4cxx system properly.  {quote}    I'd expect to be able to use LSST primitives without explicitly setting up the logging.  """
"DM-7781","Story","Firefly",8,"JUnit Test for Zscale","""The Zscale class is used by FitsRead.  Therefore, it is important to make sure it works correctly all the time.  The unit test is needed to identify any bugs introduced by changing this class."""
"DM-7770","Bug","skymap",0.5,"RingsSkyMap.findAllTracts fails with wcslib error","""Johnny Greco (Princeton) points out an exception when using {{RingsSkyMap.findTractPatchList}}:      I believe it's because wcslib can fail nastily if coordinates are well off an image (e.g. [here|https://github.com/lsst/pipe_tasks/blob/master/python/lsst/pipe/tasks/selectImages.py#L196-L199])."""
"DM-7820","Story","Firefly",1," 2D plotting package design discussion","""Participate in the 2-day discussion of 2D plotting package design,  functions supported, and strategy for introducing new 3rd party software packages,"""
"DM-7819","Story","Firefly",1," 2D plotting package design discussion","""Participate in the 2-day discussion of 2D plotting package design,  functions supported, and strategy for introducing new 3rd party software packages,"""
"DM-7818","Story","Firefly",1,"2D plotting package design discussion","""Participate in the 2-day discussion of 2D plotting package design,  functions supported, and strategy for introducing new 3rd party software packages,"""
"DM-7817","Story","Firefly",1,"2D plotting package design discussion","""Participate in the 2-day discussion of 2D plotting package design,  functions supported, and strategy for introducing new 3rd party software packages,"""
"DM-7816","Story","Firefly",3,"2D plotting package design discussion","""Participate in the 2-day discussion of 2D plotting package design,  functions supported, and strategy for introducing new 3rd party software packages,"""
"DM-7815","Story","Firefly",3," 2D plotting package design discussion","""Participate in the 2-day discussion of 2D plotting package design,  functions supported, and strategy for introducing new 3rd party software packages,"""
"DM-7814","Story","Firefly",3," 2D plotting package design discussion","""Participate in the 2-day discussion of 2D plotting package design,  functions supported, and strategy for introducing new 3rd party software packages,"""
"DM-7813","Story","Firefly",3,"Organize the 2D plotting package design discussion","""Organize in the 2-day discussion of 2D plotting package design,  functions supported, and strategy for introducing new 3rd party software packages,"""
"DM-7812","Story","Firefly",2,"2D plotting package design discussion","""Participate in the 2-day discussion of 2D plotting package design,  functions supported, and strategy for introducing new 3rd party software packages,"""
"DM-7811","Story","SUIT",2,"WBS restructure discussion","""participate discussion of WBS restructuring,  review and edit"""
"DM-7805","Bug","SUIT",1,"Changing column to plot doesn't reset the 'flip' option to unchecked state","""When doing a catalog search (or Gator), the x-axis in the xy-plot comes in 'reverse' direction which is wanted for plotting ra vs. dec.    But when the column is changed, the option should be reset to regular x-axis direction ('reverse' checkbox to be unchecked).    Please fix."""
"DM-7801","Story","afw",8,"Wrap afw::cameraGeom with pybind11","""The generated wrappers will live parallel to the Swig wrappers. This ticket only covers the C++ wrappers themselves, not the Python layer on top (which will continue to use the old wrappers) all work will stay on a separate branch and will not be merged to master until DM-6168 is complete.    The tests included in this ticket are:  # testDetector.py  # testMakePixelToTanPixel.py  # testExposure.py  # testCamGeomFitsUtils.py  # testCameraGeom.py  # testDistortedTanWcs.py  # testCameraTransformMap.py  # testColor.py  # testOrientation.py  # testCameraSys.py  # testWarper.py (moved to DM-8619)"""
"DM-7798","Story","SUIT",2,"Add remote launch capabilities to the Time Series viewer","""Do the following:     * Add hooks so the time series tool to be able to be launched externally   * Gator or the triview (or something else) should be able to launch the LC with search parameters (see my comment below about initial values for IRSA)"""
"DM-7784","Bug","IRSA",3,"WISE single exposure image fails sometime to be plotted in LC viewer","""in the LC prototype, once the phase folded table is displayed, one can highlight a row and the corresponding single exposure will be plotted based on the 'frame_id'.    For some reason, the plot request fails on 'frame_id' starting with 09xx in the example used.    Step to reproduce:  Go to LC viewer (lc.html) and use raw table from:   http://web.ipac.caltech.edu/staff/ejoliet/demo/OneTarget-27-AllWISE-MEP-m82-2targets-10arsecs.tbl  Then, click for example on the row where 'frame_id' == 09401b071, see plot fails.     Although FITS exists in IBE:  http://irsa.ipac.caltech.edu/ibe/data/wise/merge/merge_p1bm_frm/1b/09401b/071/09401b071-w1-int-1b.fits    Please investigate and fix."""
"DM-7840","Story","Firefly|IRSA",8,"Change the way the single exposure request is built from LC table to be generic","""Right now, the LC viewer knows how to fetch the single exposure by hard-coding a WebPlot request (plus some column to use) which is specific to WISE and has a particular image set that doesn't necessarily correspond to the time of the observation (see problem describe in DM-7784.    The single exposure to be displayed should come from and contained by the table itself. The LC viewer shouldn't be aware about the mission, image set or any other specific logic.     Change the way to fetch the single exposure by reading out the URL from the table (a column for each time identified by the flux as a prefix of the column name will be present in the table) and build a WebPlotRequest based on a URL fetch instead.    This method is generic for any data-set such as PTF, WISE, IRTF, etc. The generator of the table is responsible for giving the unique way to fetch the single exposure for a particular time and band.    For example, in case of WISE MEP table, it will contain 4 columns, each of them will have a name such as 'w1_url', 'w2_url', etc. When the user select the flux column to be used by the periodogram/xy-plot, for example 'w1mpro_ep', the image URL request to be used will come from the column which prefix name matches the user selected flux column, in the example, it will be 'w1_url'. The url will be an IBE call to WISE like:    http://irsa.ipac.caltech.edu/ibe/data/wise/allsky/4band_p1bm_frm/7b/00717b/102/00717b102-w2-int-1b.fits      """
"DM-7830","Story","Firefly|IRSA",2,"display single exposure from raw table as well as the phase folded curve table","""Please, add the same feature to the raw-table highlight as the phase folded table.    When the raw-table LC is loaded and a row is highlighted, display the image single exposure.    """
"DM-7825","Story","Firefly|SUIT",2,"Large catalog fail to completely load after filter was applied.","""MAJOR: imposing filters on the catalog makes the plot go away.   (1) Gator. Search in WISE. All WISE. M16. 30 arcmin  (2) In the data table, enable filters. Type >10 in each of the w1snr, w2snr, w3snr, w4snr column filter boxes. do NOT tab across to get them; it messes up the column headings.  (3) the plot never comes back, the overlays never update on the image, and the circular cyclical dots indicating Im thinking never stops. As in, I did this, reproduced this, typed this up, got distracted by a text, checked email in different accounts, came back to this, and still no updates.   Reproducibility:  restarted tool both platforms. WISE/AllWISE/M16/30 arcmin cone.  both come back with 17,816 sources.  impose filters.  plot vanishes as soon as first filter imposed. never returns from all four filters being imposed. Firefox is tilling me 695 sources are left (with the circular cyclical dots still spinning) and Chrome is telling me 979 sources are left  (with the circular cyclical dots still spinning).  another test:   restarted tool both platforms. WISE/AllWISE/M16/30 arcmin cone.  both come back with 17,816 sources.  impose JUST filter on w1snr. >10  Firefox: 3823 sources, plot vanishes, overlay doesnt update, circular cyclical dots still spinning  Chrome: 3609 sources, plot vanishes, overlay doesnt update, circular cyclical dots still spinning  So, this problem exists for one filter AND more than one filter.    *Copied from the pull request by Loi (9/30/2016)*  We were using cookies to pass websocket connection info to the server. This approach does not work in and embedded mode, ie. Gator.  I've converted to use custom http headers instead. This also affects python api. I've modified the code to reflect the changes.    This change fixed the above problem and should not have any regression issue"""
"DM-7824","Story","SUIT",2,"Document the Histogram API and fix some minor bugs","""When exposing Histogram React Component to API and writing the demo, I found the following bugs:    - log scale for y axis fails  - tooltip might be misaligned with bin boundaries   """
"DM-7823","Story","Firefly",8,"meeting with SLAC camera team for visualization discussion ","""SUIT team members Trey, Tatiana, Loi, and Gregory traveled to SLAC to meet with Tony and Stuart for a 2-day discussion of the relevant issues in using Firefly for camera I&T visualization support. We came up with a rough design which defines the interface between the camera diagnostic cluster and Firefly server, the services that camera team will provide so  Firefly can display the images at different resolutions as needed.    """
"DM-7844","Story","pipe_base",1,"cmd-line tasks should log the command being executed","""When a command-line task is executed it would be very helpful to have the command logged. This helps diagnose issues with packages such as {{ci_hsc}} and {{validate_drp}}.    This is trivial when the task is executed from the command line, e.g. add the following to {{ArgumentParser}}:    It is a bit trickier if the command is executed by code that calls {{CmdLineTask.parseAndRun}} directly; the arguments are readily available but determining the task will require introspection."""
"DM-7862","Story","Science Pipelines",2,"Update StarFast functionality","""A few components and functions of the StarFast simulator have fallen behind the needs of DM-6245. In particular, the exposures created by the simulator are missing needed metadata. This ticket is to clean up the interface to better support the current uses, and to supply the missing metadata."""
"DM-7860","Story","Design Documents",5,"Produce straw-man plan for Calibration Products Pipeline ","""Using the    * Understanding developed in DM-7560;  * Dependency map developed in DM-7558;  * Responsibility assignments developed in DM-7031;  * Rough resource requirements developed in DM-7032, DM-7034;  * Tooling decided in DM-7559;    develop an outline of a plan for Calibration Products Production."""
"DM-7858","Story","Design Documents",8,"Develop DRP planning packages","""Develop planning packages suitable for loading into PMCS which reflect the DRP plan."""
"DM-7855","Story","Design Documents",2,"Propose new WBS breakdown for 02C.04","""Develop a new WBS describing work to be undertaken in 02C.04."""
"DM-7894","Story","daf_persistence",1,"mapper and butler queryMetadata method badly documented","""The {{queryMetadata}} methods in both Mapper and Butler are very badly documented. Their docs both claim to accept a """"key"""" parameter, but the methods don't take """"key"""" (and Butler's version attempts to use one if """"format"""" is not specified), while the """"format"""" parameter (which appears non-optional from the code itself) doesn't have any docstring in Mapper. Looks like these docs rotted badly."""
"DM-7893","Improvement","base",2,"Add exception safety tag to Doxygen","""To allow easier implementation of DM-7891, all DM projects' doxygen config files should include an alias {{@exceptsafe}} that expands to a paragraph with the heading """"Exception Safety"""". The tag can be used to describe any guarantees made by documented code in the event of an exception.    -Yes, this requires touching (almost) every repository in the stack.-"""
"DM-7892","Improvement","Developer Infrastructure|Stack Documentation and UX",2,"Transfer relevant C++ doc guidelines from Confluence to Developer Guide","""Investigation supporting RFC-225 revealed that some rules in the [Confluence documentation guidelines|https://confluence.lsstcorp.org/display/LDMDG/Documentation+Standards] (e.g., the use of @ for Doxygen tags, or placing all documentation at the point of declaration) are not present in the developer guide. Ensure all relevant rules are present in the final documentation (senior developers have the final word on which rules are relevant)."""
"DM-7889","Story","meas_base|meas_extensions_convolved|meas_extensions_photometryKron|obs_subaru",5,"Activate HSC afterburner functionality","""We have just merged the functionality of the HSC afterburner (DM-6784, DM-6785).  We need to add configuration options in obs_subaru to activate the features in the coadds."""
"DM-7886","Story","afw|coadd_chisquared|meas_astrom|meas_deblender|meas_extensions_psfex|meas_mosaic|obs_base|obs_cfht|obs_lsstSim|obs_sdss|obs_subaru|obs_test",2,"Replace pyfits with astropy.io.fits in all code","""We currently use {{pyfits}} in multiple packages: afw, coadd_chisquared, obs_base, meas_astrom, meas_deblender, meas_extensions_psfex, meas_mosaic, obs_cfht, obs_lsstSim, obs_sdss, obs_subaru and obs_test.    Strangely, we only have explicit dependencies on {{pyfits}} listed for afw, obs_base, galsim, healpy and obs_subaru.    galsim can use astropy.io.fits or pyfits. healpy really does seem to not work with astropy.io.fits -- is there a newer version that does?    Please replace {{pyfits}} with {{astropy.io.fits}} where appropriate and update the table files to correctly express the dependency (and removing {{pyfits}} where inappropriate).  """
"DM-7869","Story","afw",1,"virtualDevice assumes that the display has a .frame member","""When running in verbose mode the virtualDevice assumes that it can access {{self.display.frame}}; this isn't always true.  """
"DM-7905","Epic","SUIT",100,"Finish Convert GWT code to pure JavaScript (F16)","""Finish the remaining work for converting GWT code to pure JavaScript and fix the bugs found"""
"DM-7900","Story","ctrl_pool",2,"Add --batch-type None to possibilities, disabling any MPI","""It can be desirable to run ctrl_pool enabled commands (such as constructBias.py from pipe_drivers) without any batch system.    Please add an option  bq. --batch-type None  that simply runs the job in the current process.  """
"DM-7899","Story","obs_base",1,"Move datatypes for Indexed reference catalogs to daf_butlerUtils","""The new indexed reference catalogs (for photometric and astrometric calibration) are stored under the dataset """"cal_ref_cat"""". This dataset was only added to obs_lsstSim and obs_test, and did not make it to the rest of the cameras. Since this is independent of camera it makes the most sense to move this into the common datasets in daf_butlerUtils. (The other required datatype, """"IngestIndexedReferenceTask_config"""", is already in daf_butlerUtils).    This is currently blocking usage of the new Gaia reference catalogs, so it would be very useful to have this implemented soon instead of waiting for the various dataset RFCs to close. Giving this to [~pgee] per his suggestion.    """
"DM-7896","Story","meas_extensions_convolved",2,"meas_extensions_convolved is undocumented","""Please add at least a README file providing a short summary of its functionality and some bare-bones documentation on how to enable and use it."""
"DM-7921","Story","SUIT",3,"Experiment with multiple series histogram display","""Multiple series histogram display (not connected to table)    Show how multiple histogram series can be displayed. Display multiple histogram data in an API.    (This is needed to understand how to organize multiple series data)"""
"DM-7918","Bug","Firefly|SUIT",2,"constraints column is not rendered correctly if empty cell is displayed","""[~cwang] found a problem in the catalog constraint search panel, the constraint column cell are replaced by disabled input field cell when empty value is entered. This component was working before, it must be a change recently in the TableRenderer.js.  We were talking with [~loi] and [~cwang], seems that [~cwang] was looking at it while doing the catalog search for LSST and could have a fix.    Please fix for release soon."""
"DM-7952","Improvement","DM Subsystem Science|Requirements Documents",2,"Modifications to project documents to flow down LSR-REQ-0026, re: predefined transient filters, or remove it","""In trying to close LIT-101, which was about a reference to """"limited classification"""" in the Level 2 object catalog, [~zivezic] and I rediscovered a gap in DM's requirements flowdown.  We discussed this by teleconference today.    The [SRD (LPM-17)|http://ls.st/lpm-17*] contains a """"will"""" statement about DM providing """"pre-defined filters optimized for traditionally popular transients, such as supernovae and micro lensed sources"""".    This was flowed down nearly verbatim to the [LSR (LSE-29)|http://ls.st/lse-29*] as LSR-REQ-0026, """"Predefined Transient Filters"""":    {quote}*Requirement:* Pre-defined filters optimized for traditionally popular transients shall be made available. It shall be possible for the project to add new pre-defined filters as the survey progresses.  *Discussion:* The list of pre-defined filters, by way of example, should include ones for supernovae and microlensed sources.{quote}    This requirement was never flowed down to the [OSS (LSE-30)|http://ls.st/lse-30*], the [DMSR (LSE-61)|http://ls.st/lse-61*], or the [DPDD (LSE-163)|http://ls.st/lse-163*], in the space of system-level controlled documents.    The requirement should either be formally disclaimed, which would require a variance against the SRD and a change request against the LSR, or the proper flowdown should be performed.    The latter would be in two parts: a CCB-level change request for the OSS, DMSR, and DPDD, as well as, within DM, the addition of substantive language to [LDM-151|http://ls.st/ldm-151*] towards fulfilling this requirement.    As the OSS and DMSR are currently completely silent on this, it would be acceptable simply to flow down the LSR requirement verbatim to both of these (as if a <copy> relationship in SysML terms).  However, as noted in LIT-101, the DPDD currently contains language which appears to be in conflict with LSR-REQ-0026, specifically:    {quote}we do not plan to provide any classification (eg., is the light curve consistent with an RR Lyra?, or a Type Ia SN?).{quote}    This would have to be edited to clarify that while we will _not_ attempt to produce _exclusive_ classifications - that is, assignment of objects to unique categories, but we _will_ provide pre-defined filters, with potentially highly overlapping selections, that provide good completeness but perhaps only very modest purity for a small number of object types of common interest.    It is important to retain the notion that this would be done using _only_ LSST data.    Strictly speaking, as a """"pre-defined filter"""" will not be thought of by most of our readers as a """"data product"""", it might not need to be mentioned in the DPDD, but because the existing DPDD language suggests a strong conflict, it would be very good to clarify it.    It will also be important to harmonize what we do about this requirement with what we say about the """"mini-broker"""" in our requirements flowdown, as this is also not currently very clear."""
"DM-7951","Story","Developer Infrastructure",0.5,"Rename daf_butlerUtils component to obs_base","""Now that the package move/rename in DM-7915 has been finished, can we please get the daf_butlerUtils component renamed to obs_base to match?"""
"DM-7949","Story","obs_base",0.5,"Delete daf_butlerUtils and move obs_base into lsst","""Now that the daf_butlerUtils -> obs_base move is complete, we need to move obs_base to live in the lsst organization (it's currently in lsst-dm). github provides a """"transfer repository"""" mechanism:    https://help.github.com/articles/transferring-a-repository-owned-by-your-organization/    but we can't use that until we've deleted daf_butlerUtils since obs_base is a fork (github gives the following error: """"lsst already has a repository in the lsst/daf_butlerUtils network""""). Once we're sure there are no more outstanding daf_butlerUtils branches, we can delete that repo (and thus break the fork link) and move obs_base to lsst and update repos.yaml. This shouldn't break Jenkins at all, as github does redirects when a repository is transferred.    I plan to do this at the beginning of November."""
"DM-7948","Bug","Firefly|IRSA",2,"misc. bug fixes related to Gator/Atlas/irsaviewer - feedbacks from test team","""address the bugs reported by the test team"""
"DM-7947","Story","SUIT",1,"Unit test for Circle class","""This is one of series unit test ticket for package """"package edu.caltech.ipac.visualize.plot""""."""
"DM-7941","Bug","meas_mosaic",1,"Fix config for reference object loader","""{{meas_mosaic}} if failing to un-persist the source matches for the HSC NB0921 filter with:      It seems the filterMap is not being loaded properly.  Please fix this."""
"DM-7940","Story","pex_config",0.5,"Disable colourisation when not writing to a terminal","""There's code in pex.config.history to colour output, but it's en/disabled unconditionally.  Please change it to never colour text that isn't going to the terminal.  """
"DM-7938","Story","Qserv",2,"Re-install Qserv on PDAC ","""Qserv master on PDAC has been re-install from scratch for security reasons:  https://jira.ncsa.illinois.edu/browse/LSST-801    Qserv needs to be re-installed and re-tested here once master node will be available."""
"DM-7971","Improvement","Firefly|IRSA|SUIT",8,"A highlighted point in the phase-folded light curve, the same point should be highlighted in the raw light curve and vice versa","""If the user changes XY Plots from phased to raw, the highlighted/active image displayed should not change.  But the sequence of images displayed will change, because the images sorting is tied to the XY Plot/Table, which will change from {{phase}} to {{mjd}}.    And vice versa, when XY plots changed from raw to phased ...    N.B.: Make more sense when more than 1 image is displayed."""
"DM-7970","Improvement","Firefly|IRSA|SUIT",2,"Image settings specific to LC on by default ","""LC image viewer preferences by default should be:    * WCS match should be on by default.  * The image stretch should be locked by default.  * The object position should be centered in the display by default.  * The object should be overlaid as the active target (right now the app is just guessing)"""
"DM-7969","Improvement","Firefly|IRSA|SUIT",2,"Add time zero as user defined offset different than default when phase folding","""The phase folding tool needs to allow the user to enter a zero point.  By default it should be using the minimum value of the time in the raw table but can be overwritten by the user. The phase folding option panel needs a new input field to let the user define it."""
"DM-7967","Improvement","Firefly|IRSA|SUIT",2,"Magnitudes should be plotted decreasing to the top or to the left by default","""Users shouldn't have to manually flip this. Perhaps firefly can detect it by the units? mag or magnitude or mags or magnitudes not case-sensitive should cover it. Yes, this requires some sort of hard-coding but it makes us look like we know what we are doing, so it seems worth it if a more sophisticated solution cannot be found in a reasonable timeframe."""
"DM-7965","Improvement","Firefly|IRSA|SUIT",2,"Make consistent highlight colors in the tri-view","""In the triview, a point in the XY Plot is highlighted. Simultaneously, a row in the table is highlighted and one of the images is outlined. The linking between these elements is a strength of the tool. The linkage would be stronger and look more professional if these were all the same color. The gold color used for the image highlight would work, as long as it is not too fluorescent, and as long as the highighted point in the XY plot were outlined in black or a darker color.      Use the color of image border for table rows and points on chart. (12/2/2016 XW)"""
"DM-7964","Improvement","Firefly|IRSA|SUIT",2,"User should be able to click on a XY-plot point and have the period filled in phase folding panel","""If you are looking at the periodogram, the user should be able to click on a point in the XY-plot and have that period (from periodogram) put into the phase folding tool.    Pending cases to be confirmed/agreed:  What about if you click between points?  What if you highlight a row in that table?"""
"DM-7963","Improvement","Firefly|SUIT",1,"Add cutout image size option to be exposed and user defined in LC viewer","""The LC viewer should get cutouts rather than full images.    We need to decide when the user inputs the desired size of the cutouts and add an input field option in the image viewer to control it.     By default it should be a cutout anyway."""
"DM-7956","Story","lsstsw|starlink_ast|Third Party Software",2,"Add the Starlink AST package","""As per RFC-193 add the starlink AST package. Name it {{starlink_ast}}.    Note: until we have the new WCS code further along it seems premature to add {{starlink_ast}} to {{lsst_distrib}}"""
"DM-7955","Improvement","log",3,"Improve the default log configuration","""When {{log}}/log4cxx is not configured, it uses the default configuration which is at DEBUG level.   Right now {{log}} is configured explicitly when running CmdLineTasks or python unit tests, but the stack is also used outside of the Task environment or utils unit tests environments.  It should have a more friendly and useful default level and pattern, without the user having to do anything."""
"DM-7979","Story","daf_persistence",2,"write tests and document use of URI or relative path as input and output to butler.","""butler can take a URI or relative path for it's inputs and outputs arguments, provided that it has a way to figure out what the details of the repo are, e.g. mapper, and provided the default mode (inputs 'r', outputs 'w') is acceptable.  this needs to be documented in the butler init function. and a formal test written."""
"DM-7976","Bug","afw",3,"coadd cannot be loaded directly as afw.image.ExposureF","""Loading a {{deepCoadd}} as an afw Exposure gives the following error:         This used to work, or at least it worked with a stack from Sep 8. """
"DM-7992","Story","Firefly|SUIT",1,"Handling of SDSS forced photometry data in the PDACv1 light curve viewer","""(Apologies if I'm missing an existing ticket for this; there doesn't seem to be an exactly on-point one, though DM-7990 covers some of it.)    The SUIT portal for PDACv1, the main focus of which is the service of the forced photometry data from SDSS Stripe82 (LSST 2013 processing), needs to be able to deal with multi-band photometry data in a table in which data from all five SDSS filter bands (_u, g, r, i, z_) are mixed together as separate rows in the same table.    It is a minimal requirement to be able to display the data for a single selected filter band, and this should be able to be done in a more natural way than requiring the user to enter a filtering expression in the {{filterId}} column.    As noted in DM-7990, the next step would be the ability to show the light curves for multiple filter bands over-plotted on each other."""
"DM-7987","Improvement","sphgeom",1,"Ambiguous conversion between spherical coordinates and unit vectors","""The {{sphgeom::LonLat}} and {{sphgeom::UnitVector3d}} classes provide constructors for converting between the two types. However, the axis convention used for the conversion is left unspecified, limiting the situations where these classes' interoperability can be used.    I propose that the axis convention currently used by the implementations of these classes be made part of their APIs, so that external code knows what results to expect:  """
"DM-7986","Story","SUIT",2,"fix circles connecting & add way to reorder image tabs",""" fix circles connecting & add way to reorder image tabs.  Most of this ticket has the code to reorder the images tabs in the image select panel  """
"DM-8000","Bug","pipe_drivers|pipe_tasks",2,"Error instantiating MultiBandDriverTask with LoadIndexedReferenceObjectsTask","""Error running {{multiBandDriver}} if {{refObjLoader}} is retargeted to {{LoadIndexedReferenceObjectsTask}} in {{measureCoaddSources}}, e.g. with this config override:                  I included a way to reproduce this without actual data in {{obs_decam}} branch {{u/hfc/DM-8000}}. There I added an empty Butler repo and the measureCoaddSources config override.    With that branch this command reproduces the error:      {{multiBandDriver.py $OBS_DECAM_DIR/repo/ --rerun test --cores 1}}  """
"DM-8015","Bug","afw",2,"VisitInfo repr() and str() should print a useful summary of contents","""The new VisitInfo object is a bit opaque from within Python: you can look at the individual components via e.g. {{visitInfo.darkTime}} and {{visitInfo.boresightAirmass}}, but {{print(visitInfo)}} is not helpful. it would be extremely useful for {{str()}} and {{repr()}} to print either the whole contents of the VisitInfo (it's not that much information), or for {{str()}} to print a useful summary and {{repr()}} the whole thing."""
"DM-8011","Story","xrootd",0.5,"Update XRootD from upstream","""Merge in latest changes from upstream XRootD (includes gcc 6.2 fixes)"""
"DM-8007","Story","SUIT",1,"Make firefly_client pip-installable","""Make the   {{firefly_client}} Python API installable via pip. The package will be named {{firefly_client}}. The package will exist within the {{firefly}} repository.    copied from the pul request: (XW, 1018/2016)  copied Firefly License.txt  added a simple README  added setup.py and setup.cfg  moved package files to firefly_client directory  """
"DM-8006","Story","SUIT",8,"Add 2D Chart to client side phase folding dialog","""Add 2D Chart to client side phase folding dialog.  The chart should update as the user moves the slider.    copied from the github:  (Nov. 15, 2016 XW)  The implementation mainly,    add 2D chart on the client side phase folding dialog and the plot changes as any of the phase folding parameters (time column, flux column, zero time point, period) changes.  update the parameter items in the parameter setting dialog.  Test:    localhost:8080/firefly/lc.html  open 'lc_raw.tbl' from 'Raw Table', click 'search'  select tab 'Upload/Phase folding' and click button 'Phase Folding'  experiment the setting of all entries and move slider to set 'period', the plot will be updated as any of the parameter (except Flux error column) changes  click button 'Phase Folded Table' to close the dialog and a table with phase column is created (or updated) based on current setting of period, time column and zero point time.  Note:    The time and flux column names are set in default for IRSA cases. Those column names are settable while the phase folding dialog component is used."""
"DM-8004","Bug","supertask",1,"Crash in pipe_supertask.NewExampleCmdLineTask","""I try to follow http://dmtn-002.lsst.io/ and run all examples there. {{NewExampleCmdLineTask}} example crashes with an exception:      Need to see what I'm doing wrong."""
"DM-8002","Bug","meas_algorithms",1,"Fix unguarded display code in SecondMomentStarSelector","""Something recent (maybe DM-7848) either broke or uncovered an existing bug in {{SecondMomentStarSelector}}, in which a block of display code (specifically a call to `{{lsst.afw.display.ds9.Buffering()}} is not protected by an {{if display}} guard.    I'm not sure if we expect to require all display code to be guarded like that, but all of the other display code in this file is, so I'm just going to fix that block.  If someone ([~rhl]?) can confirm that unguarded display code is safe, then there's a bug somewhere else and {{SecondMomentStarSelector}} should have a lot of its display guards removed."""
"DM-8034","Story","Validation",1,"reprocess validation_data* to contain VisitInfo","""Please reprocess the validation data sets so that their output data contains the VisitInfo metadata structure (see DM-5503). I will provide a specific weekly to in the reprocessing in a comment."""
"DM-8032","Story","meas_algorithms|pipe_tasks",0.5,"Tighten testProcessCcd thresholds once background model is fixed","""Once the {{meas_algorithms}} background model is being generated correctly, the original {{pipe_tasks}} test that first pointed to this problem in needs to be put back to higher precision. A comment in {{testProcessCcd.py}} indicates the assertions that should have their precisions lowered back to pre-py3-porting values. Presently, this test fails with lower thresholds because the background model is different than expected."""
"DM-8030","Story","meas_algorithms",2,"Identify and correct differing background model between py2 and py3","""The background model pixel values differ by 0.00011  0.00035 on average in python2 versus python3. The cause of this discrepancy needs to be tracked down and fixed."""
"DM-8028","Story","SUIT",2,"Add a utility class to upload the unit test data file","""A utility class is needed to upload the unit testing data file in firefly_test_data tree."""
"DM-8027","Story","obs_lsstSim",2,"Update obs_lsstSim to add VisitInfo to eimages","""The eimage dataset type is special to obs_lsstSim so was not updated in the process of implementing the VisitInfo ticket."""
"DM-8026","Story","log4cxx",0.5,"log4cxx gcc 6.2 compatibility fixes","""Minor fixes for gcc 6.2 compatibility"""
"DM-8023","Bug","afw",2,"afw interface.py crashes with ""ds9"" backend because there's no ds9.DisplayImpl","""Making an afw.display with """"ds9"""" backend (and perhaps others!) throws an exception and crashes because ds9 doesn't have DisplayImpl.    As an example:  import lsst.afw.display as afwDisplay  display = afwDisplay.Display(""""ds9"""")    throws:    AttributeError: 'module' object has no attribute 'DisplayImpl'"""
"DM-8021","Bug","ctrl_pool|pipe_drivers",2,"Deal with large pickles","""[~lauren] is running:    and it is producing:      We need to fix or work around this problem."""
"DM-8035","Story","daf_persistence",2,"daf_persistence test failures with gcc 5.2 on el5","""The majority of the {{daf_persistence}} tests fail when attempting to build a conda package via {{conda-lsst}} on el5 with gcc 5.2.        I'm at a loss as why the tests are failing in this environment.   The library is being successfully built.                  """
"DM-8044","Story","pipe_tasks",0.5,"Default local background subtraction to False for safe coadd clipping","""In RFC-212 we adopted turning on the """"junk suppression"""" temporary local background subtraction by default: {{SourceDetectionConfig.doTempLocalBackground=True}}.  Since the safe clipping coadd assembly (introduced in DM-2915) also performs object detection, this had the effect of turning on the junk suppression background there too.  The safe clipping algorithm was designed and tuned with no extra background estimations, thus {{doTempLocalBackground}} should default to *False* for that task."""
"DM-8051","Story","Continuous Integration",1,"weekly-release/build-build-tag jobs broken","""{{weekly-release}} failed on monday because master was broken.  The job seems to failing in odd ways today, seemingly requiring some updates the pipeline dsl syntax."""
"DM-8063","Story","Calibration Products Production",1,"Check the Stubbs Am241 gain calibration plan","""Review the document detailing Stubb's plan to use Am241 gammas from outside the cryostat to perform absolute gain calibration in the main camera for any gross errors in reasoning."""
"DM-8085","Bug","Qserv",2,"Using misspelled name TableExistError for exception TableExistsError ","""The *wmgr* Web services attempts to throw an exception of the non-existing class *TableExistError* instead of *TableExistsError*. This causes the service to fail with with the following stack trace:      The relevant code:    {code:python}  @dbService.route('/<dbName>/tables/<tblName>/chunks', methods=['POST'])  def createChunk(dbName, tblName):              ...  593:        except utils.TableExistError as exc:   {code}"""
"DM-8084","Bug","db|Qserv",2,"Throwing exception TableExistsError with no parameters","""Database utility function *createTableFromSchema* doesn't provide parameters to the constructor of the exception class *TableExistsError* when throwing the exceptions. This causes the *wmgr* Web service to fail with the following stack:      And this is the function affected:    {code:python}  def createTableFromSchema(conn, schema):      """"""""""""      Create database table from given schema.        @param conn        Database connection or engine.      @param schema      String containing full schema of the table (it can be a dump                         containing """"CREATE TABLE"""", """"DROP TABLE IF EXISTS"""", comments, etc.        Raises TableExistsError if the table already exists.      Raises sqlalchemy exceptions.      """"""""""""      if conn.engine.url.get_backend_name() == """"mysql"""":          try:              conn.execute(schema)          except OperationalError as exc:              log.error('Exception when creating table: %s', exc)              if exc.orig.args[0] == MySqlErr.ER_TABLE_EXISTS_ERROR:                  raise TableExistsError()              raise      else:          raise NoSuchModuleError(conn.engine.url.get_backend_name())    Linux64/sqlalchemy/1.0.8.lsst3+2/lib/python/SQLAlchemy-1.0.8-py2.7-linux-x86_64.egg/sqlalchemy/exc.py      {code}"""
"DM-8081","Story","stack release",3,"unable to build release git tag when 3rd party deps change","""The fundamental issue is that {{lsstsw/lsst-build}} operate on refs in the git repo.  Due to the way eups generates version strings from git tags, we are unable to tag the repos for 3rd party products.  This means that we are unable to build a last tagged release from source once a 3rd party dependency has been upgraded to an incompatible version."""
"DM-8080","Story","butler",2,"start a old-vs-new butler document","""[~rhl] requested:  I think it'd be really helpful to have a relatively short document describing (or at least mentioning) the features that are in the butler that the `classic' butler didn't have.    I think we can put a section in LDM-463 for this."""
"DM-8078","Story","afw",0,"Remove int and long from schema aliases","""In python 3 all integers are 64 bit """"long"""" integers, while in python 2, 32 and 64 bit integers are differentiated by the int and long types respectively. This causes confusion when adding a new field to a schema using addField in afw/table/Base.i in python 3, where the python type is converted into a C++ type using a dictionary    {code:python}  aliases = {      long: """"L"""",      int: """"I"""",      float: """"D"""",      str: """"String"""",      futurestr: """"String"""",      numpy.uint16: """"U"""",      numpy.int32: """"I"""",      numpy.int64: """"L"""",      numpy.float32: """"F"""",      numpy.float64: """"D"""",      Angle: """"Angle"""",  }      All existing code using `type=long` will need to be updated as part of this ticket.    This will be included in the pybind11 wrapped code, with a deprecation warning for users attempting to add fields using {{int}} or {{long}}."""
"DM-8076","Story","obs_base",0.5,"Cleanup repository move wording in DMTN-027","""There are some lingering incorrect """"you should..."""" statements in the """"merging work"""" section of DMTN-027, that should be referring to the """"other developer"""", and the text needs to be reworded to reflect that dependencies on master need to live in {{lsst}}, and so some extra repository shuffling has to happen.    A few relevant quotes from Slack:    About how to move things without deleting daf_butlerUtils:    {quote}  Tim Jenness [11:50 AM]    move daf_butlerUtils into lsst-sqre, move obs_base into lsst, move daf_butlerUtils into lsst-dm  {quote}    About unclear """"you"""":    {quote}  Kian-Tat Lim [11:53 AM]  Oh, except I missed this at the top """"Once your rename has been merged to master,""""  One thing about that section that I noticed before but didn't comment on: it's sometimes unclear who """"you/your"""" is -- the renamer or the """"other developer""""    John Parejko [11:55 AM]  I tried to make it always be you as the person doing the rename. The person the whole document is aimed at.  If I got that wrong somewhere, Im happy to fix it.    Kian-Tat Lim [11:55 AM]  But """"your work-in-progress branch"""" is really """"the other developer"""", no?  Same for """"Check that the branch in the new clone matches your branch in meas_worst,""""  @parejkoj So I think the rest of the document is fine as long as you put in that merging to master also involves moving to lsst and change the remote url in the instructions.  {quote}"""
"DM-8074","Story","Qserv",8,"Test ""Swarm mode"" high availabilty features","""Swarm mode provide high availabilty feature wich will be tested on Openstack."""
"DM-8096","Story","butler",0.5,"Make ""immediate=True"" the default for butler.get()","""Considering how problematic readProxy objects are to deal with, I feel it might be better to default to {{immediate=True}} for {{butler.get()}} calls. For any test code or interactive code, we want to get an immediately useable object, while inside the pipeline we can be more explicit about {{immediate=False}} when we realize that we're waiting on I/O."""
"DM-8095","Bug","qserv_testdata",1,"Remove integration tests warning message","""sock option must be replaced by socket:      Maybe sock should also be replaced in Qserv code/config files int the future..."""
"DM-8094","Story","Qserv",2,"Replace Swarm default test container","""version should be 'dev' here, but 'dev' need to be updated to contains DM-7139 code:    """
"DM-8091","Story","Qserv",2,"Fix cmsd warning message","""Andy H. provided the solution:  {quote}Hi Fabrice,    Yes, this is common for configurations that don't expect to be dynamically  written to but yet export the space in R/W mode (which we do). All the  message is saying is you don't have enough space for impromptu writes (which  is true but then you don't expect any). So, there is a configuration  directive to resolve this problem:    cms.space 1k 2k    The directive is documented here:  http://xrootd.org/doc/dev45/cms_config.htm#_Toc454223038    I would add this directive to the config file as soon as you can and restart  he cmsd.    Andy{quote}"""
"DM-8090","Story","Developer Infrastructure",2,"Update Verification Documentation  2","""We update the lsst-dev7 + Verification Cluster documentation to cover the transition / renaming of the head node from lsst-dev7 to lsst-dev01 . """
"DM-8087","Story","ci_hsc",0.5,"scons should clean the rerun","""When you rerun {{ci_hsc}} after changing something it fails as the versions have changed.  The/a natural reaction is to run {{scons -c}} (i.e. clean), but unfortunately that doesn't help.    Please make {{scons -c}} delete the rerun/ci_hsc directory.  """
"DM-8106","Bug","afw",1,"SpherePoint does not have move constructors/assignment","""The {{SpherePoint}} class explicitly declares that it is using the default copy-constructor and copy assignment operator, but does not do the same with the move constructor and move assignment operator. This is inconsistent with RFC-209.    Since there is no reason to disallow move semantics for {{SpherePoint}}, move constructors and move assignment should be explicitly declared. I am not aware of any way in which this change can be tested."""
"DM-8105","Improvement","afw",2,"Missing test case for SpherePoint","""One of the changes introduced during review of DM-5529 was a mismatch between the behavior of indexing in Python and C++ -- negative indices are allowed in the former but not the latter, consistent with either language's conventions. However, indexing is tested only in the Python test suite against the Python specification.    A test case should be added to {{testSpherePoint.cc}} to verify that {{operator[]}} behaves as specified when called directly."""
"DM-8103","Story","afw",2,"Add method to find edge pixels to SpanSet","""Add a method to SpanSets which returns a new SpanSet that contains the pixels at the boarder of the original SpanSet"""
"DM-8102","Story","afw",2,"Introduce Set operations between SpanSets and masks","""Currently SpanSets can intersect, intersectNot, and union between a themselves and another SpanSet. This ticket will add the ability to use these methods with masks as """"other"""". This work will replace the intersectMask and footprintAndMask methods from the old footprint implementation."""
"DM-8100","Improvement","Third Party Software",1,"Determine what astropy.io.fits does with FITS header cards for missing data","""As part of implementing RFC-239 determine how {{astropy.io.fits}} handles FITS header cards with missing (unknown) values. I am virtually certain it cannot write such cards, but what happens when it tries to read them?    This will inform implementation of RFC-239."""
"DM-8099","Story","Design Documents|Stack Documentation and UX",0.5,"LDM-493 v1 Edits from DMLT feedback","""This ticket covers edits to the [v1 integration branch|https://github.com/lsst/LDM-493/pull/4] of LDM-493 based on feedback from the DMLT."""
"DM-8122","Bug","afw",2,"SpherePoint tests fail on macOS","""Building afw on macOS Sierra I get:    It is failling for point {{(180.000000, nan)}}."""
"DM-8119","Bug","Qserv",2,"Incorrect time zone settings within Qserv Docker containers","""I have noticed that the timezone is not set correctly within the latest version of the Qserv containers. This is an example:  {code:bash}  % hostname  lsst-qserv-db01    % date  Fri Oct 28 11:33:00 CDT 2016    % docker exec -it qserv date  Fri Oct 28 16:33:10 UTC 2016      Should this be solved by running the container with this extra option which would override the default setting of *Etc/UTC* set at a container build time?  {code:bash}  % ls -l /etc/localtime  lrwxrwxrwx 1 root root 35 Sep 23 09:43 /etc/localtime -> /usr/share/zoneinfo/America/Chicago    % docker run ... -v /etc/localtime:/etc/localtime:ro  {code}  This would add the read-only map from the container's configuration file to the hosts's one."""
"DM-8115","Story","Continuous Integration",0.5,"jenkins master can't run builds / write temp files","""I discovered this morning that there are a bunch of """"dead"""" builds (zombies) listed for the build slave that runs on the same node as the jenkins master.  The master was reporting that it is unable to create temp files and that is why the threads for these builds crashed.  Further investigation shows that the master node is out of disk space and this seems to be due to 100's of GiB of console output from a build that has been running since the 25th and it is still running.  """
"DM-8147","Story","afw|meas_algorithms",1,"Fix error while loading deepCoadd fits file.","""dax_imgserv experiences an error while loading lsst-qserv-dax01:/datasets/gapon/data/DC_2013/coadd/deepCoadd/r/0/321,4.fits.   This same file should be available as:   lsst-dev01.ncsa.illinois.edu:/datasets/gapon/data/DC_2013/coadd/deepCoadd/r/0/321,4.fits.  The error is:      On lsst-qserv-dax01.ncsa.illinois.edu this can be reproduced by  """
"DM-8138","Story","obs_base",3,"Implement changes requested in RFC-247","""Move several common datasets to obs_base.  This will not affect the dataset definitions of the individual cameraMappers."""
"DM-8157","Story","SUIT",8,"Implement an image search processor to access the image from PDAC","""This is the working extension for DM-8010.  The DM-8010 implemented MetaData and TableData search processors.  The image search processor is needed as well.  It will also exercise the cutout service that SLAC imgServ API will provide.    The image search processor (LSSTImageSearch) is searching the DAX using either id or a set of ids to locate the image and then displaying them in the tree-view window.  There are two types of search URL:    Coadded image (and cutout) retrieval   curl -o outImageCoadd.fits """"http://lsst-qserv-dax01.ncsa.illinois.edu:5000/image/v0/deepCoadd/id?id=23986176""""      For Science CCD, it can also be searched using id.   But the preferred way is using a set of ids, such as:    curl -o outImage3.fits """"http://lsst-qserv-dax01.ncsa.illinois.edu:5000/image/v0/calexp/ids?run=3325&camcol=1&field=171&filter=z""""    The image search processor processes the parameters passed from the UI and then build the URL like above to find the image.              """
"DM-8156","Story","ctrl_execute",20,"add support for Slurm to allocateNodes.py","""Add support for allocation of HTCondor nodes through Slurm via allocateNodes.py command.  This is related to work being done for DM-8154"""
"DM-8155","Story","xrootd",0.5,"Update XRootD from upstream (again)","""This captures the logging plugin changes from upstream xrootd xrdssi branch. Passed jenkins."""
"DM-8169","Story","sconsUtils",2,"Use -isystem (rather than -I) for include files from external packages","""See RFC-246 for the reasoning and for an example implementation."""
"DM-8182","Story","SUIT",2,"Resend email notification when email value changes","""A new email notification should be sent for every successfully completed background jobs when a new email is entered."""
"DM-8179","Story","SUIT",8,"Preserve background jobs and statuses beyond a browser session.","""Currently, background jobs and statuses are kept on the client.  That information is lost after a browser reload.  We need to save that information so that a user can come back at a later time and still get this information presented.    Implementation:  - save data on the server.  - push all statuses to client when connected  - continue to update statuses while client is connected"""
"DM-8189","Story","SUIT",2,"CatalogConstraintsPanel need to handle fetch errors","""At the moment, when an error occurs, the panel does not update leaving the loading masks visible indefinitely.  This panel should instead update itself with error message(s) from the fetch.    TODO:  - Fix CatalogConstraintsPanel  - add generic error display into BasicTableView  - move createErrorTbl from TablesCntlr to TableUtil"""
"DM-8187","Bug","Qserv",1,"Qserv czar crashes itself and mysql-proxy on invalid queries","""h1. Problem summary    Qserv *mysql-proxy* service always crashes on queries made on either non-existing databases or made in a lack of any specific database context. The same behavior is obsolved for queries addressed to databases which are present within the MySQL/MariaDB service of the Qserv *master* node while not being registered with Qserv's CSS.    Examples of queries based on the integration test setup:      h1. Details    Once the crash happens no further details found in the service's log files (the report was made by logging into a running Docker container):  {code:bash}  [gapon@lsst-qserv-master01 ~] docker exec -it qserv bash  qserv@lsst-qserv-master01:/qserv$ ls -al run/var/log/  ..  -rw-r--r-- 1 qserv qserv 2193695372 Nov  4 00:52 mysql-proxy-lua.log  -rw-r----- 1 qserv qserv      11811 Nov  4 00:51 mysql-proxy.log  {code}  The only (and the last) relevant record left in *mysql-proxy-lua.log* is about the query causing the crash. For example:  {code}  % tail  mysql-proxy-lua.log  ..[2016-11-04T01:27:40.883-0500] [LWP:1402] DEBUG ccontrol.UserQuerySelect (core/modules/ccontrol/UserQuerySelect.cc:397) - QI=227: UserQuery registered SELECT * FROM R LIMIT 1  {code}    Another obstacle for investigating the root cause of the problem was that no core file was left by the crashed process. Further investigation has revealed that this was happening because the proxy is usually launched with the *--daemon* option (the report was taken from within a running Docker container):  {code:bash}  qserv@lsst-qserv-master01:/qserv$ ps -ef | grep proxy  qserv     1540     0  0 01:44 ?        00:00:00 mysql-proxy --daemon --proxy-lua-script=  {code}    In order to get the core dump the following actions were taken. First of all the core configuration file of the container's host machine was modified to prefix core files with the name of the crashed executables:  {code:bash}  sudo -i  echo """"%e.core"""" > /proc/sys/kernel/core_pattern  {code}  The next step was to ensure no limit for core dumps is set for user *qserv* within the Docker container of the *Master* image:  {code:bash}  [gapon@lsst-qserv-master01 ~] docker exec -it qserv bash    qserv@lsst-qserv-master01:/qserv$ ulimit -c unlimited  qserv@lsst-qserv-master01:/qserv$ ulimit -a  core file size          (blocks, -c) unlimited  ...  {code}  The next step was to disable option *--daemon* in the service management file:  {code}  /qserv/run/etc/init.d/mysql-proxy  {code}    The new configuration was tested by stopping/starting the service from within the container:  {code:code}  qserv@lsst-qserv-master01:/qserv$ run/etc/init.d/mysql-proxy stop  [ ok ing mysql-proxy.  qserv@lsst-qserv-master01:/qserv$ run/etc/init.d/mysql-proxy start  [ ok ing mysql-proxy..  {code}    The the following query was made to crash the service:  {code:sql}  SELECT * FROM R LIMIT 1  {code}  After the service went down a desired core file was found in the following folder of the running container:  {code:bash}  qserv@lsst-qserv-master01:/qserv$ ls -al   ..  -rw-------  1 qserv qserv 28422144 Nov  4 01:27 mysql-proxy.core.1402  {code}    The dump was analyzed with *gdb* to get the stack of the crash:  {code}  qserv@lsst-qserv-master01:/qserv$ which mysql-proxy            /qserv/stack/Linux64/mysqlproxy/0.8.5+12/bin/mysql-proxy    qserv@lsst-qserv-master01:/qserv$ gdb `which mysql-proxy` mysql-proxy.core.1402    Reading symbols from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/bin/mysql-proxy...done.  [New LWP 1402]  [New LWP 1436]  [New LWP 1437]  [New LWP 1438]  [Thread debugging using libthread_db enabled]  Using host libthread_db library """"/lib/x86_64-linux-gnu/libthread_db.so.1"""".  Core was generated by `mysql-proxy --proxy-lua-script=/qserv/stack/Linux64/qserv/12.1.rc1-3-g72e15fd+3'.  Program terminated with signal SIGSEGV, Segmentation fault.  #0  0x00007f4bf1445573 in lsst::qserv::qdisp::Executive::setQueryId (this=0x0, id=227) at core/modules/qdisp/Executive.cc:103  103  core/modules/qdisp/Executive.cc: No such file or directory.      (gdb) where  #0  0x00007f4bf1445573 in lsst::qserv::qdisp::Executive::setQueryId (this=0x0, id=227) at core/modules/qdisp/Executive.cc:103  #1  0x00007f4bf1293bc8 in lsst::qserv::ccontrol::UserQuerySelect::_qMetaRegister (this=0x180ea80) at core/modules/ccontrol/UserQuerySelect.cc:398  #2  0x00007f4bf1290c1c in lsst::qserv::ccontrol::UserQuerySelect::UserQuerySelect (this=0x180ea80, qs=std::shared_ptr (count 2, weak 0) 0x1801870,       messageStore=std::shared_ptr (count 2, weak 0) 0x180efc0, executive=std::shared_ptr (empty) 0x0, infileMergerConfig=std::shared_ptr (empty) 0x0,       secondaryIndex=std::shared_ptr (count 2, weak 0) 0x179fa70, queryMetadata=std::shared_ptr (count 2, weak 0) 0x17c9da0, czarId=2, errorExtra="""""""")      at core/modules/ccontrol/UserQuerySelect.cc:151  #3  0x00007f4bf12868b6 in __gnu_cxx::new_allocator<lsst::qserv::ccontrol::UserQuerySelect>::construct<lsst::qserv::ccontrol::UserQuerySelect<std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> > (this=0x7ffc21ece13f, __p=0x180ea80)      at /usr/include/c++/4.9/ext/new_allocator.h:120  #4  0x00007f4bf128607a in std::allocator_traits<std::allocator<lsst::qserv::ccontrol::UserQuerySelect> >::_S_construct<lsst::qserv::ccontrol::UserQuerySelect<std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> >(std::allocator<lsst::qserv::ccontrol::UserQuerySelect>&, std::allocator_traits<std::allocator<lsst::qserv::ccontrol::UserQuerySelect> >::__construct_helper*, (lsst::qserv::ccontrol::UserQuerySelect<std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&>&&)...) (__a=...,       __p=0x180ea80) at /usr/include/c++/4.9/bits/alloc_traits.h:253  #5  0x00007f4bf12858d4 in std::allocator_traits<std::allocator<lsst::qserv::ccontrol::UserQuerySelect> >::construct<lsst::qserv::ccontrol::UserQuerySelect<std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> >(std::allocator<lsst::qserv::ccontrol::UserQuerySelect>&, lsst::qserv::ccontrol::UserQuerySelect<std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&>*, (lsst::qserv::ccontrol::UserQuerySelect<std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&>&&)...) (__a=..., __p=0x180ea80) at /usr/include/c++/4.9/bits/alloc_traits.h:399  #6  0x00007f4bf1284c74 in std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2>::_Sp_counted_ptr_inplace<std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> (this=0x180ea70, __a=...) at /usr/include/c++/4.9/bits/shared_ptr_base.h:515  #7  0x00007f4bf1283f40 in __gnu_cxx::new_allocator<std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2> >::construct<std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2><std::allocator<lsst::qserv::ccontrol::UserQuerySelect> const, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> > (this=0x7ffc21ece387, __p=0x180ea70) at /usr/include/c++/4.9/ext/new_allocator.h:120  #8  0x00007f4bf1283427 in std::allocator_traits<std::allocator<std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2> > >::_S_construct<std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySele---Type <return> to continue, or q <return> to quit---  ct>, (__gnu_cxx::_Lock_policy)2><std::allocator<lsst::qserv::ccontrol::UserQuerySelect> const, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> >(std::allocator<std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2> >&, std::allocator_traits<std::allocator<std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2> > >::__construct_helper*, (std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2><std::allocator<lsst::qserv::ccontrol::UserQuerySelect> const, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&>&&)...) (__a=..., __p=0x180ea70)      at /usr/include/c++/4.9/bits/alloc_traits.h:253  #9  0x00007f4bf1282887 in std::allocator_traits<std::allocator<std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2> > >::construct<std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2><std::allocator<lsst::qserv::ccontrol::UserQuerySelect> const, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> >(std::allocator<std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2> >&, std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2><std::allocator<lsst::qserv::ccontrol::UserQuerySelect> const, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&>*, (std::_Sp_counted_ptr_inplace<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, (__gnu_cxx::_Lock_policy)2><std::allocator<lsst::qserv::ccontrol::UserQuerySelect> const, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&>&&)...) (__a=..., __p=0x180ea70)      at /usr/include/c++/4.9/bits/alloc_traits.h:399  #10 0x00007f4bf1281b27 in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::__shared_count<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> (      this=0x7ffc21ece928, __a=...) at /usr/include/c++/4.9/bits/shared_ptr_base.h:619  #11 0x00007f4bf1280e15 in std::__shared_ptr<lsst::qserv::ccontrol::UserQuerySelect, (__gnu_cxx::_Lock_policy)2>::__shared_ptr<std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> (      this=0x7ffc21ece920, __tag=..., __a=...) at /usr/include/c++/4.9/bits/shared_ptr_base.h:1090  #12 0x00007f4bf1280388 in std::shared_ptr<lsst::qserv::ccontrol::UserQuerySelect>::shared_ptr<std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> (this=0x7ffc21ece920, __tag=..., __a=...)      at /usr/include/c++/4.9/bits/shared_ptr.h:316  #13 0x00007f4bf127f778 in std::allocate_shared<lsst::qserv::ccontrol::UserQuerySelect, std::allocator<lsst::qserv::ccontrol::UserQuerySelect>, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, ---Type <return> to continue, or q <return> to quit---   std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> (__a=...)      at /usr/include/c++/4.9/bits/shared_ptr.h:588  #14 0x00007f4bf127eafb in std::make_shared<lsst::qserv::ccontrol::UserQuerySelect, std::shared_ptr<lsst::qserv::qproc::QuerySession>&, std::shared_ptr<lsst::qserv::qdisp::MessageStore>&, std::shared_ptr<lsst::qserv::qdisp::Executive>&, std::shared_ptr<lsst::qserv::rproc::InfileMergerConfig>&, std::shared_ptr<lsst::qserv::qproc::SecondaryIndex>&, std::shared_ptr<lsst::qserv::qmeta::QMeta>&, unsigned int&, std::string&> () at /usr/include/c++/4.9/bits/shared_ptr.h:604  #15 0x00007f4bf127cf8d in lsst::qserv::ccontrol::UserQueryFactory::newUserQuery (this=0x17c79a0, query=""""SELECT * FROM R LIMIT 1"""", defaultDb="""""""")      at core/modules/ccontrol/UserQueryFactory.cc:126  Python Exception <type 'exceptions.ValueError'> Cannot find type const std::map<std::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >::_Rep_type:   #16 0x00007f4bf129f3aa in lsst::qserv::czar::Czar::submitQuery (this=0x17c6df0, query=""""SELECT * FROM R LIMIT 1"""", hints=std::map with 3 elements)      at core/modules/czar/Czar.cc:125  Python Exception <type 'exceptions.ValueError'> Cannot find type const std::map<std::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >::_Rep_type:   #17 0x00007f4bf17e778a in lsst::qserv::proxy::submitQuery (query=""""SELECT * FROM R LIMIT 1"""", hints=std::map with 3 elements) at core/modules/proxy/czarProxy.cc:102  #18 0x00007f4bf17f5556 in _wrap_submitQuery (L=0x17703c0) at build/proxy/czarProxy_wrap.c++:4177  #19 0x00007f4bf38e50c4 in luaD_precall () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #20 0x00007f4bf38e54a4 in luaD_call () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #21 0x00007f4bf38e487b in luaD_rawrunprotected () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #22 0x00007f4bf38e565b in luaD_pcall () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #23 0x00007f4bf38e2ebc in lua_pcall () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #24 0x00007f4bf38f32f8 in luaB_pcall () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #25 0x00007f4bf38e50c4 in luaD_precall () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #26 0x00007f4bf38ee26a in luaV_execute () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #27 0x00007f4bf38e54ed in luaD_call () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #28 0x00007f4bf38e487b in luaD_rawrunprotected () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #29 0x00007f4bf38e565b in luaD_pcall () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #30 0x00007f4bf38e2ebc in lua_pcall () from /qserv/stack/Linux64/mysqlproxy/0.8.5+12/lib/libmysql-chassis.so.0  #31 0x00007f4bf1a08fa6 in proxy_lua_read_query (con=con@entry=0x176c470) at proxy-plugin.c:1227  #32 0x00007f4bf1a09155 in proxy_read_query (chas=chas@entry=0x1758620, con=con@entry=0x176c470) at proxy-plugin.c:1334  #33 0x00007f4bf36b4c4d in plugin_call (srv=0x1758620, con=0x176c470, state=<optimized out>) at network-mysqld.c:892  #34 0x00007f4bf36b6283 in network_mysqld_con_handle (event_fd=11, events=2, user_data=0x176c470) at network-mysqld.c:1617  #35 0x00007f4bf2958ed0 in event_process_active_single_queue (activeq=<optimized out>, base=<optimized out>) at event.c:1325  #36 event_process_active (base=<optimized out>) at event.c:1392  #37 event_base_loop (base=0x1769f40, flags=flags@entry=0) at event.c:1589  #38 0x00007f4bf2959b87 in event_base_dispatch (event_base=<optimized out>) at event.c:1420  #39 0x00007f4bf38dfa0a in chassis_event_thread_loop (event_thread=0x1769e90) at chassis-event-thread.c:466  #40 0x00007f4bf38df496 in chassis_mainloop (_chas=0x1758620) at chassis-mainloop.c:359  #41 0x0000000000402a09 in main_cmdline (argc=1, argv=0x7ffc21ed1d78) at mysql-proxy-cli.c:597  #42 0x00007f4bf20a1b45 in __libc_start_main (main=0x401db0 <main>, argc=6, argv=0x7ffc21ed1d78, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>,       stack_end=0x7ffc21ed1d68) at libc-start.c:287  ---Type <return> to continue, or q <return> to quit---  #43 0x0000000000401dde in _start ()  {code}"""
"DM-8206","Story","SUIT",8,"Coverage is not shown if active table set before table loads","""I think there are flaws in how showImages are set in FireflyViewerManager layoutManager saga. In the first catalog load, coverage is not shown if active table is set before the table is loaded.    At dispatchUpdateLayoutInfo time     When active table is set before table is loaded:                        tableResults.added     showImages=false  tableResults.active     showImages=false  table.loaded                showImages=true  charts.data/chartAdd  showImages=false    When active table is set after table is loaded:    tableResults.added     showImages=false  table.loaded                showImages=true  charts.data/chartAdd  showImages=false  tableResults.active     showImages=true    You can test it by changing line 340 in TablesCntlr.js:      dispatchActiveTableChanged(tbl_id, options.tbl_group);    instead of       dispatchAddSaga(doOnTblLoaded, {tbl_id, callback:() => dispatchActiveTableChanged(tbl_id, options.tbl_group)});"""
"DM-8228","Story","Qserv",0.5,"Discuss 20% DR1 dataset strategy with Serge","""Talked to Serge about the existing 10% DR1 dataset, and potential strategies for building a 20% DR1 dataset.    The existing dataset was produced from SDSS stripe82 data, scaled up to 10% DR1 by replicating to cover greater sky area.  Serge thinks we may not be able to similarly reach a 20% DR1 dataset by just scaling coverage (there may not be enough unused coverage).    Instead, we may need to increase chunk density by modifying the replicator to map source HTM cells to HTM cells of the next smaller scale.  This would increase density by a factor of four; we could then either manipulate coverage or thin data during replication to converge on the 20% DR1 target."""
"DM-8227","Story","dbserv|ImgServ|metaserv|webserv",2,"webserv: don't use single-threaded flask internal server","""The flask internal web server is single-threaded, which will cause web services to be blocked e.g. during long running queries.  We will need to place some sort of multithreaded/pooling web server (e.g. nginx + wsgi) ahead of the flask service for acceptable behavior until implementing/adopting disconnected queries. """
"DM-8224","Bug","dbserv",1,"DAX dbserv fails when returning a COUNT() result of zero.","""This query:  {{curl -d 'query=SELECT+COUNT\(*)+FROM+RunDeepForcedSource+WHERE+objectId=3219370046129638' http://lsst-qserv-dax01.ncsa.illinois.edu:5000/db/v0/tap/sync}},  which selects no rows, fails with a spectacular stream of HTML containing an error report (see attached file).      The equivalent `SELECT+*` works fine.    I suspect this is a {{dbserv}}-level problem.  Note that the {{<title>}} element in the HTML contains the string """"TypeError: Decimal('0') is not JSON serializable"""", which seems very suggestive.    This is a rather high priority to fix, because it is easy to imagine the PDAC SUIT generating queries containing {{COUNT()}} clauses.  I don't _know_ that there already is such code, though.  """
"DM-8223","Story","daf_persistence",1,"write a test for getting mapper from _parent in v1 butlers","""write a test that shows that butler can find mapper from _parent directories when using v1 butler functionality"""
"DM-8222","Story","Qserv",1,"further qserv container time offset fix","""Improve the original fix proposed by [DM-8119] to make it fully compatible with the Debian Linux distribution used to build Qserv containers. It requires to have the following two files to be properly initialized:    *NOTE*: the second file doesn't exists in the RedHat-based Linux distributions.    Some ideas on how to solve this problem for Docker container can be found in the following documents:  * [https://www.ivankrizsan.se/2015/10/31/time-in-docker-containers/]  * [https://debian-administration.org/article/213/Changing_the_timezone_of_your_Debian_system]"""
"DM-8221","Bug","meas_base|pipe_tasks",2,"Inconsistency in forced schema catalogs","""[~nchotard] has discovered an inconsistency between the {{deepCoadd_forced_src}} catalogs and their accompanying {{_schema}} dataset in some processed Megacam data; one of these (I forget which) has a few additional fields, which mostly seem related to aperture correction.    First step is to add a test for this in pipe_task's {{testCoadds.py}}; if that doesn't fail, we can try to reproduce in ci_hsc, and if that fails I'll ask for more details about the specific dataset."""
"DM-8216","Story","SUIT",2,"Pass full available precision, when doing histogram for Long values","""This ticket will handle the first part of DM-8180, which will result in correct histogram display for the long values that can be converted into doubles without loosing precision.  (ex. LSST htm index)"""
"DM-8215","Story","SUIT",20,"Use DAX metaServ to properly handle multiple databases in PDAC","""5/15/2017    dbserv v1 (albuquery) is integrated with metaserv v1. As a consequence, column metadata are returned with with the data in the metadata section of the result.    As a part of this ticket, dbserv v1 and metaserv v1 were tested and debugged, tickets were created for outstanding issues, and SUIT code was updated.   * Consolidate PDAC table information, used by SUIT in LSSTMetaInfo.json on the server side. In the future this file might be converted to a table and stored in metaserv under SUIT curation. To facilitate development, we'd like to store it as a resource with the source code.   * Update SUIT codeto work with dbserv v1 (albuquery) and metaserv v1  a. Query metaserv to create table constraints table  b. Use column metadata returned by dbserv for data definition info, such as units and description    XW (12/21/2016)   We will be using MetaServ to get the database names, data types served, table names, and other information.    09/18/2017 (Tatiana Goldina)    The information provided by the current [metaserv prototype]([http://lsst-qserv-dax01.ncsa.illinois.edu:5005/meta/v1/db/]) is not yet sufficient to automate search interface creation. There is an ongoing discussion with DAX team on which information is missing. See    [https://confluence.lsstcorp.org/display/DM/Data+Access+meeting+2017-09-11]    At the moment, it is not clear how to replace the information in [LSSTMetaInfo.json]([https://github.com/Caltech-IPAC/firefly/blob/dev/src/firefly/java/edu/caltech/ipac/firefly/resources/LSSTMetaInfo.json]) (used by SUIT to support PDAC) with the information from metaserv.    The current implementation is sufficient to get column name, datatype, unit, description, if we'd like to descope the use of metaserv just for this purpose.    Metaserv prototype:   [http://lsst-qserv-dax01.ncsa.illinois.edu:5005/meta/v1/db]    Metaserv documentation:   [http://dm.lsst.org/dax_metaserv/api.html]    Table definitions in the available database schema:   [http://lsst-qserv-dax01.ncsa.illinois.edu:5005/meta/v1/db/W13_sdss/sdss_stripe82_00/tables/]    Dump of column definitions:   [https://gist.github.com/brianv0/e6cfc4ba36ced2a57eb131210ba16c46#file-dump-yaml-L34]    _______________________________________    This ticket list two issues to be considered later:   * The test version of the two search processors had hard coded database's name. But there will be multiple databases, we need to find a better way to handle it. Should it be passed to the server side or should it be stored in a configuration file? Currently, if the database name is not defined in the property, the hard coded default name is used.       * When the DAX server is down, it takes a long time to return a failed message back. To avoid confusing the users, the timeout control is set in in the getDataToFileUsingPost of the URLDownload class. The default value is 30seconds. The timeout field may be stored in the property file later.  """
"DM-8212","Story","obs_base",1,"Add support for reading metadata, length and schema of a catalog","""The {{butler.get(dataset + """"_md"""", dataId)}} pattern is only supported for images, not catalogs.  It would be useful to allow this to work on catalogs.  At the same time, it would be useful to add support for getting the length and schema of a catalog."""
"DM-8211","Story","afw",1,"Add support for reading a catalog schema","""It would be helpful to be able to read a catalog schema without reading the entire catalog (e.g., to prepare for concatenating catalogs).  I propose adding {{static}} methods:    """
"DM-8210","Bug","meas_base",0.5,"Revert accidental rename of id->objectId in ForcedPhotCoaddTask","""The """"id"""" column in coadd forced photometry outputs is being renamed to """"objectId"""", due to some code intended to *add* an """"objectId"""" column to CCD level forced photometry being accidentally applied."""
"DM-8235","Story","daf_persistence",1,"make utils.sequencify allow dicts","""per  https://community.lsst.org/t/bug-in-daf-persistence-blob-master-python-lsst-daf-persistence-utils-py/1389/2  allow dicts to count as a 'sequence' in sequencify."""
"DM-8230","Bug","meas_base|obs_base",1,"forcedPhotCcd.py doesn't work on DECam data","""{{forcedPhotCcd.py}} on DECam data with {{tract,visit,ccdnum}} data IDs fails with a registry lookup error.  This is due to an incomplete workaround for a known issue: [incomplete data IDs with skymap keys cannot be filled in by the registry|https://community.lsst.org/t/problem-with-megacam-dataid/1199/8], because the skymap keys are included in the registry queries but don't exist in the registry tables.  Our usual workaround for datasets like {{forced_src}} (which typically require a registry lookup to fill in unspecified data ID keys) is to do registry lookup on a similar type without a skymap key (such as {{src}}) by calling {{Butler.subset}}.    In {{obs_decam}}, however, the {{src}} template requires only {{visit, ccdnum}}, while {{forced_src}} also requires {{filter}}.  Because the data ID we're passing to {{Butler.subset}} is complete for {{src}}, it skips the registry lookup and passes an incomplete (for {{forced_src}}) data ID on to later code, which fails trying to complete a {{forced_src}} data ID that includes {{tract}}.    There are a few ways I can imagine fixing this:     - We could modify the {{obs_decam}} template to remove {{filter}}.  This is really just a band-aid, but it'd be easy, and since we're discovering this bug now I think it's unlikely there's any DECam CCD forced photometry results sitting on disk that this would break.     - We could copy some of the logic in {{ButlerSubset}} into the data ID mangling code for {{forcedPhotCcd.py}}, having it call {{getKeys}} and {{queryMetadata}} directly to fill out the data ID.  We could alternatively add a new {{Butler}} method to do this more flexibly that the {{forcedPhotCcd.py}} code could delegate to.     - We could modify {{ButlerSubset}} or {{queryMetdata}} to explicitly ignore skymap ({{tract}} and {{patch}}) data ID keys when querying the registry.  I think this would be a simple fix and it would avoid painful workarounds of the sort mentioned above when reading {{forced_src}} data.    [~ktl], [~npease], the last of the above solutions is my preferred one, but I wanted to check with you to make sure you weren't bothered by the special-casing of """"tract"""" and """"patch"""" data ID keys in the butler.  I'm happy to do the work myself (this is to support some DESC work that uncovered the bug, and I'm at DESC hack week)."""
"DM-8229","Story","lsstsw",1,"Add sims_survey_fields to lsstsw","""A new package, {{sims_survey_fields}}, will be added to the _repos.yaml_ in {{lsstsw}}."""
"DM-8252","Story","SUIT",2,"Add and  modify the server side codes to search the LSSTCatalog from Science_Ccd_Exposure and DeepCoadd tables","""Two tables are added in the LSSTCatalog's UI.  Thus, the search processors in the server side need to be updated to reflect the changes in the UI.      The following work will be done:  * Find out the ra and dec columns based on the table name passed from the UI  * Process the constraints passed from the UI and add to the SQL's """"where"""" clause  * Re-arrange the codes   * Test all four tables to make sure they work for each of the search method except mutli-object.  * Add error handling when the search method is not supported  * Add error handling when the data type defined in the metadata of the DAX's JSON file is not the same as in the actual datatype in the same JSON file.   """
"DM-8251","Story","daf_base",0.5,"Unicode string not being interpreted correctly.","""The following (running on lsst-qserv-dax01)         Results in this error   """
"DM-8249","Story","SUIT",8,"Alert subscription system requirement gathering","""to gather requirement and dependencies on other DM teams for Alert subscription system developed by SUIT.    After much discussion with AP team and the re-plan exercise, the requirement for alert subscription has been identified as the following:  *use the API that AP team will provide to*    # provide a UI for user to specify the filters on alerts of their interests, the destination of the alert to be sent  # save the specification in a DB  # provide UI to allow users to make modification of the filters and destinations of alerts  # possibly to annotate the alerts and allow user to access the annotation    This will involve SLAC for DB, NCSA for user management  """
"DM-8247","Epic","Firefly|IRSA|SUIT",40,"Background job management","""When the searches take long time, the packaging of the data to be downloaded takes long time, Firefly will put them in the background so users can continue to interact with the UI. """
"DM-8245","Story","SUIT",1,"Add Image tables, Science_Ccd_Exposure and DeepCoadd,  into LSST catalogs search panel ","""- Add image tables, Science_Ccd_Exposure and DeepCoadd, into the item search list.   - show DD table if any of the image table is selected for LSSTMetaSearch.  - show the image metadata table for LSSTCatalogSearch.  """
"DM-8255","Story","pipe_base",1,"Error if CmdLineTask is given an empty rerun folder","""CmdLineTask gets confused when it's given a rerun folder that already exists but is empty, and resulting in this error message:       This happens in use cases similar to what's wanted in RFC-249: a user creates a symlink for a rerun before running the task. """
"DM-8254","Story","daf_persistence|obs_base",1,"make butler silently allow compressed files (ending in .gz)","""Butler needs to allow repositories to contain a mix of compressed files (that end in .gz) and not compressed files, where the policy template does not specify the compressed file extension (gz)"""
"DM-8265","Bug","Qserv",3,"xrootd master fails to start","""Xrootd master crashes with following error message:  {code:bash}  Plugin loaded unreleased XrdSsiLPI unknown from logging libXrdSsiLog-4.so  Config neither ssi.loglib nor ssi.svclib directive specified in /qserv/run/etc/lsp.cf  Config '-l@' requires a logmsg callback function but it was found!  161114 10:34:25 208 XrdConfig: Logging plugin initialization failed.  {code}    This breaks Qserv CI in Travis."""
"DM-8273","Bug","pex_config",0.5,"Missing newlines in ConfigurableField persistence","""{{ConfigurableField.save}} uses the Python buffer {{write}} method but doesn't append a newline (it should probably append two for readability).    This is leads to a failure to read persisted configs, first noticed in an lsst_py3 Jenkins run of tickets/DM-8230, in meas_modelfit:testMeasureImage.py:103, in {{copy.deepcopy}}.    My only guess as to how we haven't noticed this before is that it's somehow not causing a problem in Python 2, and we hadn't tested Python 3 until now."""
"DM-8303","Story","SUIT",1,"Use qserv functions instead of scisql function in catalog search processor","""Need to follow https://github.com/lsst/qserv/blob/master/UserManual.md#spatial-constraints-should-be-expressed-through-our-qserv_areaspec_-functions  to use the qserv functions, like     qserv_areaspec_box(      lonMin               DOUBLE PRECISION,  # [deg]    Minimum longitude angle      latMin               DOUBLE PRECISION,  # [deg]    Minimum latitude angle      lonMax               DOUBLE PRECISION,  # [deg]    Maximum longitude angle      latMax               DOUBLE PRECISION   # [deg]    Maximum latitude angle  )    qserv_areaspec_circle(      lon                  DOUBLE PRECISION,  # [deg]    Circle center longitude      lat                  DOUBLE PRECISION,  # [deg]    Circle center latitude      radius               DOUBLE PRECISION   # [deg]    Circle radius  )    qserv_areaspec_ellipse(      lon                  DOUBLE PRECISION,  # [deg]    Ellipse center longitude      lat                  DOUBLE PRECISION,  # [deg]    Ellipse center latitude      semiMajorAxisAngle   DOUBLE PRECISION,  # [arcsec] Semi-major axis length      semiMinorAxisAngle   DOUBLE PRECISION,  # [arcsec] Semi-minor axis length      positionAngle        DOUBLE PRECISION   # [deg]    Ellipse position angle, east of north  )    qserv_areaspec_poly(      v1Lon                DOUBLE PRECISION,  # [deg]    Longitude angle of first polygon vertex      v1Lat                DOUBLE PRECISION,  # [deg]    Latitude angle of first polygon vertex      v2Lon                DOUBLE PRECISION,  # [deg]    Longitude angle of second polygon vertex      v2Lat                DOUBLE PRECISION,  # [deg]    Latitude angle of second polygon vertex   ...  )    See more examples in https://confluence.lsstcorp.org/display/DM/PDAC+sample+queries+and+test+cases    """
"DM-8297","Story","SUIT",2,"Add examples to firefly_client repository","""An examples subdirectory can be added to the firefly_client repository at the top level. It can contain sample Jupyter notebooks. The starting point can be notebooks for the Python API from the firefly repository, where the API was first developed."""
"DM-8296","Story","SUIT",2,"Make fork of firefly_client installable by eups","""To support the afwDisplay backend for Firefly, firefly_client is being added to the stack as a third-party package. To more easily incorporate changes as firefly_client is developed, firefly_client has been forked to the LSST Github org from the Caltech-IPAC org. A branch will be created and the eups tables will be added to it."""
"DM-8295","Story","SUIT",2,"Implement ws4py as third-party package installable by eups","""Following the developer instructions for third-party packages, add the {{ws4py}} package as a third-party package that is installable by eups."""
"DM-8293","Story","Qserv",2,"Fix travis build for PR","""Fix travis PR build are broken for unknown reason since a few month"""
"DM-8312","Bug","Firefly",1,"Values are not kept after switching from one panel tab to another ","""Latest LC viewer doesn't keep the value of the form when switching from one option tab to another. Some of the field value are kept, the other are reset and back to their initial values."""
"DM-8311","Story","Continuous Integration",0.5,"fix broken jenkins jobs that execute on lsst-dev","""The change of hardware for lsst-dev has broken the {{run-rebuild}} and {{run-publish}} jobs. See: https://community.lsst.org/t/official-release-of-lsst-dev01-and-replacement-of-lsst-dev/1386    There seems to be sort of odd problem with git checkouts:      """
"DM-8309","Story","Firefly|IRSA",2,"Enable histogram in IRSAViewer","""The story is about to branch off 'dev' a version of IRSAViewer to have the latest version of Firefly and enable:    - histogram feature (simple UI, no binning method options, only column/expression input)    Test version should be ready by beginning January.     Release plan for end of January.      """
"DM-8308","Story","SUIT",8,"Update LSST search panel to work for both catalog and image search","""update the LSST search panel to work on   - catalog table and image table selection  - spatial search for either catalog or image search  - fix DD table operation bugs including     . constraint column entry is not focused  - Update status store for LSST search panel - store the status for each catalog.      """
"DM-8329","Story","Developer Infrastructure",0.5,"terraform deployment for liveness monitoring","""A basic terraform deployment that setups a VPC, ACLs, an EIP, and route53 entries for {{status.lsst.codes}}."""
"DM-8325","Story","Developer Infrastructure",5,"Detailed LSST the Docs product monitoring","""Parse the output of keeper.lsst.codes/products in order to retrieve a list of published products, and monitor the health of those endpoints."""
"DM-8350","Epic","Firefly|SUIT",100,"PDAC v2, provide access to WISE/NEOWISE data","""This epic captures the specific issues for PDAC v2  """
"DM-8336","Story","Qserv",2,"Improve Docker image creation","""qserv/qserv:dev image is based on qserv/qserv:latest and may become huge if former one isn't update on a regular basis.    This ticket will allow to create qserv/qserv:dev from scratch to reduce its size."""
"DM-8375","Epic","Firefly|SUIT",40,"publish SUIT docs","""We need to publish the documents for JS API, Python API, and Jupyter widgets."""
"DM-8374","Improvement","afw",1,"Add function for Pybind11 wrapping of PersistableFacade","""Because pybind11 requires explicit wrapping of each template instantiation, the curiously recurring template pattern is difficult to wrap -- details of which methods need to be wrapped should be centralized in one place, but the instantiations naturally belong to the classes that inherit from the template.    The {{PersistableFacade}} interface is an example of the CRTP used by roughly a dozen classes across the stack. It should be wrapped by defining a function in {{afw::table::io}} for creating a pybind11 wrapper, then calling the function when wrapping a class that implements {{PersistableFacade<T>}}."""
"DM-8373","Story","SUIT",2,"SUIT requirement from EE","""make a list of the original SUIT requirement from EE  Help with the requirement flowdown  """
"DM-8372","Epic","SUIT",20,"SUIT and Science Platform requirements definition","""This epic is to finalize the requirements  for SUIT and science platform.  """
"DM-8365","Story","pex_logging",0.5,"deprecate pex_logging","""With the implementation of RFC-203, {{pex_logging}} is no longer used within {{pipe_tasks}}.  Please check if there are project-supported codes that still use pex_logging and need to be ported, update documentations if necessary, and formally deprecate {{pex_logging}}. """
"DM-8363","Improvement","pex_config",2,"Add macro for Pybind11 wrapping of LSST_CONTROL_FIELD","""The {{LSST_CONTROL_FIELD}} macro defines multiple fields and methods in a Control object's C++ interface, most of which are implementation details hidden from the average programmer. These implementation methods must appear in an object's Python interface for {{pex_config}} to work correctly, but should not be wrapped manually as this would break the abstraction provided by the macro.    The simplest solution is to define a macro that adds all elements of an {{LSST_CONTROL_FIELD}} to the appropriate Pybind11 wrapper object. This macro must be defined in {{pex_config}} in a place where it can be included by the wrapper code for any other stack package."""
"DM-8359","Story","ctrl_pool",2,"Port ctrl_pool to log package","""Remove {{pex_logging}} dependency in {{ctrl_pool}}. """
"DM-8358","Story","meas_mosaic",2,"Port meas_mosaic to log package","""Switch from using {{pex_logging}} to {{log}} in {{meas_mosaic}}. """
"DM-8357","Story","meas_modelfit",2,"Port meas_modelfit to log package","""Switch from using {{pex_logging}} to {{log}} in {{meas_modelfit}}. """
"DM-8356","Story","ci_hsc",2,"Port ci_hsc to log package","""Switch from using {{pex_logging}} to {{log}} in {{ci_hsc}}. """
"DM-8355","Story","ip_isr",0.5,"AssembleCcdTask failure with Python 2","""E.g. when running ip_isr's {{examples/runAssembleTask.py}}:        Looks like a bad conversion to Python 3: it assumes that {{dict.values()}} returns an iterator, but in Python 2 it returns a list. Simple (but ugly) fix:        Better suggestions welcome.    Rather shocking that this wasn't caught by tests. Sufficiently shocking that I'm wondering if I missed something. I suggest that rather than just committing the above tweak, this ticket should include a test which demonstrates that the task actually runs. An easy way to do that might be to simply migrate a slightly modified version of the code from {{examples/}} to {{tests/}}."""
"DM-8395","Story","SUIT",1,"Review the draft SUIT requirement document","""Review  and give feedback of the draft SUIT requirement document. """
"DM-8394","Story","supertask",2,"Understanding supertask quanta (round 1)","""Summary of our first discussion with Gregory and K-T which covered few simplest use cases."""
"DM-8390","Story","pipe_tasks",1,"calibrateTask.py example broken","""pipe_tasks provides {{examples/calibTask.py}}, which exercises {{CharacterizeImageTask}} and {{CalibrateTask}}.    As [reported by Mandeep Gill|https://community.lsst.org/t/problem-running-calibtask-py-example-script-from-pipe-tasks-dir-examples/1426] this currently fails as follows:        In addition to that, the code also attempts to pass a {{VisitInfo}} to an {{ExposureF}} constructor, which fails."""
"DM-8387","Story","SUIT",5,"draft requirement of Level 3 and data space","""write the draft requirement for Level 3, and its relationship with data space and JupyterHub. """
"DM-8377","Story","mariadb|mariadbclient",1,"Remove tests from Mariadb build","""mariadb and mariadbclient eups package contains 330 GB of tests binaries/data. This should be removed to have a lighter stack. A mariadb package with test could be added in order to test mariadb install (or this could be performed at build time...).    """
"DM-8424","Story","skypix",0,"Wrap skypix with pybind11","""May not require any wrapping, if so then this ticket is just for tracking. Otherwise, adjust SP."""
"DM-8422","Story","obs_test",1,"Wrap obs_test with pybind11","""May not require any wrapping, if so then this ticket is just for tracking. Otherwise, adjust SP."""
"DM-8421","Story","pipe_base",0,"Wrap pipe_base with pybind11","""May not require any wrapping, if so then this ticket is just for tracking. Otherwise, adjust SP."""
"DM-8420","Story","coadd_utils",2,"Wrap coadd_utils with pybind11","""May not require any wrapping, if so then this ticket is just for tracking. Otherwise, adjust SP."""
"DM-8417","Story","afw",8,"Wrap tests that depend on both image and table with pybind11","""The following tasks depend on both {{afw::image}} and {{afw::table}}. Wrap them.    # testApCorrMap.py (enable one skipped test)  # testBox.py (add a test for the copy constructor)  # testExposureTable.py  # testPolygon.py  # testTableIO.py  # testTableUtils.py  # testValidPolygon.py  # testVisitInfo.py  # testWeather.py  """
"DM-8413","Story","Requirements Documents",20,"Add DPDD requirements to LSE-61","""As part of requirements tracing, go through DPDD, determine where requirements are missing and create new requirements in LSE-61 as required. This will also involve updating some of the existing requirements to match DPDD."""
"DM-8409","Story","SUIT",2,"Feedback issues from firefly API testing","""These are task taken from [~rhl] comments in DM-7321 that need to be done the the firefly library. They are the issues that are exclusively on the Firefly client/server side. I am also including some comments:    * -Putting up an image often generates a small image (zoom=1); a small resize of the window causes a resize.- *(#2)* - _implemented in DM-10948_  * -It'd be nice to have an option for a horizontal layout (cf. ds9)  displays tend to be wider than high, but the firefly (and default ds9) display is higher than wide so you lose image area. *(#3)*-  _implemented in DM-10948_  * In the layers display, one layer seems to be the image. Why does it have a colour and a tickbox? *(#5)* DM-13124  * Pixel coords are off by (0.5, 0.5)  the middle of the bottom left pixel should be (0, 0) (i.e. offset by (1, 1) from the fits standard, which assumes fortran-style 1-indexed arrays) *(#7)* DM-13126  * There doesn't seem to be a way to show coordinates allowing for XY0 *(#8)* _I am not sure what this means, i will need more detail_  (DM-13152)  * The nice inset detail of the image doesn't show the mask planes *(#11)* DM-13127  * The inset detail isn't always centred on the cursor. E.g. at the lower left corner, if you put the cursor on the LL pixel, that pixel is shown at the LL of the inset, not the centre *(#12)* _I am not sure this behavior is wrong, I need to be convinced_ DM-13128    * Colours for masks appear to be case sensitive (unlike at least most web standards), and illegal colours such as RED are silently ignored *(#13)*  DM-13132  * Support a rapid stream of visualization actions, some which come before async actions complete (_from slack discussion_). DM-13131          More notes:  * We have talked about make another type of api html entry point that will allow for grid type layout display. We might do this as part of the QA efforts. _*#2* and *#3* implemented in DM-10948_  * *#4, #9, #10* are probably on the python api side or need to be worked on both sides and need other tickets. I will works this out with [~shupe], they need separate tickets  * *#6* -  -I don't think this is an issue-, _update_ - will solve *#6* as I documented in the comment below.  *#1, #14* - already fixed as part of DM-7321      More issues:    Fast zooming + restore failed:  How to repeat:  Catalog search Gaia at m81: Got an coverage image.  Image search WISE at m81: The WISE image swapped the Gaia coverage map.  When zoomed in fast and all the way till the zoom option panel shows, clicked Restore before closed the zoom option panel, the image got lost and the error message showed:  """"ZoomOptionsPopup.jsx:52 Uncaught TypeError: Cannot read property 'zoomFactor' of null  at getInitialPlotState (ZoomOptionsPopup.jsx:52)  at Array. (ZoomOptionsPopup.jsx:87)  at dispatch (createStore.js:186)  at middleware.js:86  at index.js:85  at index.js:14  at dispatch (applyMiddleware.js:45)  at PlotImageTask.js:178  at Object.dispatch (index.js:11)  at process (ReduxFlux.js:269)  """"  """
"DM-8467","Story","lsst_distrib",0,"Wrap lsst_distrib with pybind11","""This is the new (taking over from DM-6168) top level ticket for gathering all pybind11 wrappers. When this ticket is merged into master the port is complete."""
"DM-8449","Story","SUIT",1,"LSST catalog search panel related bugs ","""fix and update the following LSST catalog search panel issues:     - Catalog polygon search doesn't work (wrong parameters passed)  - Can not switch to catalog search after image search fails on creating the plot.   - shorten the decimal number display on the title of table tab.    """
"DM-8440","Story","afw",20,"Create new Wcs class","""Create the new flexible AST-backed WCS class.    This will be called {{lsst::afw:;geom::SkyWcs}} to indicate that it is a celestial WCS. It will implement most of the methods of the existing {{lsst::afw::image::Wcs}}. It will subclass from {{lsst::afw::geom::Transform<Point2Endpoint, SpherePointEndpoint>}}, because that class already performs the necessary pixel-to-sky transformations. It will include various standard frames to support the LSST pixel convention.    Note that this ticket is purely to create the new WCS class. It is not intended to replace usage of the existing WCS class."""
"DM-8439","Story","afw",20,"Add wrapper on astshim to take point lists","""Once the new point classes are implemented in DM-1987 this will provide the wrapper on top of astshim to pass them in and get them out both as lists and as single points."""
"DM-8428","Improvement","Qserv",1,"Add support for container timezone for Debian host.","""Linux does not provide a standard way to get container timezone"""
"DM-8514","Story","Qserv",5,"Prepare ASTERICS demo","""Demo will run a set of SQL queries on IN2P3 cluster."""
"DM-8496","Story","Design Documents",2,"DRP LDM-151 updates from Ivezic review","""Fixes to LDM-151 DRP section in response to [~zivezic]'s comments.  """
"DM-8491","Story","ip_diffim|obs_base|obs_cfht|obs_decam|obs_file|obs_lsstSim|obs_monocam|obs_sdss|obs_subaru|obs_test|pipe_tasks",8,"Add Psf-matched CTEs and Coadds as independent data products in DRP ","""This ticket will incorporate psf-matched coadds into DRP and include the following:    1) Develop plan for processing Psf-Matched coadds as part of DRP including interface in pipe_tasks commandline tasks, and butler data product naming convention and mapped filesystem paths: https://community.lsst.org/t/who-are-the-stakeholders-for-psf-matched-coadds/1439  2) RFC plan.  3) Add new data products to appropriate mapper files, including getting input on ones with unique file paths like obs_subaru and obs_sdss.  4) Edit command line tasks (currently WarpAndPsfMatch, MakeCoaddTempExp, AssembleCoadd) to treat psf-matched and non-psf-matched coadds as separate entities.  """
"DM-8556","Story","jointcal",1,"Rename validation_data_jointcal to testdata_jointcal","""""""validation_data_jointcal"""" is really """"testdata_jointcal"""" and should be named accordingly, before jointcal becomes a stack dependency. Then all the test data I'm using can live there and we won't need optional dependencies on really large data sets (which are always installed by lsst distrib and lsstsw)."""
"DM-8553","Story","jointcal",8,"Write jointcal photometry test for cfht","""Once I have the tests in place for twinkles, write a similar jointcal photometry test for cfht. This would be the time to replace the currently-broken validation_data_jointcal/cfht data with one updated to have VisitInfo."""
"DM-8549","Story","Continuous Integration|Developer Infrastructure",2,"jenkins job(s) for sqre-git-snapshot","""Resulted in two new jenkins jobs:    * {{backup/nightly-sqre-github-snapshot}} - a """"cron"""" job that runs nightly, executing the snapshot process from inside a container  * {{backup/build-sqre-github-snapshot}} - builds the docker container used by {{backup/nightly-sqre-github-snapshot}}.    Containers are pushed to https://hub.docker.com/r/lsstsqre/sqre-github-snapshot/"""
"DM-8548","Story","SUIT",1,"Add more info in the image title in the triview","""Currently the image title in the triview has filter name, like u, g, i, ...    It would be nice to add more information about the image, say deepCoaddId or scienceCcdExposureId.     Trey added:  see LsstSdssRequestList.js    [LZ 1-4-2017]  # For DeepCoadd,           Get the baseId from the selected row:                 baseId = deepCoaddId - deepCoaddId % 8            For each filter, the title is:                id = baseId + filterId  ( numerical addition here)                title = id+""""-""""+filterName  # For science CCD, its id structure is different than deepCoaddId      scienceCcdExposureId = run+filterId + field (  string concatenation)                      """
"DM-8547","Story","jointcal",8,"Replace print/cout in jointcal with lsst::log","""Jointcal has a many {{print()}} and {{cout<<}} that clutter up the output. These should be converted to lsst.log levels as appropriate (e.g. most of the python print are probably .info, while many of the cout are .debug)/"""
"DM-8537","Story","ap",5,"Update container networking in alert_stream to use non-host network","""Current version of the alert_stream producer/consumer + Kafka broker system (DM-7453 and DM-7454) uses Docker compose and just exposes all ports to the host network.  That won't work for scaling up to multiple hosts.  Need to replace this with better networking that will work for multiple hosts."""
"DM-8536","Story","ap",5,"Add postage stamp transmission/collection to alert_stream","""DM-7452 extend the sample alert schema to include a postage stamp cutout file.  Need to  * modify alert_stream repo and Docker images to grab the new alert schema and postage stamp files  * modify producers to add ability to encode and transmit stamps (can only be done with encoding)  * add a consumer to decode and write stamp (to the local filesystem?)  """
"DM-8528","Story","jointcal",1,"Port jointcal to python 3","""Now that the rest of the stack works with python3 (particularly the obs packages), it's time to bring jointcal into the fold."""
"DM-8579","Story","SUIT",3,"Clean up the server side visualization code","""clean up including:    - moved some files our of server/visualize  - created a ...server.visaulize.imageretrieve package  - remove unused code  - clean up some caching to simplify  - removed aborting a plot  - cleaned up managing plot context  - moved the *Commands.java files to .../server/rpc  - general cleanup including some java 7 syntax updates and javadocs"""
"DM-8571","Story","SUIT",2,"The current search result table tab should be shown immediately","""In catalog or image search, if the query takes a long time to get the result, the table tab is not shown until the result comes,  user still sees the previous search result during waiting.    It would be nice to show the current table tab immediately, so user can see that the search is going on.  How to repeat the case:  Make the first query: target (1,1), cone, 10 arcsec.  Then make the second query: same target, cone 1000 arcsec.  The second table won't show until the result comes out.  """
"DM-8566","Story","SUIT",3,"Some fixes to build process","""This is an action item from [SLAC-IPAC meeting|https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=~tjohnson&title=Camera+Image+Visualization+meeting+with+IPAC]:    - generate pure war (without embedded tomcat)  - workaround duplicate nom.tam.fits classes, etc   - Add preferIPv4Stack to tomcat env    preferIPv4Stack=true is added to setenv.sh file in tomcat.  This is done in ife-evn repo.    duplicate of ticket https://jira.lsstcorp.org/browse/DM-7706  closing DM-7706."""
"DM-8561","Story","QA",1,"Filter null measurements in post-qa","""{{validate_base}} allows measurements to be {{None}} if they failed, though SQUASH doesn't accept null measurement values.    # have post-qa filter out null measurements before posting to SQUASH.  # move the configuration that decides what metrics to post to the command line, making it easier to change in the future (and disable AM3 for now).  # when handling errors, don't print JSON since django actually seems to return an HTML error page."""
"DM-8581","Story","daf_base",1,"add python unit test of Citizen","""As part of tickets/DM-8417 I added a Python unit test of Citizen. [~pschella] would like me to add the same unit test to master."""
"DM-8594","Story","Firefly|SUIT",2,"Attend Camera visualization weekly meeting","""Attend the Camera visualization weekly meeting, act as the point of contact the UIUC team, bring back the requests and bug reports to Firefly team. """
"DM-8591","Story","afw",2,"Follow-up pybind11 behavior with numpy.int64s as indices in Python 3","""DM-8557 introduced a workaround for an issue seen in afw's multiMatch module where a numpy.int64 could not be used as an index by SWIG under Python 3. This ticket is to see if pybind11 has a similar issue under Python 3, and introduce a fix if so.    Suggested procedure to diagnose the numpy.int64 as index issue is:    # Revert commit in afw from DM-8557 called """"Cast catalog indices to int as SWIG Py3 workaround""""  # See if the afw test {{tests/testTableMultiMatch.py}} runs."""
"DM-8590","Story","ctrl_stats",8,"Remove cat dependency in ctrl_stats","""Remove dependency on the """"cat"""" package in ctrl_stats"""
"DM-8588","Story","Stack Documentation and UX",0.5,"Create DOIs for DMTN-006 and DMTN-021","""PUB-39 requires DOIs for DMTN-006 and DMTN-021. For now, these DOIs are prepared manually since we haven't engineering a technote release process yet."""
"DM-8586","Story","Stack Documentation and UX",2,"Document policies for making DM talks, publications, etc available on Zenodo (or elsewhere)","""It's (fairly) well known that DM has a policy of making materials deriving from talks given, papers published, etc by DM members available on [Zenodo|https://zenodo.org/communities/lsst-dm]. But we need some documentation specifying at least:    - The details of the policy (what should be made available, who is responsible, etc);  - The mechanism (how does one upload to Zenodo, what collections should the upload be added to, etc);  - Requirements regarding licensing."""
"DM-8598","Bug","Firefly|SUIT",2,"Dispatch TBL_RESULTS_ACTIVE when table is removed","""If i have 2 or more tables and i switch from one to another, the xy plot gets updated correctly.  Now, if i close one table, the next table gets active but the plot doesn't refresh/update and fails to show the xy plot of the active table.  Please check and fix.    --------------------  TG 12/7/2016    The bug is fixed in dev by adding TABLE_REMOVE to syncChartViewer saga in ChartsSync.js  However, Loi thinks TBL_RESULTS_ACTIVE should be dispatched when a table is removed.     To test this ticket, delete TABLE_REMOVE from ChartsSync.js:syncChartViewer saga - the charts should be still in sync with the table when a table is removed."""
"DM-8606","Improvement","afw",0.5,"Improve call signature for makeCameraPoint","""{{Detector::makeCameraPoint}} accepts arguments {{(geom::Point2D point, CameraSys cameraSys)}} instead of {{(geom::Point2D point const &, CameraSys cameraSys const &)}} and similarly for the {{CameraSysPrefix}} overload. This should be fixed. Note that it will require a matching change in the pybind11 wrapper.    Also {{Detector::makeCameraSys}} returns a {{CameraSys const}} but there is no need for the {{const}} because {{CameraSys}} is immutable.    This work should not be done until after we switch to pybind11. It's too minor to require changing sooner and would needlessly complicated the pybind11 transition."""
"DM-8605","Bug","utils",1,"problems setting log level in Python unit tests","""Example: meas_algorithms/tests/testMeasure.py  In the past, I could simply change [this line|https://github.com/lsst/meas_algorithms/blob/c33f9c998fe5757b14474aa91ccf447ead665f6f/tests/testMeasure.py#L45] to  {{Log.getLogger(""""measurement"""").setLevel(Log.DEBUG)}}  and then running the test would show the DEBUG log messages. But that no longer works since DM-7955.     I think this is because:    DM-7150 added a hard-coded log configuration, using {{lsst.log.configure_prop()}}, to the initialization code of Python unit tests ({{init()}} in {{utils/tests.py}} ).  It was done because the default log configuration at that time was disliked.     Later, DM-7955 improved the default config as well as the configuration process in {{log}}, and {{lsst.log.configure_prop()}} now would reset configuration (including resetting all loggers). Customizing the log level of a specific logger on the top of the test file no longer does what users want, because init() resets it (if I understand correctly)    So, I'm thinking to remove the log re-configuring in utils; in other words. revert DM-7150.  """
"DM-8604","Story","SUIT",5,"document the issues rising out of SUIT but needs DM attention","""There are several issues rising out of SUIT requirement and design discussions. Those issues affect SUIT but need DM management attention. This ticket is an attempt to make a list of those issues and ask DM management/architecture team to address them. """
"DM-8610","Story","db",2,"Use more secure way to pass password to mysql","""Implementation of `db.utils.loadSqlScript()` runs mysql command and passes  password as command line argument which is not very secure. We want better way to pass credentials to mysql, special protected defaults file is probably the best choice."""
"DM-8626","Bug","pex_config",1,"ConfigDictField cannot handle unicode keys in py2","""Trying to use a unicode string as a key in a ConfigDictField causes a type error in Python 2. Unfortunately unicode is difficult to avoid with pybind11. I suggest trying to auto-cast such keys to str if the key is string-like and the type doesn't match the expected key type."""
"DM-8619","Improvement","afw",3,"Enable testWarper.py with pybind11","""Wrap as much code as needed to make {{testWarper.py}} and {{testWarpExposure.py}} work and enable that test."""
"DM-8629","Story","Qserv",2,"Remove cmsd log message","""On cc-in2p3 cluster (ccqserv123) next message appears in xrootd-console.log:    Maybe next lst.cf directive should be moved to global:  """
"DM-8630","Story","Developer Infrastructure",1,"/ssd/lsstsw/stack not updating on lsst-dev01","""Last weekly available is {{w_2016_48}}. Judging by the logs, builds have been failing since 29 November. Error is:    """
"DM-8648","Bug","Firefly|SUIT",8,"Image viewer incorrectly displays flux unit when loading multiextension FITS file","""Preparing next release of Herschel image set, Justin is using the IRSAViewer in {{OPS}} to load FITS file _(see attached an example of it that show the problem)_ and has found a problem with the image viewer (readout flux unit is incorrect but other value might be also affected).     When the multiextension FITS file attached is loaded, the 3 images are correctly loaded but the unit shown is the one from the last image ({{coverage}}). From the code, debug shows that  uses NO_BAND as a key, so the {{WebFitsData}} corresponding to each image is overwritten with the last one read.    The consequence is FITS values such as CVAL, NAXIS, and others of the ImagePlot might not be correct. In particular, the flux unit is '1' for all images when it should display 'Jy/beam' in the readout.    [LZ 1-3-2017]   The bug is located at the makeAllNoBand in ImagePlotCreator.java.  When the FITS file has multi-extension and the image is not three color image, each image 's band is NO-BAND.  The WebFitsData containing flux unit, dataMin, dataMax etc, is read in from the FitsRead and is stored in wfDataMap that is a  Map<Band, WebFitsData>.   However, the wfDataMap was created outside the for loop.  When each WebFitsData  is calculated, since the map key=NO_BAND is the same for all the extensions, the value in wfDataMap is replaced by the new value calculated in the loop.   When the loop is over, the wfDataMap contains the last   calculated wfData, ie., the last extension. Thus, the piArray contains three identical elements.   Except the flux unit is wrong, the dataMin, dataMax etc. are wrong as well.        This block shows the correct wfData calculation for the same input (1250p4106_1342188754_SpirePhoto_L20_PMP500_SPG14.0.fits).        This block shows what the value actually received.       Since the wfDataMa is to store each WebFitsData, it should be initialized inside the for loop.    """
"DM-8647","Story","base",0.5,"Enable autobrief in Doxygen","""{{AUTOBRIEF}} is turned off by default in our Doxygen configuration. The developers guide   https://developer.lsst.io/docs/cpp_docs.html suggests using @brief but the very first example after that omits it and much of our code omits it. I think it should be optional and certainly much of our code reflects that.    The proposed fix is set the following to {{YES}} in in `doc/base.inc`:  - {{JAVADOC_AUTOBRIEF}}  - {{QT_AUTOBRIEF}}    We mostly use javadoc style, but there is no harm in supporting both, and some of our code may already use QT style."""
"DM-8646","Story","SUIT",1,"Update eups build tables in display_firefly","""To make display_firefly be installable via eups, and with the implementation of its dependencies in DM-8295 and DM-8296, some updates are needed:    * Add the firefly_client packages as a dependency in ups/display_firefly.table  * Remove the xpa, pex_exceptions and swig parts from ups/display_firefly.cfg  * Add the display_firefly repository to etc/repos.yaml in the lsstsw repository"""
"DM-8645","Story","meas_algorithms",2,"Implement new matcherSourceSelector object for use in matchOptimisticB code. This links to DM-6824.","""astrometrySourceSelector can not be used alone in matchOptimisticB as it tests for two different criteria depending on if it's matching objects(needs good centroid, is a parent object, has a minimum S/N, valid flux) or returning those objects to astrometry.py(all the previous plus is not saturated, is not interpolated, and is not edge). The new source selector matcherSourceSelector will make former selection, astrometrySourceSelector will make the second test. This ticket extends the work of DM-6824."""
"DM-8642","Story","supertask",2,"Understanding supertask quanta (round 2)","""Few random thoughts on quanta to keep record of my misunderstanding."""
"DM-8656","Bug","meas_astrom",1,"meas_astrom tests depend on PyQt4 and Qt4 and break with PyQt5 and Qt5","""When building meas_astrom with lsstsw using -b option on CentOS7 with gcc 4.8.5 tests break through a dependency on matplotlib.    """
"DM-8654","Bug","pex_policy",1,"Policy::names(bool) ignores its argument","""The method {{names(bool topLevelOnly = false)}} in {{pex::policy::Policy}} does not use its argument, always behaving as if {{topLevelOnly}} were {{true}}. It appears that this bug went undetected because the swig wrapper for {{names(list<string> &, bool, bool)}} masked {{names(bool)}}, preventing it from ever being called from Python code.    I propose that the implementation of {{names(bool)}} be changed to share code with {{names(list<string> &, bool, bool)}}, both fixing the immediate problem and preventing inconsistent behavior from calling the wrong overload in the future."""
"DM-8652","Story","afw",1,"Wrap afw ds9 test with pybind11","""Wrap {{testDs9.py}} with pybind11.  This was left over from DM-7799 because it didn't really fit there."""
"DM-8662","Bug","SUIT",0.5,"Incorrect PYTHONPATH in firefly_client repo","""The implementation of firefly_client as a third-party package in DM-8296 does not allow the module to be imported. A small change is needed to the PYTHONPATH in the eups table.     The problem was missed in development because the module importing was tested in the repository's base directory. It is necessary to change directories before testing that the import works."""
"DM-8661","Story","SUIT",8,"Create a Unit Test for ImageData class","""To ensure the Firefly works correctly, the unit test for ImageData is needed."""
"DM-8660","Story","SUIT",8,"Create a Unit Test for Geom class","""The unit test is needed for Geom class. This class is used for making images.  Therefore it is important to make sure it works as it should.    Analysis by Lijun:  * Add unit test for its public method  * Add end to end test for its seven cases so that all methods can be run.  * Prepare different input and output data set to test different combinaitons"""
"DM-8676","Story","meas_algorithms",1,"Hide matplotlib imports in meas_algorithms","""meas_algorithms has several """"naked"""" matplotlib imports that happen at the top level, and thus prevent anything that imports meas_algorithms from subsequently setting the backend. A simple fix is to move those imports into the functions where matplotlib is used, so they only occur if matplotlib is run, and preferably wrap them in try:except and log.warn on any errors.    This is a stop-gap until 5790 is properly dealt with."""
"DM-8667","Story","lsstsw",2,"Changes to lsstsw to add ctrl_platform_lsstvc remove old ctrl_platform_* references","""This work removes the following:    ctrl_platform_lsst  ctrl_platform_gordon    from etc/repos.yaml    adds:    ctrl_platform_lsstvc    to etc/repos.yaml    and moves the repos to    lsst-dm/legacy_ctrl_platform_lsst  lsst-dm/legacy_ctrl_platform_gordon  """
"DM-8689","Bug","meas_astrom",0,"In one place code calls log.warning instead of log.warn","""In one place code from DM-8656 calls {{log.warning}} instead of {{log.warn}}"""
"DM-8688","Story","meas_algorithms",1,"testPsfSelectTest fails when run with via ""pytest *.py""","""testPsfSelectTest fails when run via {{pytest *.py}} in {{meas_algorithms/tests}}, but passes if run with {{python testPsfSelectTest.py}} or {{pytest testPsfSelectTest.py}}. Sample failing run shown below. I'm betting this is a badly-initialized random seed (e.g. the one on line 45).    Including [~vpk24] since it looks like he did the pytest port, and [~sullivan] because he added the new-style test boilerplate at the bottom.    """
"DM-8686","Story","daf_persistence|obs_base",8,"Change Child Repo Access to Parent Registries","""Child Repositories need to be able to perform lookups in the sqlite Registry of one or more parent repositories.    Old Butler repositories used to find the registry by looking in the current repo, then following the _parent symlink until a registry was found.    New Butler repositories do not access their parent repositories directly.    The shorter term fix is for butler to pass all of a repos parent sqlite registries to a repo (via an ordered list of registry objects, each of which is of course a reference). The butler will use that list, whose order will be 1. a local sqlite registry (if present), 2. all the parent registries in order, and 3. use a PosixRegisry on the local repository. In the case of no results found when searching sqlite registries, butler will verify that the tables specified for the policy are in the registry. If they are, butler will return no results. If the tables are not in that registry, butler will look in the next registry.    (The better/longer term fix is output registries, where butler updates a repo-local registry when writing a dataset to a repo, and never does lookups in parent registries.)  """
"DM-8678","Story","Continuous Integration",1,"update jenkins qserv container generation job","""Request from [~fritzm] via slack: """"update CI to generate it using following command `./1_build-image.sh -CD`"""".    As jenkins is currently using a fork of the qserv docker scripts with some minor modifications, testing will be required to migrate to the qserv master branch.  """
"DM-8696","Story","afw",1,"Wrap testTicketDM-433 with pybind11","""Moved here from DM-6297 because it depends on DM-8674 to be merged."""
"DM-8695","Bug","meas_base",1,"Fix dataRef list creation bug introduced in DM-8230","""A bug was introduced in DM-8230 such that the {{dataRef}} was not being appended to the refList in the {{PerTractCcdDataIdContainer}} found in *forcedPhotCcd.py* (resulting in an empty refList).  Please fix."""
"DM-8691","Story","meas_extensions_convolved",1,"ConvolvedFluxPlugin should measure even if seeing is small","""The {{ConvolvedFluxPlugin}} currently refuses to measure a source if the target seeing is smaller than the actual seeing.  This was a bad choice, as having a potentially-incorrect measurement is more useful than having nothing at all (so long as there's a flag indicating the problem)."""
"DM-8701","Story","Infrastructure",1,"Copy and ingest HSC Cosmos data","""Once RFC-266 is accepted, {{/gpfs/fs0/scratch/pprice/UH-Cosmos/*.fits}} needs to be copied into {{/datasets/hsc/raw/cosmos}} and ingested into {{/datasets/hsc/repo}}."""
"DM-8698","Story","meas_modelfit",1,"Jenkins build failure in meas_modelfit",""""""
"DM-8714","Bug","meas_base",1,"Fix position of psf computation for base_SdssShape_psf","""There is an error in the psf computation of *base_SdssShape_psf* in {{meas_base}}'s *src/SdssShape.cc* in that it does not provide the position of the source, so is just getting the measurement at the position returned by {{afw}}'s {{getAveragePosition()}} in *src/detection/Psf.cc* for all sources.  Please fix."""
"DM-8750","Story","jointcal",2,"eliminate jointcal compile warnings","""Jointcal produces a number of compile-time warnings (which one can miss without the scons fix described in RFC-246). We should clean these up, which might be helped by compiling with both gcc and clang, and comparing their messages. It may be best to do this after we've dealt with other problems (like the boost pointer memory management), as that may take care of some of the warnings along the way. On the other hand, there's quite a bit of low-hanging fruit in the form of variables that are defined but never used."""
"DM-8742","Epic","Firefly",100,"Firefly code refactor and bug fixes (S19)","""This version of pipelineQA portal could be used for ComCam commissioning."""
"DM-8741","Epic","SUIT",100,"Bug fixes, improvements, and code refactoring in SUIT S19","""This epic includes the tickets for improvements, code refactoring, and bug fixes needed for LSP portal."""
"DM-8729","Story","SUIT",2,"Publish display_firefly to eups","""This ticket captures work done to publish the display_firefly backend for afw.display to eups, including researching and learning the steps to do it.    * tag the ws4py and firefly_client dependencies appropriately  * rebuild display_firefly using Jenkins  * publish display_firefly using Jenkins    enabling:  """
"DM-8761","Story","Firefly|SUIT",5,"monthly test of tickets related to UI changes and bug fixes (May 2017)","""monthly test of tickets related to UI changes and bug fixes   file tickets with steps to reproduce the bugs"""
"DM-8760","Story","Firefly|SUIT",5,"monthly test of tickets related to UI changes and bug fixes (Apr. 2017)","""monthly test of tickets related to UI changes and bug fixes   file tickets with steps to reproduce the bugs    DM-10065 needs to be thoroughly tested. """
"DM-8759","Story","Firefly|SUIT",0.5,"monthly test of tickets related to UI changes and bug fixes (Mar. 2017)","""monthly test of tickets related to UI changes and bug fixes  File tickets with steps to reproduce the bugs    3/1/2017: Tested DM-8578.  """
"DM-8758","Story","Firefly|SUIT",5,"monthly test of tickets related to UI changes and bug fixes (Feb. 2017)","""monthly test of tickets related to UI changes and bug fixes.  file tickets with steps to reproduce the bug.      2/1/2017 Reviewed DM-8660: Unit test for Geom.  2/2/2017 Reviewed DM-8670: Light Curve UI (wise data).  2/3/2017 Reviewed DM-7780: FlipXYTest  2/7/2017 Reviewed DM-9247: All Sky catalog query  2/8/2017 Reviewed DM-9248: All Sky mode  2/9/2017 Reviewed DM-8661: Unit Test for ImageData  2/12/2017 Reviewed DM-7946: UnitTestForCentralPoint  2/15/2017 Reviewed DM-7780: FlipXYTest  2/16/2017 Reviewed DM-8839: Image header unit test  2/17/2017 Reviewed DM-9470: Compass layout  2/21/2017 Reviewed DM-8845: UnitTest for ImagePlot class  """
"DM-8757","Story","Firefly|SUIT",5,"monthly test of tickets related to UI changes and bug fixes (Jan. 2017)","""Test all the tickets affecting UI when merged into dev. File Jira tickets  with the steps to duplicate the bugs.      Jan. 3 2017 Tested https://jira.lsstcorp.org/browse/DM-8548 and found the bug. See comment in the ticket.  Jan. 3 2017 Reviewed DM-8648 in git hub.   Jan. 4, 2017 Tested/reviewed DM-8548.   Jan. 9, 2017 Found a bug and issued ticket DM-8957:Original plot Inconsistent does not abort  Jan. 12, 2017 Reviewed DM-8957: Original plot does not abort and over writes active plot  Jan. 12, 2017 Reviewed DM-8049: Crop related classes need to be refactored  Jan. 17, 2017 Reviewed DM-7827: Create LSST File group processor for packaging (download the LSST images)  Jan. 20, 23, 2017 Reviewed DM-8668: LC period finder  Jan. 31, 2017 Tested DM-8985: mask"""
"DM-8751","Story","afw",2,"Fix skipped testPickle in testSourceTable.py","""There is one skipped test in {{testSourceTable.py}}: {{testPickle}}. This segfaults, likely when a source catalog is pickled. Fix this.     Should all kinds of catalog be pickleable? If so, make sure all are being tested."""
"DM-8791","Story","Developer Infrastructure",0.5," lsst-dm-mac.lsst.org is inaccessible","""From my office desktop:      From the production jenkins instance:  """
"DM-8825","Story","obs_subaru|Validation",1,"cannot run singleFrameDriver on hsc data with python3 due to ""__builtin__.str"" in *Mapper.paf","""When attempting to reprocess some hsc data, I ran into a number of problems (one fixed in DM-8822). In this case, some of the python type definition in the obs_subaru {{Mapper.paf}} files are not valid: {{\_\_builtin\_\_.str}} doesn't exist on python3. Fortunately because of our use of futurize, we have {{builtins.str}}.    Although I don't plan to write it as part of this ticket, having a python2+3 validation system for the policy files would be good."""
"DM-8822","Story","ctrl_pool",1,"Fix octal umask handling in ctrl_pool","""While reprocessing some hsc data, I received the error given below. This is because python3 does not implicitly convert integers with leading zeros into octal. We should make the ctrl_pool code use an explicit octal int for the umask defined at the top of parallel.py, and then use a better formatting string where necessary.    """
"DM-8817","Story","Stack Documentation and UX",1,"Port DMTN-017 LaTeX document to technote platform","""DMTN-017 was written as a LaTeX doc before technotes existed. This story is to port DMTN-017 to a PDF viewer template (DM-4602) for PDF documents that can be published with LSST the Docs."""
"DM-8841","Story","ci_hsc",1,"ci_hsc is broken","""[~Parejkoj] in DM-8825 points out that ci_hsc is broken.  It appears to have broken between build [#932 (Jan 3, 2017 5:57:59 PM)|https://ci.lsst.codes/job/ci_hsc/932/] and [#933 (Jan 4, 2017 1:57:00 AM)|https://ci.lsst.codes/job/ci_hsc/933/].  Diagnose and fix."""
"DM-8837","Epic","meas_astrom",40,"Reference catalog proper motions, parallaxes and errors","""We will need to apply proper motion corrections when matching reference catalogs to measured catalogs.  This epic will implement that feature.  This will require several steps:  # Implement standardized schema (per RFC-271)  # Implement correction code  # Write tests and verify performance    The construction of reference catalogs is briefly discussed in LDM-151 v4.1 6.1, but we defer to RFC-271 in terms of implementation detail. A deliverable for this epic will be documentation describing the format and contents of reference catalogs.    Per the comment below, this epic also covers implementing RFC-368, including adding parallaxes to the reference catalogs."""
"DM-8832","Bug","Validation",1,"Butler mapper issue in validate_drp since Jenkins build 663","""Since [build 663 on Jenkins|https://ci.lsst.codes/job/validate_drp/dataset=cfht,label=centos-7,python=py2/663/console] we're seeing a new Butler-related issue in {{validate_drp}} even with the CFHT dataset. Could there be a butler change that is triggering this issue? This would have happened January 3-4 2017.      """
"DM-8830","Bug","Validation",1,"Fix accounting for fraction of successful measurements","""The final accounting for success/fail of the KPMs in `validateDrp.py` appears to be off:        1. Investigate why this is happening (likely a counter not being reset, or the denominator not being updated).  2. Decide on correct accounting and implement."""
"DM-8890","Story","QA",2,"Investigate if  MariaDB 10.1+ DynamicField() can be used for storing JSON blobs","""During deployment of SQuaSH we realized that JSONField() as implemented in DM-8414 works only with MySQL and that the corresponding field type for MariaDB is the DynamicField()    This ticket is to make sure we can use MariaDB features and stick with it in production."""
"DM-8877","Story","skymap",2,"Wrap skymap with pybind11","""May not have any work associated with it, but is an {{lsst_distrib}} dependency. Investigate and update SP."""
"DM-8874","Story","afw|display_ds9",3,"Wrap display_ds9 with pybind11","""May not have any work associated with it, but is an {{lsst_distrib}} dependency. Investigate and update SP."""
"DM-8872","Story","Developer Infrastructure",1,"Disable locking in shared-stack.py","""[~price] points out that we can (and likely should) disable EUPS locking globally by adding        to the EUPS configuration."""
"DM-8867","Story","lsst_apps",0,"Wrap lsst_apps with pybind11","""May not have any work associated with it, but is an {{lsst_distrib}} dependency. Investigate and update SP."""
"DM-8866","Story","datarel",0.5,"Wrap datarel with pybind11","""May not have any work associated with it, but is an {{lsst_distrib}} dependency. Investigate and update SP."""
"DM-8842","Story","meas_astrom",0.5,"LeastSqFitter1d(..., unsigned int order) should be signed","""LeastSqFitter1d's constructor's {{order}} parameter is {{unsigned int}}. However it is stored as {{int}} and {{LeastSqFitter2d}} uses {{int}} in both places.    I suggest switching to {{int}}. The existing code always supplies a small positive integer, so it's safe and trivial to fix. However, it will require the same change to the pybind11 interface file.    I further suggest not changing this until after the pybind11 transition. Then change it and make sure the whole stack builds."""
"DM-8934","Story","Infrastructure",5,"Service Management & Emergent Work  (December) ","""This story captures service management / emergent work  for December actives related to the LSST development servers and Nebula OpenStack. This include issues and project communications related to the Home Directory transition to NFS to GPFS, network settings maintenance in NPCF,  tuning of HTCondor settings & installation on lsst-dev01,  Nebula instance shutdowns / migrations to help support live migration functionality, and similar issues. """
"DM-8933","Story","Validation",0,"Fix formatting in validateDrp.py --help message","""Fix formatting in validateDrp.py --help message    The """"description"""" currently reads as        But it should read (as written in the string):        * I think this is just a matter of passing {{formatter_class=argparse.RawDescriptionHelpFormatter}} to {{argparse.ArgumentParser}}"""
"DM-8923","Story","Continuous Integration",1,"remove jenkins hipchat notifications","""The slack migration appears to be a success and HC is essentially unused.  Hipchat notifications from jenkins jobs should be safe to remove at this point and it is an opportunity to prune another plugin."""
"DM-8914","Story","Qserv",5,"Improve container build in Jenkins","""Build script is here:  https://github.com/lsst-sqre/jenkins-dm-jobs/blob/master/pipelines/qserv/docker/build.groovy#L25-L26    dev containers should be created at each build, whereas release should only be created once a month."""
"DM-8957","Story","SUIT",5,"Original plot does not abort and over writes active plot","""Sometimes in the irsa tri-view, the images don't match the table and the xy-plot.    For example:  In http://localhost:8080/firefly/lsst-pdac-triview.html;a=layout.showDropDown,  select """"Images"""" and """"Science Ccd Exposure"""",  target: ra = 9.6, dec = -1.1;    Then in the tri-view, five images have been downloaded (one of the scienceCcdExposureId is 1755410440). Now click any row which never downloaded images (for example, with the scienceCcdExposureId=4203410469), now this new set of images start to be downloaded. BEFORE (!) the downloading is finished, click back the very first row (1755410440) and wait for the downloading to finish. When the downloading is done, you will see the inconsistent tri-view:  The first row is selected in the table, the dot of the first row in the xy-plot is highlighted, but the images are the new set. If user keeps clicking on the first row, the tri-view won't change and the inconsistency stays. Only when the user clicks any other row, the inconsistency will be gone.    Bug?"""
"DM-8949","Story","ctrl_stats",8,"ctrl_stats doesn't calculate year to next year progress properly","""An issue in DM-8948 brought up a problem in how the time are calculated within ctrl_stats.  It made an assumption and used a files creation date as the year to start with;  this worked throughout the year, but failed if the files were pulled in one year, and run in the next year. (time stamps of 2016 vs the year being 2017).   This assumption was fixed in DM-8948.    There is still a problem that exists in year to year calculations, for jobs that start in one year and end in the next.  There will be negatives times calculated.   This ticket will address this issue."""
"DM-8948","Bug","ctrl_stats",1,"ctrl_stats fails tests in 2017","""{{lsst_py3}} is no longer building because {{ctrl_stats}} is getting the year wrong in tests.    3 other test files fail.  """
"DM-8944","Story","QA",0.5,"migrate squash production DB to MariaDB 10.1.x","""Migrate the production RDS instance from MariaDB 10.0 -> 10.1 in preparation for the next squash release."""
"DM-8967","Story","Stack Documentation and UX",0.5,"Documenting using emoji reactions in GitHub code reviews","""After a discussion in Slack (a while ago in Dec 2016) we agreed that we're getting too many emails during code reviews when a developer replies """"Done"""" to each line comment. A way around this is to use GitHub's emoji reactions: the dev can check off a comment, but an email is not sent out.    This ticket documents that process in the [Developer Workflow page|https://developer.lsst.io/processes/workflow.html] of developer.lsst.io."""
"DM-8965","Story","L1 Database",8,"Extend Alert Production prototype with new index type","""I want to try to improve indexing in the DiaObject table to make both search and insertion faster."""
"DM-8964","Story","pipe_drivers",0.5,"Update singleFrameDriver following changes to reference catalogs","""The signature of {{ProcessCcdTask.\_\_init\_\_}} has changed (in DM-8232 to support distinct reference catalogs).  {{SingleFrameDriverTask.\_\_init\_\_}} needs to be changed to match."""
"DM-8963","Story","SUIT",0,"FITS download (save) does not work for 3 color image if the type is FITS","""To reproduce the problem:    # Start the IRSA viewer in the browser (/ocalhost:8080/firefly/)  # Select """"Create a New Plot 3-color""""  # Select Red panel and Wise data  # Enter """"m31""""  # Click """"Search""""  # Click the file save icon in the toolbar  # Click """"Download""""   # But nothing happens after clicking download    NOTE: If the type of file is PNG, it works.  """
"DM-8978","Story","jointcal",2,"writing jointcal output is slow due to dataRef lookup","""[~boutigny] noticed that jointcal is now very slow to write its output. This is at least in part due to the way I rewrote the output code to work with decam, which does not have """"ccd"""" in its dataRefs. I think new slowdown is coming from the repeated calls to {{get(""""calexp"""").getDetector().getId()}}.    [~price] suggested making a dictionary to map visit and ccd name to each dataRef:        and then replacing the for loop and if statement with a lookup in the dict.    Note to Butler people: this problem is related to the problem of having no standard set identifiers in the dataIds: if we can guarantee that """"visit"""" and """"ccd"""" are always there (and, I'd argue, some other things), this code would be quite a bit simpler."""
"DM-8973","Story","afw",8,"Wrap new Footprints with pybind11 and create python unit test","""Wrap the new Footprints class with pybind11. A success criteria for this is successfully porting and updating the Footprints python unit test to successfully run."""
"DM-8972","Story","obs_cfht",1,"obs_cfht table file uses envAppend","""obs_cfht.table includes:      These {{envAppend}} calls should be {{envPrepend}}."""
"DM-8982","Story","ip_isr",0.5,"Incorrect binning in overscan spline interpolation","""The ordinates for the overscan spline interpolation can violate the requirement of monotonic increasing in the presence of masked rows, causing GSL to reject it and we end up raising an exception.  For example (notice the third element):        This is because the code to generate these ordinates (binning the overscan data vector) is incorrect."""
"DM-8980","Story","Developer Infrastructure|Stack Documentation and UX",1,"Revise Python Style Guide for RFC-107 (79 character docstring lengths)","""This ticket will implement RFC-107, which states that all Python docstrings and comments must have a maximum line length of 79 characters.  """
"DM-8990","Bug","Qserv",2,"wmgr database connection leak","""Igor reported mysql error when loading lots of data into qserv cluster at in2p3:      I think it happens due to wmgr creating new connection on every data load request (this was verified) because it creates new sqlalchemy engine and:  - every new sqlalchemy engine has its separate connection pool  - engines are not destroyed by sqlalchemy (and not reused)    To avoid this issue we should reuse engine instances and avoid creating new ones. May need to verify first whether my guesses above are true."""
"DM-9005","Story","Developer Infrastructure",1,"Shared stack build failures on lsst-dev01","""lsst-dev01 shared stack builds are having exactly the same problem with w_2017_2 & _3 as recorded for w_2017_1 in DM-8803:    """
"DM-9004","Story","ip_isr|obs_subaru|pipe_drivers",1,"Check uses of darktime for NAN","""The darktime can be {{NaN}} if not set explicitly in the obs package's {{makeRawVisitInfo}}.  Any scaling of an exposure by the darktime can therefore result in a useless image full of {{NaN}} values.  We therefore need to catch the case {{isnan(darktime)}} wherever we use it: pipe_drivers for construction of the dark, and ip_isr for application of the dark."""
"DM-9016","Story","ctrl_pool",1,"Drivers should be able to be made less verbose about eups","""{{singleFrameDriver.py}} (and likely other pipe_drivers scripts) echos a bunch of eups commands and their output on startup. Those commands aren't part of the standard logging system and it should be possible to turn them on/off with an argument. I suggest either:     * {{--verbose-eups-dump}} to turn them on  or   * {{--quiet-eups-dump}} to turn them off.    I'm not sure whether on or off is the better default, and I'd be happy with either.    One can turn them off currently via {{--batch-type none}}, but that changes the actual type of processing, which is not desired."""
"DM-9014","Improvement","utils",0.5,"Add 2-d version of cppIndex","""Add a 2-d version of cppindex to pybind11.h in utils in order to give better error messages when used on 2-d arrays.    Also fix the casting in the old cppIndex to avoid compiler warnings.    Note that this is pybind11-related so the work should branch from and merge to DM-8467"""
"DM-9013","Story","meas_mosaic",1,"Re-enable MKL/OpenBLAS","""Use of MKL/OpenBLAS was disabled (in commit {{6fe95ec}}) while adapting meas_mosaic to work with the LSST pipeline. It needs to be re-enabled so we're not limited to the slow matrix inversion using Eigen.    Reverting that single commit is sufficient to get the threaded matrix inversion:  """
"DM-9012","Story","SUIT",3,"Refactor FileInfo and FileData classes into one class","""We have 2 FileData classes and 1 FileInfo class which are all how information about a file.  Refactor these into one class - FileInfo."""
"DM-9011","Story","meas_extensions_simpleShape",0.5,"Make simpleShape less chatty","""simpleShape can be verbose due to throwing {{pex::exceptions::RuntimeError}}.  Throwing {{meas::base::MeasurementError}} would make it quieter."""
"DM-9041","Bug","meas_algorithms",2,"Make indexed reference loader agnostic to ingest name","""The indexed reference loader reads the dataset name out of the ingest config, but that's ridiculous because you need to give it the dataset name to find the config.  I'm removing the bit that loads the config and gets the name out of it, so that the loader will be agnostic to what name it was called at ingest time."""
"DM-9026","Bug","SUIT",1,"Firefly IPAC table reader should handle data type ""real""","""IRSA IPAC table reader handles real number as double. See detail in [http://irsa.ipac.caltech.edu/applications/DDGEN/Doc/ipac_tbl.html].    Firefly IPAC table reader currently treats real as char (data type show description) and String (the data type class). See the 4th column in the attached table.    It could be confirmed by saving the table after upload. The type for column 'V' chnaged form """"Real"""" to """"Char"""".    We need to follow IRSA'sIPACtable definition to treat real as double."""
"DM-9024","Story","Stack Documentation and UX",1,"Amend Python test naming guidelines in Developer Guide Following RFC-229","""Amend the Developer Guide to require that test modules be prefixed with {{test_}} to enable automatic pytest discovery:        See RFC-229."""
"DM-9060","Story","daf_persistence|obs_base",8,"Add metadata access to get wcs, visitInfo, and calib from a calexp dataset","""This is regarding the recent discussion in the science-pipelines room where there has been discussion about using composites to get components of a calexp.     In {{CameraMapper}}  we will add metadata readers with object constructors for wcs, calib, and visitInfo.    The API to get the components and entire calexp would be     {code:}  wcs = butler.get(calexp_wcs, dataId={})  calib = butler.get(calexp_calib, dataId={})  visitInfo = butler.get(calexp_visitInfo, dataId={})  calexp = butler.get(calexp, dataId={})  {code}    (note: we were originally going to use butler composites for this, but decided this is a better way to go)  """
"DM-9055","Story","obs_subaru|pipe_drivers",0.5,"DarkCombineTask broken","""DM-8913 changed {{DarkCombineTask}} to use {{VisitInfo}}, but this assumed that the {{combined}} variable is an {{Exposure}}, but it's actually a {{DecoratedImage}}.  That means we need to use a different means of getting the metadata in."""
"DM-9050","Story","meas_algorithms|pipe_tasks",5,"Add flags for sources used in astrometric and photometric calibration","""The PSF modeling tasks conveniently create and set flags indicating which sources were used to determine the PSF model.  The single-frame astrometric and photometric calibration tasks should do the same, indicating at least (for each procedure):   - Which sources were selected for potential matching.   - Which sources were actually matched.   - Which sources were actually used for calibration.    As we have done in PSF modeling, it would also be good to have the ability to reserve a set of candidate sources for validation purposes.    [~Parejkoj] and/or [~cmorrison] may have opinions on how this interacts with the new source selection stuff they've been working on."""
"DM-9049","Improvement","base",1,"Enable autolinking in Doxygen","""During review of DM-7891, [~jsick] said he intends for the final LSST documentation to link all mentions of API components, and requested that a style rule concerning manual links ({{@ref}}) be removed from the draft style guidelines. Without such a rule, however, current documentation will have no links at all.    Since it would be simpler to not introduce the rule now than to request/approve its removal later, the best solution is to enable Doxygen's autolinking, removing the need for {{@ref}} tags. This change should not cause compatibility problems for existing documentation that uses {{@ref}}."""
"DM-9045","Story","meas_modelfit",2,"Remove or revive bitrotted code in meas_modelfit","""meas_modelfit contains a lot of code that was used for FDR-era prototyping of modelfitting and has not been used since.  Some of this is worth keeping and reviving, because it's hard-won algorithmic code we may want to use in the future, while some of it should be removed.  In many cases, the unwanted code is being kept around because it's the only way the code we want is still tested; in other cases a small, easy-to-replace fraction of it is used by the bitrotted code we want to keep or code in active use (i.e. CModel).    This ticket is for cleaning up that mess.  Roughly, that means:   - Remove the custom table/record/catalog classes.   - Remove the custom CmdLineTasks.   - Remove the Sampler and Interpreter classes.    Some of this work may be best spawned done on other tickets, which should be linked here."""
"DM-9072","Story","SUIT",8,"Chart container tracking an active table in a table group","""Currently, ChartsContainer is only displaying the default chart viewer. In future, we want to add a tbl_group property and logic that ties a chart container to a given group.    When table group property is provided, the Chart Container would create a chart viewer for the given table group (if does not yet exist), and display the charts related to the active table in that table group.   """
"DM-9064","Story","afw",0.5,"Fix memory leak in SpanSets Persistence","""A schema used in the persistence layer of SpanSets needs to be marked as persistent or it causes a memory leak. Mark the schema as such."""
"DM-9081","Bug","afw",2,"testExposure.testGetWcs docstring is wrong, and tests should be assertIsNone","""The docstring for {{testExposure.testGetWcs}} does not match the implemented tests in the method, and at least some of those tests appear to be incorrect, given the current (SWIGed) behavior of {{lsst.afw.image.Wcs}}. I've listed several obvious problems below:    * The docstring claims exceptions should be raised, but none of the tests check for exceptions.  * In addition, {{exposure.getWcs()}} returns None if the exposure was initialized without a Wcs, not False. None is """"falsey"""", but if the API really wants None returned, we should test for that explicitly.  * The two unadorned {{getWcs()}} calls should have an {{assertEqual}} against self.wcs, since that's what those exposures were initialized with.  *  I also noticed testSetMembers, which catches a pex.Exception, prints a message, and then continues on its merry way. This should also be fixed.    This whole test suite needs to be looked at. That might be beyond scope for this ticket, but all of the above points are very worrying."""
"DM-9080","Bug","Firefly",2,"labels for tab were cutoff a little at the bottom","""The bottom of letter 'g' was cutoff in the labels.   See attached image."""
"DM-9076","Story","Firefly|IRSA",2,"Keep LS as only periodogram calculation option","""Update the periodogram panel option so is only reflect LS algorithm and keep as single option for now.   Others doesn't make sense with the current API and there won;t be time to make progress on that until March release."""
"DM-9098","Story","mariadb|mariadbclient|Qserv",1,"Update mariadb eups packages","""Experimentation with latest MariaDB containers shows indications of significant performance improvements.  We'd like to update MariaDB and client to latest versions before undertaking our upcoming qserv KPMs  """
"DM-9097","Story","Stack Documentation and UX",0.5,"Fix lsst-sphinx-bootstrap-theme deployment","""https://github.com/lsst-sqre/lsst-sphinx-bootstrap-theme is on PyPI, but the current v0.1.0 distribution is missing the {{templates/}} directory. Could have been human error in setting up the package, or a problem with wheels.    This ticket will fix the PyPI distribution, and possibly set up automated continuous delivery with Travis to PyPI."""
"DM-9096","Story","geom",0,"Wrap geom with pybind11","""Wrap package {{geom}} with pybind11 instead of Swig."""
"DM-9109","Story","pipe_analysis",5,"Create ellipticity residuals quiver plots","""Include ellipticity residual comparison and quiver plots in the analysis script, including:    *Intra-stack:*  scatter/histogram/sky plots for *psfUsed* stars of  > residual e1 & e2 ellipticities between the source and model psf at the position of the source (for both SDSS and HSM measurements), where:    > residual ellipticity, e, between source and model psf at source position quiver plot where:      *Inter-stack:*  scatter/histogram/sky comparison plots for;  > comparison of the trace radii of the sf models at the position of *psfUsed* stars matched between the two stack catalogs, where:  """
"DM-9105","Story","afw",2,"Make SpanSet operator templates more generic","""Expand the flatten and unflatten methods of SpanSets such that they can operate on multi-dimensional ndarrays. This work involves making the template parameters for these functions, and the getter classes more generic."""
"DM-9102","Story","SUIT",0.5,"Update the import package in LSSTFileGroupProcessor","""The FileInfo class was updated and moved to a new location.  It triggered LSSTFileGroupProcessor failing.  The LSSTFileGroupProcessor should be modified to import from the new location."""
"DM-9120","Bug","meas_algorithms",1,"matcherSourceSelector incorrectly uses nChild and footprints in isMultiple test.","""This bug was found by dm-square as a drop in match rms quality. The replacement for the SourceInfo class in matchOptimisticB.py has a test for isMultiple but this test was not used in the subsequent isGood or isUsable tests. The current implementation of the new matcherSourceSelector incorrectly uses this test and to parrot the performance of SourceInfo (which was the goal of DM-6824) this test should be removed. """
"DM-9113","Story","obs_decam",1,"the bias ingestion should not care about the filter ","""In the CP MaterCal bias products, the filter in the header can be anything.  Currently the ingest code updates the validity range for each filter, which can result in more than one bias at one time. """
"DM-9136","Story","Calibration Products Production|Design Documents",2,"Include CBP coordinate transformation system in LDM-151","""Per [LCR-581|https://docushare.lsstcorp.org/docushare/dsweb/Get/Version-37829/LCR-581CalibrationHardwareRequirementsUpdateApproved.pdf]:    {quote}  To be added to LSE-30 (OSS):    Beam Projector Coordinate Relationship    Specification: Coordinate system transformations shall be measured  and/or computed relating the collimated beam projector position and  telescope pupil position to the illumination position on the telescope  optical elements and focal plane, and a software interface shall be  developed to represent these relationships, including their possible  evolution in time.    Justification:    This is necessary to facilitate the data acquisition and reduction. The  user shall be able to specify an LSST pupil and focal plane position for  a given spot, then have the CBP and telescope offset accordingly.  Similarily, the spot positions should be predictable based on the CBP  and telescope position.    This requirement will need to be flowed down appropriately to the Data  Management and Observatory Control System requirements documents. It is  assumed that Data Management will develop a Python interface that  represents the relationships, and that the Observatory Control System  will use those in the construction of the control system functions  relating to the collimated beam projector.  {quote}    Note the requirements on DM above. These should be reflected in LDM-151."""
"DM-9135","Story","jointcal",2,"bulk rename of jointcal variables","""Jointcal currently uses very non-standard, non-stylistic, and/or non-helpful variable and method names (e.g. {{void FittedStar::SetRefStar(const RefStar *R)}}). I've been cleaning them up piecemeal as I go, but that results in confusing commits and can be a pain. The clang format package provides """"clang-rename"""" which might help take care of most/all of these in one foul swoop. Other suggestions are welcome (SublimeText's smart selection isn't quite smart enough, particularly for single-character variable names)."""
"DM-9131","Story","Design Documents",8,"Apply second round of Robert's LDM-151 comments","""Having applied Robert's first round of corrections, a second marked-up pdf with many few comments exists which should be applied during this iteration on LDM-151."""
"DM-9126","Story","lsstsw",0.5,"qserv_distrib does not setup qserv_testdata","""[~jammes] reported on slack that the {{qserv:dev}} container is unable to setup the {{qserv}}.    Demonstration of issue:        Expected result:        This appears to be caused by this changed commited on Dec 19th as part of DM-8256:    https://github.com/lsst/lsstsw/commit/49acd3e33364d0b4b67a7900d910fe121a0ac8fb  """
"DM-9165","Story","SUIT",3,"Add feature to overlay the searched position on the coverage image.","""The old firefly's API 'addCoveragePlot' will overlay the coverage image with the searched position given by the 'OverlayPosition' parameter.  This feature is missing from the new showCoverage function.  Also, catalog search results should also have the searched position overlaid as well.  Please confirm."""
"DM-9163","Bug","stack release",1,"newinstall.sh broken by conda package removal from public channels","""    """
"DM-9162","Story","Firefly|IRSA",1,"magnitude shoud be plotted in decrease order in period finding layout","""The preview phase folded curve in the period finding layout is showing the magnitude axis in increase order but it should be in decrease order as the result layout to be consistent."""
"DM-9196","Bug","Firefly",1,"cutout size parameter is not passed in the request by the download dialog","""The download dialog has an option 'cutout_size' but is not passed to the server.  Please fix.  """
"DM-9187","Story","jointcal",8,"port jointcal to pybind11","""Jointcal's python interface is currently SWIG-based. Now that most (all?) of the dependencies are converted, it's time to convert jointcal to pybind11."""
"DM-9186","Story","obs_subaru",2,"Create hscIsr.py script","""I have some unusual data (HSC pinhole filter images) for which I'd like to run only very basic Isr tasks (overscan subtraction and bias subtraction), which is tricky to manage with processCcd.py.  This ticket is to create a subaruIsr.py command line executable to accomplish this."""
"DM-9182","Story","afw",3,"Cleanup pybind11 code in afw","""Following the review of DM-9063, I've put together a list of fixes to make for most of afw and its dependencies, which I have attached to the ticket.  I have *not* looked at afw::table, as that will be reviewed and fixed independently on DM-8716.    First, a list of *generic* issues that weren't worth capturing on a file-by-file basis (though I did start by doing that).  This is essentially a checklist that should be used by all pybind11 cleanup issues:  - Move trivial Python extensions to C++.  - Use continueClass decorator in remaining Python files.  - Reorganize/rename files as per RFC.  - Address any TODOs  - Remove commented-out headers.  - Make sure pybind11 header is included first (because Python.h needs to be included first).  - Remove (or otherwise address) commented-out code  - Remove any use of ndarray/converters.h (redundant with ndarray/pybind11.h)  - Make sure all functions that should have kwargs do.  - Replace py::arg(""""foo"""") with """"foo""""_a (with using pybind11::literals)  - Make sure shared_ptr holder type is used for all but trivial classes  - Look for comment headings that are unused or disrupt readability  - Make sure {{py::is_operator}} is used on binary, non-in-place operators, and is not used anywhere else.  - Look for lambdas with non-const reference arguments; could they be const references?  - Look for getters that should be using reference_internal  - Remove spurious (empty) wrapper files.  - Determine whether enums are used as enums or integer constants, and adjust wrappers accordingly.  - Check for anonymous namespace and `static` usage.  - Check for worthless module docstrings.  - Define typedefs for py::class_ instantiations, or otherwise ensure they're not repeated.  - Don't use ::Ptr (here, or anywhere).  - Run clang-format?  Some of indentation is really terrible at definitely not conformant, and clang-format improves it.  - Delete trailing whitespace.    """
"DM-9166","Story","Qserv",5,"Help IN2P3 scientist to load stack processed data inside Qserv","""Help [~nchotard] to load LSST processed data inside Qserv.  """
"DM-9233","Story","afw",1,"Add default constructor to new Footprints","""Having a default constructor to Footprints would be useful in many cases. Add one which takes only a PeakSchema as a default argument, and creates a null SpanSet"""
"DM-9206","Story","SUIT",2,"Precision of expression columns","""This is a bug introduced by in DM-8367 line chart. The precision of the expression columns is not set when the values are saved to an IPAC table. When the table is read back and the first row happens to be 0.0, all values will be passed to the client with 1 decimal digit.    Test: load sample table, change y column to -count/time. Notice that all values in the point tooltip have 1 digit after decimal point and that highlighted points do not match the points on the line. (Highlighted values are calculated on client from the values of the table, plot points - on the server.)    https://github.com/Caltech-IPAC/firefly/pull/279"""
"DM-9254","Bug","Firefly",8,"Firefly is not working in Windows browser IE 11","""I've tested Firefly in Windows browser IE11 and it doesn't render.    We should try to figure out the issues first. Make new tickets for large bugs. """
"DM-9253","Story","Firefly|IRSA",8,"Prepare for IRSA Time series viewer release","""The story is to collect the ticket and track them in order to prepare and release Time Series viewer (old LC) in March.    Links to issues should be added.    The RC is expected to happen around mid February. """
"DM-9249","Story","meas_base",8,"Modify FlagHandler C++ and flagDecorator.py to make flag identification robust","""As discovered by DM-6561, the FlagHandler mechanism for connecting the enumeration of flags in C++ and the order in which the flags appear in the schema and internal FlagHandler structures is not robust.  Fix this, problem, so that the identifier used identify a particular flag and the lookup of the Flag Key are guaranteed to match.    Then fix the flagDecorator (it will be simpler) and all of the algorithms to match the new FlagHandler scheme."""
"DM-9245","Story","SUIT",1,"Replacing JS package manager npm with yarn","""Yarn is a new package manager for JS.  It increases performance and is more reliable.    You do need to install yarn. From your command prompt:  npm install yarn -g  Depending on where you install node, you may need sudo for this to work.  I've updated our docs to reflect this new requirement.    In order to get consistent installs across machines, yarn.lock is used.  If you updated package.json, you need to run yarn install to create a new yarn.lock file.  You must commit the new yarn.lock file with your updated package.json for build to work."""
"DM-9242","Story","QA",0.5,"squash KPM plots should label the time axis with a timezone","""At present, the KPM time series plots do not label the time axis with the timezone."""
"DM-9274","Story","SUIT",8,"Build Python doc using Sphinx","""Jonathon Sick has a boiler plate to bild docs for Numpy doc docstring.   This is a ticket to use that for SUIT Python doc build.  https://community.lsst.org/t/what-packages-have-numpydoc-docstrings-so-far/1612      Please add the cheat sheet for Python doc generation in https://confluence.lsstcorp.org/display/DM/Python+document+generation+cheat+sheet.    """
"DM-9261","Story","Developer Infrastructure",2,"Update git-lfs repositories to address deprecations.","""Update all git-lfs repositories to be compliant with current git-lfs best practices.    1. Remove {{batch = false}} configurations.  2. Ensure {{.lfsconfig}} files exist."""
"DM-9275","Story","obs_monocam",0.5,"Port obs_monocam to pybind11","""Port the obs_monocam package to pybind11    Note that obs_monocam is part of lsst_distrib"""
"DM-9298","Story","afw",0.5,"The stripMetadata argument of makeWcs doesn't work reliably","""The function {{afw::image::makeWcs(metadata, stripMetadata}} with its second argument true does not strip metadata if certain values are present because those values induce a deep copy of the metadata, and the keywords are stripped from the copy.  """
"DM-9294","Story","obs_decam",1,"makeCamera.py has undefined variables","""Function {{makeAmp}} in {{makeCamera.py}} has two undefined variables: {{nExtended}} and {{nOverclock}}."""
"DM-9327","Story","IRSA",2,"Create IFE app for Time series viewer","""Need a Time Series viewer app for IRSA, under IFE repository.    Please, create app with no logo (for now - for later probably we will need a new icon).    """
"DM-9326","Story","Firefly",1,"Clean up time series viewer","""Please, to be consistent with the new name of Time Series viewer:    - Rename {{lc.html}} to {{ts.html}} (Time Series replace Light-Curve)  - {{wise}} should be upper case    Thanks."""
"DM-9317","Story","SUIT",2,"Creates online help for SUIT","""Migrate Firefly's onlinehelp system so that it can be used by SUIT.  - created github repository: https://github.com/lsst/suit-onlinehelp/  - copy content from existing irsaviewer online help.  - change build/config script for SUIT.  - setup build/install environment for pdac    To build and install online help on pdac:  - log into sui-tomcat01  - switch to suiadmin  - source /hydra/cm/env/env.sh  - cd /hydra/cm/suit-onlinehelp  - git pull  - gradle install"""
"DM-9314","Story","Continuous Integration|stack release",0.5,"weekly tag/release build of w_2017_6 failed: flask","""The new flask is not building on master and this is causing the weekly tag/release build to fail. It looks like this is being triggered by DM-9268."""
"DM-9313","Improvement","obs_decam",0.5,"obs_decam should not call stripWcsKeywords","""{{DecamMapper}} presently calls {{stripWcsKeywords}} in several places. This function is not part of afw's public interface (it is in namespace {{lsst::afw::image::detail}} and the call is unnecessary because {{makeWcs}} will strip the metadata if told to do so (by setting the second argument true).    Fixing this will help the pybind11 conversion effort because the pybind11 wrapped version of afw does not make {{stripWcsKeywords}} available, and we'd rather not change that."""
"DM-9301","Story","L1 Database",8,"Implement parallel processing in L1DB prototype","""Next step in understanding alert production performance is to see if paralellising processing can help with reducing database access overhead."""
"DM-9350","Improvement","SUIT",2,"Possible to provide a drawing of the Stripe 82 sky region for context?","""I am wondering if it would be straightforward to provide a """"footprint"""" outline of the Stripe 82 area on the sky for use in highly zoomed-out context images in PDAC.    If this is an easy task, in what format would we need to specify the coordinates of the online?    I think we can do a calculation of four corners of all the coadded images and produce a sd9 region file for the outline.       ==============================================    How to generate the region files attached here:    1)Get four corners data for all the coadds FOVs for SDSS:  curl -o sdssFourCorners.json -d 'query=SELECT+corner1Ra,corner1Decl,corner2Ra,corner2Decl,corner3Ra,corner3Decl,corner4Ra,corner4Decl+FROM+sdss_stripe82_00.DeepCoadd;' http://lsst-qserv-dax01.ncsa.illinois.edu:5000/db/v0/tap/sync  2)Convert the json file to csv using a tool on line:  http://www.convertcsv.com/json-to-csv.htm  3)Sort the csv file by corner1Ra  4)Remove """"^M""""  5)Convert the csv file to a region file by adding """"polygon("""" and  """") #color=green"""" and a header """"fk5""""  6)For only plot 1% or 10% FOVs:  awk 'NR == 1 || NR % 100 == 0' input.reg > output_1pct.reg  awk 'NR == 1 || NR % 10 == 0' input.reg > output_10pct.reg    The region file can be loaded to Firefly."""
"DM-9349","Bug","Firefly",2,"Filtering selected row (ROWID filter) gives wrong results (dev version)","""In Firfefly (+IRSAVIewer) development version, when the user select table rows and filter them out, the result table is not matching the selected rows before applying the filter.  OPS is fine though.    Step to reproduce:  do a catalog search i.e., 2mass, 100"""". From the result table, select a row and apply filter. Then check that the resulting row is not the one you selected.    TG 02/10/2017 The row returned is actually the previous row.   The related issue is filtering a point from an image. A previous row is returned as a result. """
"DM-9348","Story","SUIT",8,"LSST - time series viewer results (part 2, UI work)","""This is the second part of changes to support LSST time series, which should handle band selection in UI.    We need to support mission specific input, from which the x and y columns and automatic filtering of the raw table depending on the input parameters (band selection).    https://github.com/Caltech-IPAC/firefly/pull/313    Attached to this ticket, please find the sample LSST multi-band table for object id 2990683841366709."""
"DM-9346","Story","Firefly",2,"label change requests for Firefly/IRSA viewer","""The following change will be in Firefly:  * histogram  Y axis label: Number  * Charts scatter/histogram option dialog, """"search"""" button:  """"OK""""  * Choose columns dialog """"Set column or expression"""" button:  """"OK""""    The following changes will be in IRSA Viewer:  """
"DM-9342","Story","Firefly",8,"histogram option update (input dialog and server support)","""For uniform binning (fixed bin size), there are two different ways to give the input:  1. number of bins (the current option only)  OR  2. bin width    Label may needs to be changed as well.    [March-2-2017]  To have a choice of the number of bins or bin width, two radio buttons and one text box are added.  By default, the number of bins is selected.  When the radio button is selected, a new value either number of bins or bin width should be entered and validated.   Then the histogram will be updated accordingly. Since no data range information is available before sending the request, the bin width can not be validated correction.  Thus, an exception is thrown if the bin width is large than the data range.     [March-16-17]  Based on the modified requirements, the UI is  # Add two radio buttons and two input text boxes next to the two radio buttons, one of which is number of bins and the other is bin width.  #  Add two input text boxes below the two set radio/text boxes.  One of which is for min and the other is max    After several discussions and iterations, we added the following:  # For single column histogram, since the data min/max is stored in the column variable array, they can be used to pre-fill the min and max.  # The bin width is calculated based on the number of bins and min and max and then the bin width is pre-filled.  # The bin width is recalculated each time when number of bins or min or max changes.  # When number of bin is selected, the bin width text box is disabled, when the bin width is selected, number of bins text box is disabled    """
"DM-9336","Story","Systems Engineering",2,"Complete LCR-836 (typographic correction to LSE-69)","""LCR-836 (already created) is for a long-pending typographic correction to LSE-69 to get it to match LSE-130's section headings.    The work on this ticket is to prepare the new docgen and submit it to the CCB. """
"DM-9334","Story","obs_monocam",1,"monocamIngestImages.py is vestigial","""obs_monocam provides a [{{monocamIngestImages.py}}|https://github.com/lsst/obs_monocam/blob/786219475ffd0e022c98234d5b00a5c30ca668c5/bin.src/monocamIngestImages.py] which attempts to import {{lsst.obs.monocam.ingest.MonocamIngestTask}}. {{MonocamIngestTask}} [was removed in {{7862194}}|https://github.com/lsst/obs_monocam/commit/786219475ffd0e022c98234d5b00a5c30ca668c5#diff-16d2f190c33eaa0d3ef05279458bd775L95]. I conclude that {{monocamIngestImages.py}} is a confusing remnant which should be removed."""
"DM-9371","Story","SUIT",2,"Display image cutout in LSST PDAC","""We need to provide option to display the image cutout, using DAX API."""
"DM-9364","Bug","obs_base",2,"wcs creation is mandatory","""Line 1044 of cameraMapper.py tries to attach a wcs, and crashes if the necessary keywords are not found in the metadata, and this shouldn't be the case.    One could replace this with a try block to give every exposure a dummy wcs, but this is probably not the correct course of action - on failure the wcs should _probably_ just not be set, to allow a None wcs to exist.    Whatever the fix, this should log a warning."""
"DM-9363","Story","obs_ctio0m9",8,"Construct obs package for 0.9m at CTIO","""Data from the 0.9m telescope at CTIO is being used to prototype the processing pipeline for the Calibration Telescope. In order to ingest it into the stack, we'll need an appropriate obs package (""""obs_ctio0m9""""). Please create one."""
"DM-9361","Story","Design Documents",2,"Update Calib Telescope data processing section in LDM-151","""Based on the input provided by [~aguyonnet] in DM-9356, update LDM-151 to provide a complete description of the plans for processing data from the Calibration Telescope."""
"DM-9359","Bug","Firefly",1,"Restoring coverage image after cropping it shows an empty tab entitled 'FITS data'","""I've found a something wierd after doing a catalog search and i think is not expected.    When doing a catalog search, the result tri-view shows image, table and xy-plot.  The image is called 'Coverage'.   Using the selection tool and cropping part of the image, the result is a smaller image which is correct.    Then when trying to go back and restore to default image (click the """"Restore"""" button on the toolbar), the result is 2 tabs, one with the coverage restored correctly and another one called 'FITS data' empty and active.    I think the second tab shouldn't be displayed.  """
"DM-9358","Bug","pipe_tasks",3,"Fix setting of calib_psf_candidate flag to match docstring description","""The docstring for {{calib_psf_candidate}} reads:    However, if the reserve fraction is set to a non-zero value, an object that was selected as a PSF candidate by the star selector but then flagged as reserved will have the {{calib_psf_candidate}} flag set to *False*. This is inconsistent with the docstring (and erroneously implies the object was not deemed a suitable candidate). Please update the setting of the flag to reflect its docstring description."""
"DM-9356","Story","Design Documents",2,"Summarize plans & questions for Calib Telescope work","""Summarize the plans for processing data from the Calibration Telescope and any open questions that remain about the approach to be taken in bullet-point form. Provide them to [~mfisherlevine] for incorporation into LDM-151."""
"DM-9353","Story","obs_subaru",0.5,"Update configuration for HSC calib construction","""DM-9186 changed how the ISR configuration is set, but the configuration for calib construction wasn't updated to match."""
"DM-9394","Story","lsst_distrib|meas_extensions_convolved",1,"Add meas_extensions_convolved to lsst_distrib","""This package is in active use and should benefit from regular CI. Adding it to lsst_distrib will require an RFC."""
"DM-9387","Story","Continuous Integration|Developer Infrastructure",3,"lsst_build git fetch/clone retrying","""We occasionally observe a """"wave"""" of github fetch/clone failures from {{lsstsw / lsst_build}} in the jenkins env. Where a wave is several random failures over the course of a day or two and then there are no failures for weeks.  I am convinced that these are on the github end as I have experienced clone failures when running {{lsstsw}} outside the the jenkins env.    I am loath to retry the entire jenkins build upon any failure as this might result in a legitimate build failure unnecessarily tying up build slaves.  There are two  solutions that occur to me:    1) propagate errors up from {{lsst_build}} in such a way that the CI driver can determine the reason of failure and retry a set of failure modes    2) add git fetch/clone retrying support into {{lsst_build}}    I am leaning towards #2 as the implementation is straight forward and contained within a single component."""
"DM-9386","Bug","SUIT",2,"IpacTableIpacTableFromSource returns one row less if there is no terminating new line in the table","""IpacTableFromSource processor does not return the last row of the attached table. (This table does not have the newline after the last row.)     To test, put the attached a.tbl to /hydra/workarea/firefly/temp_files and the attached test.html into /hydra/server/tomcat/webapps/firefly/demo. Use http://localhost:8080/firefly/demo/test.html to see the table.   - Notice the number of rows is 157, the last row seems to be lost.   - Sort on any column. Notice the number of rows is 158.    We noticed this problem in LC phase folded table (the one that is being uploaded to the server). The attached file is a copy of the uploaded phase-folded table."""
"DM-9384","Improvement","afw",0.5,"Fix wrapped constructor for StatisticsControl","""The constructor for {{lsst::afw::math::StatisticsControl}} has some arguments with default values, but the pybind11 wrapper omits them and only provides a default constructor. This breaks some existing code. I propose to wrap the constructor as written (which will be quite pleasant to use with named arguments) rather than fix the existing Python code that relies on being able to specify arguments to the constructor."""
"DM-9383","Story","pipe_tasks",3,"Investigate propagation of visit flags for certain patches in HSC RC processing","""For certain diagnostics plots, it is useful to select on specific subsets of the data.  An example subset would be the objects that were used actually in the PSF modeling, i.e. those with flag *calib_psfUsed=True*.  When plotting this subset for the coadds of the LSST stack processing of the HSC RC dataset (DM-6816), a large number of patches have no objects for which this flag is set.  While the list is not expected to be identical to the list from the visit processing (the flag is propagated based on the fraction of visits overlapping that object and contributing to the coadd that had the flag set for said object), ending up with a list of zero objects used for PSF modeling should be very unlikely.  The pattern is quite delineated, with sharp truncation lines beyond which no objects used in PSF modeling are found:    !plot-t0-HSC-I-footNpix_calib_psfUsed-sky-stars_LSST.png|width=500!    Of note, this does not happen for the same dataset processed through the HSC 4.0.5 stack (DM-9028):    !plot-t0-HSC-I-footNpix_calib_psfUsed-sky-stars_HSC.png|width=500!"""
"DM-9382","Story","Firefly|IRSA|SUIT",2,"Phase folded table content fix","""fix Phase folded table created  for time series viewer (DM-8670)   - fix the time column value (mjd) on the expanded cycle part. (the phase folded table is made to contain the data rows for two phase cycles): the value of 'mjd' column in the expanded part is duplicated from the original raw table.   - make the creation of phase folded to be derived from full set of raw table, not just partial raw table shown on the page.    """
"DM-9381","Story","pipe_analysis",2,"Add ability to highlight data subsets in analysis plots","""Highlighting objects based on a """"third"""" parameter, e.g. a flag setting, (other than spatial, for which we are already producing diagnostic figures) can be very useful in diagnosing pathologies (see, e.g. DM-9252).  This ticket is to add this ability to the analysis plotting scripts."""
"DM-9379","Story","lsstsw",0.5,"Changes to lsstsw to rename ctrl_events package to legacy-ctrl_events","""This work removes:    from {{etc/repos.yaml}}    and moves the repo to  """
"DM-9416","Story","jointcal",1,"Cleanup dead read/write StarList c++ code","""While converting to use lsst::log in DM-8547, I started cleaning up all of the dead read/write code for StarLists. Since we're using LSST catalogs and refcats now, we shouldn't need it for anything, and we'll eventually be able to interrogate those lists from python (once we deal with DM-4043), if such functionality is desired.    I'm filing this as a separate ticket so it doesn't clutter DM-8547 with a bunch of deleted lines."""
"DM-9400","Story","obs_ts3",8,"Construct obs package for test stand 3","""Create an obs package that provides basic access to data from test stand 3 (ie, individual CCDs). This should include loading the data from disk and providing all the standard LSST functionality, but does not need to integrate with Camera Team systems (e.g. you don't need to ingest metadata directly from eTraveller, or similar)."""
"DM-9439","Story","base",0.5,"Package version checking is non-deterministic","""When a command-line task runs, it [writes the versions of packages currently set up to the repository|https://github.com/lsst/pipe_base/blob/54f122d8ff9696ff2b1de8f72d33eff08773e0a3/python/lsst/pipe/base/cmdLineTask.py#L285]. We're then [unable to run the same task again without matching versions|https://github.com/lsst/pipe_base/blob/54f122d8ff9696ff2b1de8f72d33eff08773e0a3/python/lsst/pipe/base/cmdLineTask.py#L614]. This helps with reproducibility.    However, when I repeatedly try to run the same task with exactly the same task with exactly the same packages set up, this version checking fails intermittently. The task exits, complaining:        Note that the versions *are* the same, but are being reported in a different order ({{12.1-17-g13cfda1+6 with boost=1.60.lsst1+1 eigen=3.2.5.lsst2}} as compared to {{12.1-17-g13cfda1+6 with eigen=3.2.5.lsst2 boost=1.60.lsst1+1}}).    Please fix this so that version checking works reliably."""
"DM-9438","Story","ci_hsc|obs_subaru",1,"Switch default reference catalog for HSC to PS1 in LSST format","""With the availability of PS1 and Gaia catalogs in the LSST format, we can remove our dependence on astrometry.net.  This involves changing configuration files to use the PS1 catalog in LSST format and disable the use of astrometry.net."""
"DM-9437","Story","Continuous Integration",3,"automate jenkins workspace cleanup","""All jenkins jobs that use {{lsstsw}} consume couscous amounts of disk space and require periodic manual workspace purging.  This should either be moved to a jenkins plugin or an automated script."""
"DM-9434","Story","cat",1,"Fix database creation error in testTimeFuncs.py","""An error is occurring in testTimeFuncs.py:        The error is occurring because users don't have database creation permissions to create    databases.    This only occurs on machines in the ncsa.illinois.edu domain, because the test is skipped if not run on that domain."""
"DM-9433","Bug","afw",0.5,"ds9.py error code not working as intended","""The following code in afw's display/ds9.py appears to not function as intended:      To see this run examples/estimateBackground.py with display_ds9 not set up. What I see is:      I confess to some surprise. I am not an expert on Python's binding rules, but I expected the code to work."""
"DM-9429","Story","lsst_dm_stack_demo",0.5,"Update lsst_dm_stack_demo for pybind11","""Update lsst_dm_stack_demo for pybind11 and fix anything needed in the dependent packages"""
"DM-9428","Story","pex_exceptions",1,"Update exceptions tutorial-level documentation for pybind11","""pex_exceptions contains a tutorial in Doxygen that includes Swig-specific instructions for making sure C++ exceptions are propagated correctly to C++.  This should be updated."""
"DM-9423","Story","meas_mosaic|obs_subaru",0.5,"Port HSC patch to allow multiple filters in mosaic","""[HSC-1398|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1398] allows multiple filters to be used in the mosaic solution.  This is helpful because there are multiple r-band and i-band filters, and it's helpful to combine them.    I'll also update the {{MosaicTask}} to allow use of the new LSST format reference catalogs."""
"DM-9465","Story","SUIT",1,"bug in utility class method objetArrayToJsonSring for Projection unit test ","""The bug is FitsHeaderToJson which is a utility class for Projection's unit test.  It is under java/test.  It has nothing to do with java/src.    Bug description:    The objetArrayToJsonSring converts a 2-dimension or 1-dimension array to a Json string.  When it does the conversion, it shares a listObject and this object is cleared after each use.  How since this list is added to another 2-dimension list, the values added in the 2-dimension were accidentally reset to 0.0.    This bug was introduced when create unit test for Projection.  But this bug does not affect the Projection's unit test since the array values are not relevant to the Projection and were not used.    Analysis:  The FitsHeaderToJson was created to produce the testing files for Projection.  Since now there is util/ package under test.  This file should move to util/ directory."""
"DM-9464","Story","Stack Documentation and UX",1,"Link SublimeText clang-format setup instructions in docs","""The current [clang-format docs|https://developer.lsst.io/tools/clang_format.html] link to setup instructions for vim and emacs, but not SublimeText. We should have a similar link on that page to how to integrate clang-format (including the best choice of Sublime package for it) with SublimeText."""
"DM-9462","Story","sconsUtils",0.5,"Allow disabling adding underscores to pybind11 library names","""Our final pybind11 coding conventions dictate that the wrapper library name should match the source code name. However, all of our existing pybind11 wrappers assume that the library name will always start with an underscore (whether the source file name does or not).    I will add a new flag {{addUnderscore=True}} to the {{pybind11}} function. New code should specify this flag as False. Old code will continue to work unchanged."""
"DM-9457","Story","meas_algorithms",2,"test failure due to esutil/numpy problem","""I'm seeing a test failure in meas_algorithms due to what looks like a failure of {{esutil}} compiled code to import the NumPy C API:      This is Python 3.6 and Numpy 1.12, so it's likely I'm seeing the problem because I'm pushing to newer versions than anyone else."""
"DM-9456","Story","SUIT",0,"Rename FileLoader in test/util to UnitTestDataIO","""While working on ImageHeaderTest, I found there are some methods can be utility methods.  To add those methods there, the FileLoader is no longer meaningful.  I rename it as UnitTestDataIO which contains all kind I/O including file, json file etc."""
"DM-9495","Story","jointcal",1,"Fix all jointcal header multiple-inclusion #defines","""As pointed out in another review by [~krzys], jointcal isn't following the {{#define LSST_BLAH}} standard for multiple inclusion prevention in its header files. Should fix this with a quick pass over the current headers. Might also be a good time to look over the existing headers and see if any can disappear or be merged elsewhere."""
"DM-9490","Story","SUIT",8,"Remote api issues","""Do the following:  * make point selection work if extension is added before image * point selection is not always showing point * mask is not working when zoom is quickly changed before new mask is added * make table active row table extension * remotely turning on target match """
"DM-9476","Story","obs_subaru",1,"ISR fails in overscan for HSC visit=90738 ccd=33",""""""
"DM-9474","Story","Developer Infrastructure",0.5,"validate_drp example/runDecamTest.sh broken on decam dataset","""The {{validate_drp decam}} dataset was working in a test env several days ago.  This dataset was added to the production {{validate_drp}} yesterday and is failing.  It is also failing in the {{validate_drp hsc}} test env.      """
"DM-9472","Bug","Stack Documentation and UX",0.5,"Update pipelines.lsst.io installation docs for 12.1 release","""bq. [somebody] installing the stack following the Conda instructions at pipelines.lsst.io is actually getting v12.1, rather than 12.0?    bq. If so, we have a docs problem since https://pipelines.lsst.io/install/demo.html is pointing them at the lsst_dm_stack_demo for 12.0. And so it fails."""
"DM-9505","Story","ndarray|Stack Documentation and UX",1,"Please serve the ndarray tutorial somewhere","""At one time the ndarray tutorial was part of the Doxygen documentation, but that is no longer the case. It really should be served somewhere -- preferably linked from the docs that are already on github."""
"DM-9504","Story","afw|meas_extensions_ngmix",2,"lsst_py3 CI failure due to meas_extensions_ngmix","""[~npease] points out that the lsst_py3 Jenkins build is currently failing and has been since [build #454|https://ci.lsst.codes/job/stack-os-matrix/label=centos-7,python=py3/21317/console] (regardless of the misleading red circles on Jenkins). Reported error is:    """
"DM-9503","Bug","afw",1,"afw catalog asAstropy fails due to multiple columns of same name","""When using {{catalog.asAstropy()}}, we experience an error when converting certain tables:    """
"DM-9502","Bug","afw",1,"SpherePoint throws wrong exception for invalid arguments","""Several methods in {{SpherePoint}} throw {{pex::exceptions::OutOfRangeError}} when fed invalid arguments. Assuming the pex exceptions are intended to mimic the standard C++ exceptions of the same name (see DM-9435), this is inappropriate -- {{OutOfRangeError}} should refer to invalid indices, not other cases where an argument falls outside some interval.    These methods should be changed to throw either {{pex::exceptions::DomainError}} or {{pex::exceptions::InvalidParameterError}}, which apply to generic numerical arguments."""
"DM-9500","Bug","SUIT",3,"FitsDownloadDialog.js has bugs","""The FitsDownloadDialog only works for NO_BAND.  When a 3-color image is created, it has the following issues:    # it only shows a """"red"""" color band  # Saving file does not work  because the null FITS file name is in the URL  # It does throws the exception, for example, saving a 2mass 3-color image, the exception is:    """"GET http://localhost:8080/firefly//servlet/Download?file=null&return=twomass-j.fits&log=true 404 (Not Found)  download @ WebUtil.js:274  resultsSuccess @ FitsDownloadDialog.jsx:356  onSuccess @ FitsDownloadDialog.jsx:282  validUpdate @ CompleteButton.jsx:25  (anonymous) @ CompleteButton.jsx:34""""    1. when its s a color image,  all 3 bands should be available for FITS download  2. for PNG and region file, there i son need for band choice  3. the title of the dialog should be """"File Download"""", not """"Fits download""""  """
"DM-9531","Story","afw",0.5,"Fix override warnings in afw","""Compiling afw on modern clang results in this warning:    Please fix by marking the method {{override}}"""
"DM-9528","Story","meas_deblender",1,"Cleanup pybind11 code in meas_deblender","""Use the checklist from DM-9182 to clean up code in meas_deblender."""
"DM-9524","Story","Developer Infrastructure",2,"mangle OSX EUPS tarball shebang paths","""A method of mangling the shebangs on OSX to a valid path is needed."""
"DM-9518","Story","lsstsw",0.5,"Move activemq packages to legacy status","""With the move of ctrl_events to legacy status the activemqcpp and ctrl_activemq packages is no longer in use,      Moving lsst/activemqpp to lsst-dm/legacy-activemqcpp  (this is a move and a change in etc/repos.yaml)    and    Moving lsst/ctrl_activemq to lsst-dm/legacy-ctrl_activemq (this is just a move)"""
"DM-9517","Story","meas_algorithms",1,"Migrate meas_algorithms to modern afwDisplay","""meas_algorithms contains several (e.g. [#1|https://github.com/lsst/meas_algorithms/blob/0bf8251ccb5c79be6e181817359729fdb2425311/python/lsst/meas/algorithms/objectSizeStarSelector.py#L43], [#2|https://github.com/lsst/meas_algorithms/blob/d421edbfcf2fc993cbad9211c1498767479d069a/python/lsst/meas/algorithms/pcaPsfDeterminer.py#L35], there are more) explicit uses of {{lsst.afw.display.ds9}}. These should be replaced by calls to the generic (backend-independent) {{lsst.afw.display}} system."""
"DM-9543","Bug","Firefly",1,"calling showXYPlot API without xcol/ycol name fails","""The API call 'showXYPlot' fails when xCol, yCol is not specified.    Before migration, the function was used without specifying the column name, the xy plot was plotting the first 2 numerical columns if no column is passed in.  That is no longer the case, the function seems to be missing. If not, then documentation should be updated on how to call the same function as before.    Please check and fix."""
"DM-9539","Epic","jointcal|Validation",20,"jointcal validation framework integration (continued from S17)","""Jointcal will be the testbed for the new metrics validation system. This epic captures the work on the jointcal side, including integrating jointcal's output into the system, and writing user documentation to allow others to plug their products into validation."""
"DM-9535","Story","ip_isr|obs_subaru",5,"Assess whether differences in Brighter-Fatter implementations are contributing to the trace radii differences: LSST vs. HSC","""As noted in DM-6817 and highlighted/further explored in DM-9411, there is a trend of increasing difference in trace radii with increasing magnitude when directly comparing outputs from the HSC vs. LSST stacks.  A likely culprit is slight differences in the implementations of the Brighter-Fatter corrections between the stacks.  This ticket is to assess whether this is contributing to the trace radii differences."""
"DM-9534","Story","jointcal|Validation",5,"Output jointcal metrics via a metrics logger","""Until we have butler metrics persistence system, we can use a dedicated logger to output each product's metrics. Since jointcal is the testbed for the new metrics system, we'll use it as an example for how to produce those logs."""
"DM-9556","Bug","meas_base|meas_extensions_convolved|meas_extensions_photometryKron|meas_modelfit|pipe_tasks",1,"All NaNs in coord_ra and coord_dec columns in deepCoadd forced src tables","""In recent runs of the stack through *multiBandDriver.py*, the persisted forced src tables for the coadds are not getting ra and dec set properly (all entries for the {{coord_ra}} and {{coord_dec}} columns are NaN).  Looking back at a run in mid-Nov, 2016, these numbers were indeed set properly in the forced tables.  Assuming this was not intentional, track down the cause and fix it such that these values get set properly for the persisted forced src tables."""
"DM-9553","Story","ip_isr",1,"Investigate the best algorithm to compute derivatives for the Brighter-Fatter correction","""As noted in DM-9535, the method used to compute second derivatives in the Brighter-Fatter correction implementation can lead to significant (up to 1%, which is particularly significant for weak lensing considerations) differences in the trace radii of sources, with the differences becoming larger with brighter magnitudes (see figures in DM-9535).  This ticket is to investigate the optimal algorithm to use for the Brighter-Fatter correction."""
"DM-9552","Bug","SUIT",2,"Reported mouse position on mouse click is a couple of pixels off","""1. The symbol was drawn a few pixels off the center of the mouse when """"lock by click"""" checkbox is selected.   2. Other drawing functions, like distance tool, the area selection tool are also affected.   """
"DM-9549","Story","ctrl_stats",3,"ctrl_stats fails on mac os","""The Linux build for ctrl_stats succeeds, but the mac OS X build for ctrl_stats fails in the tests/testYearWrap.py.    Additionally, a change in Python 3.6:    now makes some code in terminated.py fail (and possibly in other places)."""
"DM-9564","Story","ip_diffim|pipe_tasks",2,"Set assembled Coadd Psf to modelPsf with auto-computed dimensions ","""DM-8088 changed makeCoaddTempExp so that the user no longer has to specify the pixel dimensions of the model PSF to match to. The model Psf dimensions are updated at runtime to match those of the warped calexp PSFs (which have dimensions impossible for a user to know ahead of time).     AssembleCoadd currently attaches the PSF corresponding to the *user-specified model PSF* dimensions rather than the updated PSF-dimensions.  This is bad because the user-specified dimensions could be way off and it's incongruous to tell users that they don't have to pay attention to this in makeCoaddTempExp, but they do in assembleCoadd.     This ticket will ensure that the modelPsf dimension information flows down from the coaddTempExps to the assembled deeepCoadd in a sensible way. Most likely using the maximum dimensions of the input coaddTempExps.    """
"DM-9561","Story","meas_deblender",8,"Improve Monotonicity Operator","""Preliminary testing of the NMF deblender shows that the radial monotonicity operator as designed does not work as expected. [~pmelchior] and I have verified that the monotonicity operator itself is built properly based on our earlier design, which uses a single reference pixel (the one that lies closest to a radial line from the peak to the current pixel) for each pixel.    Based on a pixels position from the peak, it lies in one of 8 octants that determines which pixel it will use as a reference, but it appears that the transition between reference pixel positions is causing the monotonicity operator to generate weird streaks in the deblended objects that are unphysical.    We are redesigning the monotonicity operator to use the weight of all three neighboring pixels that are closer to the peak as a reference, which we hope will fix this issue."""
"DM-9581","Bug","Firefly",2,"MSX image rotation not computed correctly.","""Update From Trey - 2/28:    This problem has nothing to do with WCS match.  It is a problem with rotation of MSX images. They are galactic based which confuses our computation.  To reproduce: Read in MSX image with target m16 and the rotate 180.  The problem is obvious. In this case the relative rotation is computed wrong. The problem begins at FitsRead.createFitsReadRotated.     ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++  ORIGINAL TITLE:  WCS match behavior is odd    ORIGINAL DECRIPTION:  Luisa reported 10 days ago on TT (#9353) on the OPS version of Firefly/IRSAViewer:    WCS align works in some odd ways in IRSA Viewer when MSX images are included; it doesn't actually align the MSX image to other images properly. If you align to MSX images, though, it works fine.  I wonder if whatever is going on is somehow tied to the galactic coordinates that the MSX tile should have, though of course the tool should only be paying attention to RA/Dec.    Step to reproduce:  OS 10.11.6  Firefox 51.0.1    search on M16, WISE ch1 (default), default size.  again, new image, MSX A band (default), all other defaults  again, new image, DSS poss2uk red (default), all other defaults.    It returns three images of the sky.  physically what is going on here is that the wise image and the DSS image that are returned should already have north up. the MSX image, however, is in galactic coordinates by default but carries the RA/Dec with it, of course. I just mean the tile is aligned with galactic coordinates by default.    At this point, the DSS image should be selected (e.g., outlined in orange).  click WCS match.  WISE doesnt change, but MSX rotates about 45 degrees. (see first attachment.) here the features in the WISE and POSS images are aligned, so they physically make sense. The MSX one isnt right.  Click on the MSX image so that it is outlined in orange.  click on WCS match to turn it off. All three images move slightly for me but dont change orientation.  click on WCS match to turn it on. Now all three images are rotated.  (see second attachment.)  the MSX image didnt change, but the nebulosity is now aligned properly, so this is really the correct alignment (though note that North isn't up anymore). The tool knows North isn't up; coordinates overlaid and a compass rose overlaid are aligned properly.     (From TT9353)    [March-1-2017 LZ]  I reproduced the bug according to Trey's instruction.  I checked the codes where the rotation is calculated and found that the rotation coordinate somehow is predefined as CoordinateSys.EQ_J2000.  Thus, if the image is not in CoordinateSys.EQ_J2000, the calculation is wrong.  My suggestion is to use the incoming coordinate instead.      """
"DM-9579","Bug","pipe_tasks",1,"nondeterministic random number seeds in MeasurePsf candidate reservation","""{{MeasurePsfTask}} randomly reserves a fraction of its candidates for validation, in a way that is supposed to be deterministic.  This seems to be broken; I've identified at least two problems:   - {{CharacterizeImageTask}} does not pass the {{expId}} argument to {{MeasurePsfTask.run}}, letting it default to zero.   - {{MeasurePsfTask}} uses Python's built-in {{random}} module instead of {{afw.math.Random}}.  Contrary to its own documentation, calling {{random.seed(0)}} does not always produce deterministic results (though I've only been able to trigger this the first time I tried it):      I have no idea what could be going on in the built-in {{random}} module (and it's hard to report upstream since I was only able to trigger it once), but we should switch to our own random number generator regardless."""
"DM-9578","Bug","SUIT",1,"warning message does not disappear even with valid data if the mouse is covering the warning icon","""if user enters invalid data and keeps his mouse over the warning icon while entering valid data into a field then the warning message does not disappear even with valid data. It stays up for the life time of the firefly webapp.    """
"DM-9594","Bug","SUIT",1,"The default radio button (point)  in scatter plot  is not selected after line style changes.","""Steps to reproduce:  - switch between different styles  - reset to default  - the selected radio button but shown.    Emmanuel reported that the default radio button is no longer selected after the line style changes.  I tested in the DM-9343 and saw it.  Then I tested it in the dev and saw it there as well.  It seems an existing problem.      [March-8-2017]  When the setOption is called by clicking reset button, the defaultParams which contains only x and y is passed to the setOption.  Since the plotStyle is not in the defaultParams, its default value is used.  How the default value never triggers the listener.  To fix it, the plotStyle was added to the default parameter.  Thus, the plotStyle is stayed after resetting the other fields.    [March-10-2017]  According to Tatiana, each plot has a set of default values.   When the reset button is pressed, the option parameters should be back to the default.  Therefore, the above implementation is against the design.     Tatiana did research and found out that the there was an implementation issue in RadioGroupInputView, see http://react.tips/radio-buttons-in-reactjs/.  The  RadioGroupInputView became an uncontrolled component when the """"name"""" is used  along with value and check fields. The uncontrolled component can not be handled by the React Component.   Thus, the checked=true is not  displayed.     To fix this issue:  # Remove the name attribute from the """"input"""" tag   # Since the fieldKey is not needed, fieldKey is remove as well.       """
"DM-9590","Bug","Firefly",8,"XY plot is unrecoverable after it fails because of column name doesn't exist","""Sometimes, Gator or LC viewer shows an xy plot by settings xCol, yCol which doesn't exist in the table.   That produce an exception and plot is not displayed, error message with the java exception is shown (*at least message should be user-friendly and not code oriented*).    From there, there is no way to recover the plot, even if the user change the column name to an existing one, it won't respond and display any data.  """
"DM-9588","Story","QA",1,"validate_drp broken on cfht/hsc datasets","""{{validate_drp}} has been failing since the 22nd. This is suspiciously coincidental with the merger of https://github.com/lsst-sqre/jenkins-dm-jobs/pull/58 .  The first build failure appears to be shell script related but the most recent failures for both the {{cfht}} and {{hsc}} data set look like they may be the result of a change in the stack.    *HSC*    https://ci.lsst.codes/job/validate_drp/835/dataset=hsc,label=centos-7,python=py2/console        *CFHT*    https://ci.lsst.codes/job/validate_drp/835/dataset=cfht,label=centos-7,python=py2/console        """
"DM-9623","Story","meas_astrom",20,"Investigate posible matcher improvements","""This issue is a catch all for investigative work relating to DM-7366 that has blocked DM-8113.    Optimistic pattern matcher B appears to preform poorly for dense stellar fields (6-10k reference stars per visit). This issue involves finding solutions, work arounds, and possible matcher improvements for both the current stack matcher and the pure Python implementation from a previous issue in this Epic. This involves finding ways to mitigate false positive matches reliably and discovering why the stack matcher fails immediately when running on dense stellar fields."""
"DM-9617","Story","Alert Production",3,"Use logging in DCR code","""The prototype DCR code currently uses print statements to issue warnings and informative messages. These should be converted to use the standard logging system."""
"DM-9616","Story","Alert Production",3,"Make DCR command line task","""It should be possible to run the new DCR template generation code from the command line."""
"DM-9615","Story","Alert Production",8,"Convert DCR code to use Tasks","""The DCR code should be written so that the classes inherit from Tasks, and make use of those features."""
"DM-9608","Bug","Stack Documentation and UX",0.5,"Fix LTD Dasher title processing (handle removal)","""The Dasher rendering code that cleans up titles tries to remove handle prefixes. So that    {}    becomes    {}    There's a bug in the filter that turns this input:    {}    into    {}    This ticket fixes that."""
"DM-9604","Story","wg-supertask",2,"Write up data/parallelization axis transformation examples for SuperTask WG","""Produce slides or a short, informal document showing examples from DRP where we need to change data units and/or parallelization axis at a scale we expect to be handled by SuperTask."""
"DM-9681","Story","meas_deblender",1,"Write function to apportion flux based on NMF template weights","""The main assumption of the current deblender is that galaxies have an identical profile in each band. This is not strictly true, as the color near the center of galaxies is more white.    It is worth attempting to use the NMF deblender output as a template, similar to the symmetric templates generated by the SDSS deblender, and re-apportion flux based on the ratio of the templates in each pixel. This may help us recover more accurate colors while still performing better in the wings of blended galaxies than the current deblender.    This ticket will refactor a version of {{lsst.meas.deblender.apportionFlux}} to re-apportion flux for NMF templates."""
"DM-9675","Story","meas_deblender",1,"Soften symmetry operator requirements","""The current symmetry operator enforces strict symmetry, meaning that all pixels that do not have a symmetric partner in the footprint are penalized. To ease this requirement, which may be necessary if some of the flux for one (or more) of the objects lies outside of the footprint, we allow the user to use a less stringent penalty value."""
"DM-9669","Story","daf_persistence",1,"Butler(root=""foo"") should not warn about mapper class instance","""when initializing butler as Butler(""""foo""""), butler warns   daf.persistence.butler WARN: mapper ought to be an importable string or a class object (not a mapper class instance)    it should not do this - a mapper instance was not passed in."""
"DM-9646","Story","Stack Documentation and UX",2,"Update DRP release notes for v13","""The v13 release [has been tagged|https://sw.lsstcorp.org/eupspkg/tags/v13_0.list], but the [DRP release notes|https://confluence.lsstcorp.org/display/DM/Data+Release+Production+WIP+F16+Release+Notes] are a couple of months out of date. Update them and provide them to SQuaRE to accompany the release."""
"DM-9639","Story","Developer Infrastructure",0.5,"Install v13 release into shared stack","""v13 has now been tagged. Update the shared-stack build script on lsst-dev to install it, and make sure that happens successfully."""
"DM-9638","Bug","Firefly|IRSA",2,"empty image tab appears unexpectedly after selecting an histogram column and cancel","""Is a very weird bug but i ran into it when i hit the 'cancel' button of the 'chart' drop down dialog.  An empty white image tab titled {{Image Meta Data}} suddenly appears next to the {{coverage} tab.    To test: Open tri-view, do a catalog search, then click 'charts', then 'histogram' radio button. Then select column (this is the part that make the bug apparent), then 'ok', then 'cancel'. The empty tsab will appear next to 'coverage' tab.    From Trey 3/1:  This bug is probably in FireflyViewerManager.js    From Tatiana 3/2    Another test case:  1. Load Firefly.  2. Do catalog search (m31, default settings) - tri-view table, xyplot, coverage shows up  3. Click on FITS Header icon - empty """"Image Meta Data"""" tab comes up    Looks like the empty white image tab titled {{Image Meta Data}} appears whenever we add a new table, which is not coverage or catalog. In the scenarios above, the tables are column table or fits header table - both of them appear to FireflyViewerManager as """"image metadata"""" tables. The bug is in the last line of converterUtils.js:isMetaDataTable function - Boolean(converter) is always true, because we have """"UNKNOWN"""" converter. So the question is when this UNKNOWN converter is relevant and how can we separate image metadata tables with UNKNOWN converter from other tables.   """
"DM-9686","Story","Stack Documentation and UX",1,"Add LSST branding to pipelines.lsst.io","""Similar to DM-6120, add LSST branding to pipelines.lsst.io theme.    Add:    - Edit on GitHub button  - LSST branding  - Edit on GitHub button  - LTD edition dashboard links"""
"DM-9682","Story","Developer Infrastructure",0.5,"Update git-lfs in lsst-dev shared stack","""The {{git-lfs}} installed in the shared stack on {{lsst-dev}} is pretty elderly. Please provide a newer version."""
"DM-9715","Story","utils",0.5,"cppIndex should raise Python's built-in IndexError","""In order to synthesis {{\_\_iter\_\_}} from {{\_\_getitem\_\_}} Python apparently requires *exactly* {{IndexError}} to be thrown, so that's what we should throw in these functions.    That will require rewriting the testPybind11.cc unit test in a way that has access to Python symbols (which should be done anyway).    There will likely be workaround code in afw/table/python/catalog.h that can be cleaned up after this change (I'll just catch OutOfRangeError there and re-throw as IndexError)."""
"DM-9711","Improvement","meas_base",2,"Clean up meas_base pybind11 wrappers","""Rebasing meas_base and other packages with `meas.base.Algorithm` subclasses for the DM-9249 changes.    This will require new/different pybind11 wrappers for changed C++ interfaces."""
"DM-9710","Story","SUIT",1,"Update the FitsReadTest.java due to the changes in rotation's calculation in FitsRead","""After DM-9581 was implemented, the FitsRead's unit test is failed because the testing data prepared is no longer correct. The FITS file used in the unit test for rotation was created by running FitsRead.createRotationAngles.  Since this method is modified, the old FITS file is no longer correct.    The following needs to be done:    * Generate the new testing data and store in the firefly_test_data  * Re-run the unit test to make sure everything work    """
"DM-9743","Story","Firefly",2,"Field of time column name handling for Time Series Viewer","""- The raw data table should be updated and a light curve calculation restarted (the existing phase folded table is removed) if the time column name in TS viewer changes because the table is sorted on the new column -- currently nothing happens when user changes the input value for the time column name field to be another valid one.   - add time column name field for LSST   """
"DM-9740","Story","Continuous Integration",2,"Make lsst_ci run obs_cfht, obs_decam example in its scons test.","""Make {{lsst_ci}} run {{obs_cfht}}, {{obs_decam}} examples in its {{scons}} test.    The {{test}} step of {{lsst_ci}} should verify that the simple test example runs of {{obs_}} packages succeed.    Monitoring the results using {{validate_drp}} will be delayed for a later ticket.  Just making sure things run successfully through {{processCcd.py}} or the equivalent is the goal here.    1. [x] Add {{validation_data_cfht}}, {{validation_data_decam}} to required dependencies.  2. [x]  Run command-line based test scripts.  3. [x] Wrap these scripts in scons test to report pass/fail based on just successfully completing."""
"DM-9752","Story","jointcal|lsst_distrib",1,"Add jointcal to lsst_distrib","""This ticket implements RFC-300.    Once jointcal has been ported to pybind11 (DM-9187), it will be ready to join the stack in lsst_distrib. This includes the {{jointcal_cholmod}} dependency, and the optional {{testdata_jointcal}} package (which will be excluded from most installs due to size).    Note to [~jhoblitt]: We'll need to add {{testdata_jointcal}} to the various exclude files once this is ready to go. I'll ping you at that time."""
"DM-9745","Story","Stack Documentation and UX",0.5,"Update text relating to baseline CentOS versions for building stack","""Following RFC-293 we have agree that we can specify a minimum CentOS7 version for building the stack. Locate relevant documentation and update it with this information."""
"DM-9769","Story","SUIT",3,"Provide SLAC information on image cutout, reference IRSA existing practice","""SLAC has delivered imageServ APIs to retrieve the image cutouts but they have questions about how to provide the cutouts for coadds (per Kenny Lo). They would like our team to provide how-to.     Thanks to Tatiana who points out that IRSA has been using the cutouts algorithm in http://irsatest.ipac.caltech.edu//ibe/cutouts.html. Basically users provide the center coordinates and the size of the cutout. """"The size parameter consists of one or two (comma separated) values followed by an optional units specification. Units can be pixels (px, pix, pixels) or angular (arcsec, arcmin, deg, rad); the default is degrees. The first size value (x) is taken to be the full-width of the desired cutout along the first image axis (NAXIS1), and the second (y) is taken to be the full-height along the second axis (NAXIS2). If only one size value is specified, it is used as both the full-width and full-height. Negative sizes are illegal.""""     Should we suggest SLAC team to consider to adapt the same algorithm for LSST image cutouts, both single epoch and coadd? Need David C. and Gregory to consider this and approve it.    Please see the full document in the link below.  """
"DM-9766","Improvement","SUIT",0,"FITS ""can opener""","""It would be useful to expose in Firefly applications the ability to read an arbitrary FITS file, browse its headers and any extensions, and be able to visualize whatever subset of data types Firefly can natively handle (e.g., image, basic table).    Mutatis mutandi for other file types we support.    This would be a useful debugging tool, but it would also be useful in the JupyterLab environment where plugins can be associated with specific """"file"""" types in the file browser component.    Then, if users have FITS files in their workspace storage, they can open them in the JupyterLab environment with simple UI actions.    It may also be of interest in other Firefly application contexts, e.g., in IRSA, to offer this capability, but of course there are security issues associated with providing a general """"upload a FITS file and we'll tell you all about it"""" capability."""
"DM-9765","Bug","afw",1,"Suspicious numerical precision code in Angle","""The implementation of {{Angle::wrapNear}} includes several corrections for possible truncation error, the last of which is to rescale the wrapped angle by (1 - 2) if it is too far below {{refAng}}. This requirement is odd, for example because it is sensitive to the absolute values of {{refAng}} and the angle to be wrapped.    However, I have not been able to create a test case that exposes a problem in the wrapping, either by trying to carefully tune the value to give zero wrapped angle or by trying to work with very large angles like 10000. Attempts to reproduce the suspected bug should continue, and if successful the bug should be fixed."""
"DM-9764","Bug","afw",0.5,"SOURCE_IO_NO_FOOTPRINTS and related enums should be properly wrapped in pybind11","""In order to use {{lsst.afw.table.SOURCE_IO_NO_FOOTPRINTS}} in python, it has to be explicitly cast to {{int()}}. This is a bug in the pybind11 wrapper."""
"DM-9761","Story","daf_persistence",1,"butlerProxy test does not clean up after itself properly.","""the tearDown function needs to be updated to reflect recent changes to the path in the setUp function."""
"DM-9758","Story","astshim",2,"astshim fails to build on linux","""astshim fails to build on linux using Jenkins. Here is a build log  https://ci.lsst.codes/job/stack-os-matrix/22127/label=centos-7,python=py2/console    Also fix build warnings"""
"DM-9757","Story","Qserv",1,"Add stat table usage options to mysql config file","""For mariadb query optimization (DM-9175) in qserv, the relevant parameters must be set persistently in the mysql configuration file so that the generated stats tables are used to run queries on table chunks. The options to be added are:        Their default values are {{'NEVER'}} and {{1}}."""
"DM-9754","Story","daf_persistence",1,"re-separate python Storage & cpp Storage","""due to a naming collision, there are separate classes both called Storage in cpp and python. They got combined during the pybind11 conversion and are re-separated here.  """
"DM-9795","Bug","ci_hsc|meas_modelfit|obs_subaru",2,"CModel priors are weighted incorrectly relative to likelihood","""When per-pixel variances are turned off, CModel likelihoods are computed without using the variance at all.  This would not matter in a pure likelihood fit, but it means the prior and likelihood are not given the appropriate relative weights - and the relative weighting is not even consistent; it depends on the noise level of the image.    Since the typical effect of this is to make the prior much more informative, there is some danger that fixing this bug will cause other problems due to poorly-constrained fits.  To avoid this, I'll add a configuration option to tune the relative weighting of the prior via a constant (which we could set to the typical variance level of the images to get behavior like what we have now without the inconsistency)."""
"DM-9794","Story","sconsUtils",2,"Pass both LSST_LIBRARY_PATH and DYLD_LIBRARY_PATH in scons on Mac OS","""To allow both Python code and shell scripts to inherit the necessary env settings, I'd like {{sconsUtils.utils.libraryLoaderEnvironment}} to pass both {{LSST_LIBRARY_PATH}} and {{DYLD_LIBRARY_PATH}} to things it calls on Mac OS.    Currently {{libraryLoaderEnvironment}} is used within {{sconsUtils}} only by {{sconsUtils.tests.Control.run}} to ensure that, on Mac OS, that {{DYLD_LIBRARY_PATH}} is passed with either {{DYLD_LIBRARY_PATH}} or {{LSST_LIBRARY_PATH}}, whichever is defined first in that search order.    But a shell script will be called out of {{/bin}} or an equivalently system-protected directory and needs {{LSST_LIBRARY_PATH}} passed (which will not be stripped) so that that shell script can then reset {{DYLD_LIBRARY_PATH}} (which will be stripped by SIP).    The particularly motivating usage is to enable Python test code to call a shell script as part of DM-9740."""
"DM-9792","Bug","astshim",2,"Mapping::getInverse not exception-safe","""The current implementation of {{Mapping::getInverse}} allocates a new {{AstMapping}}, but does not free it if AST's internal error flag triggers an exception via {{assertOK}}. -In addition, {{Object::fromAstObject}} does not free {{rawObjCopy}} if there is a dynamic casting error.-    The leaks in these methods should be fixed using either {{assertOK}} or a {{catch}} or {{finally}} block. Unfortunately, as I understand it astshim's object and type juggling would interfere with using a {{unique_ptr}}.    In addition, both methods should document the exceptions they throw and their (intended) exception safety."""
"DM-9790","Bug","Stack Documentation and UX",1,"Items missing from the pybind11 wrapping guide","""I've been using the [pybind11 wrapping guide|https://developer.lsst.io/coding/python_wrappers_for_cpp_with_pybind11.html] to wrap jointcal, and it's generally been quite helpful, but there were a few questions it didn't answer for me.     * what to change/add in {{python/SConscript}} and {{__init__.py}}.  * how many of the wrapped modules to include in {{__init__}}: should they all be included as a general rule, or just those that one definitely wants to be accessible from python?  * How to choose between {{clsBlah}} and {{cls}} when naming the wrapped code (it's discussed in the style guide, but it would be useful to say something about it in the wrapping guide, with a link to the style guide sections).  * how to import new pybind11 modules in python (no more blahLib).    It might be useful to also have a list of """"how to remove all your SWIG stuff"""", for those dealing with packages that were previously SWIGed."""
"DM-9789","Bug","Stack Documentation and UX",1,"pipelines.lsst.io v13 needs some fixes","""After perusing the latest version of pipelines.lsst.io, I made the following comments on the merge commit:  * {{metrics/v13_0.rst}} line 9: Should we explain that we are not trying to compare to the """"glide path"""" in LDM-240 anymore and that the targets are hence goals for much later rather than thresholds we are supposed to meet with this release?  * {{releases/note_source/v13_0.rst}} line 659: There's no release note that says that {{daf_butlerUtils}} was moved to {{obs_base}}? And I think the title of this would be a bit better if it had """"definitions"""" appended.  * {{releases/note_source/v13_0.rst}} line 786: If there were no documentation improvements, this section should be omitted.  But I think there were some, at least to pipelines.lsst.io itself..."""
"DM-9784","Story","meas_deblender",5,"Implement test for overlapping galaxies","""Once DM-9644 is completed we need to create a test that calculates the amount of overlap between galaxies, basically    (S{~}i~ S{~}j~)^2^ / ((S{~}i~^2^) (S{~}j~^2^))    for both the measured intensities and simulated intensities."""
"DM-9775","Story","meas_deblender",3,"Create NMF deblender presentation","""Create a presentation for the Princeton Monday Meeting to outline NMF, proximal operators, and the new deblender."""
"DM-9812","Story","ci_hsc|meas_astrom|obs_base|obs_subaru|pipe_tasks",2,"Clean up outputs from CharacterizeImageTask and CalibrateTask","""We're writing the {{icExp}} files in {{CharacterizeImageTask}}, which we don't use, but greatly increases our disk usage.     We want the denormalized match catalogs from {{CalibrateTask}} and from multiband processing."""
"DM-9811","Story","obs_subaru",1,"Add 1.3 arcsec target seeing for convolved flux measurement","""Masayuki Tanaka asks that we also include a 1.3 arcsec target seeing in the {{ConvolvedFluxPlugin}}.  This target seeing is larger than any expected seeing in the coadd, and so we'll always get a useful result."""
"DM-9810","Story","meas_extensions_psfex|obs_subaru",1,"Make PSFEx oversampling configurable","""Add a configuration option that lets PSFEx decide when to oversample PSF images.    """
"DM-9808","Bug","lsstsw",1,"astshim does not build on Ubuntu","""The stack cannot be built on Ubuntu because the build of {{astshim}} complains about a missing symbol:  bq. lsstsw2/stack/Linux64/starlink_ast/lsst-dev-g4bd2b55bd7/lib/libast_pass2.so: undefined reference to 'astPutErr_'"""
"DM-9802","Story","ap",2,"Update base docker images for alert stream","""The base kafka image in the docker-compose file for the current alert_stream repo is deprecated already.  :(  Need to swap this image out with the current stable version of kafka, go through new release docs to update deprecated environment variables, swap out the zookeeper image, and upgrade the python base image of the main Dockerfile.  We want to do this before testing because the currently used version of kafka and also the python base image lack features/performance we will want later, so we should test the versions we want to use."""
"DM-9798","Bug","meas_deblender",1,"Remove superfluous print message","""During the pybind11 port someone (meaning me, probably) left a print statement that print """"STRAY FLUX"""". This should be removed."""
"DM-9797","Story","obs_subaru",2,"Investigate HSC-Y background configs","""Default background configs fail to remove a rotating ellipse-shaped ring of scattered light in the  y-band HSC data:         !https://paper.dropbox.com/ep/redirect/image?url=https%3A%2F%2Fd2mxuefqeaa7sj.cloudfront.net%2Fs_CE3712A3B91055C667598BDAAFD85C792A8BC38908F5D92E32C19E3223FF4694_1489481658883_Screen%2BShot%2B2017-03-14%2Bat%2B5.23.22%2BPM.png&hmac=8V%2F3Mr6bDlLZbvSguW8pJDZRR9CzFz1%2Fr85NKoWsCjc%3D&width=600!    This ticket will capture work to identify appropriate background configs for removing. """
"DM-9826","Story","afw",2,"Add hasTranForward and hasTranInverse to Transform","""Like the {{Mappings}} they adapt, a {{Transform}} may or may not have a forward transformation, and may or may not have an inverse transformation. Test methods should be added to {{Transform}} to let clients defend against calling a missing transformation."""
"DM-9824","Bug","Firefly|SUIT",0,"Fail to upload additional catalog after initial upload","""Select Catalogs -> Load Catalog  Upload the sample catalog file below.  Click Search.  Everything works as intended.    Now, try to upload another catalog.  Clicking Search does nothing.  No error indications.  You'll find uncaught errors in the console.    sample catalog file:    """
"DM-9818","Story","Stack Documentation and UX",1,"Design dochub-prototype (www.lsst.io builder)","""Write up a lightweight specification+design for the {{dochub-prototype}} project (the build infrastructure for www.lsst.io) to help [~athornton] make the initial implementation.    {{dochub-prototype}} is itself a prototype for what will become DocHub (https://sqr-013.lsst.io)."""
"DM-9817","Bug","Stack Documentation and UX",2,"Doxygen tries to parse pybind11 wrappers","""Doxygen currently reads {{.cc}} files in the {{python/}} directory, leading to silly documentation like https://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/namespacelsst_1_1afw_1_1camera_geom.html#a2a868ed61ae08543a5cc793c35f5674e.    I propose that any C++ files in {{python/}} be excluded using an {{EXCLUDE}} or {{EXCLUDE_PATTERNS}} configuration. I'm not sure whether this only needs to be changed in {{base}} or in all packages."""
"DM-9816","Story","SUIT",8,"Evaluate Plotly.js as a replacement to Highcharts","""Plotly is an open source plotting package that is more oriented toward science than Highcharts.    Study the following:  * Can we control tooltips?  * What control do we have during selection?  * In general, can monitor or have hooks into their events?  * How hard to port histograms, scatter and density?  * How hard to create a heat map to replace density?  * Do they support optimized updates and not complete redraws?    Overall we want a sense if we should go to the next step of replacing Highcharts.  We need to understand how much efforts would be involved."""
"DM-9851","Story","Alert Production",2,"Improve DCR code use of the butler","""The current DCR template generation code requires the user to supply the name of the telescope, and has telescope-specific code that interfaces with the butler. This code should be re-written to be less fragile and to remove the lines that depend on the telescope."""
"DM-9848","Story","daf_persistence|obs_base",1,"obs_subaru test failures possibly related to daf_persistence","""Both [~wmwood-vasey] and myself have seen {{obs_subaru}} test failures today.  In my case, the test failure was non-reproducible.  I am concerned that this might be a concurrent butler access issue.    https://ci.lsst.codes/job/release/job/run-rebuild/472/consoleFull#console-section-13      """
"DM-9846","Story","astshim",1,"Improve handling of error messages","""astshim presently prints AST error messages to stderr. Improve this so that the messages and up as the text of exceptions, instead.    This work requires the new AST capability of registering an error handler which has just been released."""
"DM-9828","Story","meas_algorithms",2,"Enable rectangular binSizes in SubtractBackgroundTask","""While validating on HSC data, we encountered a use case for rectangular bin sizes in {{SubtractBackgroundTask}}.  We propose two new config fields:    * binSizeX  * binSizeY    By default they will be None and populated with the value in binSize. This change will be 100% backwards compatible. Everyone's config files will produce the same results.   """
"DM-9866","Story","meas_base",1,"Make change to remove flagDecorator (RFC-302)","""This is a follow up to the FlagHandler modification DM-9249.  Posted this last deletion to flagDecorator.py in case anyone unknown was using it."""
"DM-9863","Improvement","ip_isr|obs_base|obs_cfht|obs_decam|obs_lsstSim|obs_sdss|obs_subaru|obs_test|pipe_drivers|pipe_tasks",0.5,"Replace use of makeVisitInfo(... with VisitInfo(...)","""{{lsst.afw.image.makeVisitInfo(...)}} is superseded by {{lsst.afw.image.VisitInfo(...)}}. Remove existing usage of {{makeVisitInfo}}.    {{makeVisitInfo}} is used in one or two places in most obs_ packages and a few other packages as well.    Note that this can be done on a package by package basis as time permits. Once all usage is gone we can get rid of {{makeVisitInfo}}."""
"DM-9862","Story","meas_mosaic",3,"Update meas_mosaic's wcs/fcr output files to reflect LSST coordinate system","""When importing {{meas_mosaic}}, the coordinate system for writing out the wcs/fcr files was not adapted to that expected from LSST (which always associates the detector origin with the electronics, whereas HSC's is such that a given detector's origin, pixel (0, 0) is associated with its LLC w.r.t. to the focal plane), but rather the tasks in {{meas_mosaic}}'s *updateExposure.py* were adapted to account for the rotated CCDs.  It was assumed that this was the only place those corrections were every used.  This turns out not to be the case since the wcs used to create the coadd gets attached to it in *coaddInputs*.  If {{meas_mosaic}} was run and *doApplyUberCal=True* (which are both the case for our HSC data processing), the wcss that are getting attached to the coaddInputs are not in the coordinate system appropriate for LSST for any nQuarter != 0 ccds.    Since this is already causing an issue in {{pipe_tasks}}'s *propogateVisitFlags.py*, see issue highlighted in DM-9383, (and could very well be causing issues elsewhere as yet undiscovered), we have decided these outputs need to be written out in the coordinate system expected by LSST."""
"DM-9857","Story","SUIT",8,"Research Support of Evaluation of Plotly as a replacement to Highchartts","""Plotly is an open source plotting package that is more oriented toward science than Highcharts. Provide a second set of eyes in evaluation of Plotly.js and support DM-9816.    Study some of the following:  Can we control tooltips?  What control do we have during selection?  In general, can monitor or have hooks into their events?  How hard to port histograms, scatter and density?  Do they support optimized updates and not complete redraws?  How  would a Plotly react component work?  Overall we want a sense if we should go to the next step of replacing Highcharts. We need to understand how much efforts would be involved."""
"DM-9882","Story","afw",8,"Add integrate interface to BoundedField/ChebyshevBoundedField","""In order to implement the """"mean zero point"""" functionality of PhotoCalib, I need to compute the integral over the bounding box. {{BoundedField}} does not include facilities for integration/differentiation. Fortunately, my primary usage is {{ChebyshevBoundedField}}, which has a relatively straight-forward recurrence relation for integration.    I suggest an interface like the following on {{BoundedField}}, with a virtual """"not implemented"""" default:    """
"DM-9873","Story","daf_base",3,"PropertySet does not support values of None","""In DM-5466, we needed to pass the results from {{ParseTask.getInfo()}} to the butler as a dataId. This is normally valid, since both are dictionaries, and even though {{getInfo()}} often contains extraneous entries that aren't relevant, the butler will usually ignore them. However, when parsing calibration files this dictionary contains some values that are set to {{None}}, since they will be filled in later. These extraneous keys are then placed in {{ButlerLocation.additionalData}} ([butlerLocation.py:221|https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butlerLocation.py#L221]), which throws an exception as it is a PropertySet and does not support python {{None}} as a value.    DM-5466 has a work-around that strips these None values from the dictionary, but this is inelegant. The main driver for excluding None from PropertySet seems to compatibility with FITS headers. This seems like an unwarranted mixing of data model and persistence formats. Unless there is some advantage to not being able to store None in our dictionary-like objects, it seems preferable to shift the burden of accommodating FITS's peculiarities onto the persistence layer rather than PropertySet.   """
"DM-9871","Story","obs_subaru",0.5,"Move wcs and fcr datasets out of {pointing} directory in obs_subaru","""We should change the templates for {{fcr}} and {{wcs}} to the following:      This will avoid problems in copying/updating directories at NAOJ during incremental releases.  """
"DM-9900","Story","Science Pipelines",2,"Recreate DCR simulation images for testing","""The existing simulation data used for testing the DCR template building code is missing some important metadata. Those simulations should be brought up to date, and re-created with all the required metadata."""
"DM-9897","Story","Continuous Integration",3,"conda channel errors causing lsstsw/bin/deploy to fail","""We see errors installing both osx and linux packages like the following:        I believe the best resolution is to mirror the public conda channels internally.  Another, less desirable, option would be build retrying into the conda command."""
"DM-9895","Bug","afw",2,"FrameSet frames not preserved by Transform(frameSet) constructor","""When an {{lsst.afw.geom.Transform}} is constructed from an {{astshim.FrameSet}} the internal frames in the frame set are lost. I strongly suspect what is happening is that the mapping constructor of {{Transform}} is being called, instead of the {{FrameSet}} constructor. Reversing the order in the pybind11 wrapper file should fix the problem. A unit test is required."""
"DM-9894","Story","supertask",1,"SQuaRE SuperTask Collaboration Week of 2017-03-20","""Bucket ticket to cover non-specific SuperTask collaboration activities (see linked meeting notes)."""
"DM-9893","Story","supertask",1,"Write SQuaRE User Stories for SuperTask","""Write a set of user stories and consequent SuperTask design implications that address SQuaRE needs."""
"DM-9885","Story","ci_hsc|obs_base|obs_cfht|obs_decam|obs_lsstSim|obs_sdss|obs_subaru|pipe_tasks",1,"Rename deepCoadd_srcMatch as deepCoadd_measMatch","""Implement RFC-306."""
"DM-9917","Improvement","afw",1,"Add a callback to cameraGeom.showCamera","""It is sometimes very convenient to modify the data that {{cameraGeom.utils.showCamera}} displays;  the classic case if trimming, bias subtracting, or gain-correcting raw data.      Please port old RHL HSC code that registers a callback to do the work (much better than adding more and more special-case code to {{showCamera}})  """
"DM-9916","Story","Science Pipelines",3,"Re-write internal DCR template wcs-matching","""In the DCR template generation code, when exposures are warped that operation is currently performed in-place, over-writing the array values and wcs info. This could potentially lead to bugs down the road, so either the implementation should be made more robust or checks should be put in place to verify that it is safe."""
"DM-9925","Improvement","astshim",1,"PolyTran should not provide an iterative inverse by default","""{{PolyTran}}'s constructor that takes only forward coefficients provides an iterative inverse by default (as does its other constructor if the forward coefficient array is empty). This seems like a bad idea for several reasons:  - Most polynomials do not have unique inverses. That said, the iterative inverse will do sensible things in that situation (nan if no value exists, else a valid value if multiple choices exist).  - The iterative inverse is much less efficient to  compute than the fit inverse provided by `PolyMap.polyTran`.    I propose to disable the iterative inverse by default, using the philosophy of """"when in doubt, refuse to guess""""."""
"DM-9921","Story","Stack Documentation and UX",2,"Uploader for dochub-prototype HTML to LSST the Docs","""Publish dochub-prototype HTML to {{www.lsst.io}} via LSST the Docs."""
"DM-9920","Bug","SUIT",2,"The catalog search in IRSAViewer does not work for multi-object search ","""While working on LSST multi-object search, I found that the multi-object search in IRSA viewer does not work.      After spending hours to look into the reason, I found that the uploaded table in CatalogSelectViewPanel.jsx is not proper defined.     The correct way should be:    """
"DM-9949","Story","SUIT",2,"Update the PDAC sample queries and test cases page","""Update the PDAC sample queries and test cases page [https://confluence.lsstcorp.org/display/DM/PDAC+sample+queries+and+test+cases] to include WISE data"""
"DM-9948","Story","SUIT",8,"LSST catalog search processor","""make sure the current catalog search processor handles WISE catalog data search properly"""
"DM-9946","Improvement","astshim",0,"Remove debugging example refcount.cc","""The file {{examples/refcount.cc}} was intended for debugging, not distribution. Remove it."""
"DM-9942","Story","SUIT",3,"Plotly Change: Create Plotly loading infrastructure and React wrapper ","""Setup plotly environment:    * Set up how we are going the load plotly using a deferred load  * Create a plotly react wrapper  * set up Firefly environment to  contain a property to switch between plotting packages"""
"DM-9940","Story","Science Pipelines",3,"Simplify package dependencies of template generation","""The DCR matched template code has dependencies on sims packages that might be replaced with functionality from core software. Once DM-9615 is completed, some of these (such as the bandpass) may be obtained from the relevant obs package."""
"DM-9937","Story","afw|geom",3,"Add noexcept specifiers to applicable methods in afw","""C++11 methods that are declared {{noexcept}} enable compilers to streamline code that calls them, in some cases (e.g., STL code) unlocking more efficient algorithms that would be unsafe with throwing methods. These changes are most useful for low-level types, whose methods are also the most likely to be provably non-throwing.    This ticket shall add the {{noexcept}} specifier to any methods that are guaranteed not to throw and are unlikely to be modified to throw exceptions in the future (e.g., trivial getters will usually qualify, but methods for which some inputs are invalid will not even if the existing code performs no input validation). Particular attention shall be paid to constructors, assignment operators, and {{std::swap}} implementations, as these are the methods where {{noexcept}} provides the biggest gains.    The classes covered by this ticket are (based on assumed simplicity, and therefore subject to change):  * {{afw::cameraGeom::CameraPoint}}  * {{afw::cameraGeom::CameraSys}}  * {{afw::cameraGeom::CameraSysPrefix}}  * {{afw::cameraGeom::Orientation}}  * {{afw::coord::Coord}} and its subclasses  * {{afw::coord::Observatory}}  * {{afw::coord::Weather}}  * {{afw::detection::Threshold}}  * {{afw::geom::Angle}}  * {{afw::geom::AngleUnit}}  * {{afw::geom::Box}}  * {{afw::geom::CoordinateBase}} and its subclasses  * {{afw::geom::CoordinateExpr}}  * {{afw::geom::Span}}  * {{afw::geom::SpherePoint}}  * {{afw::geom::polygon::Polygon}}  * {{afw::image::Calib}}  * {{afw::image::Color}}  * {{afw::image::DefectBase}}  * {{afw::image::Filter}}  * {{afw::image::FilterProperty}}  * {{afw::math::FitResults}}  * {{afw::math::Function}} and its subclasses  * {{afw::math::MaskedVector}}  * {{afw::math::Statistics}}  * {{afw::table::BaseRecord}} and its subclasses  * {{afw::table::ConstFunctorKey}}  * {{afw::table::FieldBase}} and its subclasses  * {{afw::table::InputFunctorKey}} and its subclasses  * {{afw::table::KeyBase}} and its subclasses  * {{afw::table::Match}}  * {{afw::table::OutputFunctorKey}} and its subclasses  * {{afw::table::ReferenceFunctorKey}}  * {{afw::table::SchemaItem}}  * {{afw::table::io::Persistable}}  * {{afw::table::io::PersistableFacade}}"""
"DM-9931","Story","ci_hsc",1,"Add dependency of ""refcat"" on ""preSfm"" in ci_hsc","""{{ci_hsc}} fails in my lsst-dev/lsstvc/slurm env (using 1 node) although it passes on Jenkins.    The problem arose when {{preSfm}} ran before  {{refcat}}.     I think this is because {{preSfm}}, effectively {{processCcd.py DATA --rerun ci_hsc --doraise}}, needs the {{ref_cats}} link already in the repo. Running the command in a repo without the {{ref_cats}} gives this error:       """
"DM-9975","Story","Design Documents",0.5,"Port LDM-151 to new latex style","""LDM-151 is currently using a default Latex style. It needs to be ported to use the standard look and feel {{lsstdoc.cls}}."""
"DM-9970","Story","daf_persistence",1,"Fix Composite Policy Docs","""in this block:  {quote}  2.16.9   Composite Policy  To indicate that a dataset should be serialized/deserialized from components, the policys dataset definition has a keyword composite. The structure is:    {quote}  assembler & disassembler are in the wrong spot, the need to be below composite not componentName"""
"DM-9968","Story","Third Party Software",1,"Add eupspkg build for igprof","""The profiler we recommend using in the developer guide isn't provided as part of the stack, and isn't entirely trivial to build on most operating systems (though it's not hard).    This ticket will provide eupspkg builds for igprof and its dependencies.  Hopefully that will make it easy to also make it eups-distrib-installable in the near future, though it shouldn't ever be a dependency of any stack packages (or metapackages).  """
"DM-9967","Story","ctrl_pool",1,"ctrl_pool should not accept a default for --time on real batch systems","""ctrl_pool's {{--time}} is easily confused with the inherited {{-t}} from CmdLineTask, which makes it easy to use the wrong one and get your batch jobs killed too early.  We should always be forced to provide a time estimate when submitting to a real batch system."""
"DM-9966","Improvement","Stack Documentation and UX",1,"Recommend that TODO comments link to Jira","""Following discussion on RFC-307, this ticket adds the following rule to the Python style guide:    h3. To-do comments SHOULD include a Jira issue key    If the commented code is a workaround for a known issue, this rule makes it easier to find and remove the workaround once the issue has been resolved. If the commented code itself is the problem, this rule ensures the issue will be reported on Jira, making it more likely to be fixed in a timely manner.            ----    and the following rule to the C++ style guide:    h4. 6-26. To-do comments SHOULD include a Jira issue key    If the commented code is a workaround for a known issue, this rule makes it easier to find and remove the workaround once the issue has been resolved. If the commented code itself is the problem, this rule ensures the issue will be reported on Jira, making it more likely to be fixed in a timely manner.        """
"DM-9965","Story","meas_deblender",1,"Fix bug in monotonicity operator","""There appears to be a bug in the monotonicity operator that causes some edge pixels to wrap monotonicity around the edge to the next (or previous) line. The cause of this needs to be found and fixed."""
"DM-9964","Story","SUIT",1,"Change LSSTCatalogSearch 's behavior to the same as IRSA's catalog search","""When the search result in IRSA catalog search is empty, the IRSA catalog search shows the table with empty row data.  The LSSTCatalogSearch returns the message with """"no data found"""".   I think that the behaviors in two catalog searches should be consistent.       Since the meta server is not available, the data definitions are obtained from the search result.  When there no data is available, there is no data type definition either.  The current implementation threw an exception when the empty table is returned from the PDA search.  But for multi-object search, the exception will stop further searches for the other object.  For now,  it is modified as below:  # Let getDataFromUR return null if the result is empty  #  When the PDA search returns empty, the exception in LSSTCatalogSearch is deferred at the loadFile  # In LSSTMutliObjectSearch, when one of the callable returns empty result, it will be skipped. Thus, all targets in the input file will be searched.    NOTE:  When the meta server is working, the above implementation will be changed accordingly.   So is the meta definition in LSSTQuery.             """
"DM-9962","Story","DM Subsystem Science",2,"Write proposal for storing coadd HeavyFootprints","""Deblending results in the form of HeavyFootprints should be available to users, which means they must be stored.    This proposal should include an estimate of how much storage this will require for a given area of sky, which can probably be derived from the average HeavyFootprint size in HSC data.  This will be a function of depth, so it will not be the same at the beginning of the survey as it will be at the end (but we should have HSC data that spans those depths).    This will be a conservative estimate - it is possible that deblender outputs may take a form that allows them to be highly compressed and quickly reconstituted given coadd data.    We will not consider the possibility that it will be necessary to store per-epoch HeavyFootprints for ForcedSources."""
"DM-9961","Story","validate_drp",3,"Add treecorr to validate_drp and lsst_ci dependencies","""Create a package for {{treecorr}}  to allow for calculation of correlation functions in a fast, robust, and tested code.    This will not add dependencies to {{lsst_apps}} or {{lsst_distrib}}.     Implementation is likely  1. Create wrapper install packages for {{treecorr}}.  2. Figure out how to avoid adding the FITS reader dependency in {{treecorr}}.  3. Add treecorr dependence to {{validate_drp}} table file.    TreeCorr is a  """"[c]ode for efficiently computing 2-point and 3-point correlation functions"""" and is being proposed for use in {{validate_drp}} to calculate the correlation function of the PSF residual ellipticity (DM-8951).  The GitHub repo is here:    https://github.com/rmjarvis/TreeCorr    TreeCorr depends on the following Python packages.    numpy  future  fitsio  pandas  pyyaml  cffi  """
"DM-9959","Story","supertask",1,"SQuaRE SuperTask Collaboration Week of 2017-03-27","""Bucket ticket to cover non-specific SuperTask collaboration activities."""
"DM-9958","Story","supertask",1,"SQuaRE SuperTask Collaboration Week of 2017-03-13","""Bucket ticket to cover non-specific SuperTask collaboration activities (see linked meeting notes)."""
"DM-9955","Story","Developer Infrastructure",0.5,"Investigate building stack on CentOS7 with devtoolset-6","""RFC-303 approved the principle that we can mandate a CentOS7 baseline operating system that requires a devtoolset to build the stack. This ticket is to demonstrate that a stack can build and run using devtoolset-6 on CentOS7 without running in to problems. A successful outcome should result in an RFC requesting a new compiler baseline."""
"DM-9954","Story","meas_deblender",2,"Optimize PSF convolution to use sparse matrices","""Currently the PSF convolution operator is a collection of 2D sparse arrays, which are different for each band, that converted are into full arrays in order to use [~pmelchior]'s proximal operator algorithm. Since the current simulated data is PSF matched, the processing time can be significantly reduced (by several orders of magnitude) by using the PSF operator as a sparse matrix in each band.    This fix is temporary so that we can profile and test PSF convolution and other features of the new deblender but  it is expected that this section of the code will be re-written in C++ in the final deblender before it is merged into the stack in a future sprint."""
"DM-9989","Epic","ip_diffim|pipe_tasks",40,"Incorporate ZOGY and A&L decorrelation option into imageDifference.py","""Incorporate ZOGY and A&L decorrelation option into imageDifference.py. This is specifically regarding the spatially-varying variants of each, which rely upon the ImageMapReduce tasks. This epic includes fixing various bugs discovered after incorporation into imageDifference.py and running them on real images."""
"DM-10009","Story","ip_diffim",2,"Ensure masks are valid from ImageMapReduceTask","""Ensure that the reducer subtask correctly sets the mask to invalid for pixels where the reduced exposure is infinite or NaN."""
"DM-10008","Bug","astshim",0.5,"MapBox.maxOutCoord not set to nout if specified as 0 during construction","""MapBox claims that maxOutCoord will be set to nout if specified as 0 in the constructor, but that does not happen. Fix it and add a unit test.    Also consider making some or all fields const. (Making the computed vectors const is almost certainly more work than it is worth)."""
"DM-9999","Story","meas_modelfit",2,"Review literature on CModel","""Where """"literature"""" likely means the relevant section of the HSC pipeline paper, provided by [~jbosch]."""
"DM-9993","Story","DM Subsystem Science",2,"Prepare presentation on crowded field processing","""Audience is the PST-SC Chairs telecon scheduled for April 18th.    Should be able to mostly reuse slides from last P&CW, with some updates from LDM-151."""
"DM-9992","Story","obs_ctio0m9",1,"Provide CTIO 0.9m data in NCSA","""Please transfer appropriate CTIO 0.9m datasets to NCSA in order to facilitate the construction and test of obs_ctio0m9."""
"DM-9991","Story","obs_ctio0m9",2,"Provide functional obs_ctio0m9","""Building on the work done by [~aguyonnet] in DM-9363, provide an obs_ package that can be used with data from the 0.9m at CTIO."""
"DM-10035","Story","SUIT",1,"Rotate class needs some minor refactoring","""While working on DM-8854, the unit test for Rotate class, I noticed that it needs some minor refactoring.    After investigating how this class is used, I found that the class just needs some document.  I added the algorithm and   brief description what it is doing.      This ticket can be closed.  """
"DM-10023","Epic","Alert Production",40,"Build prototype alert filtering system","""This is to do the research and coding necessary to produce a prototype alert filtering mechanism (simple broker) for the LSST."""
"DM-10069","Story","Qserv",0.5,"Remove boost_thread Qserv dependency","""The sole remaining boost_thread dependency in Qserv seems to be some thread-local storage used by the mysql qserv module.  Since the baseline minimal compiler is gcc 4.8, we can use C++11 thread_local instead."""
"DM-10066","Improvement","utils",3,"Provide utility function for wrapping operator<<","""We frequently want to implement a class's {{\_\_str\_\_}} or {{\_\_repr\_\_}} methods in terms of its {{operator<<}}. The current approach has led to a fair amount of code duplication throughout the stack.    Once a function template that takes a printable object and returns a string is available, explicit wrappers for {{operator<<}} should be rewritten to use it."""
"DM-10051","Story","Design Documents|lsst-texmf",0.5,"Add core documents to shared bibliography","""The lsstdoc.cls file defines standard macros for referring to core documents but not all of these are found in the shared bibliography in lsst-texmf. Add these missing documents. Also redefine the {{\ds}} macro to use a citation rather than a direct docushare link."""
"DM-10047","Story","Design Documents",0.5,"Add LSST refs to LDM-151","""LDM-151 doesn't cite LSST documents so they don't appear in references. They need to be added."""
"DM-10046","Improvement","SUIT",2,"Remove deprecated upload URL from firefly_client","""In spring 2017, a change was made to the URL for uploading data to a Firefly server. The Python API handles this change in DM-9843 by checking the old and the new URL. After some months, the old URL can be considered deprecated and can be removed from the upload functions in {{firefly_client}}."""
"DM-10042","Bug","Qserv",5,"Update mariadb statistics on 35TB dataset","""Join query has a very strange query execution plan on 35TB dataset.  Statistics have to be updated in order to fix that."""
"DM-10039","Story","meas_base",1,"Incorrect docs for CatalogCalculationConfig","""meas_base's [{{CatalogCalculationConfig}}|https://github.com/lsst/meas_base/blob/0b6c81b6fe40f3d0e39237a9a83394b219cce41a/python/lsst/meas/base/catalogCalculation.py#L104] claims that it is:    {quote}  Default CatalogCalculationConfig. Currently this is an empty list, meaning that there are no default plugins run. The config object for each plugin must use this variable to specify the names of all plugins to be run  {quote}    This is wrong in a number of ways  it's not a list, it's not empty, and it doesn't make sense for each plugin to have to specify the names of all other plugins in use.    Please fix it."""
"DM-10091","Story","afw|ci_hsc",1,"Fix problems left over from DM-9952","""DM-9952 is merged to master, but I typoed the Jenkins run {{DM-9952}} not {{tickets/DM-9952}} and didn't notice failing tests from afwdata; afwdata is not present on tiger in Princeton where I did my local testing.    This ticket is to capture the errors turned up when I *did* run the tests.    """
"DM-10089","Story","QA",1,"Simplify validate_base Blob into a concrete collection type","""validate_base's BlobBase type is currently intended to be an abstract base class that apps create subclasses for. The original intention was that blob data would be computed within the Blob subclass's code.    With the new validate_base we're going towards a composition model with container types. This ticket is to convert BlobBase into a Blob class, and permit applications to store data into the Blob instance through standard mapping idioms."""
"DM-10101","Bug","afw",1,"bad exception handling in afw for python3","""Looks like a missed 2to3 compatibility check:        """
"DM-10096","Story","afw",2,"Add unit test asserts for SpherePoint, SpherePointList and PointList","""Add unit test asserts to lsst.afw.geom.utils:  - assertSpherePointsAlmosttEqual  - assertSpherePointListsAlmostEqual  - assertPointListsAlmostEqual    and unit tests for them. This work is needed (or at least very useful) for the new WCS classes."""
"DM-10094","Story","obs_ctio0m9",1,"Copy CTIO 0.9m data to /datasets/ctio0m9/raw","""See RFC-313 and DM-9992  """
"DM-10093","Story","lsst_apps",1,"Revert disabling of meas_modelfit dependency in lsst_apps","""In DM-8467, the meas_modelfit dependency of lsst_apps was temporarily removed:        meas_modelfit is now pybind wrapped (DM-8465), so this should be reverted."""
"DM-10118","Story","supertask",1,"SQuaRE SuperTask Collaboration Week of 2017-04-03","""Bucket ticket to cover non-specific SuperTask collaboration activities."""
"DM-10112","Epic","Firefly|SUIT",20,"Visualization algorithm research (f17)","""This epic captures the algorithm related research for visualization. """
"DM-10111","Story","ip_isr",1,"Add overscan exclusion regions as an ISR config parameter","""As per the discussion in RFC-315, two config parameters need to be added to overscanCorrection() to allow excluding the first and last n rows.    Both parameters should default to 0, so that the default configuration reproduces current functionality. """
"DM-10105","Bug","meas_modelfit|pipe_tasks",1,"Inconsistency in meas/forced wcs leads to CModel failure","""From Sogo Mineo:    """
"DM-10103","Story","Developer Infrastructure",1,"Investigate segfaults in lsst-dev01:/ssd/lsstsw/stack shared stack","""The {{w_2017_14}} weekly fails to build as part of the shared stack in {{lsst-dev01:/ssd/lsstsw/stack}}. This may be related to segfaults previously reported by [~tmorton]."""
"DM-10102","Story","Developer Infrastructure",1,"Reset lsst-dev01:/ssd shared stack","""Implement RFC-317 by wiping out the shared stack in {{lsst-dev01:/ssd/lsstsw/stack}} (or, perhaps, moving it aside) and creating a new stack in its place.    Take precautions to make sure that the toolchain used to build the new stack is always consistent.    Consider bumping to newer versions of EUPS, Anaconda etc than come by default in the {{shared-stack.py}} script. Also install AstroPy through {{conda}}."""
"DM-10132","Story","Science Pipelines",2,"Make DCR template unit test data robust","""The current unit tests for the DCR template generation prototype uses `numpy.save()` and `numpy.load()` to persist and depersist test data. This format is fragile and has already been broken once with the conversion from swig to pybind11, so a more robust test data format should be used."""
"DM-10151","Story","meas_deblender",3,"Investigate a better symmetry operator","""The current symmetry operator work by comparing each pixel to its symmetric partner and projecting the difference to zero using a proximal operator, forcing the solution to be symmetric. This works relatively well, but not as well as the current deblender in certain cases. For example, in a blend with only two sources, with one source much brighter than the other, the faint source using the NMF deblender attempts to steal a small amount of flux from its brighter neighbor. We had hoped that the near zero flux opposite the bright source would be enough to limit this effect (when combined with symmetry) but the algorithm breaks when the fainter object wants to steal flux near the same level as the noise. Sparsity is not much help, as l0 sparsity limits the size of brighter objects more than the smaller ones.    This blending issue is accounted for in the current deblender (adapted from SDSS) because it doesn't just force a symmetric solution, it forces the symmetric solution to use the minimum of each pixel and its symmetric partner. This is a much stronger constraint (and more useful) constraint.    It would be useful to update the NMF deblender to have the same minimum pixel value constraint. One way to do this is to use a proximal operator that projects each template onto a space that uses the minimum of each symmetric pair. This will no longer be a linear operation, as choosing the minimum pixel value is non-linear, so it is unclear how this will affect convergence.    If we can make this work, combining the new symmetry operator with monotonicity might eliminate the need to use a sparsity constraint, which is advantageous as [~pmelchior] and I are realizing that sparsity is a wilder beast than it first appeared to be, and taming it is not a simple task. This is because the sparsity of an image is dependent on the total flux in the image, and the brightness of each source, so it might be that using sparsity would require each source in a blend to have a different sparsity requirement dependent on it's brightness, which could be a difficult scheme to implement. Taking care of this directly using a better symmetry constraint is preferable."""
"DM-10149","Story","Firefly",2,"The range of the phase value and period value for periodogram in time series are not correct","""The range of phase value should be [0, 2)    plotly based phase folding chart doesn't react properly while an invalid period value is selected from the periodogram table. The phase folded chart should show empty content when an invalid period value is selected. """
"DM-10146","Bug","astshim",0,"Fix minor doc typos","""Object.h and WcsMap.h both refer to {{astshim::}} when they should refer to {{ast::}}. I'll fix that for now, but I am becoming increasingly aware that {{astshim::}} would be less confusing. Still...changing that would be another (simple) ticket."""
"DM-10144","Story","Stack Documentation and UX",2,"Document lsst-texmf","""People are starting to use lsst-texmf for document writing but there is some confusion. This ticket is to write a document explaining how to use the lsst latex classes.    The consensus is that this document should match the LSST """"software guide"""" standard and be written using sphinx in a subdirectory of lsst-texmf (rather than writing it in Latex). The documentation will be published to https://lsst-texmf.lsst.io and will include links to the rendered example PDFs.    This ticket covers the writing of the guide. Publishing will be handled separately."""
"DM-10142","Story","obs_ctio0m9",1,"Change HDU used in obs_ctio0m9 from 1 to 0","""obs_ctio0m9 looks in the wrong HDU for data. Config parameter just needs to be changed from 1 to 0."""
"DM-10138","Story","meas_deblender",3,"Compare the convergence of ADMM, SDMM, and GLM algorithms","""The convergence of our new algorithms, SDMM and GLMM are unknown as of now, so we should study the convergence rates of both algorithms (and compare them to the ordinary ADMM) to understand convergence in all three algorithms."""
"DM-10152","Bug","afw",0.5,"Fix bug in Box Python stringification","""The implementation of {{Box2I.\_\_repr\_\_}} in the pybind11 wrappers incorrectly labels it as a {{Box2D}} which is very confusing.  """
"DM-10173","Story","Developer Infrastructure|QA",0.5,"Update bokeh to version 0.12.4","""New version of bokeh released, updating from 0.12.3 to 0.12.4.   """
"DM-10161","Bug","meas_mosaic",1,"Remove maxtasksperchild=1 during pool initialization in meas_mosaic","""Testing for DM-10043 has revealed that having {{maxtasksperchild=1}} in the pool initialization for {{mosaic.py}} (the pool being used to read input catalogs in parallel) causes a bug where {{mosaic.py}} hangs indefinitely.  Curiously, this happens only in with the LSST stack (pybind11 version), not with the HSC stack.  It has been demonstrated that removing this constraint removes this hanging behavior."""
"DM-10195","Story","QA",0.5,"Improve comparison handling in Name and SpecificationSet classes of verify framework","""I realized that not {{__ne__}} is not automatically implemented when {{__eq__}} is implemented. This can cause unexpected behavior with the {{!=}} operator.    This ticket implements {{__ne__}} in existing classes in verify.    I also implements {{__lt__}}, {{__le__}}, {{__gt__}}, and {{__ge__}} operators to the Name class to support Name sorting."""
"DM-10188","Story","SUIT",8,"Fix two drawing related issues with the new rotation scheme  and check regions","""Fix two drawing related issues with the new rotation scheme      - marker resize handles off when rotated   - footprint rotate handles off when rotated    Check both wit flip as well.     Also check if the region code is working the flip and rotate.      This ticket should be done as a pull request against branch dm-10065-canvas instead of dev."""
"DM-10187","Story","dbserv",1,"Properly handle decimal.Decimal types in dbserv","""The WISE dataset uses fixed precision decimals and dbserv doens't properly handle them when serializing to JSON.      """
"DM-10183","Bug","meas_mosaic",2,"Investigate why maxtasksperchild=1 causes mosaic.py to hang on pybind11 stack","""{{mosaic.py}} uses {{multiprocessing.Pool}} to read catalogs with multiple cores.  When this pool is initialized with {{maxtasksperchild=1}}, {{mosaic.py}} hangs indefinitely at a consistent point in the running---that is, running with the same arguments multiple times will freeze up in the same place.  This is only a problem with the pybind11 version of the stack, as this behavior does not occur in the HSC stack, which is currently still wrapped with swig.  The underlying cause of this should be investigated to make sure that there is not some deeper issue that might cause problems with parallelization elsewhere.  """
"DM-10206","Story","obs_decam",0.5,"Fix obs_decam compatibility with 0-indexed HDUs","""The recent implementation of DM-9952 caused the ingestCalibs config in obs_decam to break when ingesting defects (and possibly other calibration products too). A quick fix should adjust the default HDU indexing to begin at 0 instead of 1."""
"DM-10197","Story","Design Documents",1,"Clarify wording relating to flat-fielding in LDM-151","""On reading LDM-151, I asked [~mfisherlevine] a question about how flat-fields were being applied. He's provided some updated text. On this ticket, we'll include it in the document."""
"DM-10217","Story","Requirements Documents",1,"Locate LSE-63 source and modernize","""In order to annotate LSE-63 with requirements I need to locate the source from [~tony], add it to github and make it work with the new Latex look and feel."""
"DM-10212","Story","Qserv",3,"Check memory locking in containers","""Memory locking should be controlled inside containers"""
"DM-10233","Story","pipe_tasks",1,"getInfoFromMetadata() throws away errors without warning.","""getInfoFromMetadata() throws away errors without warning. This makes debugging writing translator functions very hard."""
"DM-10231","Bug","daf_persistence",1,"FileForWriteOnceCompareSame does not respect umask","""Viz:        This means in particular that {{repositoryCfg.yml}} files will be written with restrictive permissions. See also DM-10229."""
"DM-10229","Bug","pipe_base",1,"pipe_base tests try to write to obs_test","""And then fail when they don't have permission. That is:    """
"DM-10225","Story","obs_ctio0m9",1,"Ingest IMGTYPE along with other header keys","""Ingest {{IMGTYPE}} along with other header keys. Add a translator so that these end up with useful/sane values."""
"DM-10221","Story","pipe_base",1,"Allow --id to use any key in the registry","""As described in DM-5902 it is very useful to be able to specify arbitrary registry keys in the {{--id}} of e.g. {{constructBias.py}}.  Unfortunately only keys that are returned by {{butler.getKeys}} for the appropriate dataset type are currently accepted, even if other keys would be sufficient to define the desired data.    Please fix this.  """
"DM-10220","Bug","Stack Documentation and UX",1,"Miscellaneous corrections to C++ Doxygen guidelines","""The following minor changes should be made to the C++ Documentation style guide:  * The guide should note that multi-line brief descriptions must be prefixed by {{@brief}}.  * The guidelines for covering multiple parameters in a single {{@tparam}} or {{@param}} tag claim that Doxygen can't handle parameters separated by both a comma and a space. Testing has shown that this is not the case; Doxygen correctly identifies what's a parameter and what's the first word of the description.  * Likewise, parameters can be documented as {{\[in, out]}} rather than {{\[in,out]}}.  * The guidelines for the {{@throws}} tag should say how to namespace-qualify exceptions: the rules given for {{@see}} work, but namespace abbreviations must not be used (Doxygen won't resolve the links correctly).    This ticket *should not* be started before July 2017 to give time for more errors to be identified."""
"DM-10242","Improvement","pipe_tasks",1,"Stop using astrometry_net by default","""There is code in {{pipe_tasks}} that uses {{astrometry_net}} to load catalogs and fit astrometric solutions. This ticket is to move to the new reference catalog format and newer astrometry fitter.    Note that when this is done in {{pipe_tasks}} that we can remove {{meas_extensions_astrometryNet}} as a dependency.    I suggest this wait on DM-2186, though that is not strictly necessary."""
"DM-10241","Story","SUIT",1,"Need to fix the East arrow in the North/East compass when close to the polar region","""In http://irsawebdev1.ipac.caltech.edu/firefly/;a=layout.showDropDown?visible=false, search for image: RA = 45, Dec = 89, select IRAS with 5 degree cutout; Add grid, add the North/East compass. The East arrow line should be perpendicular to the North arrow line. """
"DM-10236","Story","meas_mosaic",2,"Properly apply the meas_mosaic solution","""As stated in DM-9862, meas_mosaic assumes the 0,0 for each CCD to be the lower left hand corner.  LSST uses a different coordinate system so meas_mosaic rotates the wcs into the LSST frame when writing to disk.  However the photometric correction is still in the HSC frame, so when applying the meas_mosaic correction we need to rotate the wcs back to the HSC frame.  We can then create the photometric correction, rotate it into the LSST frame and apply it to the image.  We then rotate the wcs back to the LSST frame."""
"DM-10235","Story","pipe_drivers",1,"Bug in coaddDriver when selecting images by PSF quality.","""In DM-9855, the option to select input images based on PSF quality was added and made the default for assembleCoadd in obs_subaru.  However, coaddDriver has its own function to select images and sets the one in assemble coadd to null.  The config in obs_subaru was overriding this and the selection of images was being run twice and having strange results.    The resolution is to set the image selector in coaddDriver to the PSF quality selector and set the assembleCoadd selector to null."""
"DM-10234","Story","Stack Documentation and UX",1,"Submit lsstDebug notes to Developer Guide","""A while back, I wrote some (brief!) notes on {{lsstDebug}}, which I think are more helpful than https://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/base_debug.html. Rather than having them get lost, let's see if we can add them to the Dev Guide.    (Ultimately, they should be in a """"framework"""" section of the pipelines docs,  la DMTN-030. But that doesn't exist yet.)"""
"DM-10252","Bug","pipe_drivers",1,"getOutputId() assumes keys will exist, and doesn't use butler to retrieve them","""In constructCalibs.py, getOutputId() assumes certain keys will exist exist within a dataId. Whilst this information will likely exist in the registry, it _shouldn't_ already exist in the dataId (that's not what they're for), and these should be retrieved at this point using the butler."""
"DM-10251","Story","Continuous Integration",0.5,"weekly release w_2017_16 failed due to lsstsw@lsst-dev breakage","""The jenkins node running as {{lsstsw@lsst-dev}} used for publishing eups distrib packages is unable to build from current master, thus preventing the weekly release process.  Speculation is that some installed products were built from a mixture of the system gcc and devtoolset-3."""
"DM-10281","Bug","astshim",2,"compiler warnings in astshim","""I'm seeing several variants of the following errors in afw builds against astshim:    This happens virtually anywhere there's a call to an AST function with the results of {{.c_str()}}.    I also see two instances of signed/unsigned comparison:      This is with gcc 5.4.0 on Ubuntu 16.04.  """
"DM-10275","Story","SUIT",5,"Add save image button for Plotly charts","""When a chart is plotly chart, image download button should be present on it's toolbar.  Start with png and jpeg (which require no payment plan)."""
"DM-10272","Story","Continuous Integration|stack release",1,"scons build fails under miniconda3 on el6","""We are unable to build on el6/py3 as the {{scons}} product's {{eupspkg.cfg.sh}} references {{python2.7}}.  The system python interpreter on el6 is {{python2.6}}.  If scons is still compatible with 2.6, and we want to support the combination of el6/py3 (???), this could be fixed by changing the interpreter to be {{python2}}.      """
"DM-10271","Story","meas_algorithms",3,"Fix order of operations when using temporary local backgrounds in detection","""Our current implementation of the temporary local background approach to avoiding spurious detections near bright objects simply subtracts a local background from the full image before performing any detection steps.  That can result in missed isolated-object detections and incorrect Footprints for large objects.    Instead, we should:  1. Detect Footprints and Peaks.  2. Subtract the local background.  3. Detect Peaks within each Footprint again, and use the new set of Peaks instead of the old set if and only if there is at least one Peak in the new set.    This really ought to be fixed before the HSC internal release or major HSC processing at NCSA."""
"DM-10270","Bug","ip_isr",1,"isrTask does not provide config option for defects","""Most things in isrTask are configurable, but whether defects masked is not currently protected by a config option, and furthermore, the default behaviour when a defect file isn't found is a fail.    A config parameter should be added to allow not doing defects."""
"DM-10268","Bug","daf_persistence",2,"Butler cannot read a repo using the realpath when it was created with a link ","""With the recent Butler changes (likely when {{_parent}} link was removed), Butler can no longer read an output repo if the repo path was from a symlink.   For example, on lsst-dev, I have a symlink   {{/datasets/hsc/repo/rerun/private/hchiang2/}} -> {{/scratch/hchiang2/hscRerun/}}   (therefore {{/datasets/hsc/repo/rerun/private/hchiang2/xxx}} ==  {{/scratch/hchiang2/hscRerun/xxx}})    so I processed some hsc data and the outputs went to my scratch space   (e.g. {{processCcd.py /datasets/hsc/repo --id visit=18194 ccd=9 --rerun private/hchiang2/xxx}})     Then I tried to read the output repo. I can only read it through {{dafPersist.Butler(""""/datasets/hsc/repo/rerun/private/hchiang2/xxx/"""")}}, but not {{dafPersist.Butler(""""/scratch/hchiang2/hscRerun/xxx/"""")}}.  The latter had errors finding its parent:           Above was with the  {{w_2017_14}} stack. The {{repositoryCfg.yaml}} file in the repo has    {{\_parents: \[../../../..\]}}"""
"DM-10267","Story","daf_persistence|obs_base|pipe_tasks",2,"Port HSC support for PostgreSQL registries to LSST","""At least some of the implementation was in    $OBS_SUBARU_DIR/python/lsst/obs/subaru/ingest.py    on the old HSC fork."""
"DM-10265","Story","afw",1,"Include table persistence docs in Doxygen listing for afw","""There's some documentation at https://github.com/lsst/afw/blob/1d3521f81d348fdc49b708342eba0be1caf5295b/doc/tablePersistence.dox which seems useful, but is basically impossible to find in Doxygen. Let's include it on the list at https://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/afw.html."""
"DM-10302","Story","afw",8,"Rename ""*_flux"" fields to ""*_instFlux"" in SourceCatalogs","""This is the implementation ticket for RFC-322. The implementation is as follows:    * Rename all of our {{*Flux_flux}}/{{*Flux_fluxSigma}} table fields to {{*Flux_instFlux}}\{{*Flux_instFluxSigma}} to hold the post-ISR counts.  * Add {{*Flux_flux}} and {{*Flux_mag}} fields for the post-calibrated flux (in Maggies) and magnitudes.  *Rename the {{InstFlux}} slot to {{GaussianFlux}}, and remove the {{InstMag}} slot.  * Add associated documentation to the above.  * Pass these changes on to the relevant database groups to update e.g. {{cat}}.    Implementing this will wait until Calib is removed from the stack and replaced by PhotoCalib (not yet scheduled, but likely within the next couple months)."""
"DM-10295","Story","dax|metaserv",1,"Fix metaserv v0 table listing and deploy docker containers","""metaserv table listing uses {{information_schema}}. It should utilize DBRepo and DDT_Table in metaserv."""
"DM-10292","Story","afw",0.5,"The FrameSet returned by Transform.getFrameSet can change the contained FrameSet in Python","""The {{ast::FrameSet}} returned by {{Transform.getFrameSet}} is not immutable in Python, and modifying it modifies the frame set owned by the transform. In C++ the returned FrameSet is immutable, but that is impossible to enforce in Python, so the obvious fix is for the Python wrapper to return a copy."""
"DM-10289","Bug","afw|pipe_tasks",1,"record.setValidPolygon(xxx) does not accept None as a valid input anymore ","""makeCoaddTempExp is crashing at https://github.com/lsst/pipe_tasks/blob/master/python/lsst/pipe/tasks/coaddInputRecorder.py#L148 because None is not accepted anymore as a valid input for record.setValidPolygon.    Just skipping this instruction when there is no valid polygon set in the exposure seems to be a possible workaround"""
"DM-10288","Bug","jointcal",1,"afwImage.TanWcs.cast() not supported anymore in jointcalCoadd","""The cast at : https://github.com/lsst/jointcal/blob/master/python/lsst/jointcal/jointcalCoadd.py#L54 is not supported anymore and is probably useless since the pybind11 migration"""
"DM-10287","Story","meas_base",0.5,"Add measurement plugin to store footprint area","""This is a trivial feature request that would have also been very useful on DM-9962.  In terms of effort it should be """"in the noise"""" of everything else blocking DM-10266, so I'm going to try to get it in."""
"DM-10305","Story","SUIT",2,"Update firefly_widgets for changes in external dependencies","""Update firefly_widgets to account for some changes in external dependencies:    * Generalize the connection parameter, for working with Firefly servers now being deployed with {{suit}} or {{irsaviewer}} in the URL, as was done for firefly_client in DM-9843  * Make some minor syntax changes to work with ipywidgets 6.0  * Update example notebooks accordingly"""
"DM-10304","Story","Design Documents",3,"Create tech note describing options for DM software releases","""Following RFC-188 and discussion the 2017-04-17 DMLT meeting, discuss options for the DM release process with stakeholders and create a technote summarising important considerations."""
"DM-10338","Bug","meas_base",0.5,"Mix of tabs and spaces in breaks meas_base builds","""Seems to have been introduced in DM-430; [~pgee], please make sure your editor is configured to use spaces instead of tabs."""
"DM-10336","Bug","afw",0.5,"DM-10271 seems to have broken afw","""As of DM-10271 I can no longer build afw on my Mac. I see errors such as:    I am using a Python 3 lsstsw stack on macOS 10.12.4 with the current clang: Apple LLVM version 8.1.0 (clang-802.0.42)"""
"DM-10333","Bug","obs_base",1,"duplicate keys in obs_base/policy/datasets.yaml","""For example: 'processCcd_config' and `characterizeImage_config` both occur twice.  Maybe others?    Not a problem right now since the values are the same for a given key (at least for the two examples above), but could lead to errors in the future if, for example, second entry overrides the first.    Should probably use a yaml loader that would raise an exception on duplicate keys, e.g.,  https://gist.github.com/pypt/94d747fe5180851196eb  """
"DM-10332","Story","meas_deblender",5,"Test deblender with exact positions","""[~pmelchior] and I believe that the main failure of the current deblender is due to the difference between a sources peak position and its integer position in the pixel grid, which causes the symmetry operator to fail. In DM-10189 we created a translation operator that can shift the position of the peak to a fractional position and before we implement a solution to fit this position (DM-10310) it will be advantageous to check use the exact position (known in a simulated image) and see if this resolves the problem.    There is no reason to proceed with DM-10310 until we are sure that better positions and the translation operator will improve the deblender performance.    Since this ticket requires re-writing the functions that calculate the likelihood, this will also include updating the intensity matrix ({S}} in the NMF code) so that each source is in the center pixel. This suggestion by [~jbosch] allows each source to use the same monotonicity and symmetry operators, whose calculation were one of the more time consuming parts of the new deblender. It should also make optimization easier once parts of the code are ported to C++."""
"DM-10329","Story","wg-supertask",2,"Write up Science Pipelines perspective on SuperTask interfaces and concepts","""Describe (my) perception of the current state of the SuperTask interface from the Science Pipelines perspective to gather feedback from other Science Pipelines stakeholders and clarify any problems to the rest of the SuperTask working group."""
"DM-10349","Story","Firefly",2,"Chart expression logarithm to be the same as other languages","""In Firefly  chart column expression, we use log() as 10-based logarithm, ln() as natural logarithm.     I checked Python, Perl, C, C++, Java, the convention is to use log() as natural logarithm, and log10() as the 10-based logarithm.     We need to make the change and document it. """
"DM-10344","Story","SUIT",0.5,"The Validate failed to validate the integer range","""In HistogramOption, the numBins field used the validator: """"Validate.intRange.bind(null, 1, 500, 'numBins')"""" to validate its value.  However, when the empty string is entered in to the  numBins, the validation still shows it is valid.  The empty string is not in the range of 1-500, by definition, it is not valid. """
"DM-10343","Story","Developer Infrastructure",1,"Update lsst-dev shared stacks to use devtoolset-6","""Update both shared stacks on {{lsst-dev01}} to build against devtoolset-6.    Since this won't be ABI compatible with the earlier (no-devtoolset) stacks, we'll need to create entirely new stacks, which should probably build over a weekend."""
"DM-10370","Story","SUIT",8,"Refactor server side image code so that we cut memory size in half","""Moving some of the image processing to the client side allows us not to use as much memory on the server. We currently keep to versions of the FITS data a 2D array and a 1D array.  Remove the need to hold on to the 2D array."""
"DM-10360","Story","Qserv",2,"Documentation for generating statistics for L2/catalog data","""Statistics were generated at IN2P3 for correcting {{JOIN}} queries. The general process needs to be documented so we can optimize it in the future (see DM-9757 for reference)."""
"DM-10391","Story","Science Platform",5,"jupyterlab technote","""Work involved in SQR-018."""
"DM-10386","Story","afw",1,"Add Constructor documentation to Footprints","""Somehow in my many rebasings I lost the doxygen documentation to the Footprint constructors. Add that documentation back in."""
"DM-10381","Story","meas_deblender",1,"Enhance test for meas_deblender's clipFootprintToNonzeroImpl","""In DM-10361, [~nlust] added a quick fix for a problem in this function which was breaking the stack demo.    That fix has done the trick, but it would have been nice to be able to catch the problem before it propagated as far as it did. There's already a fine unit test for this function; extend it to catch the problematic case."""
"DM-10379","Bug","Firefly|SUIT",2,"After a catalog search with a globe coverage map, the catalog search doesn't work anymore.","""In today's build, either http://irsawebdev1.ipac.caltech.edu/firefly/ or http://irsawebdev1.ipac.caltech.edu/irsaviewer/, a bug is found:    Catalogs, WISE, m81, search; then Catalogs, WISE, m31, search; Now the coverage map is shown as a whole globe. Now select Catalogs, it won't work. If select Images, this search panel can't proceed to search or being cancelled.    The error message:  CatalogSearchMethodType.jsx:179 Uncaught TypeError: Cannot read property 'x' of null      at a (CatalogSearchMethodType.jsx:179)      at Object.s [as reducerFunc] (CatalogSearchMethodType.jsx:395)      at J (FieldGroupCntlr.js:384)      at Z (FieldGroupCntlr.js:363)      at p (FieldGroupCntlr.js:274)      at combineReducers.js:132      at d (createStore.js:179)      at middleware.js:52      at index.js:75      at Object.dispatch (index.js:14)    """
"DM-10398","Story","meas_astrom",8,"Analyze run metadata from validation runs","""Analyze and make summary plots for the metadata collected in DM-12440.  This may involve investigating further any failure modes that may have cropped up."""
"DM-10393","Story","ctrl_platform",0,"correct variable name in sites.xml template","""Need to fix a typo in a variable name."""
"DM-10392","Story","Qserv",5,"Upgrade kubernetes/docker on cc-in2p3 cluster","""Work performed in DM-10314, DM-10212 and DM-10042 has to be integrated on cc-IN2P3 nodes ccqserv100->124."""
"DM-10401","Bug","utils",1,"getPackageDir raises RuntimeError instead of pex::exceptions::NotFoundError","""The documentation for {{utils.getPackageDir}} claims {{@throw lsst::pex::exceptions::NotFoundError if desired version can't be found}}, but it actually raises {{RuntimeError}}:        We should either fix the docstring, or fix what is raised (likely at the pybind11 layer).    We also need to fix the {{GetPackageDirTestCase}} unittest so that it tests against the correct exception being raised (it currently tests {{Exception}}, which is unhelpful)."""
"DM-10421","Story","Design Documents",1,"Publish LDM-294 draft to LSST the Docs","""Publish [LDM-294|https://github.com/lsst/LDM-294] to LSST the Docs, with a landing page pointing to PDFs. This landing page is an MVP that will be improved and made generally available for all LaTeX-based DM documents."""
"DM-10416","Improvement","afw",0,"Make lsst.afw.geom.Transform and SkyWcs pickleable","""The new `lsst.afw.geom.Transform` classes and the subclass `SkyWcs` should be pickleable.    One possibility is to pickle the string representation for the contained FrameSet."""
"DM-10441","Bug","ImgServ",2,"Image cutout is off the center when size specified in Ang degrees.","""Following update from DM-10364, David Shupe reported seeing cutout images (calexp) is off the center.  Further diagnosis revealed it's only the case when the cutout size is specified in Ang Degrees, not by 'pixel'."""
"DM-10439","Bug","Firefly|SUIT",2,"bug in WCS match or compass overlay ","""Access PDAC http://lsst-sui-proxy01.ncsa.illinois.edu/suit, follow the steps and see the bug  appear:    # search CCD exposure images at position (0, 0)  # filter on run = 5895  # turn on WCS match  # turn on compass overlay  # r-band image has east up while all other bands have east down  # click on North up icon, r-band compass has North down    Attachment is the portal after WCS match and north up actions.  """
"DM-10438","Story","Science Pipelines",2,"Add DCR model data types","""To use existing code in the stack for multi-band photometry, forced photometry, etc.. on the models generated with the DCR algorithm, many data types need to be added to obs_base. These will be added using the current name 'dcrModel' throughout, though it is expected that name might change following the eventual RFC to add the data type."""
"DM-10433","Story","Firefly",1,"Build date information at wrong place in small browser window","""Usually the application build date is at the bottom of the browser window on the dark bark. But when the browser window is small, the build date information flows up at the bottom of the visible portion of browser window.     We need to fix it. """
"DM-10430","Improvement","ctrl_pool",1,"Add time stamps to the standard outputs to BatchCmdLineTask","""Add time stamps to the logs by default in {{ctrl_pool}} jobs.  In slurm jobs, this changes the log format in the JOBNAME.oJOBID log files."""
"DM-10427","Story","ImgServ|webcommon",20,"Establish sha256 hashing framework for VO API and content signatures","""The idea of introducing SHA256 hashing in VO context is for the quick identification and verification of signatures for API method calls, as well as the returned content such as generated FITS images, which will become handy for caching and asynchronous operation."""
"DM-10426","Bug","Qserv",2,"Identify stable version of kubernetes and docker on openstack","""Kubernetes and Docker have provided quick update which have broken both openstack and cc-in2p3 setup. Stable version and configuration have to be identified."""
"DM-10453","Bug","meas_astrom",2,"Fix bugs in matchPessimisticB","""Bugs have been found in the latest refactor of matchPessimsiticB that effect performance of the matcher.    failedPatternList persists between runs of MatchPessimisticBTask when running a range of ccds in the same processCcd run.  failedPatternList is not currently used properly in the matcher loop.  The pair_id lookup table is not filled with the correct data for half of the matrix."""
"DM-10452","Story","obs_base",1,"Create bboxFromIraf function in obs_base utils","""Create (move) utility function to create a bbox from from an IRAF box from obs package to obs_base so others can use it."""
"DM-10465","Story","Firefly|SUIT",8,"Better error messages for position input","""When user input a position like (-34, 23) or (123, -91), Firefly treated it as object name and gave the error message """"Could not resolve Object: Enter valid object"""". It is hard for user to understand exactly what was wrong with the input. In reality it is the position out of range error. Firefly should provide better error message for situation.    Another issue: """"12.3, 23.4"""" is valid input, but """"12.3, 23.4 gal"""" is not. And we have an example for the latter in the input pane.    input """"18.0, -23.0"""" has been interpreted into """"18.0,-23.0Equ J2000 """". but the latter is invalid    input """"12 34 56.89 -23 45 16.56"""" has been interpreted into 12h00m00.00s,-23d00m00.0sEqu J2000"""
"DM-10461","Story","SUIT",0.5,"WCS match can be a little off for plots that are nearly north","""There is a roundoff error for computing rotation for plots that are nearly north"""
"DM-10455","Story","dax|db|dbserv",1,"Use pool_recycle=3600 for long-lived database connection pools","""We get """"mysql server has gone away"""" errors when dbserv hasn't been used in a while. This might not be a problem in the future, but it's a problem with pooled connections too.      The fix is to use pool_recycle parameter when creating sqlalchemy:    http://docs.sqlalchemy.org/en/latest/core/pooling.html    3600 seconds is probably appropriate."""
"DM-10477","Story","Firefly|SUIT",2,"""WCS match""  checkbox on/off behavior improvements ","""Current behavior:  When there are more than one images displayed,  turning """"WCS match"""" checkbox on will zoom and rotate all the images to the same pixel size and direction as the active image (selected, with orange color highlight), turning the checkbox off does nothing.     Improvement:  Turning off the """"WCS match"""" should reset the images to a zero rotation.    Also include two bug fixes:    - A rotation issue: clicking rotate north on north up images fliped them south  - When north is up, clicking north up makes the image rotate south.    """
"DM-10486","Bug","afw",3,"warpExposure and warpImage do not test correctly for dest = src","""warpExposure and warpImage are supposed to throw an exception if destImage = srcImage. However, the unit test for this is mis-written, due to checking for Exception being raised, instead of a more specific exception, hiding other problems. The test case in question is {{testWarpIntoSelf}}.    Worse, on my Mac, when I correct the test I find that it is possible to warp one image or exposure into itself, even though this results in altering the supposedly const input image and produces an incorrect destination image. Thus the C++ code that attempts to check for dest == src is not working."""
"DM-10483","Story","meas_deblender",1,"Create testdata_deblender Repo","""Create a repository to store data for testing {{meas_deblender}}. At present this is the simulated data generated by [~rearmstr] in DM-9644 but later is likely to include public HSC data of particularly difficult blends."""
"DM-10496","Bug","astshim",1,"test_chebyMap.py sometimes segfaults","""test_chebyMap.py occasionally segfaults when run on my Mac (something on the order of 1 in 10 times). When this occurs it happens almost immediately and no output is printed.    One thing to try is updating to the latest AST since a known bug in the Chebyshev handling of AstPolyTran has been fixed. If that doesn't solve the problem then more digging will be required (e.g. valgrind, but that would be much easier if I could write a pure C++ program that exhibited the behavior)."""
"DM-10495","Story","jointcal",1,"turn on travis and flake8 protections in jointcal","""The branch protection+travisCI+flake8 system will soon be made available for activation on LSST repositories. I've volunteered be a non-SQuaRE person to test the process, using the jointcal repo (which has a very small list of commit users right now).    Once the """"final draft"""" instructions are available, I'll follow them for jointcal and provide feedback to SQuaRE."""
"DM-10490","Story","obs_subaru",1,"Cache camera in HscMapper","""The lion's share of the time in instantiating a butler goes to building the camera object, because that involves parsing a {{Config}} with many lines, and a {{stat}} call for each line to get the traceback.  Multiple butler instantiations (e.g., for multiprocessing or pipe_drivers) could benefit from caching the camera once it's built."""
"DM-10512","Story","Developer Infrastructure",1,"Upgrade IPython on the shared stack to >=5.2","""The current version of IPython on the shared stack on lsst-dev is 5.1.0    Unfortunately, 5.1 introduced a nasty bug that makes it ~impossible to quit ipdb in any remotely sane manner. All versions >=5.2 fix this.    For details, see the first bullet point in the changelog for the 5.2 release on  http://ipython.readthedocs.io/en/stable/whatsnew/version5.html#ipython-5-0  """
"DM-10511","Story","Design Documents",1,"Apply Tim's comments to LDM-151","""Apply comments"""
"DM-10508","Bug","ip_diffim",1,"Remove writing of warped template added in DM-8145","""I accidentally committed a line added for debugging, which saved the warped template in ImagePsfMatchTask. Delete this line."""
"DM-10505","Story","validate_drp",2,"Robustify validate_drp fitting and catching errors.","""First attempt to run `validate_drp` on HSC data failed with the following:        1. [X] Catch errors in computing things, recover, and do something reasonable.  2. [X] Make the fitting more robust."""
"DM-10502","Story","meas_deblender",1,"Update NMF deblender to use new footprints","""Development on the new deblender has been using an older version of the stack before the new footprints were pushed. In order to complete DM-9784 it is useful to have access to the new {{Footprint}}/{{SpanSet}} API, so this ticket will update the user branch {{u/fred3m/deblender}} that the holds the new deblender work to the current version of the stack."""
"DM-10522","Story","Science Pipelines",3,"Make dcrCoadds proper coadds","""The dcrCoadd dataset type needs to be compatible with existing tools and functions that process coadds. """
"DM-10521","Story","validate_drp",3,"Create script to produce release performance table","""Take the JSON output of a {{validate_drp}} run and produce a report suitable for a Characterization Metrics Report.    See, e.g.,     https://pipelines.lsst.io/metrics/v13_0.html#metrics-v13-0    https://github.com/lsst/pipelines_lsst_io/blob/master/metrics/v13_0.rst    and the attachment for an example to how to format things.      """
"DM-10520","Bug","SUIT",3,"""Restore to the defaults"" icon doesn't work properly","""Build firefly from today's dev (May 11, 2017, the last commit is dd74beba73c8ab99bc8751b329bcf7e36627e591).  Open firefly, search image, target = m81, WISE and SDSS. Select WISE image. Change to single image mode. Zoom out the WISE image. Click the """"Restore to the defaults"""" key: The WiSE image is restored to the original size but right after that the SDSS image pops up.   The restore key should only do the restoring job, not changing images.   """
"DM-10516","Story","ap",1,"Default Null type for Avro schema may be incorrect","""The current Avro schemas in lsst-dm/sample-avro-alert (and also in ZTF's schemas) can give a warning when decoded in Spark using that says (e.g., shows up I think for all nullable fields):        This happens when I use Spark package com.databricks:spark-avro_2.11:3.2.0, create a SparkSession, and read data this way:        This might be because null needs to be in quotes and it isn't?  I don't know.      This story is try quotes around """"null"""" type in default type field and see if     1) the Spark warning goes away  2) data still serializes/deserializes with plain Python modules and nullable fields   """
"DM-10514","Bug","Qserv",2,"Check qserv/qserv:dev works correctly","""This container was broken, it will be re-generated and tested on Galactica and ccqservxxx."""
"DM-10530","Story","obs_base",1,"don't set filter if the filter ID is not UNKNOWN (instead of testing if filter is None)","""the filter is never None, but it can be not-set. In that case the Id is Filter::UNKNOWN."""
"DM-10532","Story","Design Documents",2,"Pursue project-level policy on secure external protocols","""We would like to recommend that the DM-level policy adopted under RFC-326 be promoted to a project-level policy.  This action is to begin work on that, which might take the form of submitting an LCR advocating adopting this as an OSS-level requirement, or as a separate policy document.    The basic policy proposed is that all services facing the public Internet should use secure protocols, unless a specific, technically justified exception is adopted via formal change control and with sign-off from the ISO."""
"DM-10531","Story","Design Documents",1,"Add DM-level policy on use of secure Web protocols to LDM-148","""Implement the consensus decision on RFC-326 to state, as a DM policy, that all services facing the public Internet will use secure protocols (https:, in particular, for Web services), unless a specific technical justification for not doing so is accepted by the DM-CCB and the project ISO."""
"DM-10546","Story","meas_mosaic",1,"meas.mosaic.updateExposure.applyMosaicResultsExposure will not if there is no mosaic solution","""Furusawa-san pointed out that coaddDriver can produce outputs even if mosaicking has not been run though {{doApplyUberCal=True}} (which is the default value for HSC). This appears to be due to allowing null values of the {{wcs}} and {{ffp}} in {{updateExposure.py}}.    We should allow the functions in there to fail if the appropriate values are not available, or the user can be deceived as to what corrections have actually been applied."""
"DM-10542","Story","afw",2,"Replace XYTransform::linearizeTransform","""Many clients of {{XYTransform}} use its methods {{linearizeForwardTransform}} and {{linearizeReverseTransform}}. We do not yet have analogous code for {{Transform}}. This functionality can be implemented as either a method on {{Transform}} or a separate function; the latter would provide better encapsulation."""
"DM-10541","Story","afw",1,"Add properties to image classes","""This is the most obvious and useful application of RFC-279:   - Add {{image}}, {{mask}}, and {{variance}} properties to {{MaskedImage}} (and {{Exposure}}, for convenience).   - Add a {{maskedImage}} property to {{Exposure}}.   - Add {{array}} properties to {{Image}} and {{Mask}}.    These will cut down on unnecessary characters and save us from having to make temporary variables in order to assign to an image component.  """
"DM-10553","Technical task","meas_deblender",1,"Correct simulation positions","""There are two issues with the simulation positions, both of which are likely related.    The images created in DM-9644 are split into 4 quadrants, each of which is generated separately. The intensity values in the simulated tables are only the size of the quadrants, not the entire images,  so the x,y positions in the table do not correspond to the position of a source in it's intensity image.    The other issue is that the x,y positions in the catalog can be off by 1/2 pixel, which might depend on the quadrant chosen. In this case all of the positions will need to be adjusted accordingly.    This ticket will use the position of the source to determine the quadrant it is located in to adjust the x,y positions to the correct positions in the quadrant, and make any adjustments needed to properly align the sources with the image."""
"DM-10552","Story","SUIT",2,"Upgrade display_firefly to work with more servers","""Implement changes to display_firefly to enable it to work with more servers, and fix some issues found in testing.    * Add a {{basedir}} parameter, to make use of the capability added in DM-9843, to allow the firefly backend to be used with the PDAC server and the public IRSA server.  * Pass keyword arguments to the FireflyClient constructor.  * Update the image and mask handling, in part for changes due to the pybind11 conversion, and to restore mask labeling.    In afw.display:    * Fix the \_\_getattr\_\_ method of the display interface  * Reorder tests so that displays are not closed prematurely"""
"DM-10551","Technical task","meas_deblender",2,"Display templates together","""It will be useful to have a script that can compare peaks using several different deblender methods side-by-side."""
"DM-10550","Technical task","meas_deblender",2,"Convert comparison text to plots","""A lot of the data comparisons, like {{compareMeasToSim}} display a lot of information in text that would be easier to digest (and more compact) in the form of plots, which need to be created."""
"DM-10549","Technical task","meas_deblender",3,"Use all simulated peaks","""One of the shortcomings of the NMF deblender is that undetected sources wreak havoc on detected sources, where the likelihood causes detected sources to account for the extra flux with no local peak to attribute it to.    [~pmelchior] and I have discussed methods to work around this problem but in the short term it will be easier to just use the exact locations of all of the objects from the simulated catalog, as opposed to only fitting the peaks detected by the pipeline.    This ticket will give the user the option of using a set of simulated peaks instead of the detected peaks."""
"DM-10559","Story","afw",1,"afw.image.makeWcs() returns null pointer without warning","""Line 49 of https://github.com/lsst/afw/blob/master/src/image/makeWcs.cc should log a warning before returning a None wcs, as it makes it hard to track things down without it."""
"DM-10558","Story","daf_persistence",1,"disable or remove butler caching","""the reused object aspect of caching (documented in LDM-463 draft) is causing confusion because shared objects can be mutated, and this is not what some developers would expect. Disable it and/or remove the code for now. If it's wanted, we can have an RFC or RFD about how to handle mutable objects.    Also update LDM-463 (remove the bit about caching)  """
"DM-10557","Technical task","meas_deblender",2,"Use SingleFrameMeasurementTask to test deblender results","""Because the simulated galaxies we are using to configure the deblender are extended with very large wings, comparing the deblended flux with the simulated flux is deceptively difficult. The problem is that a large percentage (as much as 50%) of the simulated flux can lie below the noise level, where it is truncated in the deblender, making it difficult to compare the total flux of each object.    It was recommended by [~jbosch] that running {{SingleFrameMeasurementTask}} on both the deblender output and simulated images will allow us to make a better comparison of the results.     This ticket will implement a set of tests using {{SingleFrameMeasurementTask}}."""
"DM-10563","Technical task","meas_deblender",1,"Migrate to non-LSST deblender packages","""Much of the new deblender's design was written by [~pmelchior] as part of a similar effort for WFIRST. This has included the creation of two new packages, one that uses proximal operators to solve minimization problems and another that implements an NMF deblender. Currently development is occurring on both the stack and the new packages, but the structure of the external packages is changing as we prepare for publication and it is becoming increasingly difficult to co-develop them.    Eventually all of the stack code will be refactored to optimize the NMF deblender, so to make it easier to share changes with [~pmelchior], {{meas_deblender}} should be modified _slightly_ to call the two external packages when applicable.  This amounts to removing {{proximal_nmf.py}} and instead making a call to the new deblender package, which has a nearly identical API and with some performance improvements, including an angular symmetry operator.    This ticket will strip out the unnecessary modules in {{meas_deblender}} and make calls to the new {{deblender}} and {{proxmin}} packages."""
"DM-10576","Story","dax|dbserv",1,"Propagate information from qserv exceptions in dbserv","""QServ throws non-standard MySQL exceptions. mysqlclient/MySQLdb doesn't propagate errors higher than a predefined number, so it returns an error code of -1 with message """"Totally whack"""" The goal of this issue is to propagate the errno and error in that exception."""
"DM-10575","Story","obs_decam",1,"obs_decam build takes 10 minutes","""Running under Jenkins:      I believe this is due to running {{ProcessCcdTask}} within the {{TestCase.setUp}}; it should be in the {{TestCase.\_\_init\_\_}} so it only gets run once."""
"DM-10574","Story","meas_deblender",1,"Hit AssertionError in deblender","""In a validation run for hscPipe 5.0-beta5:      After a bit of poking, I believe it's due to the use of {{LOCAL}} [here|https://github.com/lsst/meas_deblender/blob/master/python/lsst/meas/deblender/plugins.py#L282]."""
"DM-10597","Bug","SUIT",1,"firefly_client upload_data test fails with Python 2","""The FireflyClient upload_data  and upload_file methods includes a test upload of a small number of bytes using io.StringIO. StringIO must be given a Unicode string, which is not the default for strings in Python 2.    The fix is to explicitly specify Unicode, e.g. io.StringIO(u'test'). """
"DM-10594","Story","ci_hsc|Stack Documentation and UX",2,"Investigate apparent slow-down of ci_hsc","""ci_hsc is now taking over an hour to run, when it used to take around half an hour. Why?"""
"DM-10603","Story","Science Platform",2,"Outline for Science Platform design","""Prepare an outline for Science Platform design document"""
"DM-10601","Story","SUIT",5,"Add reStructuredText documentation to display_firefly","""Add documentation in reStructuredText format to the display_firefly package, in a doc/ subdirectory. The documentation will include setup of the afw.display interface, including the host, port, etc. parameters that are specific to display_firefly. Other points (like known issues) unique to display_firefly will be covered.    display_firefly is not yet included with lsst_apps or lsst_distrib. Initially, an Installation section will be included. It is expected to replace the contents with links to centralized pages on how to install additional packages against a core stack installation.    Copied for pull request  https://github.com/lsst/display_firefly/pull/7  * Add doc/_static placeholder README  * setup initial files following validate_base as template  * add installation, start tutorial  * ignore eupspkg directory  * add setup of display_firefly for Python API ref  * add introduction, installation content  * fill out rest of Using... section  * Pin Sphinx<1.6.0  * Various reStructuredText formatting fixes  * reformat Makefile  * Merge branch 'tickets/DM-11017' into tickets/DM-10601"""
"DM-10623","Bug","log|pipe_base|pipe_tasks",1,"Mismatching dataId in logger output","""When running {{processCcd.py}} on multiple visits, self-contradictory outputs are generated by the logger. For example:        and        The problem above is that the visit numbers don't match, but there should be no way for this to ever be the case, as far as I can see. FWIW, the second number is the true visit number, at least in my case.    This is only noticeable when {{--longlog}} is used, to allow disentangling of parallel processed data, but I don't know whether that means the logger is also wrong when sequentially running multiple visits on a single core (I suspect it's OK in that instance, but I'm not certain).    This bug is _bad_ for tracking down which visits are failing and why."""
"DM-10621","Story","pipe_base",1,"ArgumentParser's butler doesn't output calibs in the calib storage","""Following DM-8686 (between tagged weeklies {{w_2017_11}} and {{w_2017_12}}), the {{constructBias.py}} (etc.) scripts in pipe_drivers write their outputs in the output storage rather than in the calib storage (e.g., {{/tigress/pprice/ci_hsc/DATA/rerun/ci_hsc/BIAS/2017-12-34/NONE/BIAS-2017-12-34-012.fits}} instead of {{/tigress/pprice/ci_hsc/DATA/rerun/ci_hsc/CALIB/BIAS/2017-12-34/NONE/BIAS-2017-12-34-012.fits}}).    This appears to be due to the output repo being unaware of calibs because it's not being told about them by the {{ArgumentParser}} in pipe_base.    This was originally reported by Furusawa-san at NAOJ."""
"DM-10617","Story","ndarray",2,"Fix ndarray type casters to work with nullptr (i.e. None) arguments","""In contrast to the regular pybind11 type casters the ndarray ones don't work well with {{nullptr}}.  E.g. the function {{void testOptionalArray(ndarray::Array<double, 1, 1> * arr = nullptr)}} should accept {{None}} as a default argument, but it does not."""
"DM-10615","Story","meas_deblender",8,"Convolve to common PSF","""The current PSF operator in the new deblender uses the PSF for the image in each band to attempt to deconvolve the image to a single pixel. This appears to be causing issues with deblending the wings of faint extended objects that are not seen when using PSF-matched images and no PSF operator (see attachments for an example).    It is thought that convolving the image in each band to a common PSF (such as the best seeing)  will remove the artifacts that the current PSF convolution operator produces."""
"DM-10613","Story","meas_deblender",3,"Implement smoothness constraint","""When using images not convolved with the PSF, we've long known that """"snowflakes"""" or spiky fractal-like structures are created due to the monotonicity operator. It is likely that a smoothness operator, which is used in compressive sensing applications, will be able to fix (or at least suppress) this problem."""
"DM-10612","Story","meas_deblender",3,"Implement strict monotonicity","""The current deblender uses an update scheme similar to ADMM, where constraints are not strictly enforced in any given step but instead the solution converges to meet the constraint. It should be possible to make monotonicity a proximal operator applied to the likelihood gradient, as opposed to a linear constraint, which will force a strict monotonic solution.    This ticket will be an attempt to add the option of using strict monotonicity in the deblender."""
"DM-10633","Story","pipe_base",1,"Increase CmdLineTask multiprocessing timeout","""The timeout in {{CmdLineTask}} catches a lot of people unawares, and causes lots of confusion and annoyance. It's necessary (because of that python {{multiprocessing}} bug) to have _some_ value, but as soon as we stick a value in people manage to exceed it. [~mfisherlevine] had a good idea: we make the value a number _per target_, which will make it harder to exceed when people throw lots of data at {{-j}}. That just means calling {{getTargetList}} a bit earlier."""
"DM-10737","Story","meas_mosaic",0.5,"Make meas_mosaic use new reference catalogs by default","""DM-2186 broke meas_mosaic (not surprising since it isn't in CI), and it looks like the right fix is to move the configuration that makes us use the new reference catalogs instead of astrometry.net into meas_mosaic itself, since there's no point having an override in obs_subaru when only obs_subaru uses meas_mosaic.  """
"DM-10691","Story","supertask",1,"SQuaRE SuperTask Collaboration Week of 2017-04-17","""Bucket ticket to cover non-specific SuperTask collaboration activities"""
"DM-10690","Story","supertask",1,"SQuaRE SuperTask Collaboration Week of 2017-04-10","""Bucket ticket to cover non-specific SuperTask collaboration activities"""
"DM-10686","Story","skymap",1,"RingsSkyMap.findAllTracts() behaves oddly at poles","""Sogo Mineo writes:  {quote}  I found that RingsSkyMap.findAllTracts() behaves oddly at poles.    The docstring of RingsSkyMap.findAllTracts(self, coord) says it returns a list:  https://github.com/lsst/skymap/blob/master/python/lsst/skymap/ringsSkyMap.py    When coord is IcrsCoord((0, -90), degrees), however, findAllTracts() returns not a list but a TractInfo. (line 163).    When coord is IcrsCoord((0, 90), degrees), it raises an error because line 166 """"return self[-1]"""" is wrong. It has to be """"return self[len(self)-1]"""".  {quote}"""
"DM-10748","Story","Data Release Production",2,"Test meas_mosaic pybind11-related fix by RC data processing  ","""Test the corrections made in {{meas_mosaic}} in DM-10688 by running a full HSC-RC run with the current stack to see if the ellipticity residuals are better."""
"DM-10779","Story","Alert Production",8,"Implement running time metric(s)","""By the All Hands Meeting, we should be able to demonstrate verification metrics by reporting running times (wall-clock) for AP pipeline stages. This ticket covers writing code for applying the {{verify}} framework to inline tests, profiling each stage, and supporting SQuaSH export (though the export itself is the responsibility of {{verify_ap}}).    See DM-11118 for a list of pipeline stages. This ticket may report metrics at a finer-grained level than is presented there."""
"DM-10778","Story","butler",5,"Add metadata access for Filter","""Please add metadata access for {{Filter}} objects via the same pattern used to implement {{DM-9060}}.  I hope this is essentially trivial."""
"DM-10777","Story","afw|astshim",8,"Create TransformBoundedField","""Jointcal's improved photometric fit is done on the full focal plane, and thus we need its persisted output to be able to convert pixel coordinates on one CCD to the focal plane. Probably the easiest way to implement this is to create an {{astBoundedField}} that we can put into a {{PhotoCalib}}.    We may eventually want to replace {{PhotoCalib}}'s use of {{BoundedField}} internally with AST, but for consistency with [~jbosch]'s {{meas_mosaic}} work, keeping the {{PhotoCalib}} interface the same is probably best.    For reference, jointcal's photometric output looks something like {{f(g(x,y))*h(x,y)}}, where {{(x,y)}} are in pixel coordinates, {{g}} is the pixel to focal plane transformation, {{f}} is a Chebyshev polynomial, and {{h}} is some chip-level transform (currently a constant).    Tagging this PairCoding, as it might be nice for me to sit with [~rowen] as he works on it, to aid my familiarity with AST."""
"DM-10769","Epic","afw",40,"Astropy integration for F17","""It has been deemed useful to integrate with astropy where possible.  In particular, we should integrate with NDData."""
"DM-10764","Improvement","afw|astshim",2,"Rename Transform::of and Mapping::of to ::then","""astshim.Mapping and afw.geom.Transform both support concatenation using {{of}}. However, we normally specify transforms as """"aToB"""" (e.g. pixelsToSky), resulting in this awkward notation:    To make code easier to read I propose renaming """"of"""" to """"then"""" and swapping the order of concatenation, resulting in the following:    This also follows the constructor order for SeriesMapping:      I propose to do this soon, while Transform is still not used in the DM stack."""
"DM-10760","Story","pipe_tasks",0.5,"Switch warpType from enum to strings","""DM-8491 added some code that enumerated warpTypes as enum.Enums.  This third party package is not an official dependency. Backing that out. """
"DM-10807","Story","ImgServ",13,"Create command line interface (CLI) for ImgServ","""This ticket will de-couple the REST interface, and potentially the VO API layer as well, from ImgServ Core, which will then become a library, thus enabling greater flexibility for change the web front ends while providing scalability to handle service requests. After completion, be able to perform a simple VO operation:  is service available? """
"DM-10805","Story","ip_diffim",8,"Spatially-varying ZOGY option","""Use ImageMapReduce to implement a spatially-varying A&L decorrelation task. Integrate that task as an option in imageDifference.py.    Will possibly want to implement it as a subclass of ImagePsfMatchTask, because that task includes wrapper code for warping, which will be necessary here."""
"DM-10800","Story","meas_algorithms",1,"Merge matcherSourceSelector and matcherPessimisticSourceSelector","""DM-9751 created a new source selector that inherits from matcherSourceSelector called matcherPessimisticSourceSelector. This source selector is a stop gap measure to preserve the behavior of matcherSourceSelector for matchOptimisticB. If the new matchPessimisticB is adopted from a future RFC as the default matcher this ticket will merge the two source selectors and matcherSourceSelector with take on the behavior of matcherPessimisticSourceSelector."""
"DM-10799","Improvement","afw|astshim",0.5,"Rename Transform::tranForward to applyForward","""The {{tranForward}} and {{tranInverse}} methods of {{Transform}} go against the LSST convention discouraging abbreviations. Rename them to {{applyForward}} and {{applyInverse}}, respectively."""
"DM-10795","Story","Alert Production|Science Pipelines",3,"Outline L1 Minimum Viable System","""Outline and prioritize components required for end-to-end testing of L1 alert generation--most immediately to enable verify_ap development (DM-9676 and others)."""
"DM-10785","Bug","pipe_tasks",1,"setBrightObjectMasks does not properly construct footprint. ","""This causes coaddDriver to fail when bright object masks are turned on, e.g.         This should be covered in a unit test as well.  Probably a good idea to do a quick scan for similar issues elsewhere too."""
"DM-10782","Story","ci_hsc",1,"Add bright star masks to ci_hsc","""We're running production with bright star masks, so those should also be in the integration test. Otherwise there's the possibility that production fails when ci_hsc passes."""
"DM-10819","Improvement","afw",2,"Define Endpoint equality","""To allow for future development, {{BaseEndpoint}} should have an equality operator that accepts another {{BaseEndpoint}}, possibly with different template parameters, and returns true iff the two {{Endpoints}} have the same implementation class and the same (implementation-specific) state.    Implementations and test cases must be carefully designed to avoid substitution-principle-related issues. At worst, this may require imposing a convention that all concrete subclasses of {{BaseEndpoint}} must be final."""
"DM-10809","Story","Stack Documentation and UX",0.5,"Release LTD Mason with pinned ruamel.yaml version 0.14","""Create a new release of LTD Mason with the version of ruamel.yaml pinned to prevent future version incompatibilities.    See https://github.com/lsst-sqre/ltd-mason/pull/5 :    bq. There will be API changes in the 0.15+ versions, that might lead to warnings that your users could see. Therefore please release a version of your package with this change, so that it will not automatically take the latest ruamel.yaml release."""
"DM-10839","Story","supertask",8,"Implement missing features of command line SuperTask activator","""Missing features include:  - specifying multiple SuperTasks on command line  - loading Pipeline from serialized format  - support for """"show"""" command    Multi-task support may need rethinking of UI for command line."""
"DM-10838","Improvement","SUIT",1,"Expose channel and connid from WebsocketClient","""A {{firefly_client.FireflyClient}} instance can be connected to a Firefly widget when the {{channel}} and {{connID}} are known. The {{channel}} and {{connID}} are logged to the browser Javascript console when the {{connect}} method from the {{firefly_widgets}} package is invoked in a notebook. The requested improvement is to expose the function that returns {{channel}} and {{connID}} as an API.     The benefit would be that the functionality of the Python API could be used on widget instances.    """
"DM-10837","Story","Science Pipelines",0.5,"Fix eimageIsr import","""`eimageIsr.py` in `obs_lsstSim` imports functions from `ip_isr` with `from lsst.ip.isr import isr`, but this only imports functions inside `isr.cc`. This import statement should be changed to `import lsst.ip.isr as isr` for the rest of the code in the module to work."""
"DM-10831","Story","SUIT",8,"Histogram in multi-trace chart","""We need to migrate Firefly Histogram (with the bind calculated on the server) to multi-trace chart architecture. This includes options and table connections.     Since histogram parameters do not map exactly to Plotly bar chart attributes (we use variable width bars to represent bins), this would be a good addition to the multi-trace charts proof-of concept.    Other items that should be resolved by this ticket   - Separating firefly specific things from plotly trace data  - Not storing fetchData function in tablesource, it's preferable to store a string id that can be resolved into this function  """
"DM-10828","Technical task","meas_deblender",5,"Generate comparison plots for the simulated deblender data","""Run the deblender on all of the simulated images and compare the results to the truth, and to the results from the old deblender."""
"DM-10854","Story","Firefly|SUIT",8,"User workspace access API ","""We need to decide the API to use to access user workspace (storage). DAX team will implement a WedDAV API first, VOSpace APIwill be implemented later.    Work with DAX team during their implementation phase on the issuescoming up.        [https://jira.ipac.caltech.edu/browse/FIREFLY-94]"""
"DM-10853","Epic","SUIT",40,"SUIT portal integration with PDAC v2 Science Platform ","""We will start integrate the SUIT portal into the science platform.   Major features will be:  * Enable use login  * accessing user workspace (storage space) from portal   *  """
"DM-10842","Story","afw|Design Documents",3,"RFC new design for afw::math::Statistics","""Make sure there are no overwhelming community objections to the design & requirements outlined in DMTN-043"""
"DM-10871","Improvement","log",1,"Add unit test for MDC overwriting","""DM-10623 does not add unit test for the piece of functionality that it altered, would be nice to add one. """
"DM-10908","Story","ImgServ",5,"Refactor Butler instantiation code in ImgServ","""Pull Butler instantiation code further up in imgserv, so it can be done externally to the ImgServ library when the ImgServ library is split into its own module (will enable use to cache Butlers in the Flask/CLI layers for improved performance)"""
"DM-10903","Story","Stack Documentation and UX",1,"Update DMTN-23 tutorial to work with recent versions of the stack","""I'm planning to publicize this document at the Lyon meeting next week as a part of a tutorial session on how to use the stack, but it has some instructions that no longer work.    I know [~jsick] has been working through this and fixing things (and probably putting it in a new, more permanent location), but I don't want to assume anything about that yielding results by next week."""
"DM-10926","Story","afw",1,"Incompatibility with NumPy 1.13","""Per [this report on CLO|https://community.lsst.org/t/difficulty-installing-on-python-3-6/1961], our test suite fails when run against NumPy 1.13.0:        This has been promoted from a {{DeprecationWarning}} to a {{TypeError}} as of [NumPy 1.13.0|https://github.com/numpy/numpy/releases/tag/v1.13.0], which was recently released."""
"DM-10922","Story","Alert Production",3,"Outline necessary metrics for verify_ap","""Outline range of metrics needed in verify_ap."""
"DM-10921","Story","Design Documents",0.5,"Deploy LDM-503 to LSST the Docs","""Deploy LDM-503 to ldm-503.lsst.io using Lander."""
"DM-10920","Story","Stack Documentation and UX",0.5,"Improve metasrc's parsing of latex for metadata","""DM's LaTeX authors make use of whitespace in command invocations that weren't anticipated by metasrc's regular expressions. For example:        This ticket adds flexibility to the regular expressions to work with this whitespace.    *Eventually we really need to replace the regular expressions with a fully-fledged TeX tokenizer.*"""
"DM-10919","Story","Review Documents",1,"Add WBS breakdown to LDM-294","""Update LDM-294 so that, given a textual description of the WBS, it:    - Automatically includes that in the document  - Associates each WBS element with a set of products from {{productlist.csv}}"""
"DM-10937","Story","Systems Engineering",2,"Update ICD tracking sheet for DM","""Based on a request from Brian Selvy to all subsystems, update the ICD status tracking sheet Document-19424 to reflect appropriate need dates, issues, etc."""
"DM-10934","Story","Design Documents|Review Documents|Stack Documentation and UX",1,"Fix ""Sigma"" and ""Err"" in change controlled DM docs","""Find all uses of {{Err}} and {{Sigma}} in the version controlled DM documents (hopefully just LDMs?), determine if they are correct or not, and fix the ones that are incorrect.    How many LDMs are there (of order 20 on the page below), and where do they all live? This document is a good start at finding them:    https://confluence.lsstcorp.org/display/DM/Requirements+and+Design+Hierarchy    This git repo should encompass all the important ones:    https://github.com/lsst-dm/dm-docs.git"""
"DM-10931","Bug","meas_astrom",1,"Fix variable name bug and remove print statements in matchPessimisticB.","""A print statement that was inserted for debugging should be removed from the stack version of the code.    The empty struct returned by the PessimisticPattern matcher class has an incorrect name for distances_rad which was introduced in DM-9751."""
"DM-10947","Bug","afw",1,"Allow linearizeTransform and affineTransform to simplify their mappings","""The current implementation of {{geom::linearizeTransform}}, and the initial implementation for an AffineTransform -> Transform conversion factory, use unsimplified mappings internally to work around AST bugs. This makes them unneccessarily slow, particularly {{linearizeTransform}}, which composes three mappings at present. Simplification should be added once the bugs in question are fixed."""
"DM-10945","Story","Continuous Integration",2,"update eups to 2.1.3 to improve tarball package installation","""{{newinstall.sh}} should be updated to use eups 2.1.3 to reduce the time required to install binary tarballs.  {{lsstsw}} should be updated at the same time to keep our build envs in sync."""
"DM-10943","Improvement","astshim",0,"References to TranForward and TranInverse are confusing","""Various doc strings reference the {{Mapping}} attributes {{TranForward}} and {{TranInverse}}. However, these are obtained using {{hasForward}} and {{hasInverse}}, so much of this documentation is confusing. Clean this up."""
"DM-10953","Story","afw|ip_diffim",8,"Give  ModelPsfMatchTask ablilty to match to all PSF types","""Ticket named """" 'Psf' object has no attribute 'resized'"""" as filed.     {{ModelPsfMatchTask}} calls {{Psf.resized}}, but that method is only defined for certain specialised {{Psf}} classes ({{SingleGaussianPsf}} and {{DoubleGaussianPsf}}). It should have a default implementation, and be defined for {{CoaddPsf}}.        Bug reported by [Ai-Lei Sun|mailto:alsun@asiaa.sinica.edu.tw]."""
"DM-10984","Story","Firefly|firefly_client|SUIT",5,"Write ""user guide"" documentation for firefly_client","""In addition to the existing Python docstring documentation in {{firefly_client}}, it would be desirable to have """"user guide""""-type documentation, including examples, available."""
"DM-10983","Technical task","Firefly|firefly_client|SUIT",3,"Get Python docstring content from firefly_client published to firefly-client.lsst.io","""At the """"Firefly documentation mini-workshop"""" it was agreed that the Firefly Python API in the firefly_client package should be published on a {{firefly-client.lsst.io}} mini-site using [~jsick]'s standard technology.    Docstring content is available in that package but the site doesn't seem to be active.  This ticket is about getting the site up and running.  """
"DM-10982","Technical task","Firefly|SUIT",2,"Ensure that Firefly package's JSDoc content is updated on firefly.lsst.io","""https://firefly.lsst.io/ and https://firefly.lsst.io/builds/ seem to exist, but they have not received any new content since March.  We need to be clear about what updates we expect to go to this site - all updates to the {{dev}} branch?    Decision: the JSDoc is in sync with github master branch."""
"DM-10981","Story","Alert Production",3,"Schedule and implement a conversation with DAX about L1 DB","""We need some sort of mocked up interface to the level 1 database.  Specifically, this requires the ability to retrieve DIAObjects based on spatial position and the ability to put potentially updated versions of those DIAObjects back from multiple threads.    Ideas were to either use a sqlite database and interact directly through SQL, but it might be informative to have a shimmed butler interface to do this interaction.    In either case, the schema are defined and reside in the {{cat}} package."""
"DM-10977","Story","obs_decam",2,"Share ImageSelector from Twinkles","""Bring the good seeing ImageSelector from the Twinkles branch into the {{decam_hits}} repository.  Add a {{goodSeeingCoadd}} config parameter to use it."""
"DM-10976","Story","obs_decam",5,"Get HiTS 2014 data","""* Get HiTS data for 2014 fields matching 2015 fields for the prototype AP system (DM-7925), to be used for template generation  * Once the dataset exists, make a git-lfs repo for it and/or add it to /datasets on lsst-dev (along with the 2015 field data to be used as """"science"""").  This should adhere to the layout defined in DM-11116."""
"DM-10975","Story","obs_decam",2,"Update input repositories and config for Gaia","""* Update lsst-dev butler repository to include Gaia ref cat (my be a no-op).  * Update DMTN instructions, if necessary.  * Update configs used by the prototype to use Gaia as the astrometric ref and PS1 (or SDSS) as the photometric ref"""
"DM-10974","Story","obs_decam",2,"Ensure linearity is being applied in ISR to decam","""Linearization was implemented in DM-6356. Make sure that linearity is still applied given the full decam ISR task."""
"DM-10973","Story","afw",5,"Make SkyWcs transform to IcrsCoord instead of SpherePoint","""At present {{SkyWcs}} is a subclass of {{Transform<Point2Endpoint, SpherePointEndpoint>}} and this means that {{pixelToSky}} transforms to {{SpherePoint}}. However {{SkyWcs}} is always normalized to ICRS and so {{pixelToSky}} should probably produce {{IcrsCoord}}.    The simplest way to change this is to change {{SpherePointEndpoint}} to {{IcrsCoordEndpoint}}. One obvious alternative is to keep both and change the endpoint class {{SkyWcs}} uses. However, we have no identified need for {{Transform}} to transform to {{SpherePoint}} (nor {{IcrsCoord}} except as a base class for {{SkyWcs}}). Furthermore if we have N {{Endpoint}} classes then we instantiate N^2 {{Transform}} classes. So I propose to simply rename for now."""
"DM-10965","Bug","afw",1,"FootprintSet setter unable to accept results from getter","""A bug in afw FootprintSets was reported where the returned value from getFootprints could not be used in the function call setFootprints as shown below. Success of this ticket will be when the output can be used as an input.      {code:python}  (Pdb) footprintSet.setFootprints(footprintSet.getFootprints())  *** TypeError: setFootprints(): incompatible function arguments. The following argument types are supported:      1. (self: lsst.afw.detection._footprintSet.FootprintSet, arg0: std::vector<std::shared_ptr<lsst::afw::detection::Footprint>, std::allocator<std::shared_ptr<lsst::afw::detection::Footprint> > >) -> None    Invoked with: <lsst.afw.detection._footprintSet.FootprintSet object at 0x7fdc226da928>, [<lsst.afw.detection._footprint.Footprint object at 0x7fdc226dac38>, <lsst.afw.detection._footprint.Footprint object at 0x7fdc226dadf8>, <lsst.afw.detection._footprint.Footprint object at 0x7fdc226dac70>]  {code}  """
"DM-11000","Story","Qserv",1,"Fix pyyaml build problem in Qserv base container","""The recent pyyaml change to build on top of libyaml busted the Qserv base container builds.      It looks like a necessary -L option for libyaml is missing of the CFLAGS additions in the build() override in the eupspkg.cfg.sh; in miniconda installs this goes unnoticed since the lib is picked up from miniconda.  Since the Qserv base containers are non-miniconda builds, they broke."""
"DM-10998","Story","Continuous Integration",0.5,"buildbot-scripts cleanups","""There are a couple of small issues with {{lsst-sqre/buildbot-scripts}} that could be improved, including:    * Inconsistent use of true/false, 0/1, and """"yes""""/""""no"""" for boolean values.  * printing of variables that are no longer in use (DEMO_ROOT & DEMO_TGZ).  * inconsistent use of posix and bash style conditional expressions"""
"DM-11010","Story","afw",1,"Footprint.transform may be transforming the wrong position","""{{Footprint.transform}} contains the following code:      I strongly suspect it should be transforming Fx, Fy instead of Fx, Fx. If so, the code would be simpler and less error-prone as:      In the same vein: a variant of {{addPeak}} that took a {{Point2D}} for the position would be a useful addition."""
"DM-11009","Bug","utils",1,"Automatic backtrace printing is unhelpful","""All in all, I think this could be more useful:     """
"DM-11002","Story","Stack Documentation and UX",0.5,"Simplify Git LFS documentation in the Developer Guide","""With the Git LFS updates, the Git LFS documentation (https://developer.lsst.io/tools/git_lfs.html) as written seems to be unclear. This ticket will clean that up."""
"DM-11016","Improvement","base",1,"Add standard library tag file to Doxygen","""cppreference.com provides a [tag file|http://en.cppreference.com/w/Cppreference:Archives#Doxygen_tag_file] that allows Doxygen builds to link to its documentation on standard library types ({{vector}}, {{string}}, standard exception classes, etc.). Using this file in {{lsst.base}} would save developers working with Stack code from having to look up these classes by hand. A minor feature, but a convenient one.    -One question that would need to be addressed is whether the tag file should be stored in {{base}} or downloaded from the website each time. The former is easier (and allows documentation to be built without an internet connection), while the latter would prevent the tag file from going out of date.-"""
"DM-11013","Story","SUIT",2,"SUIT needs to throw out a more meaningful error message when DAX has connection issue","""When DAX has problem as today (6/22/17), select the table """"Forced photometry based on i-band coadds"""" table from """"SDSS Stripe82"""" in http://localhost:8080/firefly/lsst-pdac-triview.html;a=layout.showDropDown, in the metadata table area SUIT throws out this error message:    """"Catalog Fetch Error: edu.caltech.ipac.firefly.server.query.DataAccessException: DataAccessException:ERROR:DAX Error: OperationalError from:unknown""""    We need to improve the error message, following exception convention implemented by Trey in ticket DM-10560, for our users."""
"DM-11018","Story","Firefly|SUIT",1,"check Firefly display of mask after DM-7477 implementation","""RFC-25 triggered DM-7477 to increase the mask plane from 16 bits to 32 bits. Firefly has the function to display mask plane when it is part of teh extension. We need to double check to make sure the display still works. """
"DM-11033","Bug","butler",2,"Problem with exists/getStorage() with composite datatypes","""When using composite data types (e.g. with obs_comCam), seemingly all cmdLineTasks (certainly {{processCcd.py}} and {{constructCalibs.py}}) fail with        It seems that these composite objects don't have the function defined.    Steps to reproduce can be found by setting up a stack on lsst-dev with {{. /home/mfl/nate.sh}} and the repo can be remade and the failing command run with {{. /home/mfl/rerun_nate.sh}}."""
"DM-11051","Story","afw",1,"Change logger level for wcs warning","""DM-10559 introduced a warning when makeWcs() fails to construct a wcs, but the level was too high. It should be reduced DEBUG level warning."""
"DM-11094","Bug","SUIT",1,"The time series page should not be named as "": Viewer""","""localhost:8080/suit/  SDSS Stripe82, Object table, RA=9.6, Dec=-1.1, radius=10 as  Click any row with coadd_filter_id=3  Click """"View Time Series: <id>"""" button  The time series will popup. At the upper left corner, """":Viewer"""" is there.     I think the leading title was missing.    Fix: Use a more meaningful name, like """"Time Series Tool: Viewer""""  """
"DM-11091","Story","pipe_drivers",1,"Fix multibandDriver attempting to run detection when no data present","""MultibandDriver attempts to run detection if no calibrated exposures are found. It should skip trying to do this if there is no data present at all."""
"DM-11104","Story","Continuous Integration|Developer Infrastructure",1,"generate py3/lsst_distrib docker containers from tarballs","""At present, the docker containers that are published as part of the weekly pipelines/apps tag/release process are using python 2.7.  In addition, they are from scratch builds which should no longer be necessary as weekly binary """"tarball"""" builds are being published."""
"DM-11097","Story","pipe_base",1,"Document required entry points for Tasks","""Per RFC-352, all {{Task}}s (modulo approved exceptions; see the RFC for details) are expected to provide a {{run}} method as their primary point of entry, and may also provide {{runDataRef}} for operating on dataRefs. Please update the documentation in pipe_base to explain this requirement (and the procedure for obtaining an exemption)."""
"DM-18276","Improvement","ts_middleware",2,"Make SAL message timestamp visible to Python","""All SAL messages contain a timestamp, but this fields is not visible to Python. Please make this field available to Python code, along with any other similar topic metadata that might be useful."""
"DM-11147","Story","obs_ctio0m9",2,"Reconfigure obs_ctio0m9 to work after changes to meas_astrom","""After DM-10253 and DM-10565 things were working well with obs_ctio0m9, but changes to some defaults in meas_astrom meant that the {{processCcd.py}} config merged there is no longer correct. This ticket exists to make those changes."""
"DM-11138","Story","jointcal|meas_mosaic|obs_base|obs_cfht|obs_decam|obs_subaru",2,"Convert meas_mosaic wcs output to a format directly readable by the butler","""{{meas_mosaic}} writes its WCS as FITS header with no attached image, which requires loading code to use the following pattern:    instead of simply    Using a header-only format also limits us to FITS-standard WCS mappings.    Because {{Wcs}} inherits from {{afw::table::io::Persistable}} it already has {{writeFits}} and {{readFits}} methods that utilize our FITS binary table format, which will be able to save more complex WCS solutions.  It's also compatible (or will be soon, on DM-10728) with the """"FitsCatalogStorage"""" butler storage type, so we should be able to fix this by:   - Redefining """"wcs"""" to be a """"FitsCatalogStorage"""" dataset, instead of a """"FitsStorage"""" exposure in all mappers;   - modifying meas_mosaic (and possibly jointcal, if needed) to use {{butler.put}} directly.   - modifying any code that consumes the {{wcs}} dataset to use {{butler.get}} directly.    In addition, this issue should include creating a simple command-line script that can be used to convert a data repository from the old format to the new one."""
"DM-11137","Bug","daf_persistence",0.5,"testSafeFileIO fails with too many open files on Python 3 and Terminal","""testSafeFileIO.py fails on my mac (iMac and laptop) from Terminal using Python3. It passes on Python2 and using iTerm2 on Python3. The open file limit seems to be on the edge and might have to be calculated dynamically."""
"DM-11158","Bug","meas_base",1,"Doing a stack install using Anaconda 4.4.0 (Python 3.6.1) results in 3 tests failing during the build in meas_base.","""Both at NERSC and on a Linux machine at Duke I see the following identical behavior.  The Duke machine is one of our reference platforms so I believe the behavior should be reproducible anywhere.        I installed Anaconda 4.4.0 (Python 3.6 version) and used it for the stack install (instead of the 3.5 based miniconda).    I used the newinstall from:    {{https://raw.githubusercontent.com/lsst/lsst/master/scripts/newinstall.sh}}    I issued the following command after the eups bootstrap:    {{eups distrib install -t w_2017_25 lsst_apps}}    The build runs until meas_base where 3 of the tests fail.  The three resulting failures are:        For example:    """
"DM-11166","Story","obs_base",0,"Fix typo in log message","""Please fix the typo for """"metadata"""" in makeRawVisitInfo.py:    """
"DM-11164","Story","pipe_drivers",1,"Write suitable metadata for VisitInfo when writing calibrations","""We need to be able to get darktime from {{VisitInfo}} when using e.g. master darks, so please add code to write suitable metadata.  """
"DM-11163","Story","obs_base",1,"Always create VisitInfo from metadata when available","""Please create {{VisitInfo}}  whenever we read an {{Exposure}} from disk if suitable metadata is available.    Currently this is done in the {{std_raw}} method, but it's also needed when e.g. reading master dark calibration frames from {{DecoratedImages}}.  """
"DM-11162","Story","afw",20,"Replace all use of Coord and subclasses with SpherePoint","""Implement RFC-353 by replacing all use of {{Coord}} and its subclasses with {{SpherePoint}}.    Things to keep in mind:  - afw will no longer support coordinate conversions. We do not rely on this now (except for a very small number of cases of use of FK5 J2000 instead if ICRS that is likely a mistake).  - {{SpherePoint}} and {{Coord}} have slightly different APIs (for instance {{SpherePoint}} is immutable) so some usage will need to change.  - {{Coord}} has some methods that {{SpherePoint}} does not. These may have to be added to {{SpherePoint}} or implemented as free functions.    This would also be a good time to eliminate the {{SpherePoint(double raDecRad[2])}} constructor. This was added to support {{Transform}} but turned out to be unnecessary."""
"DM-11160","Story","Design Documents",1,"Add metadata to LDM-534 draft","""It should have a change record, note of repository URL, etc."""
"DM-11192","Story","Qserv",0.5,"Status monitoring for qserv disconnected queries","""Revisit qserv status monitoring (SHOW PROCESSLIST etc.) and ensure that it will be usable for monitoring the status of qserv disconnected queries"""
"DM-11183","Story","Data Access",2,"PEP8 and Python 3 Improvements for imgserv","""Rewrite more of imgserv according to PEP8 and Python 3 improvements"""
"DM-11217","Story","daf_persistence",2,"Butler+CmdLineTask cannot output to a (non-repo) folder where some files already exist","""[~sthrush] noticed that tasks fail if the output is a non-empty non-repo folder.  To reproduce with {{w_2017_26}}:         This gives errors:         If the folder is empty (i.e. skipping {{$ echo 1234 > out/a}} in the example) then the task runs just fine."""
"DM-11215","Improvement","validate_drp",5,"Enable validateDrp.py to run from JSON file.","""Enable validateDrp.py to run from JSON file.    Currently, the basic running is:      This produces an output JSON file, along with STDOUT of the results, and plots of KPMs and related metrics.    Behavior will be the (slightly magic):    where the code will just check to see if it was being passed a JSON file, and, if so, then load those results and produce requested output solely based on the JSON file."""
"DM-11196","Story","obs_base|obs_comCam",0.5,"Move yaml camera model to obs_base","""[~rhl] designed a nice replacement for the camera model using yaml description.    This ticket is to, as an experiment, move it to {{obs_base}} without activating it, so that it can be tested and integrated where people so choose.    An RFC will be filed regarding switching to it as our default camera description once the move is complete."""
"DM-11230","Technical task","meas_deblender",5,"Investigate divergence in spectral normalization","""In hyperspectral mixing, a similar but easier to solve problem then a deblender, we normalize the spectra in exactly the same way that we do in the deblender, namely requiring that the values of each component's spectrum are positive and sum to one.    What we notice is that if we perform the normalization as a linear operator, the algorithm quickly diverges. Understanding why this happens is likely to improve our understanding of deblender failures, so this ticket aims to understand the reason for this divergence."""
"DM-11229","Story","meas_deblender",5,"Investigate GLMM convergence","""While testing the proximal gradient methods (ADMM, SDMM, and GLMM) on more simplistic functions, [~pmelchior] and I have been noticing strange behavior in the algorithms, noticeably that under certain circumstances the solutions diverge.    This ticket is meant to be a placeholder for sub-tickets that will dive into specific cases where we have noticed that the algorithms fail to understand and correct the behavior."""
"DM-11237","Bug","afw",1,"Please turn down verbosity of sipterms.cc test","""It's very hard to see what tests are failing as the sipterms test spits many *many* lines of output all over the screen.  The most recent changeset is 3d57adbe, hence the assignment of this issue.  It's not your fault, but we might as well change the tests to {{#if 0}} or some CPP symbol at the same time.    """
"DM-11247","Story","Requirements Documents",2,"Add additional alert packet contents to DPDD","""Per https://jira.lsstcorp.org/browse/RFC-348, add (approximate) history of nondetections to the alert packet.    Also clarify (per https://jira.lsstcorp.org/browse/RFC-350) that DIASource records will include filterName."""
"DM-11245","Story","Design Documents",1,"Improve Lander's logic for displaying 'draft' notice and docushare links","""Make the following changes to Lander:    - Always include the """"View on DocuShare"""" button for controlled document types (LDM, LSE, LPM, and so on). Implement as a whitelist, and use the ls.st short link form. This makes the {{--docushare-url}} command line optional have a good automatic default.  - Do not show the DRAFT notice for builds on {{master}} and {{docushare-vN}} branch/tag names."""
"DM-11251","Story","daf_persistence|obs_base",2,"add support for the standardize function for composite datasets","""composite objects should get passed to the std_<datasetType> function of the mapper, if there is one."""
"DM-11256","Story","lsst-texmf",1,"Update beamer to LSST2017 templates","""A new set of templates are provided, which we should use starting with the July NSF/DOE review.  Please change lsst-texmf to use them.  """
"DM-11271","Story","Design Documents",1,"DocTree is incorrect about LDM-151","""Our DocTree currently describes LDM-151 as the """"L2 Pipeline Design"""". It does not provide a design for L1 (or calibration products) pipelines.    In fact, LDM-151 covers all of these pipelines, and we should make this clear in the diagram.    (I don't think it's critical to fix this before the review, though.)"""
"DM-11269","Story","afw",1,"Please move ""Empty WCS extension, using FITS header"" from INFO to DEBUG","""When reading raw or rawish files you often have a WCS in the header but not one of the custom LSST WCS extensions; this is not interesting to the user, but it's currently logged as INFO (and it's pretty common -- e.g. when assembling biases you get it for every bbox read by {{constructCalib}} scripts):      Please move this to DEBUG.  """
"DM-11280","Bug","obs_subaru",0.5,"Update configs missed in DM-10469","""There were a few {{obs_subaru}} config updates missed in DM-10469 in support of running the {{pipe_analysis}} QA scripts.  These will be addressed here."""
"DM-11299","Story","SUIT",8,"WISE coadded images displayed ignored cutout size","""For WISE images PDAC in  PDAC v2, the input cutout size was ignored for the coadded images. steps to repeat:  # select WISE images in LSST search panel  # user target m51, input cutout size 600 arcsec  # then use the same target, do NOT specify size  # Compare the images returned, they are the same    The 600arcsec images should be much smaller, and show a pretty spiral galaxy  """
"DM-11289","Story","butler",1,"RepositoryArgs needs to check that mapperArgs is dict-like","""{{RepositoryArgs.mapperArgs}} is assumed to be dict-like (e.g. {{if 'root' not in mapperArgs}}), but it can be initialised to {{None}}.    The init function needs to guarantee that {{mapperArgs}} is dict-like. I think that we should also fix the default value ({{RepositoryArgs.\_\_init\_\_()}} has a default {{mapperArgs=None}}), although we could just add the test;  but I think it's clearer to set the default to a valid value too.    N.b. mapperArgs is omitted from the class docstring, which otherwise duplicates most of the {{\_\_init\_\_}} docstring.  """
"DM-11324","Story","ap_pipe",2,"rename decam_hits repository ap_pipe","""As we generalize the prototype AP pipeline to non-DECam, non-HITS datasets we should have a more general name than `decam_hits`.  I suggest `ap_pipe`."""
"DM-11322","Story","pipe_analysis",1,"Add calibUsed-only qa plots for astrometry and photometry","""For qa analysis it is useful to have plots and statistics based solely on the objects that were used for any particular calibration.  We have so far been making *calib_psfUsed*-only plots as the PSF modeling was the only provided such a flag in the output catalogs.  As of DM-9050, we now also have *calib_astrometryUsed* & *calib_photometryUsed* flags for the astrometry and photometry fitting.  This issue is to add the relevant/useful plots to the analysis scripts based on these objects."""
"DM-11336","Story","obs_decam",1,"Switch default reference catalog for DECam to PS1 in LSST format","""Following {{obs_subaru}}, it would be nice to change the configuration files of {{obs_decam}} so to also use the PS1 catalog in LSST format and remove dependence on astrometry.net."""
"DM-11335","Story","obs_cfht",1,"obs_cfht tests fall over due to -9999.9 for TELEAZ for calibs","""After DM-11163 (and its related tickets), visitInfos are created for calibs (we need darkTimes and expTimes etc).    However, some of the metadata in the {{testdata_cfht}} contains values which make {{makeRawVisitInfo}} unhappy. Luckily, the {{megacamMapper}} had a {{_standardizeDetrend}} method for stripping out this which upset things downstream.    This ticket just adds the {{TELEAZ}} and {{TELEALT}} keywords to those removed. This should only be called for biases, and therefore not upset anything else."""
"DM-11334","Story","Stack Documentation and UX",3,"Update documenteer dependency for lsst-texmf, developer.lsst.io sites, and technotes","""Pin documenteer >0.1,<0.2 in these projects to preserve existing assumptions about dependencies.    For technotes, the right approach might be to update to documenteer 0.2 and make the necessary changes to their conf.py files."""
"DM-11328","Story","afw",2,"afwImage doesn't roundtrip through numpy","""  fails with    """
"DM-11348","Story","Calibration Products Production|ip_isr|obs_comCam",2,"Generate PDF report from stack-driven eotest outputs","""We now have eotest callable from within the DM Stack. Fix its driver script for producing PDF reports to work with the data products as stored by stack execution, and use this to demonstrate that it's doing the same thing as the stand-alone eotest.  """
"DM-11378","Story","pipe_tasks",1,"Remove config option to make PSF-matched warps with old and wrong order of operations","""In DM-8289 we switched the order of operations when PSF-matching warps to warp first and PSF-match second (so that we don't undo the matching by warping).  I add a config parameter matchThenWarp  to invoke the old behavior while while the epic was in progress.  Now, that that it has been tested, it is time to remove the matchThenWarp branch. """
"DM-11377","Story","Alert Production",5,"Prepare for AP Verification Metrics session at LSST 2017 Meeting","""There is a 90 minute session at LSST 2017 about AP Verification Metrics.  This ticket is to plan and prepare for the session, which includes    * determining how to structure the session; meeting organizers sent suggestions  * inviting relevant non-AP staff to attend (esp. SQUARE)  * preparing relevant talks and/or demos  * aggregating and summarizing feedback after the session"""
"DM-11376","Bug","Firefly",2,"backgrounding job bug","""In Firefly catalog searches,  do a position search on catalog """"Gaia G-band Time Series of Variable Sources"""".    it runs until put in background monitor, then the """"Unexpected error"""" appears.    Since this search is illegal, the error message should appear right away, not until in background."""
"DM-11368","Story","Developer Infrastructure",1,"Update EUPS_PKGROOT in shared stack","""Following DM-11355, the {{EUPS_PKGROOT}} used to distribute the stack has changed to {{https://eups.lsst.codes/stack/src/}}. Update the shared stack on {{lsst-dev01}} (and Tiger/Perseus, for Princeton users) to pull from that."""
"DM-11398","Bug","Firefly|SUIT",2,"Time Series image display location issue ","""1. Search WISE source from PDAC, m81  2. Highlight one source, click on the """"View Time Series ..."""" button for that source  3. change to the time series tab    change the number of images displayed to 1, use arrow key to go down the table, the displayed image jumps around, sometimes is in the middle of the image display area, sometimes is at the left side, sometimes at the right side.  """
"DM-11397","Story","jointcal",0.5,"Remove twinkles1 jointcal testdata and tests","""The reference catalogs supplied with the twinkles data I have are in the a.net format, and do not contain flux errors. When we update them to the new style format, we should also add flux errors of some sort, so that they can be used with jointcal's new photometry system.        Update: after much thought and discussion, we decided that the twinkles1 jointcal testdata no longer serves a useful purpose, and is holding us up from removing a.net refcats and{{obs_lsstSim}}. Instead of trying to update the included refcat (the HTM indexed version that [~krughoff] found was not a drop in replacement), I'm going to delete the twinkles data and tests all together. We'll be getting some DC2 data built on obs_lsst soon enough, and we will have to write entirely new tests for that anyway."""
"DM-11395","Story","jointcal",2,"Update testdata_jointcal refcats to new Indexed format","""Many of the reference catalogs provided with {{testdata_jointcal}} are in the old astrometry.net format, which is now deprecated. We should update those provided refcats to the new style format, which will also simplify the test configuration."""
"DM-11385","Story","Developer Infrastructure",1,"shebangtron breaks scons","""The current behavior of {{shebangtron}} is mangle all {{#!}} statements.  This breaks {{scons}} in an otherwise py3 based installation.    Steps to reproduce:        """
"DM-11410","Story","validate_drp",1,"validate_drp incorrectly outputs filenames as '_<filter>.json'","""After the merge of DM-11300, validate_drp has dropped the repo from the output filename.  Thus, {{<repo>_<filter>.json}} has become {{_<filter>.json}}."""
"DM-11404","Story","meas_deblender",5,"Identify cause of new API inconsistencies","""The new deblender API appears to have large residuals in most blends and completely fails in certain cases, even when using identical constraints. This ticket will attempt to identify and fix these issues."""
"DM-11424","Bug","Firefly",2,"After filtering a plot or on a sorted table, i can't filter selected rows anymore","""In dev, after filtering chart points, i tried to filter out couple row selected but nothing happen. Error in the console log is thrown:    It happen in tri-view and timeSeries tool.  If i sort a table, it also fail to filter the selected row."""
"DM-11422","Story","ap_pipe",3,"Adapt prototype pipeline to use coadds as templates","""Once we have useable coadds from the HiTS 2014 fields matching our HiTS 2015 dataset, these should be used as templates for the AP prototype pipeline (soon to be {{ap_pipe}}). The pipeline will still accept another visit as a template, but the default will be to use the coadds from a specific location in the dataset repo."""
"DM-11421","Story","Alert Production",0.5,"Fix unicode support in obs_lsstSim","""obs_lsstSim tests that """"raft"""", """"sensor"""", and """"channel"""" are of type `str`, but this fails in python 2.7 since these may be unicode."""
"DM-11415","Story","Stack Documentation and UX",0.5,"Add additional DocuShare link roles to Documenteer","""Add additional DocuShare roles to Documenteer. Make it so that any {{ls.st}} functionality is available from reStructuredText (support LTS, LEP, LCA, DMTN, SQR, Document, etc.)"""
"DM-11444","Story","lsst",1,"newinstall.sh fails to install Miniconda","""  """
"DM-11432","Story","pipe_tasks",8,"Implement Robust Coaddition using PSF-matched Warps for Artifact Removal","""Follow up to DM-10005 (Prototype). Implement Robust Coaddition task and merge into stack. """
"DM-11429","Story","afw|pipe_tasks",2,"tests/testPhotoCal.py fails on 2017-07-31 ""master""","""Starting this morning, (2017-07-31 ~ 03:00am EDT), {{pipe_tasks}} on master fails {{tests/testPhotoCal.py}}.  See first attached file ({{consoleText.txt}} for full log from Jenkins job.  second attached file {{pipe_tasks_failure_build.log}} for the same error with a local build on my desktop."""
"DM-11461","Story","ap_verify",1,"Add defect and refcat support to Dataset","""The {{ap.verify.dataset.Dataset}} class currently recognizes three types of input data: raw science images, calibration images, and templates. Depending on future policy decisions, up to two more data types -- reference catalogs and defects -- may have their own locations.    For forward compatibility (i.e., to avoid having to change hardwired assumptions about where these files are located) the {{Dataset}} class should have properties giving the location of these two data types. At present, they may be defined to be equal to or subdirectories of {{Dataset.calib_location}}."""
"DM-11459","Story","Alert Production",2,"Fix Butler compatibility issues","""Recent changes to the Butler have broken the DCR template generation code. This ticket is to update the DCR code to work with the latest version of the Butler."""
"DM-11458","Bug","Firefly",2,"Periodogram table rows are no longer selectable and highlighted","""In time series tools, on a periodogram table, the first row can be selected but not the others. The highlight is also gone. But i think is still updating the period value so somehow the table panel is not updated.   If you click on the peak table and back, you will see the row selected.    in Dev branch  """
"DM-11454","Improvement","astshim",1,"Modify UnitNormMap to round trip zero-length vectors","""In AST {{UnitNormMap}} transforms a zero-length vector into {{(NaN, Nan, ..., NaN, 0)}} in the forward direction, as one would expect (since the components of the unit vector are not well defined and the norm is 0), but the inverse transform of that is {{(NaN, NaN, .., NaN)}}. Enhance {{UnitNormMap}} so the inverse transform of {{(NaN, NaN, ..., NaN, 0)}} is {{(0, 0, ..., 0)}}, instead, so zero-length vectors round-trip correctly.    Also document the behavior at zero and update the unit test.    Be sure to do this on a branch of master, rather than LSST's branch.    Finally, update astshim documentation and unit test accordingly."""
"DM-11467","Bug","Qserv",2,"Fix docker image name generated with travis-ci","""+underlined text+Travis will then automatically generate docker images on each gitbuh commit. This will avoid developer to build docker image on their own.  Image will be named qserv/qser:$SHORT_COMMIT_ID (example qserv/qserv:b78189f) and their alias for branch tip will be qserv/qserv:travis_$BRANCH_NAME (example qserv/qserv:travis_DM-11467)"""
"DM-11475","Story","SUIT",8,"Grid Layout: access plotly support and make another demo","""continue working on the grid layout for firefly, access the plot.ly support, and make more demo/test code"""
"DM-11473","Improvement","afw",1,"Add SpherePoint(long, lat, unit) constructor","""Implement RFC-367 by adding a {{SpherePoint(double longitude, double latitude, AngleUnit unit)}} constructor.    This will simplify DM-11162: Replace all use of {{Coord}} and subclasses with {{SpherePoint}}."""
"DM-11487","Story","Qserv",1,"Fix OSX flakiness in qhttp unit test","""Qhttp unit test fails frequently under OSX.  Investigate and fix."""
"DM-11488","Story","Continuous Integration|Developer Infrastructure",0.5,"weekly release w_2017_31 failed","""The {{w_2017_31}} weekly release failed building master due to what appears to be a repeatable git-lfs error, possibly triggered by DM-11095.      """
"DM-11518","Story","db",1,"Modify db tests to support pytest","""This ticket is for the work of migrating the DB tests such that they run with the py.test test runner."""
"DM-11517","Story","Design Documents",2,"Define Science Pipelines milestones in LDM-564 (draft)","""The current LDM-564 draft (on {{tickets/DM-11468}}) uses short names (""""DRP-MS-IMCHAR-6"""", etc) for SciPi milestones. Turn them into something readable."""
"DM-11516","Improvement","base",1,"Let Doxygen report inherited methods inline","""[~mrawls] showed me that the new Sphinx-based documentation system reports inherited methods as full documentation rather than as links to the base class documentation.    If the plan for C++ code is still for Doxygen to produce XML output which is then fed to Sphinx ([~jsick], is this still the case?), it would be helpful to set {{INLINE_INHERITED_MEMB}} to {{YES}} so that it has the same behavior."""
"DM-11514","Story","sconsUtils",8,"Modify sconsUtils to use pytest for test execution","""This ticket is for modifying sconsUtils such that it uses pytest for test execution rather than python.  This is part of improving the test execution environment such that we can capture output from tests in a JUnit format compatible with Jenkins, and so that we can report on skipped tests as well as test execution times."""
"DM-11512","Story","Third Party Software",0.5,"Create pytest eups package","""Create an EUPS package for pytest PyPI distribution."""
"DM-11507","Bug","lua",1,"Lua build fails if GNU sed is the default on Darwin","""See:    https://community.lsst.org/t/sed-e-expression-1-char-1-unknown-command/2147/4    for the description of the problem. Proposed resolution is to update lua's eupspkg scripts to test for gnu vs. BSD sed."""
"DM-11538","Story","Qserv",0.5,"fix a few C++ compiler warns","""These small fixes address some warns that I have encountered in more recent gcc and clang releases, and some things flagged by the eclipse c++ code analyzer """
"DM-11529","Story","Notebooks",1,"Stack tutorial - notebook content","""Adapt Jim's notebook and dataset for the stack tutorial. """
"DM-11528","Improvement","SUIT",8,"Publish Firefly to npm in support of JupyterLab Widgets development","""JupyterLab Widget requires JavaScript libraries to be npm installable.  We need to package Firefly as an npm package and publish it.  """
"DM-11548","Story","Requirements Documents",1,"Update text for CCB/SE group in LDM-294","""The text for membership of the DM SysEng and DM CCB groups is inconsistent. Make them identical."""
"DM-11547","Story","SUIT",3,"work with NCSA in deploying a Firefly app in lsst-dev or Nebula","""Work out all the issues in deploying a Firefly server in lss-dev or Nebula environment. """
"DM-11545","Story","Science Platform",2,"Copyedit LDM-542 in preparation for DM Review","""In preparation for the DM Review, make an editing pass over the entire document."""
"DM-11542","Story","pipe_analysis",3,"Adapt qa analysis script to matplotlib versions on shared stacks","""These scripts were being developed on an old version of matplotlib (which was being provided by the shared stack on {{tiger}} at Princeton -- this has recently been updated).  The shared stacks on {{lsst-dev}} and {{tiger}} (at Princeton) provide a newer version which results in deprecation warnings and badly formatted plots (to the point where axis labels fall off the side of the figures).  This makes several tweaks to adapt to the currently supplied shared stack versions:  """
"DM-11540","Story","Third Party Software",1,"Experiment with pytest-flake8 eups package","""The {{lsst.verify}} package uses flake8 pytest configurations meaning that by default {{verify}} fails when DM-11514 is active because the flake8 plugin is not installed. Add this package as a dependency of sconsUtils. We may have to install flake8 as well, although that might be in the conda installations already."""
"DM-11569","Story","SUIT",5,"Plotly 3d bug fixes","""scatter3d bugs:   - 2d axes should not show  - options should be basic (not scatter) and should not include options for 2d XY  - drag mode buttons should be those that are supported for 3d  - selection button should not show unless chart supports selection  - zoom to original should work"""
"DM-11566","Story","Continuous Integration",8,"automatic purging of daily eups distrib tags","""Short lived tags (daily, etc.) should be automatically cleaned up once they have """"expired"""". This should include eupspkg and tarball repos."""
"DM-11563","Bug","SUIT",2,"firefly grid display bugs found during testing ","""Fix the following:    - http code that starts with """"file://"""" now goes through LocalFileRetriever, better security this way.  - fix layout issues with charts  - fix issues with initial plot returning the wrong RangeValues  - reinit now hides all dialogs"""
"DM-11556","Story","SUIT",1,"Update chart content of grid-view sample, ffapi-slate-test2.html ","""Update the chart content of ffapi-slate-test2.html to be in sync with the change of the relevant sample in firefly_client.     The content for each chart on WISE search is updated as follows,   2D scatter: w1-w2 and w2-w3 for x and y  heatmap: 3 sets, w1 vs. w2, w1 vs. w3, and w1 vs. w34.  histogram: 2 sets, w1, w2.  3D scatter: w1, w2, w3 for x, y, z.    """
"DM-11580","Story","JupyterLab",2,"Add a default .pythonrc to the JupyterLab environment","""It would be nice if the images spawned by the JupyterLab environment had a set of Python configs that would make using the interpreter nice.  This is likely just a `.pythonrc` file in the home directory with at least tab completion (it's possible this comes for free when using ipython instead of python, but I haven't checked)."""
"DM-11578","Story","jointcal",0.5,"Cleanup public:private: ordering in jointcal headers","""Many of jointcal's classes have a {{public:protected:private:}} ordering that doesn't match our standard. It'd be good to clean this up, as a separate single commit."""
"DM-11577","Story","Continuous Integration",2,"newinstall.sh fails if a pre-exisitng python is not in the path","""  """
"DM-11574","Improvement","obs_subaru",1,"Make testDistortion test the distortion","""The unit test testDistortion.py tests a few things but those do not include the actual distortion computation (instead it prints a series of values that includes an error. The test contains outdated data (the camera geometry has changed) so some error values are unreasonably large.    I propose to do the following:  - Update the test to optionally write the expected results to a file (e.g. by setting a constant).  - Have the test read the data from a file instead of as text in the file.  - Instead of printing output it will test on the difference.    Unfortunately this assumes that the current distortion function operates correctly, so it's not quite as thorough a test as we might like, but it will be an improvement and will greatly help DM-5922 which changes to a new distortion function."""
"DM-11584","Story","JupyterLab",2,"jupyterlabdemo w_2017_32 build failed","""The jenkins {{build-jupyterlabdemo}} job failed with package dependency errors."""
"DM-11595","Bug","daf_persistence",3,"daf_persistence tests fail with pytest-xdist","""With DM-11514, we get tests run in parallel using pytest-xdist. This seems to cause individual tests to be parallelized in multiple processes, leading to the daf_persistence tests failing because they assume that a single temp directory can be used for all tests in a single class.    We need to change this so that {{setUp}} allocates a proper temp directory with a unique name."""
"DM-11594","Bug","obs_subaru",1,"test_distortion fails when run from pytest","""test_distortion.py fails when run from pytest while unpickling:  """
"DM-11590","Story","Developer Infrastructure",0.5,"community.lsst.org TLS cert expires on 2017-10-14","""Per nagios:        """
"DM-11604","Story","Firefly|SUIT",8,"Support showing the active chart traces","""When the active trace is changed then move it to the top. This changes the order of the trace and replots,    This might needs to be discuss with [~tatianag] and [~loi] before the work begins."""
"DM-11602","Story","Firefly|SUIT",3,"change syntax for table column data identification ","""Details:    * tbl_id in data  * syntax- """"table::column"""" or """"table::expression"""""""
"DM-11599","Story","Qserv",2,"Migrate qserv LUA wrapper from SWIG to native C API","""Last step in getting rid of SWIG dependency is to replace our SWIG-generated LUA wrapper for proxy with hand-crafted one. The interface is not too complicated, there are just four methods in C++ API that need wrapping."""
"DM-11613","Bug","ctrl_execute",0.5,"ctrl_execute fails with pytest-xdist","""Testing ctrl_execute with pytest-xdist (eg using ticket branches {{tickets/DM-11514}} and {{tickets/DM-11514-base}}, results in the following error:    The problem seems to be that tests are assuming they are running sequentially but with {{pytest -n 8}} individual tests can run in different processes and since the tests use the same config directory they all race with each other.    [~spietrowicz] before I look deeply at the code, is there an obvious way for the tests to use different temp directories or config files?"""
"DM-11610","Improvement","Firefly",0,"Panel size is not fixed in catalog search when adding a new tab","""The VO panel in catalog search changes its size when accessed the first time.    If you go to Catalog search and switch to """"VO"""", the panel shrink automatically to fit the space.    The size should be fixed in advance."""
"DM-11609","Bug","Firefly",2,"File upload URL input field is not editable","""While testing the new upload feature search, i realize that the URL input field is not editable. If a user try to write or edit the URL, it looses focus and can no longer write.   Please, allow a user to enter manually a URL.  """
"DM-11608","Story","scisql",1,"Update scisql version to 0.3.8 in lsst repo","""New scisql version 0.3.8 is out, it fixes issues in running deployment scripts with Python3 (and hence it's needed for Qserv Python3 migration).  """
"DM-11615","Story","Qserv",1,"Fix flaky qhttp ajax unit test","""The qhttp ajax unit test still fails intermittently when run under Jenkins CI.  Logs indicate a timing sensitivity.  Rework this unit test to make it more robust."""
"DM-11618","Bug","ctrl_execute",0.5,"Bug where a test directory is being used twice caused a race condition and failure","""In fixing DM-11613, I missed an test where a non-unique directory was being created through code that was being exercised.  When this test was run in parallel, a race-condition occurred and a test failed."""
"DM-11625","Bug","pipe_tasks",1,"Bug in calculation of number-of-detected-in-bands in peak culling","""HSC internal release processing uncovered a bug in our peak culling in MergeCoaddDetectionsTask, due to a schema string with periods instead of underscores.  The result is that when testing how many bands a source appears to have been detected in, the result is always zero.    This has apparently been present on the LSST for a long time (possibly since the code was ported there), and has gone unnoticed because this test is only operative in the very largest blends, which are moderately rare in the Wide survey.  We certainly should have spotted it in the UltraDeep RC tests, however; we need to make sure our RC tests include checking for changes in the number or density of detected sources."""
"DM-11630","Story","Stack Documentation and UX",0.5,"ltd-mason bug uploading Science Pipelines docs with lsst.verify API info","""The ltd-mason-travis build is showing:        Turns out the problem is that the {{ObjectManger.list_dirnames_in_directory}} method is suddenly including {{'..'}} as one of the returned directory names, which is an empty directory that can't exist on S3.    I'm already filtering {{'.'}}, so I just need to filter {{'..'}} too."""
"DM-11628","Bug","pipe_tasks",1,"Fix minor bugs in peak culling","""Sogo Mineo reports another bug in peak culling that makes it hard to disable via configuration:  {quote}  The docstring of class CullPeaksConfig says:        To disable peak culling, simply set nBandsSafe=1.    If I assume `nBandsSafe` is a typo for `nBandsSufficient`  and set nBandsSufficient = 1,  then the condition for a peak to be kept:        if ((rank < self.config.cullPeaks.rankSufficient) or          (self.config.cullPeaks.nBandsSufficient > 1 and           sum([peak.get(k) for k in keys]) >= self.config.cullPeaks.nBandsSufficient) or          (rank < self.config.cullPeaks.rankConsidered and           rank < self.config.cullPeaks.rankNormalizedConsidered * familySize)):    will be equivalent to:        if ((rank < self.config.cullPeaks.rankSufficient) or          (rank < self.config.cullPeaks.rankConsidered and           rank < self.config.cullPeaks.rankNormalizedConsidered * familySize)):    and peak culling will be still active in spite of the instruction of the docstring.  {quote}  """
"DM-11650","Bug","ap_verify",1,"Clean up file-based unit tests in ap_verify","""The current unit tests for {{Dataset}} and argument parsing use fixed filenames. They should be rewritten to use randomly generated names as recommended on [Community|https://community.lsst.org/t/pytest-is-now-being-used-for-test-execution/2201]."""
"DM-11677","Story","scisql",0.5,"Fix broken tar file in eups scisql 0.3.8","""Tar file in eups scisql 0.3.8 was created with an incorrect prefix.  Builds and """"installs"""" without error, but fails subsequently becuase installed files are in the wrong places."""
"DM-11698","Story","ap_verify",2,"Let ap_verify support multiple --dataIdString arguments","""Tasks take multiple {{\-\-id}} arguments to allow data satisfying one or more complex conditions. {{ap_verify}} does not currently have this capability; if the user passes multiple {{\-\-dataIdString}} values, only the last will be used. This behavior should be changed to let users have more of the flexibility they expect from running {{CmdLineTasks}} directly.    Note that this ticket cannot be satisfied by using {{pipe.base.ArgumentParser}}, because that class assumes its program only needs repository (i.e., previously ingested) input.    This ticket may require changes to {{ap_pipe}} to forward multiple IDs to relevant tasks."""
"DM-11692","Story","Continuous Integration",2,"artifact stack-os-matrix build .log files","""Post merger of DM-11612, junit xml files have been recorded with a non-zero failure count even though the build completed successfully.  There is concern that there is a failure mode in which {{pytest}} observes a test failure but exists {{0}} (confirmed in DM-11693).    As the build is successful, {{lsstswBuild.sh}}'s log printing is not triggered.  It would be useful for debugging purposes to unconditionally artifact all of the build's {{*.log}} files.  Tangentially, saving all of the log files would mean that {{lsstswBuild.sh}}'s could be invoked without the {{--print-fail}}, possibly removing the need to address DM-5887."""
"DM-11691","Bug","daf_persistence|obs_sdss",1,"Test failure with butler in obs_sdss","""In a Jenkins run last night the Mac failed with an error in obs_sdss:  """
"DM-11745","Improvement","ap_verify|Science Pipelines",2,"Investigate wrapping external function calls in ap_verify","""As discussed in https://jira.lsstcorp.org/browse/DM-10779, it may be possible to minimize code duplication in {{ap_verify}} by using a wrapper function to perform appropriate metrics handling on the library calls to {{ap_pipe}}.  This ticket is to investigate the utility of such an approach."""
"DM-11744","Story","git",1,"Move ci_ctio0m9 to use LSST backed LFS","""Currently the {{ci_ctio0m9}} package is using the github backed LFS server.  The typical policy is to use the LSST git-lfs server.  This package should be converted to use that backend."""
"DM-11735","Story","obs_test",0.5,"fix tearDown race conditions in obs_test","""Because the test does not use a temp dir for each test method, rmdir in tearDown can collide:  https://ci.lsst.codes/blue/organizations/jenkins/stack-os-matrix/detail/stack-os-matrix/26515/tests/"""
"DM-11731","Improvement","Firefly",0,"default min/max values for histogram need more significant digits","""# Upload the attached file  # add a histogram for glon, all look good  # add a histogram for glat, an empty histogram shows up (see attached PNG file)  # open the option panel, the min/max vales are the same    We need to add more significant digits to those values so the min and the max values are different.  There is no point to get histogram if there is no spread in values. """
"DM-11728","Story","Continuous Integration",0.5,"lsst-build output not visible in jenkins console","""This may only (always?) happen with the osx / py3 combination. The symptoms are that the console shows:        with no further output for a considerable portion of the build but inspecting the node directly shows that the build is progressing normally.  Speculation on possible causes is:    * python stdout buffering  * jenkins agent buffering  * jdk issues -- of note is that the version of java on the osx nodes is at a different patch level"""
"DM-11725","Story","sconsUtils",3,"Add coverage testing of unittest","""The {{pytest-cov}} plugin should be enabled to write coverage reports from unit testing. This ticket covers the work to enable per-product coverage testing solely from the unittests associated with that product. This can be enabled as part of normal test execution. It is possible to write coverage results to html, the terminal and XML. XML is needed for Jenkins support -- it may be desirable to default to HTML and terminal reporting but allow Jenkins to enable XML output via an environment variable."""
"DM-11720","Story","meas_deblender",2,"Investigate feasibility to use colors to estimate source boundary boxes","""For the deblender to be optimal in the long term survey, which includes possibly deblending entire images as a single blend, we need to be able to define a bounding box for each source that is a small fraction of the total image size (see the issue created by [~pmelchior]    at https://github.com/fred3m/deblender/issues/14).    Issue DM-11718 has been created to develop an effective algorithm to do this, but will not likely be added to the stack until after testing has been run on a large patch of real HSC images.    This ticket is created to track work that has already been done to test whether or not such an algorithm might be possible, and resulted in [this|https://github.com/lsst-dm/deblender_examples/blob/master/test_bbox.ipynb] ipython notebook, which shows that such a procedure is likely to exist.    It also shows the possibility of performing multi-band object detection in the future, although discussion with [~pmelchior] indicate that this might be difficult (and/or time consuming) in practice."""
"DM-11718","Story","meas_deblender",1,"Select bounding box for each source","""For the deblender to be useful in the long term, which includes possibly deblending entire images as a single blend, we need to be able to define a bounding box for each source that is a small fraction of the total image size (see the issue created by [~pmelchior]    at https://github.com/fred3m/deblender/issues/14).    This ticket will attempt to identify the best algorithm to create an initial bounding box large enough to fit all of the flux for _most_  individual objects, with the possibility of growing the box during optimization if the source appears to need a larger area."""
"DM-11772","Story","ap_verify",8,"Study how to integrate metrics into Tasks","""At the moment, we do not have a clear plan or framework for how we will make measurements of {{verify}} metrics, particularly those that are specific to a single Task's implementation details. Future development of {{ap_verify}} and feature requests for {{verify}} depend on how we intend to handle these metrics.    This ticket is for researching one or more designs for supporting metrics within the Task framework. The result shall be a tech note describing my understanding of the requirements for metrics usage, a summary of what {{verify}} currently supports, and specific proposals for how to incorporate metric measurements into Tasks and/or {{ap_verify}}. The note shall be sent for review to the stakeholders for {{verify}}, {{ap_verify}}, and {{pipe_base}}."""
"DM-11771","Bug","obs_base",0.5,"obs_base fails to build on NFS-mounted systems","""When I tried to build {{obs_base}} on an NFS-mounted machine, I got the attached failure.  This is after the upgrade to {{pytest-xdist}}."""
"DM-11758","Story","ip_diffim",1,"Make  WarpType configurable in GetCoaddAsTemplateTask","""Now that there are multiple types of coadds for the different warp types, we should allow specifically requesting PSF-matched templates for image subtraction.   """
"DM-11790","Story","jointcal",2,"Move jointcal doc to DMTN-36","""In order to make the jointcal document more readily accessible, I will port the current LaTeX into DMTN-36, using the lsst-tex system."""
"DM-11785","Story","jointcal",8,"Run jointcal on acceptance data","""Run jointcal on the acceptance data, and produce catalogs that are ready to be validated via validate_drp."""
"DM-11784","Story","jointcal|meas_mosaic",1,"Find all the necessary data for jointcal/meas_mosaic comparison","""The data that was selected for the jointca/meas_mosaic acceptance test is listed on this website:    https://confluence.lsstcorp.org/display/DM/JointCal+Acceptance+Tests    We need to confirm that it is all available and processed with a recent enough version of the stack, including necessary reference catalogs."""
"DM-11791","Story","Continuous Integration|stack release",0.5,"weekly release w_2017_35 failed","""{{_35}} failed in the canonical build on lsst-dev failed due to a full disk or quota limit.      """
"DM-11809","Story","sconsUtils|Third Party Software",1,"Explicitly enable pep8-naming tests","""Currently, {{flake8}} is installed with minimal plugins and does not include {{pep8-naming}}. This is problematic on two counts:    # The developer guide explicitly specifies naming tests with a set of ignored codes. These codes are not currently checked.  # If a developer happens to have {{pep8-naming}} installed their build can break because the flake8 testing in CI and in default builds is not testing what it should be.    I am going to add {{pep8-naming}} eups package and enable name testing. This will also require fixing any flake8 problems in the packages that have automated flake8 testing.    I do not believe an RFC is required to add this package as the developer guide already implies we are using it."""
"DM-11802","Story","Continuous Integration|lsst|lsstsw",0.5,"bump eups version to 2.1.4","""Update the eups version to {{2.1.3}} for an important py3 compatibility fix."""
"DM-11800","Story","meas_mosaic",1,"Update meas_mosaic to new transform-based API for afw::cameraGeom","""With the merge of DM-5922, {{meas_mosaic}} is currently broken with errors like:      Please update {{meas_mosaic}} to the new {{afw::cameraGeom}} API."""
"DM-11863","Story","meas_deblender",1,"Fix bug in strict monotonicity","""There is a bug in the strict monotonicity algorithm that occurs when a faint object is close enough to a bright object that its initial SED is a poor choice, and is closer to the SED of its brighter neighbor. In this case the algorithm completely fails.    To test the projection, I ran a deblend using only the symmetry operator, which resulted in the first attached image. I then ran the projection, which resulted in the 2nd image, which is not strictly monotonic. This ticket is to investigate the origin of this strange behavior."""
"DM-11862","Story","daf_persistence",1,"writeFitsCatalogStorage calls obj.writeFits incorrectly","""{{writeFitsCatalogStorage}} calls {{obj.writeFits(logLoc.locString(), flags=flags)}}, where {{obj}} is """"the object to be written"""". If {{obj}} is an {{afw.Persistable}}, this is an invalid call (Persistable.writeFits doesn't take {{flags}}), so I cannot persist PhotoCalibs in jointcal:    """
"DM-11867","Story","Stack Documentation and UX",1,"Update developer guide with flake8 testing instructions","""Now that flake8 testing can be enabled as part of normal tests, we should document how to do that."""
"DM-11870","Story","Continuous Integration|stack release",2,"weekly release w_2017_36 failed","""The build / eups distrib tag / tarball completed but the pipeline died in the container """"build from eups distrib"""" before building the jupyterlabdemo image. Presumably, the failure was because {{lsst_distrib}} can no longer be built in the docker default 10GiB root volume size.    The easiest solution would be to replace the eupspkg build with a tarball install.      """
"DM-11871","Story","afw",1,"afw.table column access is slow via__getitem__ (as compared to get)","""See https://community.lsst.org/t/afwtable-performance-degradation-using-brackets-vs-explicit-get-for-fields."""
"DM-11873","Story","pipe_analysis",2,"Optimize QA code for speed in accessing/assigning afw table columns","""The QA scripts in {{pipe_analysis}} do a lot of column accessing & assigning of afw tables.  A recent [community post|https://community.lsst.org/t/afwtable-performance-degradation-using-brackets-vs-explicit-get-for-fields/2236] highlighted the inefficient nature of accessing catalog elements with {{catalog\[fieldName\]}} vs {{catalog.get(fieldName)}} (or, even better, {{catalog.get(filedNameKey)}}).  Please update the code for speed efficiency according to the findings and recommendations of [this community post|https://community.lsst.org/t/afwtable-performance-degradation-using-brackets-vs-explicit-get-for-fields/2236]."""
"DM-11895","Improvement","astshim",3,"Support getting data for current card of FitsChan","""AST {{astGetFits<X>}} functions ({{astGetFitsS}}, {{astGetFitsF}}, etc.) take a name to specify which FITS card to read; if the name (a {{char *}}) is {{NULL}} then the current card is read. astshim does not yet support the ability to read the current card, and it is very useful; in particular it would be a big help for DM-10765. I propose to add this functionality as follows:  - if {{name}} is """""""" then read the current card  - {{name}} will default to """"""""  - In the pybind11 wrapper allow name=None, which will be the default    In addition, the most recent version of AST enhances {{astTestFits}} to support {{name=NULL}} for the current card. Add similar support to astshim, as above.    An obvious alternative is to add an overload for each {{FitsChan.getFIts<X>}} that has no {{name}} argument. That is arguably a bit more C++-like, but in my opinion it adds too many new member functions to be worthwhile. Plus overloads make the Python interface a bit harder to understand."""
"DM-11904","Story","Continuous Integration|lsst",2,"""namespace"" all newinstall.sh functions","""Virtually all {{newinstall.sh}} functions should be namespaced to facilitate using the script as a """"library"""" from other scripts.  At present, only the most recently modified functions have been namespaced under {{n8l::}}."""
"DM-11902","Story","eigen",1,"LSST Eigen installs are not discoverable by cmake","""Our Eigen package has an all-too-clever eupspkg.cfg.sh that """"emulates"""" the CMake build that comes with Eigen - and fails to install files that other CMake packages can use to find it.    This was discovered while testing an external PR on ndarray that improves and cleans up its CMake build.    My planned solution is to simply remove the eupspkg.sh and let Eigen's CMake build do its thing."""
"DM-11921","Story","ap_verify",2,"Change match method in DIAObjectCollection to return DIAObject ids","""The match method of DIAObject Collection currently returns the indices of the DIAObjects in the collection that are updated rather than their unique ids. This ticket is to change this return from the former to the latter."""
"DM-11916","Story","jointcal|meas_mosaic",1,"Warnings ""Extent2I object has no attribute getWidth"" when running meas_mosaic, jointcal","""Running  {{MosaicTask}} with {{w_2017_36}} and current {{meas_mosaic}}  gives many warnings like this:          """
"DM-11909","Story","meas_deblender",5,"Test functionality of deblender task ","""DM-11329 involved creating a deblender task to run the new deblender on HSC data. This ticket is designed to run that task on a few HSC fields to test its performance before the larger task of running the deblender on a large patch of data and analyzing the results (DM-11330). """
"DM-11931","Story","jointcal",2,"Fix jointcal exit status and doRaise handling","""jointcal is giving these warnings since DM-4141 was implemented:        To fix this, I think I need to do the following:    * add this to the start of {{run}}: {{exitStatus = 0  # exit status for shell}}  * add {{exitStatus}} to the returned Struct  * wrap most of {{run}} in {{try: except:}}  *  set {{exitStatus=1}} (or some other number) if {{doRaise}} is False and something went wrong.    Anything else I'm missing?"""
"DM-11957","Bug","astshim|jointcal",3,"Cannot round-trip >7th degree Chebyshev photometry models","""If I set {{photometryVisitDegree > 7}} in jointcal's {{ConstrainedPhotometryModel}}, I receive {{RuntimeError: Could not read an AST object from this channel}} when trying to unpersist the {{PhotoCalib}} object containing the {{TransformPoint2ToGeneric}} that I had written via {{butler.put('photoCalib', photoCalib)}}. I will attach example files produced with degree=7 and 11, to help with debugging."""
"DM-11954","Story","Continuous Integration",0.5,"add `w_latest` and `d_latest` docker image tags","""We are publishing weekly and daily tags to the docker.io registry but it would be convent to also have {{7-stack-lsst_distrib-[dw]_latest}} tags."""
"DM-11949","Story","Continuous Integration|lsst",1,"newinstall.sh should warn about env vars known to cause problems","""https://pipelines.lsst.io/v/14-0/install/newinstall.html#running-newinstall-sh-in-an-already-set-up-shell"""
"DM-11948","Story","pipe_drivers",1,"Add option to force detections in coaddDriver","""If detections exist somewhere in the butler hierarchy the detection task is not being run. This is problematic if the input repository is a reprocessing of data. Add option to force rerunning detections."""
"DM-11945","Story","JIRA|Stack Documentation and UX",1,"Document usage of groups and labels on JIRA","""Per RFC-385, we have defined a number of teams and standard labels for use on JIRA. Please ensure these are described in the Developer Guide."""
"DM-11944","Story","JIRA",1,"Delete old JIRA teams","""Please verify that there are no tickets currently assigned to the following teams (this should be the case after DM-11943 is completed), then delete them:    - DMLT / Management  - T/CAMs  - Project Science  - Process Middleware  - Site Infrastructure"""
"DM-11943","Story","JIRA",2,"Map tickets from old teams to new teams","""Per RFC-385, please ensure that all tickets currently assigned to """"old"""" teams are assigned to one of the """"new"""" teams.    The following direct mappings apply:    - Process Middleware  Data Facility  - Site Infrastructure  Data Facility    The following will need manual intervention to map tickets to whichever team is paying for the work:    - DMLT / Management  - Project Science  - T/CAMs"""
"DM-11942","Story","JIRA",1,"Create new JIRA teams","""Per RFC-385, please create the following new JIRA teams:    - System Management  - DM Science  - Data Facility"""
"DM-11966","Story","Alert Production",1,"Update DCR and simulation tools to Python 3","""Fix python 3 compatibility issues in the prototype DCR code and StarFast simulator before stackification."""
"DM-11987","Bug","ap_verify",1,"ap_verify should allow output to non-empty repos","""At present, {{ap_verify}} will not run if the destination (output repo) has anything in it. Ideally, it would not care and use the checks in {{ap_pipe}} to be able to pick up where it left off. For example, if it previously completed successfully through raw image ingestion only, I don't want to have to blow that away in order to resume running the next step (calib ingestion)."""
"DM-11974","Story","pipe_analysis",1,"Add calibUsed-only qa plots to CoaddAnalysis","""Add plots similar to the visit-level *calibUsed*-only versions added in DM-11322 but at the coadd level. This cannot be done until the flags are propagated to the coadd catalogs when DM-11866 lands."""
"DM-11973","Story","Continuous Integration",0.5,"run-rebuild job does not artifact build logs","""The jenkins {{run-rebuild}} job does to artifact the build logs, other than the {{manifest.txt}} as is done by {{stack-os-matrix}}.  This makes debugging build problems difficult."""
"DM-11971","Bug","astshim",3,"memory leak in astshim isSeries function","""Running the attached script results in the failure        It is possible that this is expected/desirable behavior, given that I am needlessly calling {{makeCameraSys}} over and over again on the same inputs.  I was under the impression, however, that these would get deleted upon exiting the {{getCenterPixel}} method defined in the script."""
"DM-12003","Story","afw",2,"Add default slot for PSF shape","""{{validate_drp}} needs to access various columns from source catalogs to do its work.  Not all of these have slots defined.  I am going to add the slot that's missing so the validation scripts are more future proof."""
"DM-12006","Improvement","astshim",0.5,"Improve testing of copyPolymorphic","""While working on DM-11971 I found that {{CmpMap}} was missing an override of {{copyPolymorphic}}. Improve the unit tests so this would be caught.    Consider removing the definition of {{copyPolymporphic}} and {{copy}} from {{Mapping}}, since that class is abstract. This may make it easier to detect omission in subclasses of {{Mapping}}, since such code will not compile. However, that still leaves deeper classes that could forget to override it, so unit testing is more important.    Finally, remove the {{virtual}} since it is implied by {{override}}.    Consider adding explicit @copydoc to {{copyPolymorphic}}, though Doxygen already shows the documentation."""
"DM-12015","Story","butler",2,"Derive SQuaRE, CI and commissioning butler requirements","""Go through CI, commissioning, and SQuaRE use cases and derive requirements for them."""
"DM-12008","Story","SUIT",2,"Add a test suite to firefly_client","""Following discussion at the 2017 Project & Community Workshop, implement a minimal test suite for firefly_client. A minimum automated test is to import the package. """
"DM-12007","Story","SUIT",2,"Add tests to display_firefly","""Following discussions at the 2017 Project & Community Workshop, add a minimal test suite to the display_firefly package. Since a Firefly server is needed to use this package, a minimal test suite can implement an import test. Interactive user tests are already included in the afw.display package."""
"DM-12029","Story","jointcal",2,"recompress jointcal's testdata zeroed images with fpack","""Now that the stack supports tile compression of FITS files, and a number of bugs related to handling of FITS image metadata were fixed (DM-11332), I can recompress the images (really just holders of the metadata) I zeroed out in {{testdata_jointcal}} so that they aren't just gzipped files. Once done I can use the new butler calls (DM-9060, DM-9153) to directly access that metadata. This should drastically speed up file ingestion for jointcal.    The compression step is probably best done via a short bash script that runs gunzip and then fpack, with some carefully chosen parameters (the files are zeroed, so it probably doesn't matter much which compression scheme is selected).    If this works, we can close DM-6911 as well, as that probably got fixed """"for free"""" as part of DM-11332."""
"DM-12028","Story","Continuous Integration|lsst|stack release",0.5,"newinstall.sh should not set PATH unless miniconda is bootstraped","""  """
"DM-12019","Story","Qserv",8,"Document use of k8s setup","""Explain to [~jgates] how to use k8s on ccqserv100 to ccqserv124 and improve related documentation."""
"DM-12040","Bug","afw",2,"Errors in test_transformFactory.py","""test_transformFactory.py has a few errors that flake8 catches in the method {{testLinearize}} including:  - rng is undefined  - nDelta is undefined    The reason the test passes is that the code in question never runs: {{invertible}} is False for the one time the code in question runs.    This code looks like a potentially useful check for several different transforms (e.g. a radial polynomial and a normal polynomial). Perhaps it should be moved into a new """"check<something>"""" method and called in more than one place?"""
"DM-12038","Story","pipe_analysis",2,"Update pipe_analysis to provide inputs for Bokeh based QA system","""Together with [~lauren], ensure that the pipe_analysis scripts efficiently & effectively dump all the information that Tim's plotting scripts need to Parquet files without wasting time generating redundant plots or stripping out useful data."""
"DM-12031","Story","DM Subsystem Science",2,"Write presentation for DESC Blending Task Force meeting","""I've been asked to outline the DRP pipelines to kick off DESC's Blending Task Force on Monday, October 2 at 12pm.  This will take some preparation.  """
"DM-12030","Story","obs_subaru|pipe_analysis",1,"Persist parquet tables from pipe_analysis scripts","""In order to make interactive QA plots such as DM-11682, we need to persist parquet files containing the compiled data that are used to make the static matplotlib plots.  Admittedly, this should be a temporary step until all the source info is easily loadable from a column-store database, but for now it is necessary.  At the visit level it might be less so, but I'll do it anyway.  This is probably technically part of DM-10859, but I thought it might be useful to get it in its own ticket so it can be merged quickly."""
"DM-12053","Story","SUIT",3,"Package v1.2 of firefly_client for PyPI and sync the LSST fork","""Recent improvements to the {{firefly_client}} package need to be gathered into a v1.2 release due to some API changes. At an appropriate point, tag this version, publish to PyPI (for {{pip install firefly_client}}, and synchronize the fork in the lsst Github org."""
"DM-12052","Improvement","SUIT",2,"Upgrade ws4py to 0.4.2","""A {{pip install firefly_client}} pulls in the latest released version of ws4py for web sockets, as version 0.4.2, released on 2017 March 29. This package is included in the LSST stack as a TaP package, version 0.3.5 released on 2014 April 1. This ticket is for upgrading the TaP package to version 0.4.2."""
"DM-12061","Story","afw",1,"Eliminate test warnings in test_methods.py","""test_methods.py issues {{DeprecationWarnings}} while testing deprecated assert methods. As of Python 3.2 unittest offers {{assertWarns}} which would allow us to make sure the deprecated methods actually do issue the appropriate warning, and stop pytest from complaining.    The trick will be making sure the tests run under older versions of Python (even if pytest warns in that situation).  """
"DM-12085","Improvement","obs_base|obs_test",1,"Camera geometry incorrect and outdated in obs_test","""The optical distortion model is backwards."""
"DM-12080","Story","obs_comCam",1,"Update lsst_repos to include obs_comCam","""Add {{obs_comCam}} to https://github.com/lsst/repos"""
"DM-12070","Story","obs_comCam|obs_ctio0m9",1,"Include obs_ctio0m9 and obs_comCam in lsst_distrib","""Implementation ticket for RFC-391.    Get {{obs_ctio0m9}} and {{obs_comCam}} included in {{lsst_obs}} and thus {{lsst_distrib}}"""
"DM-12069","Story","ImgServ",5,"In imageREST_v1 _file_response(): investigate writing lsst.afw.Image straight to data vs temp FITS file first","""There is existing comment inside imageREST_v1.py mentioning the desirability of writing Image object to data object in memory instead of to a temporary FITS file, then reading it into memory, to improve image response performance and avoidance of using temp files in the local file system.     Since afw.Image does not provide an existing/ready method to do so, some investigation of alternative ways of doing this is warranted.      """
"DM-12068","Story","meas_deblender",2,"Create Presentation for STSci PSF Photometry Workshop","""Create a 20 minute presentation on the deblender and the LSST's current plan for photometry in crowded fields."""
"DM-12089","Bug","SUIT",5,"Plotly chart with 1M points","""While it's generally a bad idea to plot more than 100,000 points, Firefly should be still producing the requested plot, however slow.    Several issues are covered by this Story, the attached test comes from David Shupe.    1. Firefly produces Maximum call stack size exceeded, when mapping large table columns into points to plot.    2. hoverinfo = 'skip' is not honored. When no hover layer is present, tooltips are not displayed and point click and select are not supported. The chart should be displayed with no highlight or select layer and no point select option.    Also as a part of this ticket remove fireflyScatter type. Regular scatter plot should behave as fireflyScatter (with the improved tooltips and axis labels).     """
"DM-12108","Story","pipe_tasks",1,"Add fake sources after wcs update","""As it stands now, fake sources that are added according to wcs positions are using the wcs provided by the telescope which can be off. If adding fake sources this should happen after wcs has been updated. This also means that detection and measurements will need to be re-run such that the fake sources are inserted,"""
"DM-12107","Story","Stack Documentation and UX",0.5,"add CI (jenkins) to developers docs","""Create dev/user documentation for the DM Jenkins instance.  Presumably, to supplant or be linked to from:    https://developer.lsst.io/processes/workflow.html?highlight=jenkins#testing-with-jenkins"""
"DM-12104","Story","ImgServ",5,"Add JSON Schema validation package for ImageServ","""The specification for the data model of imageREST_v1 is based on the standard JSON schema specification: http://json-schema.org.    The schema validator package for JSON-based queries is available on Github: https://github.com/Julian/jsonschema.  """
"DM-12102","Story","afw",1,"add input validation for SpherePoint(double, double, AngleUnits) constructor","""Add input validation for the new {{SpherePoint(double, double, AngleUnits)}} constructor"""
"DM-12128","Story","validate_drp",2,"Fix y-band for HSC in validate_drp","""The filter maps are not quite right in validate_drp for HSC any more.  Fix up the filtermaps so that y-band data can run to completion."""
"DM-12121","Story","Continuous Integration|JupyterLab",3,"build-jupyterlabdemo failing","""https://ci.lsst.codes/job/sqre/job/infrastructure/job/build-jupyterlabdemo/67/consoleFull      """
"DM-12117","Bug","butler",3,"repositoryCfg.yaml input root not backwards compatible","""The following butler command fails  on a dataset on lsst-dev that was written with {{w_2017_17}}, when using a more recent stack (in this case, {{w_2017_39}}). It also fails if {{root=PATH}} is used instead of just passing the path as the first arg. See discussion beginning here on slack: https://lsstc.slack.com/archives/C3UCAEW3D/p1507226925000049        On the other hand, if the input is specified as """"inputs=\{'root':PATH\}"""" it succeeds. Either {{RepositoryCfg_v1}} should have its version number bumped, or the newer Butler should transparently read the older .yaml.    Full stack trace of the failure:    """
"DM-12170","Story","Requirements Documents",8,"Create LDM for Butler Use Cases","""Convert the Butler Use Cases developed by the Working Group into an LDM document ready for DM internal review."""
"DM-12159","Story","Qserv",8,"Replication DB implementation","""Implementing database support for requests and jobs"""
"DM-12155","Story","Qserv",8,"Replication state schema design","""Database schema to support persistent states for requests, complex replication operations, replicas statuses (including file sizes, checksums), and persistent logging."""
"DM-12153","Story","Qserv",8,"Replication master/worker comms improvements","""Refined and improved communication model providing master-side connection pull and logical connection multiplexing"""
"DM-12135","Story","Design Documents",8,"Finish high-level Butler design (P)","""Turn DMTN-056 into a polished, internally-consistent proposal for a new Butler design.    This should include:   - Python and SQL interfaces at and above the Registry and Datastore level   - walkthroughs of how the design supports various use cases   - a preliminary list of the concrete Registry and Datastore implementations needed.    This is the ticket for [~pschella]'s piece of the work; DM-12132 captures [~jbosch]'s.  """
"DM-12132","Story","Design Documents",8,"Finish high-level Butler design (J)","""Turn DMTN-056 into a polished, internally-consistent proposal for a new Butler design.    This should include:   - Python and SQL interfaces at and above the Registry and Datastore level   - walkthroughs of how the design supports various use cases   - a preliminary list of the concrete Registry and Datastore implementations needed.    This is the ticket for [~jbosch]'s piece of the work; a similar ticket will follow for [~pschella]."""
"DM-12174","Story","Developer Infrastructure|Stack Documentation and UX",1,"community.lsst.org backups not being sent to S3","""The daily backups on community.lsst.org _should_ be uploaded to S3 (builtin Discourse functionality), but they aren't. We are doing weekly DigitalOcean snapshots that mitigate some of the data loss risk, but it would be better if we copied those daily backups.    Check if it's a permissions issue that can be fixed. Alternatively, set up a {{cron}} service that {{scp}}s the backup to S3."""
"DM-12184","Story","pipe_tasks",8,"Coaddition Tasks cannot assume that N masks can fit in memory","""[~pgee] and [~tjohnson] have recently reported high memory usage by {{SafeClipAssembleCoadd}} for examples with either large N (number of warps) or large patch sizes.  For simulated data processed by DESC,   [~tjohnson] reported 70GB processes coadding 6kX6k patches and unknown N. (Fill this in if you remember)   For DES data, [~pgee] reported memory usage >32GB  with 10kX10k patches and unknown N.  (Note: patches this large are not recommended). Masks were still uint16 at the time.     Profiling reveals that this memory usage was likely due to holding N masks in memory. In this example, patches were 4200X4200, mask pixels = int32, and N=33. 4200*4200*4*33/2**20 = 2220MiB. Full profiling print out attached.         For the simulated data example, N=~1000, patch size = 6KX6K, mask pixel size = uint16 (May 2016) , would have yielded a theoretical usage of 6e3*6e3*2*1000/2**30 = 67GiB.   For the DES, example with the 10kX10k patches any more than 150 visits would have not fit on the 32G system.    Now that we've switched to int32 masks this is even more important, as the memory usage doubles for examples with  large N or large patches. Even with 4k X 4k patches, it only takes N=180 to get memory usage > 10GB.    This ticket will  remove the assumption that N masks can fit in memory from the implementation of {{CompareWarpAssembleCoadd}}. Because the solution will likely be the same for SafeClipAssemble too it will likely be implemented at the same time. """
"DM-12189","Story","SUIT",2,"Firefly should not longer use path segment parameters, it should use query string","""Firefly has been using path segment parameters to specify meta parameters {{;}} such as channel and action type.  This does not work exactly has expected on all servers. Therefore we are going to go back to using classic query string {{?}}. {{wsch}} (channel) parameter will now be {{__wsch}}, {{a}} (action) will now be {{__a}}    Fix should be put into rc."""
"DM-12200","Story","jointcal",0.5,"jointcal tests fail when optional testdata_jointcal is not present","""The most recently merged PR is https://github.com/lsst/jointcal/pull/45    {{jointcal}} from master is not buiding via {{eups distrib install}}.  I suspect this is because unit tests we introduced that are dependent on the {{setupOptiona}} {{testdata_jointcall}} product.  Test that rely on optional packages should bail out gracefully without failing.      """
"DM-12216","Bug","validate_drp",0.5,"Not all plot files append outputPrefix with an underscore","""Some of validate_drp's plot filenames are created as {{outputPrefix+""""something.png""""}} instead of {{""""%s_%s""""%(outputPrefix, """"something.png"""")}}. This can make the output filenames less readble. As an example showing the differences:        Should be an easy fix, unless there's other code that expects the files to be handled that way?"""
"DM-12215","Bug","validate_drp",0.5,"matchedVisitMetricsTask outputPrefix results in hidden files","""{{matchedVisitMetricsTask.py}} has a default {{outputPrefix="""".""""}}, which results in files like {{.\_PA1.png}} and {{..json}} in the directory it was run from. The default should probably be {{""""""""}}, or {{""""./""""}}, as the plotting code uses {{%s_%s}} with the first substitution being outputPrefix.    An alternate solution would be to use {{--output}} for this purpose, since this is a {{Task}}, and does appear to require an explicit output. Edit to add: the {{outputPrefix}} that gets passed on to {{validate}} should maybe be {{output/outputPrefix}}, though that still doesn't work with the substitution that's used when making the plot files, if outputPrefix is {{""""""""}}"""
"DM-12208","Bug","SUIT",2,"Firefly viewer loading race condition - should wait for document load","""Firefly sprint can attempt to access the DOM before it is ready.  It needs to check {{window.document.readyState}} and wait for onload if necessary."""
"DM-12230","Story","astshim",1,"Mapping.applyForward and applyInverse fail on empty arrays","""Mapping.applyForward and Mapping.applyInverse fail on empty arrays: it triggers an AST error.    This showed up as a mysterious error in DM-10765 in afw test_footprint1.py    The fix is trivial: have Mapping._tran skip the call to astTranN if the input array has 0 points."""
"DM-12233","Story","meas_deblender",3,"Improve interface for multiple components","""The current interface for the deblender takes constraints and components as arguments but doesn't utilize that information when building the constraints for each object (for example having default constraints for different component types). It also doesn't pass those parameters to the main NMF algorithm without being explicitly given as function arguments, so improving this interface would make constraints and components easier to use and more robust against inconsistencies (for example this weekend I had forgotten to pass the constraints to the function to build the monotonicity operator, causing half of the components to not have monotonicity applied)."""
"DM-12232","Story","meas_deblender",1,"Create presentation for DESC blending group","""The LSST-DESC blending group has asked Peter and I to give a presentation on the new deblender. Most of the talk was already created for LSST-2017, however some work is needed to update it with the latest results using multiple components and the current status."""
"DM-12257","Story","ap_verify",1,"Implement association step in ap_verify","""Let {{ap_verify}} call the association step in {{ap_pipe}} and verify that the code runs to completion on the standard {{ap_pipe}} dataset ({{verify_ap_hits2015}}, {{visit=410985 ccdnum=25}})."""
"DM-12256","Story","ap_pipe",2,"Incorporate AssociationTask into ap_pipe","""Let {{ap_pipe}} call {{AssociationTask}} and verify that the code runs to completion on the standard {{ap_pipe}} dataset ({{verify_ap_hits2015}}, {{visit=410985 ccdnum=25}})."""
"DM-12254","Story","jointcal",1,"Switch jointcal to default to IndexedRefObj instead of a.net","""Jointcal currently defaults to using {{LoadAstrometryNetObjectsTask}} for its {{refObjLoader}}. This can be dangerous in that if one doesn't retarget in the config, loading the skyCircle will fail and getting to that point can take a long time with lots of files.    We also plan to phase out A.Net catalogs over time, so this is a good idea long term as well. It does require some reconfiguration of the unittests however."""
"DM-12307","Improvement","Continuous Integration",1,"update blue-ocean to 1.3.0","""Blueocean 1.3.0 has been released and the changelog lists a fix for non-working http links in console output.  Perhaps this will also fix linking to triggered jobs?    changelog: https://plugins.jenkins.io/blueocean"""
"DM-12306","Bug","ap_verify",2,"Make datasets optional for ap_verify","""According to the [developer guide|https://developer.lsst.io/build-ci/new_package.html#handling-git-lfs-backed-repos], git-lfs repos cannot be a required dependency of any Stack package. {{ap_verify}} currently requires {{ap_verify_hits2015}} for testing purposes. This behavior must be changed before {{ap_verify}} can be included in {{lsst_apps}}.    Note that {{Dataset}} cannot be tested at all without a dataset package, and command-line parsing can only be partially tested."""
"DM-12305","Story","SUIT",20,"Research HiPS viewing in Firefly","""Begin researching HiPS viewing in Firefly. Do the following:    * Learn about Healpix  * Learn about HiPS  * Determine how a viewer would fit into Firefly  * Look at Aladin Lite code and tool  * Look at Aladin Lite API  * If straightforward, add a proof of concept HiPS viewing into Firefly."""
"DM-12272","Improvement","astshim",0.5,"Fix bug in arrayFromVector","""arrayFromVector has a bug: internally the strides vector is wrong, which can lead to memory issues. Fix this, wrap it for use in Python, and provide a unit test.    Also, coefficient array arguments for {{ChebyMap}}, {{PolyMap}} and {{MatrixMap}} do not have const elements. Fix this."""
"DM-12270","Bug","astshim",1,"AST persistence is not exact","""AST persistence by writing to a string is not exact because double precision values are not written to sufficient precision. The result is tiny differences in computations from FrameSets that have been persisted and unpersisted. David Berry is working on a fix. This ticket provides a place to record the issue and mark temporary workarounds in our tests."""
"DM-12315","Story","ap_pipe",8,"Generalize ap_pipe to non-HiTS data","""Currently, {{ap_pipe}} has some hardcoded assumptions that it is working on DECam data, and the ingestion step is specific to HiTS. Both of these assumptions should be lifted (likely delegating much of the work to a standards-compliant {{obs_*}} package) to allow {{ap_pipe}} to be run on arbitrary datasets."""
"DM-12362","Story","Qserv",0.5,"SCons 3 rebuilds qserv binaries every time","""For some reason new SCons 3 wants to rebuild all binaries (shared objects included) on every scons invocation."""
"DM-12361","Story","Qserv",0.5,"Qserv needs more changes after xrootd shared object renaming","""In DM-12308 we changed the names of some shared objects that come from xrootd. There are still references to other shared object in xrootd config file that needs similar change."""
"DM-12359","Story","pipe_base",1,"send Task log output to stdout","""Send Task {{lsst.log}} output to stdout instead of stderr.    This is the implementation ticket for RFC-402."""
"DM-12384","Story","jointcal",2,"exit/raise when data is less than parameters","""Jointcal should exit or raise when the number of data points is less than the number of fitting parameters (e.g., constrained 4th order polynomial) with only 3 stars). I thought there was once such a check for astrometry, but I can't find it now."""
"DM-12375","Technical task","afw|meas_algorithms",2,"Attach transmission curves during ISR or std_raw","""Make sure we have spatially-varying transmission curves attached to Exposures by the time we write the calexp dataset.    Will need to decide how to store filter curves - best bet is probably as a butler dataset keyed only by filter for now."""
"DM-12374","Technical task","pipe_tasks",2,"Add transmission curve coaddition to coadd Task code","""Add high-level code to combine spatially-varying transmission curves during coaddition."""
"DM-12373","Technical task","afw",3,"Add spatially-varying transmission curves to Exposure/ExposureRecord","""Attach an instance of the ABC defined in DM-12367 to Exposure and ExposureRecord.    While we could add these to Filter rather than add it to Exposure directly, my preliminary feeling is that it'll be better to let this represent the full throughput rather than associating it strictly with the filter.  It may *also* make sense to make Filter hold one of these objects to represent its contribution only, but that isn't what's needed for DM-12366."""
"DM-12372","Technical task","meas_algorithms|obs_subaru",2,"Add transmission curves for HSC filter traces","""Implement the interface of DM-12367 using [~erykoff]'s approach to interpolating HSC filter traces."""
"DM-12370","Technical task","meas_algorithms",2,"Add a coadded transmission curve implementation","""Implement the interface of DM-12367 with a proxy that combines other concrete transmission curves as a function of position."""
"DM-12369","Technical task","meas_algorithms",1,"Add a coordinate-transform proxy transmission curve","""Implement the interface of DM-12367 for a proxy that changes the coordinate system of a different transmission curve object, using the new Transform objects.    Should support at least focal-plane to CCD pixels and coadd pixels to CCD pixels.  Does not obviously need to support sky coordinates."""
"DM-12368","Technical task","meas_algorithms",0.5,"Add a trivial spatially-constant transmission curve implementation","""Implement the interface of DM-12367 for non-spatially varying transmission curves."""
"DM-12367","Technical task","afw",2,"Add an abstract base class for spatially-varying transmission curves","""Add a C++ abstract base class (with Python wrappers) for classes that represent wavelength-dependent transmission (e.g. filter curves) as a function of position.    These should make it possible to use an implementation in one coordinate system (e.g. focal plane coordinates) to provide a transmission curve looked up via another set of coordinates (e.g. pixels) via a proxy subclass of the ABC.    Design probably deserves an RFC.  Many conversations on this the appropriate design for this functionality have been started but none have converged; some prior art exists in Sims.  Should defer discussions about functionality beyond what's needed for HSC filter curve coaddition as much as possible.    These objects will need to be persistable with afw::table::io."""
"DM-12391","Story","pipe_tasks",1,"Improve error message for case when warpCompare can't find any psf-Matched warps","""This message means that no psfMatched warps were found, and a static sky model could not be built but a user might not deduce that from:    ```Traceback (most recent call last):    File """"/software/lsstsw/stack/Linux64/ctrl_pool/13.0-6-gf96f8ec+54/python/lsst/ctrl/pool/parallel.py"""", line 496, in logOperation      yield    File """"/software/lsstsw/stack/Linux64/pipe_drivers/13.0-21-g61c0bd4+9/python/lsst/pipe/drivers/coaddDriver.py"""", line 261, in coadd      coaddResults = self.assembleCoadd.run(patchRef, selectDataList)    File """"/software/lsstsw/stack/Linux64/pipe_base/13.0-14-g8b3bf66+40/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/home/yusra/lsst_devel/LSST/DMS/pipe_tasks/python/lsst/pipe/tasks/assembleCoadd.py"""", line 388, in run      supplementaryData = self.makeSupplementaryData(dataRef, selectDataList)    File """"/home/yusra/lsst_devel/LSST/DMS/pipe_tasks/python/lsst/pipe/tasks/assembleCoadd.py"""", line 1629, in makeSupplementaryData      templateCoadd = self.assembleStaticSkyModel.run(dataRef, selectDataList).coaddExposure  AttributeError: 'NoneType' object has no attribute 'coaddExposure'```"""
"DM-12390","Story","daf_persistence",2,"Butler doesn't raise when failing to write data","""If you supply insufficient data in the dataId for a butler to {{put()}} the data, it will just pretend to have done it (_i.e._ it doesn't raise or warn, it just silently returns as if all was fine).    If one does    where the {{postISRCCD}} template looks like  {{template: """"postISRCCD/postISRCCD_v%(visit)d_f%(filter)s.fits""""}}  then this will work. However, if you provide an empty dataId dict, it will not complain, but nothing will get written (of course).    This seems like a moderately serious problem, as it is easy to accidentally under-specify or mis-specify a dataId.    (FWIW, if I change 'postISRCCD' to an undefined dataset type I _do_ get an error)."""
"DM-12445","Story","obs_subaru|pipe_tasks",3,"Set appropriate default configs for CompareWarp Coadds","""Set default configs for makeCoaddTempExp, assembleCoadd, and coaddDriver in pipe_tasks and obs_subaru based on testing results.    These include the usual obs_subaru defaults for AssembleTask and SafeClipAssembleTask and more.  For example, these will probably include these configs:    """
"DM-12436","Story","Continuous Integration|stack release",1,"remove jenkins py2 builds - post v15 release","""Remove py2 support from:    - jenkins ({{stack-os-matrix}} + assorted publishing/release related jobs)  - {{newinstall.sh}}  - {{lsstsw}}"""
"DM-12432","Bug","ap_verify",2,"Fix timing measurement construction","""At present, {{ap_verify}} produces few timing measurements because I was not aware of DM-11935 when I wrote the code (and the pipeline was not yet in a state where it could be tested). The code should be changed so that measurements are reliably generated, either by fixing DM-11935 or by working around it."""
"DM-12417","Story","daf_persistence",0.5,"yaml dump prepends !!python/unicode to everything","""Calling {{dumpToFile}} on a daf_persistence.policy causes !!python/unicode to get prepended to everything. As per https://stackoverflow.com/questions/1950306/pyyaml-dumping-without-tags it seems that changing {{yaml.dump()}} to {{yaml.safe_dump()}} should fix this."""
"DM-12447","Improvement","afw|ip_isr|jointcal|meas_base|meas_mosaic|obs_sdss|pipe_tasks",5,"Make Detector.transform and Camera.transform support lists of points","""Implement RFC-392: make Detector.transform and Camera.transform support lists of points (or single points) and delete the CameraPoint class. Removing the CameraPoint class also requires a minor change to Camera.findDetectors and findDetectorsList."""
"DM-12450","Story","pipe_base|pipe_drivers|pipe_tasks",2,"Implement RFC-407: improve interface for clobbering vs. reusing outputs","""See RFC for description.    IMO, this has bitten too many DRP team members recently to just put it on the backlog; I think it's really costing us time and money.  Even if the RFC needs to stew for a while before merging, I'd like to get at least a partial implementation on a branch while it's fresh in my mind.  """
"DM-12455","Story","Developer Infrastructure",1,"Please install v14.0 in the shared stacks on lsst-dev ","""The stack release v14.0 just came out. It would be useful if v14.0 is available in the shared stack on lsst-dev. """
"DM-12452","Improvement","astshim",2,"Add FrameDict class","""Add a new class FrameDict to astshim that is a FrameSet with a table for looking up frame index by domain. This can greatly simplify much of the code in afw that manipulates FrameSets."""
"DM-12476","Story","Science Pipelines",5,"Re-write Bandpass class and usage in prototype DCR code","""The current bandpass implementation leads to an inaccurate effective wavelength calculation for DCR. That implementation should change, and the way the bandpass is used throughout the prototype code should be updated"""
"DM-12475","Story","Science Pipelines",2,"Simplify PSF calculation in prototype DCR code","""In order to simplify the transition of the prototype DCR code to the stack, several components should be re-written. This includes the PSF model, which currently depends on a lot of old and complicated code that deconvolves DCR from measured PSFs."""
"DM-12473","Story","afw",2,"Add getParallacticAngle() to visitInfo","""[~sullivan] has done a bunch of math for calculating things related to refraction. Some of these should live in VisitInfo, since it knows the necessary values for the calculations. In particular, {{visitInfo::getParallacticAngle()}} would be very helpful. I suspect that there are some others in his DCR code that we'd like to have more broadly available.    Ian suggests that he could do this as a pair coding exercise with [~rowen] or [~krzys], since he doesn't know C++ that well."""
"DM-12467","Story","Science Pipelines",2,"Prototype DCR code maintenance","""While working on the design of how the DCR algorithm will fit in the stack, the existing prototype code is expected to change to reflect new functionality and limitations. """
"DM-12465","Story","Science Pipelines",3,"Revise DCR technote","""Revise the DCR technote DMTN-037 based on feedback received on the initial full draft."""
"DM-12464","Story","Science Pipelines",2,"DCR correction design review","""Review the design of the DCR algorithm in the stack, and gather feedback from stakeholders."""
"DM-12463","Story","Alert Production",8,"Create initial design for how DCR will fit in the stack","""Now that the prototype DCR code is finished it needs to be refactored and brought in to the stack. Since there is a substantial amount of code involved I will write an initial design first. The result of this ticket will be a brief report describing the code that will be added to existing packages and any anticipated changes."""
"DM-12480","Story","obs_comCam",5,"Update obs_comCam policy file","""Following review comments on DM-12429, the policy for obs_comCam is not the minimal required to produce the same functionality, as a lot of things are redefined identically to how they are defined for the default in obs_base. This ticket is to make a best-effort at improving that situation, _and_ to fix a number of places in the path templates that are not currently correct (this is a newish obs_package and they were born wrong)."""
"DM-12491","Story","pipe_tasks",2,"Reduce compareWarp I/O","""We already assume that a list of spanSets representing the artifacts can fit in memory, so we can assume that the list of artifact CANDIDATES can also fit in memory. Lets loop over the warps once, building the count map and candidates at once  and then filter them afterwards."""
"DM-12531","Story","pipe_base",1,"Implement RFC-409: only check configurations/schemas/versions in output repos","""Implements RFC-409.    If this is as easy as I'm guessing, I should be able to get this done before the RFC is adopted, and then merge it at the same time as DM-12450 to allow me to group the announcements about these changes in behavior."""
"DM-12529","Bug","skymap",0.5,"Enum comparison should use == not is","""The *showVisitSkyMap.py* script in the {{examples}} sub-directory of the {{skymap}} repo uses the comparison:    This no longer evaluates to *True* when appropriate.  The condition here should be `==`, not `is` (it is likely the behavior changed along with the pybind11 wrapping and has simply gone unnoticed since)."""
"DM-12527","Bug","sconsUtils",2,"base build failure on Ubuntu due to gcc non-detection","""sconsUtils is not correctly detecting the default gcc (5.4) on Ubuntu 16.04. This results in {{-fno-lto}} not being included in the compiler options, resulting in a build failure (first failing package is {{base}}).    Here's what the gcc non-detection looks like in the build log:    """
"DM-12524","Bug","astshim",1,"AST should still write in FITS-WCS format after offsetting CRPIX","""If I offset CRPIX by inserting a shift at the beginning of the GRID to IWC mapping, the resulting WCS cannot be written in FITS-WCS format. David Berry has a fix in AST.    This will require a new unit test in astshim and enables an improvement in ast: the shift can be added after GRID instead of between PIXEL0 and GRID (breaking the desired rule that PIXEL0 to GRID is always a shift of +1)."""
"DM-12556","Story","validate_drp",1,"reportPerformance.py can't handle new metrics","""Now that TE1 is calculated on the master branch of {{validate_drp}} but not included in the release metrics.  This causes a {{KeyError}} when I run {{reportPerformance.py}} on JSON files produced with a master version."""
"DM-12555","Story","SUIT",8,"HiPS: query a HiPS server to see what is available.","""This issue needs research. It is currently possible from CDS if there is a standard. Research and implement the ability to create a list of HiPS repositories.    The service is documented in section 5.2 of the attach HiPS pdf.    The development includes,   * send query to HiPS server to get public HiPS  per information from[http://aladin.u-strasbg.fr/hips/list|https://github.com/Caltech-IPAC/firefly/pull/url]  the available HiPS images can be retrieved by sending the query like  [http://alasky.unistra.fr/MocServer/query?hips_service_url=*&dataproduct_type=!catalog&dataproduct_type=!cube&get=record|https://github.com/Caltech-IPAC/firefly/pull/url]   * show the list of the found public HiPS in a table"""
"DM-12547","Epic","SUIT",40,"SUIT and Firefly integration and test","""This epic will capture the effort for integration and test in S18 of SUIT, including PDAC portal update/test,  new features in portal an dFirefly test,  packaging and deployment issues. """
"DM-12561","Bug","Continuous Integration|JupyterLab",1,"jupyterlabdemo build failing","""  """
"DM-18249","Story","ts_middleware",2,"SAL features - add authList support to XML","""Detailed design"""
"DM-12588","Story","validate_drp",2,"Port validate_drp documenattion","""The code in {{validate_drp}} was ported to use {{verify}} in DM-12253, but that did not include porting the documentation.    This ticket is to update documentation in {{validate_drp}} for API changes as well as general docstring cleanup."""
"DM-12587","Story","Qserv",8,"Use minikube for travis-ci","""* Improve Qserv container version management: use tag for Qserv container (produced with git describe (--parent?))   * Build run-kubectl container at runtime with a given version or install kubectl   * What about qserv/qserv:dev container?   * add qserv_deploy to qserv_distrib?   * Try to speed up the build... (reduce container image size)"""
"DM-12571","Story","Developer Infrastructure",1,"Update dev guide to allow super()","""This ticket is to implement the final change from RFC-397. I've tweaked the wording slightly here to clarify the single/multiple inheritance point.    This is the replacement version of the section of the python style guide about {{super()}}:    """
"DM-12611","Bug","astshim",1,"FrameDict(FrameSet const &) broken","""FrameDict(FrameSet const &) results in an unusable FrameDict in C++ because AST has already reclaimed the raw pointer.    pybind11 avoids the issue, so it is difficult to test in Python. Add a simple C++ function that Python can call to induce the problem, call it from {{test_frameDict.py}} to demonstrate the problem, then fix the problem."""
"DM-12610","Story","Developer Infrastructure",1,"Document lsst-dev filesystems","""{{lsst-dev01}} has access to all the GPFS filesystems available to the Verification Cluster (ie, as documented at https://developer.lsst.io/services/verification.html#verification-gpfs). However, if you didn't already know that, you wouldn't discover it by reading https://developer.lsst.io/services/lsst-dev.html. Please cross-link this documentation appropriately."""
"DM-12596","Bug","meas_extensions_astrometryNet",1,"AstrometryTask.distort broken","""The changes in DM-5922 were not propagated to {{AstrometryTask.distort}} in {{meas_extensions_astrometryNet}} so that method is broken. The fix is trivial.  """
"DM-12593","Story","pipe_tasks",2,"Use HSC S17A Junk List to validate CompareWarp","""Use Junk list from Matsuoka-san to validate CompareWarpAssemble"""
"DM-12652","Story","Firefly",2,"code change to deal with 32bit mask layer in LSST image","""Update the code to auto-generate the mask layers for all 32 bits when the mask extension is detected in the image. """
"DM-12616","Bug","SUIT",2,"BUG: partial decimated data returned on repeated request","""Using slate-demo-explicit2.ipynb from firefly_client examples.    If the request is reissued (last cell reloaded) before the first one completes, partial results (100 pts instead of ~1000) are returned for heatmap. (See attached.)    Controlling pageSize in DecimationProcessor.java fetchData does not work when the cached version of the data is returned. We need to pass pageSize from the client.    """
"DM-12615","Improvement","astshim",1,"Add copy-constructors to astshim objects","""Most astshim objects do not provide a copy-constructor (motivated by the discussion in DM-9174?). This means that to copy an object, one needs complex statements like {{Object(std::move(*object.copy()))}}. Since astshim objects can be copied anyway through {{copy}} or a temporary object, adding a copy-constructor would allow for more idiomatic C++. The copy-constructor could be implemented either by indirect constructions like the one above, or by something more efficient."""
"DM-12660","Story","Qserv",5,"Install test and study a local k8s installer","""this local installer could be used for running integration tests on travis-ci."""
"DM-12658","Story","pipe_tasks",2,"base_PixelFlags_flag_clipped not getting set on measurements on CompareWarp Coadds","""Catalogs measured from CompareWarpCoadds don't have {{base_PixelFlags_flag_clipped}} set if clipped.   The only reason SafeClipped coadds do is because the coadd masks are manually set before writing out as a workaround for: DM-9953.         I""""m going to add this to CompareWarp, but we should remember to remove it from both when DM-9953 is finished. """
"DM-12690","Story","jointcal",0.5,"Make ConstrainedPolyModel actually support initFromWCS","""While sorting out the best approach for getting jointcal to ingest a SkyWcs, we discovered that the {{ConstrainedPolyModel}} was ignoring the {{initFromWCS}} constructor boolean flag. Looking at the history, it appears it was never used: the chip transfo was always being initialized with the input WCS.    This is an easy fix, and I'll also make it a configurable, so we can test how larger datasets behave when it is {{False}}; the testdata all appears to be fine (initial chi2 is different, but it quickly settles down to the same value)."""
"DM-12675","Story","Stack Documentation and UX",1,"Developer guide inaccurately summarises issue semantics","""https://developer.lsst.io/processes/workflow.html#tickets makes various claims about the association of different types of issue (story/bug/improvement) with epics. In particular, it claims that """"bug"""" and """"improvement"""" type issues are not associated with epics.    This is simply incorrect: bugs and improvements should be associated with epics in just the same way as stories, and are treated identically for the purposes of earned value accounting.    (I think this bad documentation is based on a misunderstanding of the outcome of RFC-43.)"""
"DM-12667","Story","daf_butler",8,"Implement minimal Butler POSIX Datastore prototype","""Implement a minimal Butler Datastore (as defined in DMTN-056) backed by a POSIX filesystem.    The intent of this ticket is to build a minimum prototype for testing purposes to be used with either the Registry from DM-12613 (or DM-12371).  This prototype is to be as simple as possible but should be useable to inform decisions about pluggability, chaining, caching and API layering for later versions."""
"DM-12721","Story","SUIT",0,"SUIT and Firefly deployment in docker","""deployment of SUIT, PDAC using docker technology"""
"DM-12720","Epic","stack release",40,"Prepare and execute 15.0 release","""Ensure that all of the following steps are executed, performing as many as possible directly and training on each:  * Identify any pre-release blockers (must-have features)  * Track blockers to closure  * Eups publish rc1 candidate  * Git Tag v15.0-rc1  * Github release lsst_demo 15.0  * Branch 15.0 of newinstall.sh (lsst)  * Track any latent bugs to closure  * Repeat with additional -rcN candidates  * Confirm DM Externals are at stable tags  * Tag DM Auxiliary (non-lsst_distrib) repos  * Perform full OS testing (see https://ls.st/faq2 )  * Git Tag 15.0, rebuild, eups publish  * Produce factory binaries  * Test factory binaries  * Gather contributed binaries  * Update Prereqs/Install  * Update Known Issues  * Gather Release notes  * Gather Metrics report  * Email announcement"""
"DM-12718","Epic","Developer Infrastructure",40,"Investigate alternatives for packaging/build infrastructure","""Investigate and propose an alternative to current product/package structure and packaging and build tools.  Submit an RFC or determine that one is not timely."""
"DM-12712","Epic","Design Documents",20,"Update LDM-148 for Commissioning Review","""Adjust text and diagrams to match service designs.  Submit RFC to baseline new version."""
"DM-12701","Story","skymap",1,"Update showVisitSkyMap.py for unique visit and tract identification","""Update the color mapping of the visit outlines such that each visit gets a unique color.  Also add a legend with the visit numbers such that they can be identified in the plot.  Additionally, allow for multiple tracts to be specified and have their outlines drawn on the plot with unique gray-scaling and added to the legend.  """
"DM-12700","Story","obs_subaru|pipe_tasks",2,"Flip CompareWarpAssembleCoaddTask on by default for RC and ci_hsc","""Switch defaults everywhere (not just obs_subaru coaddDriver).   Includes running ci_hsc with CompareWarpAssembleCoadd. """
"DM-12697","Story","pipe_tasks",3,"Fix hollowed out cores of saturated stars in CompareWarp","""Thus far I've been clipping any any region for which we don't have information from the PSF-matched warp. This includes more area than direct warp because of  matching kernel smears out the bad pixels and edges of calexps.  Test allowing saturated pixels through. Merge if it works. """
"DM-12694","Story","ctrl_execute",1,"Add queue option for allocateNodes.py","""Following IHS-612, there will be multiple slurm queues on LSSTVC.   It would be great to be able to tell {{allocateNodes.py}} which queue to send jobs to. """
"DM-12692","Story","pipe_tasks",2,"Improve  temporal threshold for CompareWarp","""An integer maxNumEpochs is too crude. The original fraction temporalThreshold of the number warps entering an image is too crude.     Evaluate and test a fraction with a floor based on the local N_epochs. """
"DM-12771","Improvement","astshim",1,"Support the new FitsChan SipReplace attribute","""Add support for the new {{FitsChan}} attribute {{SipReplace}}. This makes AST believe the inverse SIP coefficients and will be usable in DM-12764 to improve the accuracy of SkyWcs.skyToPixels for WCS with SIP terms."""
"DM-12766","Story","pipe_drivers",1,"coaddDriver  with --cores > 1 produces MPI_Abort(MPI_COMM_WORLD, 1) ","""To reproduce, the first one with --cores=1 works, but second with --cores=2 does not:          Note to get any useful output you'd need to either switch:  makeCoaddTempExp.doApplyUbercal=False  AssembleCoadd.doApplyUbercal=False    OR     setup meas_mosaic (which I currently can't build with the python3 stack)"""
"DM-12765","Story","obs_subaru|pipe_tasks",1,"Record filter ratios in HSC coadds","""This is the most minimal version of DM-12366, requested by NAOJ.  It makes sense to do it on a separate ticket.    This will mostly be highly HSC-specific code, as it's a lot harder to come up with a way to report fractions of different filters used when you can have more than two filters and arbitrary names for them; for HSC we know exactly which pairs of filters we need to take ratios of."""
"DM-12764","Story","afw",20,"Overhaul SkyWcs","""As part of DM-10765 it became apparently that SkyWcs needed many changes, including:  - Do not inherit from Transform  - Add FITS binary table persistence  - Add missing functionality as methods or free functions    In addition, it is possible to greatly simplify the code using the new {{ast::FrameDict}} class.    [~jbosch] suggested, and I agree, that it is better to do the SkyWcs overhaul on a ticket separate than DM-10765, making DM-10765 itself smaller and more focused."""
"DM-12794","Story","Qserv",1,"Fix Qserv dev container (and Travis CI) builds","""The recent upgrade of the python3 baseline after stack release 14.0 seems to have busted the Qserv container builds (and thus Travis CI for Qserv)"""
"DM-12783","Story","meas_deblender",1,"Normalize weights differently for morphology and SED updates","""It is believed that the problems with bad colors in HSC-Z and Y that we observed in DM-12776 are due to the way we are using inverse variance maps to weight gradient steps in the deblender. When two bands have substantially different mean variance, certain colors converge more quickly than other colors, and at all times are capable of taking larger steps toward the minimum, which we believe results in poor colors in the bands with higher variance. Similarly, images with widely varying pixel variances could also see some pixels reaching convergence more quickly than others (although we have not observed this directly).    To combat this [~pmelchior] and I propose to normalize the weights for SED updates along each band, so that only pixel by pixel variations are weighted for each SED update, and normalize the weights for morphologies along each single band image. This should give us more uniform convergence and hopefully solve DM-12776 as well."""
"DM-12780","Story","Continuous Integration",2,"prune eups.lsst.code s3 backups","""The daily backups for {{s3://eups.lsst.codes}} were growing unbounded.  Backups have been prune down to retain only the 1st day of each month prior to the current month. Eg.        Either a rotation script is needed or s3 object expiration needs to be set.  Ie., backups on every day but the first of the month have a 30 day expiration set on the objects."""
"DM-12802","Story","pipe_analysis",1,"Add shape measurements to coadd comparison.","""Add ext_shapeHSM_HsmShapeRegauss_e1, ext_shapeHSM_HsmShapeRegauss_e2, ext_shapeHSM_HsmShapeRegauss_resolution to the coadd comparison script to aid with assessing changes relevant to shear measurements."""
"DM-12819","Improvement","ImgServ",5,"Explore possible reduction of memory footprint needed for image cutouts","""Currently, ImageServ is passing data id to butler to retrieve the FULL image from the underlying fits file, before performing the cutout per user-specified dimensions, in a 2-step process.    It may be possible to combine the two steps into a single one, in the following manner:               image = butler.get(dataset_type, bbox=bbox, immediate=True,                              tract=tract, patch=patch, filter=filterName)    Note: bbox dimensions always in pixels."""
"DM-12818","Story","Qserv",3,"CSS needs new parameter for match table separation.","""Currently qana uses database-global """"ovelap"""" value as a match table """"separation"""" parameter which is wrong. Database-global """"ovelap"""" is supposed to be a default overlap value for tables that don't define their own overlap. Match table separation is not really related to overlap, so to reduce confusion we need to add new parameter to match table configuration in CSS and use is to set qana parameters.  """
"DM-12815","Story","Continuous Integration",0.5,"convert jenkins jenkins-ebs-snapshot job to pipeline","""This trivial job needs to be converted to pipeline in order to implement timeouts."""
"DM-12854","Story","Continuous Integration",5,"ongoing jenkins dockerd/xfs errors","""Jenkins jobs that use docker are frequently hanging and {{dockerd}} / {{xfs}} errors are appearing in the {{dmesg}}:        These problems seem to go away, at least for awhile, after the node is restarted (they will not soft reboot).  It isn't yet known if this is a kernel bug or some of random EBS I/O timeouts.  As it seems to be only (?) triggered by dockerd, it seems much more likely to be a kernel issue.  What is unusual is that this doesn't seem to have been an issue until ~ a week ago and this doesn't correlate with a kernel or dockerd version change."""
"DM-12848","Bug","ap_verify",2,"ap_verify unit tests fail on lsst-dev","""One of the unit tests for {{ap_verify}} tests whether its running-time metrics return a sensible time for a dummy Task execution. Because the task is a dummy, it almost immediately raises an exception, allowing the timing code to run.    However, on {{lsst-dev}} (and, so far, only {{lsst-dev}}), the running time returned is equal to {{0.0 * astropy.units.second}}, failing a test for a positive value. This result should be investigated and, if necessary, the test modified to return a nontrivial result. The assertion should not be removed if at all possible, because a measurement of zero could result from incorrect propagation of {{None}} or other invalid values."""
"DM-12861","Story","Continuous Integration",0.5,"jenkins s3backup-eups job is failing","""The last several {{s3backup-eups}} builds have failed. Eg.,    https://ci.lsst.codes/job/sqre/job/backup/job/s3backup-eups/215/consoleFull      """
"DM-12873","Story","pipe_analysis",2,"Run pipe_analysis scripts on w_46-processed RC data at NCSA","""In support of the LDM-534 QA milestone, run {{coaddAnalysis.py}}, {{colorAnalysis.py}} and {{visitAnalysis.py}} on all coadds and visits from the weekly 46 RC processing run (/datasets/hsc/repo/rerun/RC/w_2017_46/DM-12545/).  """
"DM-12909","Bug","meas_mosaic",0.5,"Test failure in meas_mosaic","""Carelessness in the merge of DM-12882 led to a failing unit test.  Fixing it now."""
"DM-12894","Improvement","Firefly|SUIT",2,"Comments on ""beta"" HiPS viewing in Firefly","""Congratulations on getting HiPS viewing going in Firefly!    In general it looks really good.  I have mostly minor comments of a wide variety, which I will post as a document attached to this ticket."""
"DM-12890","Story","ImgServ",1,"Remove imageREST_v0 (deprecated API) wrapper from code base.","""As is imageREST_v0 API (URL pattern/style) is already supported on top of v1 code base.    Once we transition over to imageREST_v1, which can be seen as v0++ from functionality standpoint,  there is really no need for the old v0 code (isolated to a few files) to remain in the code base.    """
"DM-12882","Bug","meas_mosaic",2,"Frequent catastrophic misalignment in coadd inputs","""Catastrophically bad WCSs that print through to the coadd seem to have much more common between _42 (where they were basically nonexistent) and _46.    This manifests both as duplicated sources and bad clipping."""
"DM-12881","Story","pipe_drivers",0.5,"coaddDriver tries to unset doMatchBackgrounds, which does not exist","""See https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1426  """
"DM-12924","Improvement","afw",1,"SpherePoint.offset should work at the poles and for negative offsets","""In replacing Coord with SpherePoint (DM-11162) I discovered a problem in the skymap package: skymap makes heavy use of Coord.offset, including for points at a pole. However, SpherePoint rejects such offsets (as well as negative offsets).    I believe the behavior of {{offset}} for a coord at the pole is unambiguous and unsurprising if the coord is constructed from longitude, latitude. However, I acknowledge that this is less so for a coord constructed from a 3-vector. Nonetheless, I propose to change the behavior of SpherePoint to match Coord and document the behavior at the pole.    I also propose to allow negative offsets, as the intent is unambiguous for those and Coord supports it.    Also make sure the sign convention for the orientation of offset is the same for {{SpherePoint}} as {{Coord}} and document it carefully."""
"DM-12943","Story","meas_algorithms",2,"Investigate coadd covariance impact on detection kernels","""Determine the correlation matrix empirically from blank patches of sky on a coadd, then see if we can construct a detection kernel that corrects for it."""
"DM-12940","Bug","SUIT",1,"Catch the error when adding marker or footprint to a plot without image (due to image search failure)","""For the plot with no image due to an image search failure, some running error occurs while adding a marker or a footprint to that plot. The marker/footprint adding should skip the undefined plot or the plot with no image.   """
"DM-12938","Bug","ap_verify",2,"ap_pipe crashes if --output is absolute path","""If {{ap_pipe}} is called with an absolute path as its {{--output}} directory, it will crash soon after attempting to ingest defects with a message like:    A similar error appears if {{--output}} is relative and the working directory is anything other than the parent of {{\[outputdir]}}.    I suspect the problem is because {{defectIngest}} assumes {{repo}} must be a path relative to the output directory's parent, but have not tested to make sure."""
"DM-12937","Bug","ImgServ",5,"Image retrieval via v0 API for 'i' band deep coadd returning index out of range","""The error response should have been along the line of 'image not found'.    Just for record, deepcoadd cutouts for bands other than r result in the `IndexError: list index out of range`.  Example: `http://lsst-qserv-dax01.ncsa.illinois.edu:5003/image/v0/deepCoadd?ra=9.6&dec=-1.1&filter=i`"""
"DM-12949","Bug","SUIT",8,"Filtering table from scatter chart fails when column expressions are involved","""The error is:    """"...from data where (""""w1mpro-w2mpro"""" > -1.3191681767193026) and (""""w1mpro-w2mpro"""" < -0.7958581413409266) and (""""w3mpro"""" > 8.643434512115258) and (""""w3mpro"""" < 13.130081532416503) ) as b) WITH DATA]; nested exception is java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: w1mpro-w2mpro from:null""""    Here """"w1mpro-w2mpro"""" should probably be """"w1mpro""""-""""w2mpro""""    12/14/2017 TG  https://github.com/Caltech-IPAC/firefly/pull/516    - now using db to calculate column expression values for general charts (we used expression lib before)  - fixed filter from chart when column expressions are used  - allow same columns to be used for x and y  - fixed filtering issues for expressions with alpha-numeric columns. Unfortunately, if a column name contains space, filter will not work the second time, because filter parser is using space as a delimiter. Created DM-13037 for this issue.  - updated histogram request to get the expression calculation in the database.  - fixed selection bug in heatmap I have introduced when checking that user is selecting active trace.  - created tickets for outstanding column expression issues:    DM-13036 Use db to calculate expressions for decimation (heatmap data)    DM-13039 Use custom database functions for column expressions functions not supported by DB    DM-13038 Support column expressions for column names that are not alpha-numeric    """
"DM-12972","Story","meas_deblender",8,"Write paper on deblender","""[~pmelchior] has been writing up a paper based on the new deblender. For my part I will help write some sections of the paper, including results from tests on both HSC and Sim data."""
"DM-12969","Story","Design Documents|Requirements Documents",2,"Configure LDM/DMTR docs on Travis for LSST the Docs","""This ticket covers effort associated with configuring LDM and DMTR (LaTeX documents) for deployment on LSST the Docs."""
"DM-12968","Story","obs_subaru|pipe_drivers|pipe_tasks",1,"Include INTERP+CR pixels in coadds","""I think we agreed at the 2018-12-11 Monday Meeting that it's better to included interpolated CR pixels in the coadd (since the interpolation is pretty good) rather than leave them out and get lots more pixels masked with INEXACT_PSF.    [~price], if you're in a position to do this quickly before the next HSC release, please steal it.  Otherwise I'll try to get to it later."""
"DM-12992","Story","SUIT",1,"Confirm access to the newly loaded NEOWISE data table","""confirm  that the newly loaded NEOWISE data table is accessible through current DAX service"""
"DM-12980","Story","lsst_distrib|SUIT",1,"Add display_firefly to lsst_distrib","""This ticket implements RFC-421.    {{display_firefly}} will be added as {{setupRequired}} to the table file in {{lsst_distrib}}."""
"DM-13041","Story","meas_deblender",2,"Attend Galaxy and Cosmology Class in Dec","""Attend Michael Strauss and Jenny Greene's observational galactic astronomy class to better understand the scientific applications of the deblender.    There are only 2 weeks of class this month."""
"DM-13037","Bug","SUIT",3,"Second filter fails on column names with spaces (NED)","""If a column name contains space, filter will not work the second time, because filter parser is using space as a delimiter. (see parse in FilterInfo.js)    Test case:  NED catalog search.    Using table filters, filter on """"Redshift Points"""" in table, then filter on """"Distance"""".    Alternatively, create a chart with the columns that contain spaces, filter from the chart. The second filter is producing a db error."""
"DM-13054","Story","jointcal",8,"Add colorterm config support to jointcal","""[~boutigny]'s work on color terms in u/fix_outliers should help improve the photometry models.    This ticket is to port over [~boutigny]'s work in the u/fix_outliers branch (specifically this commit: https://github.com/lsst/jointcal/commit/e1d0292c71275315a6b17b67ecaf47acd2ffbee8 ) to use {{ReferenceSourceSelectorTask}}, add a unittest to demonstrate that the color terms do affect the fit (for both the simple, and constrained models), and update the other tests to reflect any changes in the fit metrics."""
"DM-13052","Bug","ap_pipe",2,"AssociationTask does not call update on associated DIAObjects","""After running ap_pipe and ap_verify the L1DB produced by AssociationTask does not update the values of the stored DIAObjects. This causes the appearance that each DIAObject is associated with only one DIASource. This ticket will fix this case."""
"DM-13045","Story","meas_deblender",5,"Test new deblender on simulated data","""Before updating the stack API (DM-12404) and testing the deblender on HSC data (DM-11330), we should make sure that the new version works on the same simulated data as well or better than the previous version."""
"DM-13055","Story","meas_algorithms",1,"reject NaN centroid sigmas in astrometrySourceSelector","""Jointcal is still getting NaNs in some of the HSC PDR1 data. It appears that finite errors are not guaranteed by the centroid_flag, so we have to reject non-finite Sigmas during source selection. For now, we'll add it to astrometrySourceSelector, but we'll have to think of a better solution since this will affect all source selectors."""
"DM-13073","Story","System Integration and Test",1,"Add CCOB Milestone test in LDM-503","""Update LDM-503 to include approriate tests for handling data from Camera Calibration Optical Bench (CCOB). This may only be possible after the Feb meeting which sets the CCOB schedule. """
"DM-13084","Improvement","afw",2,"Be smarter about combining metadata from FITS headers","""Our afw code that reads FITS headers for images and exposures works as follows:  - It reads the metadata (as a PropertySet or PropertyList) from the first HDU  - It reads the metadata from the next HDU (the image plane)  - It combines them using PropertySet.combine    If the same keyword is present in both sets of metadata, this can cause problems. For example:  - In some files LTV[12] is specified as 0 in the first HDU and -XY0 as a float in the image HDU. This causes a failure with a complaint about mismatched types. Even if the type is int in the second HDU we end up with an array of values which is not what we want.  - In some files NAXIS[12] is specified as 0 in the first HDU and typical values in the next HDU. This results in an array value for NAXIS[12], which is not what we want.    My suggestion is to write a free function that combines metadata in a FITS-friendly manner:  - For a select few FITS-specific keywords, including COMMENT and HISTORY, use the current behavior: every time the keyword is found, add its value to an array. Require that the types match.  - For all other keywords, when a name is re-used, keep only the most recent version. Do not require that the types match."""
"DM-13082","Bug","pipe_tasks",0.5,"test failure due to DM-12968 config move","""It was not in fact safe to move the badMaskPlanes config option from CoaddBaseTask to AssembleCoaddTask.  Master is broken."""
"DM-13080","Story","pipe_analysis",2,"Add reference band flags used for forced coadd measurements to persisted parquet tables","""It is very useful for qa/debugging to know which band was used as the reference band for the measurements in forced photometry on the coadds.  These are currently only persisted in the *deepCoadd_ref* output file, so will need to read these in and add the appropriate columns to the parquet tables."""
"DM-13099","Bug","Firefly",3,"Can't set only one axis binning value on decimated plot","""In the decimated plots, I can't change the number of bins in the x-direction only.  I enter a number, hit apply, and nothing happens.  Seems that i have to set both axis. Can we use a default value for the one that is not filled in?"""
"DM-13096","Story","Alert Production",2,"Add refraction calculation to the stack","""Add a calculation of atmospheric refraction and utilities for differential refraction to the stack. These calculations are needed for the DCR-corrected templates that are being written in DM-9615, but they can be made more general and separated from the rest of the DCR code."""
"DM-13116","Story","meas_deblender",2,"Implement weighted strict monotonicity","""The strict monotonicity projection using only the nearest neighbor creates fractal-like unphysical features and affects the accuracy of the deblender. This ticket is to implement a strict, weighted monotonicity projection similar to the weighted monotonicity operator that calculates the radial gradient.    For speed, this will have to be written in C++."""
"DM-13136","Story","pipe_tasks",2,"Investigate processing failure of HiTS visit 411657, ccd 47","""During the DM-503-3 processing, we encountered an error for HiTS dataId visit 411657, ccd 47, filter='g':        Further investigation shows that 6 PSF sources are selected, but all have self.refFluxKeys.flag set, so they raise the error above in {{measureApCorr}}.     This ticket is to investigate the root cause of the failure to select usable PSF sources."""
"DM-13135","Story","Firefly",0,"Firefly Python API: need to deal with killing Firefly display window","""Robert's input #10, DM-7321    Killing the firefly display window seems to leave the notebook that's talking to it perfectly happy, but it doesn't respawn the window even if I call the constructor again."""
"DM-13134","Story","Firefly",3,"Firefly Python API: disp.pan(0,0) is ignored","""Robert's input #9, DM-7321    disp.pan(0, 0) is ignored (I think anything below (0.5, 0.5) fails). I'd expect to be able to pan any point to the centre of the display, but I'd certainly expect that it'd clip to a valid coord not silently ignore my request)"""
"DM-13129","Bug","afw",0.5,"Warnings in test_camGeomFitsUtils.py ","""test_camGeomFitsUtils.py issues warnings that appear to be bugs we should fix. Examples:    See attached log for more info"""
"DM-13126","Story","Firefly",0,"possible bug in pixel coord readout","""From Robert's input #7 in DM-8409:    Pixel coords are off by (0.5, 0.5)  the middle of the bottom left pixel should be (0, 0) (i.e. offset by (1, 1) from the fits standard, which assumes fortran-style 1-indexed arrays) *(#7)*  """
"DM-13123","Story","doxygen|Stack Documentation and UX",1,"Doxygen search broken","""When I visit http://doxygen.lsst.codes/stack/doxygen/x_masterDoxyDoc/index.html, type something into the search box, and hit enter, I get a {{search.php}} file to download in response.    Obviously, I should get search results.    This was discussed on DM-10544, but doesn't seem to have actually been fixed there (or, if it was, it has subsequently broken again)."""
"DM-13145","Story","Stack Documentation and UX",0.5,"Fix LTD Dasher's title truncation","""LTD Dasher trims document handles from titles to protect from cases where the document handle was accidentally inserted into the document title string. But for test reports, the title legitimately includes a document handle (but for a different document). See https://dmtr-53.lsst.io/v/index.html The fix is to only trim the document's own handle from a title (and only if it occurs as a distinct word unit)."""
"DM-13144","Story","Qserv",3,"Launch S15 large scale test @ cc-in2p3","""Non regression on Qserv performances"""
"DM-13162","Story","Science Pipelines",0.5,"Fix warning in processEimage","""`processEimage.py` currently loads the metadata of a simulated observation twice and runs the same code both times, except it only provides a mapper the second time. This generates a warning the first time the code is run, and is unnecessary because the second call provides the correct exposure with VisitInfo."""
"DM-13172","Story","SUIT",8,"Make HiPS popular list configurable and update HiPS list content","""- Create a method for the application to configure the list containing popular HiPS data.   - Research what information to report for the HiPS data list in addition to data's type, title and url.     """
"DM-13169","Story","Continuous Integration",1,"jenkins security update - spectre/meltdown","""Update the running kernel on all jenkins related linux nodes as a partial mitigation of the    https://spectreattack.com/    Centos 7/EL7 related links:    https://access.redhat.com/security/vulnerabilities/speculativeexecution  https://lwn.net/Articles/742919/  https://access.redhat.com/errata/RHSA-2018:0007    EC2 instances may need to be restarted regardless due to AWS patching hypervisors, so it makes sense to update the kernel at the same time.    Presumably, the jenkins OSX nodes will also need to be updated but this may be split into a separate ticket."""
"DM-13166","Story","starlink_ast",0.5,"Update AST to add support for writing SIP terms","""Update AST to the latest version, which adds support for writing SIP terms to FITS headers."""
"DM-13181","Story","Requirements Documents",1,"Flowdown LCR-1024 OSS changes to LSE-61","""In LCR-1024 requirements language was added to LSE-30 to connect it to LSE-163. This ticket is for adding the derived requirements relationships from the relevant DM requirements back to LSE-30."""
"DM-13187","Bug","jointcal",2,"jointcal selected_*_refStars is not correctly computed","""Jointcal reports the {{collected\_\*\_refStars}} and the {{selected\_\*\_refStars}}, which should represent the total number of available refStars from the input refcat, and the number that were associated to fittedStars. The latter is the number that are important for the actual fit. Thanks to [~rowen]'s investigation about a separate issue, I realized that the {{selected_*_refStars}} metrics are incorrect: jointcal does not alter the {{associations.refStarList}} during selection, but rather the pointers between fittedStars and refStars.        To fix this, we need to traverse the fittedStarList and count the number of fittedStars that have a non-nullptr \{\{refStar}}. Once done, we'll have to update all of the {{selected_*_refStars}} metrics.    Fixing this will help debug the jointcal test failures in DM-10765."""
"DM-13201","Bug","Validation",1,"calexp have TPV and SIP terms","""The {{calexp}} exposures in {{validation_data_decam}} have TPV distortion terms in HDU 0, which should have been stripped (and probably are when using the current master of the DM stack). In addition they have the expected SIP distortion terms in HDU 1. Thus it is possible that some FITS readers will read the WCS as having both TPV and SIP distortion terms.    Please reprocess the calexp (and all other processed files, for consistency). The current DM stack properly strips the TPV terms when generating {{calexp}} exposures, so that should take care of the problem."""
"DM-13193","Bug","Continuous Integration|stack release",0.5,"weekly release w_2018_01 failed","""{{w_2018_01}} failed over the weekend due to git-lfs being down due to the nebula maintenance period.(Jira was down for maintenance most of yesterday, so there may not be a tickets for the git-lfs problems)    The build was restarted yesterday, which failed attempting to publish eupspkgs.    https://ci.lsst.codes/blue/organizations/jenkins/release%2Fweekly-release/detail/weekly-release/137/pipeline"""
"DM-13189","Story","afw",1,"Add FunctorKey for Boxes","""We often store Box2Is and Box2Ds in tables.  We should have a FunctorKey to do this to reduce code duplication.    Unfortunately we may not be able to use this actually reduce existing code duplication when code has used a different convention for naming fields (as we'd need to maintain backwards compatibility with already-persisted objects), but this should at least reduce duplication going forward.    I'm planning to do this now for DM-12370 so I can use it there."""
"DM-13212","Bug","dbserv",2,"dbserv on PDAC returning 502 Bad Gateway when querying image metadata","""Tatiana of SUIT reporting this bug when executing the following query on PDAC:    curl -o imagesContainTarget.json -d 'query=SELECT+*+FROM+sdss_stripe82_00.DeepCoadd+WHERE+scisql_s2PtInCPoly(9.462, -1.152, corner1Ra, corner1Decl, corner2Ra, corner2Decl, corner3Ra, corner3Decl, corner4Ra, corner4Decl)=1;' [http://lsst-qserv-dax01.ncsa.illinois.edu:5000/db/v0/tap/sync]        Brian's investigation: Python 3 issue with base64encoding of binary data        """
"DM-13204","Story","Validation",2,"Create v14.0 versions of validation_data_(cfht|decam|hsc)","""Create v14.0 versions of validation_data_(cfht|decam|hsc).        1. Update these data reference sets with a processing by v14.0 of the stack    2. Add a v14.0    """
"DM-13215","Story","Developer Infrastructure",1,"Install 2018-vintage shared stacks","""The shared stacks on lsst-dev01 (and Tiger & Perseus, for the Princeton crowd) should be updated to install 2018-vintage weeklies. This should just be a matter of tweaking the regexp."""
"DM-13214","Story","meas_deblender",1,"Simultaneously recenter all sources in a blend","""When the deblender was updated to use different size boxes for all objects, the {{recenter_sources}} method was modified to fit each sources position separately. This might be the reason behind some faint sources that we see drifting during the fit, so this ticket will update the {{recenter_sources}} method to project each source onto the full model so that the positions can be updated simultaneously again."""
"DM-13213","Story","galsim",1,"Cannot build packages against galsim binaries distributed by eups distrib","""I have installed my stack using the eups distrib binaries. Today I went to rebuild the meas_extensions_hsm package which links to the galsim package, and the build failed. It complained about not being able to find libgalsim.dylib in the galsim package. Upon looking in the directory for galsim I see:        Which shows the simlink for the dylib is still pointing to the a directory on the build system. I propose that if this cant be fixed on the packaging side that we need a program like the shebangtron that will rewrite all the simlinks"""
"DM-13232","Improvement","daf_base",2,"Python PropertySet.set mis-handles array of bool","""PropertySet and PropertyList both mis-handle set(name, array-of-bool). The call succeeds, but the item is not correctly saved. Consider the following example:      Note that it is possible to set an array of bool using add, so it seems to be something about PropertySet.set."""
"DM-13231","Story","afw",1,"Make photoCalib outField write to _flux instead of _calFlux","""DM-10729 implemented one way of writing back out to a catalog prior to RFC-322 being implemented, that introduced a {{_calFlux}} field for the {{outField}}. {{_calFlux}} isn't used elsewhere in the stack, and is inconsistent with the documentation.    This ticket is to change it to write to {{outField+""""_flux""""}}, which allows writing the calibrated fluxes back to the same field (by having {{inField==outField}}), which is consistent with what meas_mosaic is currently doing."""
"DM-13225","Story","Requirements Documents|supertask",2,"Edit SuperTask requirements for order-independence","""MagicDraw enforces alphabetic order for requirements (within a package). This makes it impossible to define the order of the requirements as they appear.    The existing SuperTask requirements in LDM-556 were written without realizing this and contain references to previous requirements as """"above"""".    It is desirable for requirements to be meaningful in isolation in any event, so this task is to clean up the language and avoid positional references."""
"DM-13234","Story","Qserv",8,"Use k8s headless service","""Headless service will set up a constant DNS name for all Qserv nodes. This will allow to ease configuration."""
"DM-13250","Story","ap",8,"Write simple filter for sims alerts","""Experiment with a simple way to filter alert data in Python using sims data."""
"DM-13242","Story","Qserv",2,"Leftover result tables must produce errors","""There was an incident reported by [~vaikunth] on slack:    {quote}  I did a count(*) on LSST20 and it gave me back real data and columns for the result       [3:31]    ```[vthukral@ccosvms0070 in2p3]$ time mysql --host ccqserv125 --port 4040 --user qsmaster LSST20 -e """"SELECT COUNT(*) FROM Object;"""";  +--------------------+---------------------+---------------------------+----------------------------+-----------------------------------+------------------------+------------------------+------------------------+  | ra                 | decl                | raVar                     | declVar                    | radeclCov                         | u_psfFlux              | u_psfFluxSigma         | u_apFlux               |  +--------------------+---------------------+---------------------------+----------------------------+-----------------------------------+------------------------+------------------------+------------------------+  | 284.98083849415934 |  -63.32859963197394 |       0.03588015008077164 |        0.04575243321809053 |       0.0000000012152185681231455 |  7.396697501646931e-30 |  9.604600362557029e-31 |  9.647062881997884e-30 |  ```  (and many more rows)  {quote}    and Igor dug out this from the log:      This looks like there was a leftover result table whose name was reused for new query (this could happen when someone resets QMeta autoincrement ID).    Qserv should handle this situation better, there should be an error returned to user in that case, not data from old result table (or leftover table should be deleted)."""
"DM-13240","Improvement","dbserv",2,"Fixes in dbserv for better handling with reporting SQL errors and int datatype","""Tatiana G. at SUIT reported this:    Instead, it'll be more informative to redirect the SQL error back up through dbserv to query originator.    The {{int}} datatype should be set to {{long}}, removing the implicit assumption that clients of dbserv must be Python-based.        """
"DM-13258","Improvement","Continuous Integration",1,"upgrade blueocean to 1.5.x","""blueocean 1.4.0 was released today:    https://plugins.jenkins.io/blueocean    The changelog needs to be inspected to see if it addresses any of the open user requests."""
"DM-13270","Story","jointcal",1,"cherry pick ccdImage method cleanups from DM-9071","""I made a number of cleanups of method names in DM-9071, in this commit:    https://github.com/lsst/jointcal/commit/9efc5d23808b5e6f33d69e7ccd9bcf6c0bc844cb    These should be picked out of that ticket and pushed to master."""
"DM-13269","Story","jointcal",8,"Improve jointcal debugging output","""The fitter chi2 contributions debug output files need to be cleaned up and improved so we can do direct comparisons of jointcal's internal model, pre- and post-fit. Also have to make some plots to test that the output is good."""
"DM-13267","Story","meas_deblender",2,"Create presentation for Princeton Monday Meeting","""Create a presentation to give the Princeton software group an update on the new deblender, which is likely to be implemented in the stack as part of the current epic."""
"DM-13265","Bug","SUIT",5,"Saga error handling","""Firefly is using sagas for action side-effects.    An errorin masterSaga causes problems in later application behavior, like the following table loads not completing on the client unless they are explicitly backgrounded.    To test, modify getCovColumnsForQuery in CoverageWatcher.js to produce an error:    ```        The function above produces the exception and console output in the attachment, when a catalog search is requested in firefly.    Notice that the following catalog searches will not complete on the client (trackFetch in TableCntlr.js will not be called).        Implementation done:   * Use spawn when using dispatchAddSaga. This prevents the unhandled exceptions in one saga to cancel all the siblings.   * Use fork with dispatchAddActionWatcher, because we are catching the unhandled exceptions. If an exception occurs in the callback, it won't cancel the saga.   * Added documentation for actionWatcherCallback   * Fixed a bug preventing remote charts on the test page   * converted some dispatchAddSaga to dispatchAddActionWatcher, including coverage and image metadata watchers and firfely.utl.addActionListener API method.    Test case:[http://localhost:8080/firefly/demo/ffapi-highlevel-test.html]Open console to view the output, """"Start selection extensions"""", """"Track mouth readout"""". Before, you would get an error when switching readout from one image to the other, which would cancel both listeners. Now, a single error in user defined readout listener does not prevent the following calls to succeed."""
"DM-13264","Story","butler",1,"Add use case for jobs as composite datasets","""Add a use case and requirement that describes the need for the {{Butler}} to have the ability to persist the data blobs associated with a {{Job}} and the JSON file that describes the {{Job}} in different datastores. For example the blobs may be placed in an object store with the {{Job}} could be ingested in a JSON aware SQL database."""
"DM-13302","Improvement","Qserv",3,"Adding support for worker-specific resources in Qserv","""Extend the present implementation of Qserv worker plugin (xrootd SSI) to recognize (and route to the corresponding handler) requests to the worker-specific resources. The proposed extension is planned to be used for the following tasks:  * integrating Qserv with the replication system which requires an interface for interacting with the worker services to notify the ones about changes in chunk availability on the corresponding nodes  * allowing to pull worker-specific stats and counters into the custom service monitoring applications"""
"DM-13301","Improvement","Qserv",3,"Configurable worker identity and chunk availability map in Qserv","""This ticket proposes two improvements to be made in a scope of the Qserv worker services:  # replacing the current mechanism of deriving a list of available chunk numbers by parsing table names within the MySQL's _information schema_ with a new one based on an explicit persistent configuration stored within a database. The present mechanism has one major limitation preventing from integrating Qserv with the dynamic chunk replication system - it runs only one time when the worker services are being started. In the proposed model a list of chunk numbers (along with the corresponding table and database names) will be stored in a dedicated table seen by the relevant worker services. This will also allow a consistent view onto a stable collection of chunks. It will also lay a foundation for implementing a safe and efficient coordination mechanism between the replication system and Qserv worker services.  # adding a persistent support for the unique identity of the worker services. The idea here is to store some unique (in a scope of a particular Qserv cluster) name within databases used by the workers. These identifiers will be used as a foundation for setting up worker-specific resources and by the replication system. Extend the implementation and the API of the Qserv's module *wpublish* to support the proposed improvement.    For both tasks make proper changes to the Qserv management, integration and data loading scripts to populate the newly added table with a valid set of chunks and the worker identity strings, so that these resources would be available to the corresponding worker services.    Make sure the unit tests were updated accordingly.  """
"DM-13289","Story","Qserv",5,"Change SsiSession to be deleted by shared pointer.","""SsiSession is currently deleted by a call to Finished, and this can happen before tasks using the object are all done with it, causing a segfault and worker crash. Moving the the UnBindRequest call to the destructor and using a shared pointer for the SsiSesion object should make it safe. Also, it looks like eliminating the SsiSession::ReplyChannel class will make the code simpler, but some changes need to be made to expose the functions ReplyChannel calls in xrdssi."""
"DM-13274","Bug","meas_deblender",2,"Deblender sometimes fails to model second object, or crashes","""This issue was reported by Erin Sheldon's student. The problem was thatsome blends failed during initialization witha {{ValueError:}}    And other times failed during the fit with a {{LinAlgError}}:        The root cause of both issuesis that the new deblender takes coordinates as (y,x) while the user was passing (x,y) (see the discussion on[github|https://github.com/fred3m/scarlet/issues/26] for more).        The first error wasthrown because the incorrect position given had no flux above the noise level at the peak, so the source couldn't be initialized. We should implement a check for this to warn the user and have some fallback initialization.        The second error is caused by a problem with fitting positions for sourcesthat have no flux, which [~pmelchior] has fixed in a soon to be merged branch.        I'll make the change to the initialization error and close this ticket once [~pmelchior]'s branch has been merged."""
"DM-13307","Story","ap",3,"Add final conclusions to DMTN-028","""Add summary and conclusions regarding suitability of Kafka to alert distribution system needs to DMTN-028."""
"DM-13325","Bug","afw",2,"warpExposure does not propogate visitInfo","""[~sullivan] discovered that warpExposure is not propagating the visitInfo of its parent exposure. This is a bug, and it should be a trivial fix on line 250 of {{afw/math/warpExposure.cc}} (doing the same as the wcs and calib), plus a bit of unittests."""
"DM-13322","Bug","starlink_ast",0.5,"memory mishandled inside UnitNormMap","""AST UnitNormMap mis-handles the memory for the center parameter when unpersisting: it may allocate one too many doubles and fill the final one with garbage."""
"DM-13317","Bug","Firefly",1,"Filtered table display in image overlay fails to apply the filter","""This is in the test build [~tatianag] is running in response to DM-13099.    I've queried two tables on PDAC: AllWISE catalog sources and WISE All-Sky (4 band) single-epoch sources.  I've identified a cluster of sources in the single-epoch data that I suspect come from a single object, and I'm trying to identify that object in the AllWISE catalog.    I drew a box around the cluster in the single-epoch data and used it as a filter.    I then tried to copy the filter specification from the """"filter panel"""" dialog from the single-epoch table:     {quote}""""ra"""" > 0.9909882575279574;""""ra""""  < 0.992205622144179;""""decl"""" > 0.0072994581062348135;""""decl""""  < 0.009400119782442063""""{quote}    to the filter panel on the AllWISE table.  That didn't work at all - a separate problem? - so instead I copied the two expressions from the column headers from the one table to the other: """"> 0.9909882575279574; < 0.992205622144179"""" for {{ra}} and """"> 0.0072994581062348135; < 0.009400119782442063"""" for {{decl}}.    That worked, and the row I wanted ended up selected in the table.  However, the selection was not successfully applied to the coverage image for the AllWISE table, only for the single-epoch table.  See screenshots."""
"DM-13337","Bug","Firefly",1,"selection of overlaid catalog does not work after filtering with a region selection (either circle or rectangle)","""When I have a catalog overlay and an elliptical or rectangle region, I can successfully filter the catalog on that region. However, I cannot then click on any of the overlay points to select them. I have to get rid of the elliptical region by clicking on the image toolbar. And then I can't get that region back.    """
"DM-13374","Story","daf_butler",2,"Deconstruct Butler prototype for redesign","""Remove all elements (and associated tests) in current prototype of Butler and Registry that will be redesigned (as opposed to keeping everything working during redesign)."""
"DM-13371","Story","daf_butler",0.5,"Enable flake8 testing in daf_butler","""Now that the butler prototype is becoming the new butler, flake8 tests should be enabled."""
"DM-13363","Story","daf_butler",8,"Minimal in-memory caching Datastore","""This ticket is for creating an in-memory datastore and adjusting the tests to run with it and the existing posix datastore.  """
"DM-13361","Story","daf_butler",20,"Minimal S3 backed Datastore","""This would exercise {{Datastore}} and {{Formatter}} by requiring:    * Pass-through of credentials  * SHA instead of filename  * Serializing into memory rather than file  * Write to file then upload.    Only implement for one or possibly two {{DatasetType}}s."""
"DM-13345","Story","pipe_tasks",2,"Improve template and warp variance for Warp Compare","""Template: The PSF-matched sigma-clipped coadd variance is computed from the variance planes of the inputs and not the empirical dispersion of the images as expected. Intuitively if we're looking for outliers, we'd want the template variance to use the dispersion of the images.        Warp: As pointed out by [~price], we'd also want to scale the variance in the warps for the same reason we scale the variance on coadds before detection on coadds."""
"DM-13342","Story","daf_butler",0.5,"Refactor Datastore prototype to improve orthogonality","""In order to facilitate work on the Datastore prototype the existing code should be refactored a bit."""
"DM-13384","Story","Qserv",1,"Fix Qserv docker image build","""A recent merge has broken docker image build scripts used by developers and Travis and Jenkins CI (undefined variable $DOCKER_RUN_DIR in several Dockerfiles)  """
"DM-13381","Improvement","afw",2,"Rewrite updateRefCentroids and updateSourceCoords to convert all positions at once","""The current updateRefCentroids and updateSourceCoords functions are pure Python and compute one position at a time. SkyWcs performs much better if it can convert a batch of values at once.    I could rewrite the Python code to extract all the positions, convert them, then loop through the catalog again. But I worry this will be needlessly slow (the looping is already slow, and this will only make it worse), so I propose to rewrite the functions in C++ instead."""
"DM-13379","Improvement","lsst-texmf",0.5,"Determine whether the LSST LaTeX documentclass document type codes can be retired","""Currently, LSST documents generated from LaTeX source use a template that has a """"document type"""" parameter.  This parameter has documented values of """"DM"""", """"MN"""", and """"CP"""" at this time, and a commonly-used but undocumented value of """"SE"""" as well (for LSE- and LPM- documents).    As the documentation at https://lsst-texmf.lsst.io/lsstdoc.html says:  {quote}DM defines the document type to be a Data Management document. Other options include MN for minutes and CP for conference proceedings but these are holdovers from the original Gaia class file and currently have no effect on the document output. They are considered optional, but descriptive, at this time.{quote}    I suggest that we either add """"SE"""" to the list above or, recognizing that the document type is in fact unused in the LaTeX template (it relies on the DocuShare handle, instead), remove the mention of the document type from the {{lsst-texmf}} documentation and, opportunistically, remove the document types from existing documents when other editing actions occur."""
"DM-13389","Story","obs_subaru",0.5,"Enable transmission curve attachment for HSC by default","""Set    in {{SubaruIsrTask}}."""
"DM-13388","Story","ci_hsc|obs_subaru",0.5,"Enable visit-level sky subtraction for HSC by default","""Turn on visit-level sky subtraction by default for HSC, which I believe means updating the coaddition configuration to expect its outputs to be available."""
"DM-13412","Bug","obs_sdss",3,"camera mapper should specify DecoratedImageU instead of ImageU","""Here's pointer to the camera mapper in question:   lsst.obs.sdss.sdssMapper.SdssMapper    Problem with the return image object type (via butler) for the following data:      /datasets/sdss/preprocessed/dr7/runs/2708/40/corr/3/fpC-002708-r3-0103.fit.gz    Per [~ktl], the correct fix should be following (and new RFC for caution):    If you want the metadata and WCS, I think it will be sufficient to change these lines [https://github.com/lsst/obs_sdss/blob/master/policy/SdssMapper.yaml#L37-L38]   GitHub lsst/obs_sdss obs_sdss - SDSS-specific configuration and tasks for the LSST Data Management Stack    [2:31 PM]   to say `DecoratedImageU` instead of `ImageU`"""
"DM-13410","Story","obs_subaru|pipe_drivers|pipe_tasks",5,"Shrink input bboxes in inputRecorder per psfMatched Warp in WarpCompare","""WarpCompare has no temporal information for the pixels that are outside the boundary of the psfMatched Warps. These pixels are marked NO_DATA. The BBoxes in the CoaddInputRecorder should be shrunk so that we can have an exact CoaddPsf for sources that fall in the border of calexp."""
"DM-13403","Bug","daf_butler|daf_persistence",1,"numpy types fail in butler dataIds","""The {{np.int64}} type appears to be treated differently from the built-in python {{int}} type in butler dataIds. As an example:        However, if one attempts to use that `np.int64` type in a {{butler.get}}, it raises an exception with the value appearing without its type ({{str(15)}} and {{str(np.int64(15))}} are the same), which is extremely confusing to the user.        Note also that {{hash(15) == hash(np.int64(15))}}, so there is a general expectation that these will behave similarly."""
"DM-13396","Bug","afw|meas_base|meas_extensions_shapeHSM|pipe_drivers|pipe_tasks",2,"Fix coadd mask propagation","""DM-9953 created the SENSOR_EDGE mask to mark coadd pixels that were on or near the boundary of an input CCD (and hence should have INEXACT_PSF set as well).  It also started the propagation of those EDGE regions to the coadd.    Propagating the EDGE regions to the coadd caused problems, however, because many of them were affected by otherwise-unmasked bad pixels (leaks from amps or somesuch), so that was disabled on DM-12931.  Contrary to comments on that ticket, this seems to have broken the propagation of SENSOR_EDGE, or perhaps something more recent broke it.    We should also consider whether to split the current CLIPPED flag into both CLIPPED and REJECTED, with the latter being used for pixels rejected due to mask values from the calexps rather than an explicit smart-clip algorithm (e.g. SafeClip or CompareWarps).  """
"DM-13417","Story","afw",0.5,"Cleanup error reporting and docstrings in cameraGeom.utils","""The docstring for {{cameraGeom.utils.makeImageFromCamera}} could be cleaned up (return type specified, binSize and other parameters clarified), and the """"Unable to fit image for detector"""" warning message should include the exact exception message that was raised (figuring out the nature of the problem is difficult otherwise). That {{print()}} should probably also be turned into a log message."""
"DM-13416","Story","Firefly",2,"Firefly should reconnect periodically to the server when the connection fails","""Firefly requires a persistent websocket connection to the server in order to function properly. In the case when the client is disconnectedfrom the server, Firefly should periodically attempt to reconnect. This can happen when one closes his/her laptop or switching from one network to another.    When Firefly is no connected to the server, there should be an indication showing that it's no longer connected.    """
"DM-13413","Bug","Continuous Integration",1,"blueocean 1.4.0 pipeline view ignoring clicks","""After a jenkins core + blueocean update to {{1.4.0}}, clicks in the build pipeline view to change between branches are frequently ignored. It appears that this is only happening for builds that are actively running.    A search of the upstream jenkins Jira did not find an existing issues thats even in the ballpark. A screencast should be made to report upstream. Downgrading BO to {{1.3.x}} may be the best option."""
"DM-13420","Story","Firefly",5,"error message handling for failed table filtering","""From DM-13203 item 1, 4, 5.   # Generate a meaningful error message when a column filter expression applied to a table is invalid. This may not require any extra parsing effort for the filter expressions - the system knows the name of the column and the text typed in the filter field, and can just wrap the underlying error message with something like """"The filter expression 'xyzzy' applied to column 'foobar' is invalid."""". For the purposes of debugging it may be useful to provide a UI action (e.g., a disclosure triangle) that makes it possible to see the full underlying exception text.   #    #    # Ensure that, when an invalid filter expression is entered, after dismissing the error message the user is returned to the_same state of their data and previously-specified filters as before the failed attempt to construct a filter_. This does not require arbitrary undos, but only that the displayed state of the table is not changed before the filter has been determined to be valid.   # Do not use the word """"Reload"""" for the button that dismisses the error dialog. """"Back"""", """"Close"""", """"Cancel"""" would all be better choices. Consider asking for feedback from others, e.g., Vandana, for this choice. """"Reload""""_strongly_suggests - to me - that the underlying data retrieval operation would be repeated rather than just abandoning the filter attempt."""
"DM-13460","Story","Qserv",13,"Extend antlr4 parser abilities","""Extend antlr4 parser beyond simple statement, for example:    {{SELECT COUNT ( * ) as OBJ_COUNT FROM Object WHERE qserv_areaspec_box ( 0.1 , - 6 , 4 , 6 ) AND scisql_fluxToAbMag ( zFlux_PS ) BETWEEN 20 AND 24 AND scisql_fluxToAbMag ( gFlux_PS ) - scisql_fluxToAbMag ( rFlux_PS ) BETWEEN 0.1 AND 0.9 AND scisql_fluxToAbMag ( iFlux_PS ) - scisql_fluxToAbMag ( zFlux_PS ) BETWEEN 0.1 AND 1.0)))));}}"""
"DM-13459","Story","Qserv",13,"Parse single example query statement with antlr4 and build query objects as antlr2 would","""Parse a query like """"SELECT objectId, ra_PS FROM Object WHERE objectId=1234"""" with the new antlr4 parser."""
"DM-13456","Story","Qserv",8,"Finalize and cleanup data for KPM30","""Prepare and finalize data readiness, generate appropriate ObjectIDs and queries for KPM30 run."""
"DM-13453","Story","Third Party Software",0.5,"Upgrade psutil to version 5","""psutil has had some major updates since RFC-176 with some significant speed ups.    This also seems to fix a DeprecationWarning triggered by the current version (which is my main motivation for updating this).    psutil is only used in utils.tests at this time."""
"DM-13452","Story","daf_butler|supertask",8,"Extend QuantumGraph implementation","""Current implementation of QuantumGraph (with different name) is rather minimalist and is optimized mostly for efficient storage. We want to extend it to make usable for other cases as well. """
"DM-13451","Story","ap_pipe|ap_verify",8,"Make ap_verify responsible for ingestion","""Currently, {{ap_pipe}} ingests and processes data. For its ongoing conversion to a {{CmdLineTask}} (DM-13163) and forward-compatibility with {{Pipeline}} classes, {{ap_pipe}} should work on an externally provided repository.    For the time being, this functionality should be moved to {{ap_verify}} (which currently requires uningested data), and the final responsibility for ingestion will be determined later."""
"DM-13441","Story","obs_comCam",2,"Fix nominal gains and readNoise values","""Some gains are zero, that's bad (leads to inf variance, and therefore NaNs).    The other values are meaningless as this is currently being used for any given raft, so lets set them all to 1 for now. Also set all the readNoise values to 10 for now."""
"DM-13439","Bug","Continuous Integration",0.5,"jenkins update-cmirror job broken","""This job fails in the current stripped down jenkins env and probably needs to build in a container:        https://ci.lsst.codes/job/sqre/job/infrastructure/job/update-cmirror/267/console    This job is also not running periodically as it should be.  The cron trigger must have been lost during a re-factoring."""
"DM-13438","Story","meas_deblender",8,"Create simulations with real COSMOS galaxies","""LSST internal reviewers suggested using a set of simulations using real galaxy data as a more robust test of the new deblender.This ticket involves creating another 10k simulated blends (this time with real galaxies) and running both the new and old deblenders on it."""
"DM-13477","Story","ap_association",5,"Move association math from DIAObjectCollection into AssociationTask","""Removes the score and match methods from DIAObjectCollection and puts them, for now, into AssociationTask. Once AssociationTask moves into lsst-distrib we can move the further into meas_algorithms."""
"DM-13493","Bug","meas_algorithms",1,"BaseSourceSelectorConfig should not filter on ""interpolated""","""Given the recent change to how {{interpolated}} is used in the stack, it appears that {{BaseSourceSelectorConfig}} should not include {{interpolated}} in its list of default {{badFlags}}. We may want to add any new """"why interplated"""" flags instead."""
"DM-13492","Improvement","ap_verify",1,"Remove --rerun argument for ap_verify","""Nobody remembers why {{\-\-rerun}} was originally added to {{ap_verify}}'s command-line interface; see discussion on DM-12853. In the absence of a compelling case for it (it cannot behave exactly like the {{\-\-rerun}} argument for command line tasks, because {{ap_verify}} does not have an input repository), and given its currently confusing behavior, we should remove {{\-\-rerun}} from the {{ap_verify}} API. It can be added back once we have a clear expectation of how it should behave."""
"DM-13485","Bug","obs_subaru",0.5,"Fix NB filter transmission curve dataset filenames","""Some narrow-band filter names used by {{installTransmissionCurves.py}}are missing leading zeros (e.g. should be NB0921 rather than NB921)."""
"DM-13506","Story","Qserv",2,"Review and fixups for antlr4 eups package","""Assist Nate in packaging antlr4 as a third-party TaP eups package"""
"DM-13501","Improvement","Validation",0,"Add obs_decam to validation_data_decam/ups","""Add    setupRequired(obs_decam)    to a    ups/validation_data_decam.table    file."""
"DM-13498","Story","pipe_tasks",3,"Add config to make WarpCompare very conservative","""Currently a drawback of WarpCompare is any epochs where a source doesn't look like the other epochs gets clipped. This leads to some loss of signal in bright sources. While future work on the image comparison will improve this (background matching, image-to-image psf matching, etc....) for now, we probably want a nuclear option config:    If an artifact candidate fits entirely within a template coadd source, then don't clip it. This means that unfortunate CRs or supernovae won't be clipped, but will improve the photometry. For the HSC release,  coadd photometry seems to be a higher priority.   """
"DM-13510","Bug","Design Documents|System Integration and Test",3,"Correct inconsistencies in LDM-503 text and tables and improve auto-generation process","""The existing LDM-503 package has traces of a strategy to autogenerate substantial sections of the document from a milestone table maintained as the {{dmtestmilstones.csv}}file (as well as other portions from other .csv files). In particular, from this file a {{dmtestmilstones.tex}} file is generated, for use in {{schedtab.tex}} in Section 6 of the document, as well as a file {{testsections.tex}} used as the body of Section 7 of the document.    There are signs that both of those {{.tex}} files were hand-edited after the last time the autogeneration was performed, and these edits are at variance with each other, with the outcome that there are three versions, slightly differing, of the associated text.    The auto-generation script is not part of the {{Makefile}}, and its outputs are part of the Github _acquis_ for the package,or this would have turned out differently.    Note also that the autogeneration script has a provision to substitute a longer description of a milestone into {{testsections.tex}} if one is available. Currently this is only the case for LDM-503-2, for whichthere is an {{LDM-503-2.tex}} file in the package (and a much more extensive {{f17_drp.tex}} file which it in turn includes). This longer description appears to predate the fuller, separate test specification for DRP and may be redundant or even in conflict with it; I have not checked that."""
"DM-13509","Bug","meas_extensions_convolved|obs_cfht|obs_lsstSim|skymap",0.5,"Some pure python packages add to LD_LIBRARY_PATH","""The pure python packages listed in Components have ups tables that add themselves to LD_LIBRARY_PATH and two related library paths. They should not do this. Remove the following from their ups table files:  """
"DM-13507","Story","skymap",2,"Add stable hash to SkyMap objects","""In the Gen3 butler, the tracts and patches defined by a SkyMap will be loaded into a database, and that will make it much more important to recognize when the same SkyMap has already been loaded. While SkyMap objects already support equality comparison, it'd be nice if they could also produce a stable hash that can be used to uniquely label them.    -Since that basically amounts to being able to hash the SkyMap's configuration, I think it makes the most sense to actually add this hashing support directly to {{pex_config}}. Being able to compare hashes to check for config equality seems like it'd be generally useful to.-    I'm currently planning to do this with {{hashlib.sha1}}, rather thanjust the {{hash}}builtin, because I want something that's guaranteed to be stable between Python versions.    Note that these in-memory hashes will not be equivalent to hashes of the files in which these objects are stored."""
"DM-13520","Story","obs_subaru",0.5,"Add readme to obs_subaru","""[~yusra] pointed out the diagram of the HSC focal plane in obs_subaru, which I wouldn't have thought to check. To make it more obvious for future me, I've created a readme and added a note about the diagram to it."""
"DM-13519","Story","pipe_analysis",5,"Implement per-object Galactic Extinction correction in color analysis QA plots","""Implement a per-object Galactic Extinction correction for use with the color-analysis QA plots to replace the per-field placeholder included in DM-13154. It looks like there is code in \{\{sims_photUtils}} (and dependencies) to do this, so this will be an attempt to get that working with the analysis scripts.        Note that this requires the A_filter/E(B-V) extinction coefficients for the HSC filters (awaiting a response from the HSC team, the placeholder noted above is just using SDSS filter values)."""
"DM-13526","Bug","Qserv",0.5,"Fixed a bug in the schema migration tool for worker databases","""The original implementation of the schema migration tool deployed for worker side databases *qservw_worker* as per [DM-13301] won't work for tables which have '_' in their base names. The original tool was designed and tested for the LSST-style table names:    However, it won't work for tables like:    The first symbol '_' will confuse the stored procedure implemented in the original version of the tool.    A goal of this ticket is to fix this problem by making the stored procedure to look for the last '_' when separating the base names of tables from the trailing chunk numbers."""
"DM-13524","Story","ap_verify",2,"Add unit tests for ingestion","""As a self-contained module within {{ap_verify}}, {{ingestion}} should have unit tests of its functions. It may be possible to implement a unit test by specifically ingesting only 1-2 files of each type."""
"DM-13536","Story","ap_pipe|ap_verify",3,"Use repositories more idiomatically","""For forward-compatibility with DM-13163, {{ap_verify}} should create separate repositories for ingestion and calibration. In effect, the current """"output repository"""" should be a convenient """"workspace"""" directory but not a repository.    In addition, the interface module {{pipeline_driver}} should make a distinction between input and output repositories, choosing the location of the latter instead of deferring the choice to {{ap_pipe}}. Neither {{CmdLineTasks}}, nor in the future {{Pipelines}}, are responsible for output paths.    Because the API will change again as part of DM-13163, changes to the interface between {{ap_pipe}} and {{ap_verify}} should be kept minimal; most likely, this will entail removing the ill-advised wrappers added in DM-12257 and calling the existing functions from {{pipeline_driver}} again."""
"DM-13535","Story","ap_pipe",1,"Accept idiomatic input repositories","""Currently, {{ap_pipe}} requires a single input repository with two directories, {{ingested}} and {{calibingested}}, each a repository in its own right. This will be a problem for DM-13163 because most command-line tasks allow the URIs of the data and calib repositories to be independent, and in any case the Stack convention is different from our current usage.    This ticket will change the command line to accept a separate calib repository (the argument should behave the same as {{processCcd.py --calib}}?). The API to {{ap_verify}} will not be changed, as it will almost certainly change when DM-13163 is implemented."""
"DM-13534","Story","ndarray",1,"Upgrade ndarray to upstream 1.4.2","""If all goes well, this should allow us to start removing our dependence on the NumPy C API (left for another ticket).    This will probably require modifying our pybind11 build to install its CMakeconfig files (unless we're doing that already, which I doubt), since ndarray now uses those to find pybind11."""
"DM-13550","Story","Qserv",0.5,"Fix Qserv docker image build","""Qserv docker image builds broken after merge of DM-13458 (because libuuid prerequisite is not captured in Debian prereq install script)"""
"DM-13546","Story","ap",8,"Build robust Kafka 3-broker cluster","""Current alert_stream Kafka prototype uses a single broker Kafka instance. Build a cluster of 3 brokers and ensure that if one is inaccessible the others can receive and emit alerts. Also, the current alert_stream Kafka cluster loses all data if a broker container goes down because the Kafka container houses all the data. Figure out how and where to mount external volumes for Kafka and Zookeeper so that data is recovered and so that consumer offsets are recovered (consumers unaffected) if one or all brokers go down."""
"DM-13539","Bug","astshim",0.5,"astshim fails to preserve SIP terms for some TAN SIP when writing FITS metadata","""[~lauren] has found some cases where a TAN-SIP SkyWcs is not written as TAN-SIP to FITS metadata (instead a local TAN approximation is used). The attached file is a program showing an example. I have reported the issue to David Berry in hopes he can fix it or suggest a workaround.    This issue actually consists of two parts:  - Normal TAN-SIP WCS cannot be written as FITS-WCS header cards. David Berry has implement a fix for that problem.  - WCS rotated by rotateWcsPixelsBy90 cannot be written as FITS-WCS. I have split that into a separate ticket: DM-13564."""
"DM-13538","Story","Firefly",2,"Add a Jenkins job to build and deploy Firefly's app to a local k8s cluster","""During a pull request oran evaluation of an added feature, it's useful to have a specific version of a Firefly app up and running.    Add a job to Jenkins to build and deploy a Firefly app to a local k8s cluster.    This job shouldtake as input; branch, env, and a label used to reference the instance running in k8s."""
"DM-13562","Story","Qserv",1,"Migrate base docker containers to Centos7 + Devtoolset6","""The new antlr4 package requires gcc 5.0 or greater, but Debian Jessie, on which the Qserv base containers are based, only supports gcc 4.9.  Upgrading the base containers to Centos7 + Devtoolset6 seems the best option.    This should also address currently busted Travis CI runs, and buildability of containers off latest master (sphgeom pybind11 compiler compatibility issue)."""
"DM-13557","Story","meas_algorithms",0.5,"Minor config doc fixes for SourceDetectionTask","""These are being generated in real-time when answering questions about detection in the DRP team meeting, but I want to get everyone to review my improvements instead of just merging them (even though that's formally permitted).    """
"DM-13556","Improvement","dbserv|ImgServ|metaserv",5,"Upgrade sqlalchemy to 1.2","""This is to upgrade lsst/alchemy from 1.08 to 1.2.2, with two years worth of improvements and bug fixes, which willfacilitate dax_v1 implementation at retrieving/mapping data from the SQL database.    """
"DM-13554","Improvement","starlink_ast",0.5,"Build starlink_ast with opt=3","""At present stalrink_ast is built using optimization level 2. I propose to build it with our standard optimization level of 3 in hope of increasing performance.  """
"DM-13575","Bug","jointcal",0.5,"fix minor bug in photometry ipynb","""While looking at HSC data, I noticed that my on-sky dependence plots were not handling the initial dataset correctly. I've fixed that, but it should be committed separately from other open tickets."""
"DM-13574","Improvement","Qserv",1,"Adding support for building executables of C++ applications","""The current build system for the *qserv* package lacks a support for building executables from the C++ applications. A goal behind this ticket is to fix this."""
"DM-13571","Bug","jointcal",0.5,"fix plot_photoCalib bounds","""[~jbosch] identified the bug that caused {{plot_photoCalib.py}} to not be able to plot meas_mosaic output. The fix is to change the linspace bounds."""
"DM-13568","Bug","Continuous Integration|stack release",1,"nightly-release d_2018_02_15 -- some eups tarball builds failing with pip install error","""https://ci.lsst.codes/blue/organizations/jenkins/release%2Ftarball/detail/tarball/1978/pipeline        """
"DM-13565","Story","jointcal",1,"Put correct copyright/license headers in all jointcal files","""Jointcal got caught during the RFC-45 copyright/license uncertainty and many of its files don't follow any of the proposals there. We should get them cleaned up, following whatever standard was finalized in that RFC."""
"DM-13588","Story","L1 Database",2,"Document API for current L1DB prototype","""Piecesof APIthat I have now in L1DB prototype could be useful for AP group, need to make sure that it has reasonable documentation.    """
"DM-13583","Story","Stack Documentation and UX",5,"Strategize DMTN upload to Docushare","""Propose plan for handling DM tech notes in docushare.    There are a number of issues:    * Generating a PDF from rst tech note  * Allocating numbers in docushare.  """
"DM-13600","Story","daf_butler",1,"Add YAML formatter","""Add a YAML formatter to daf_butler."""
"DM-13599","Story","daf_butler",0.5,"Update copyright info following RFC-45","""Now that RFC-45 is official, update the daf_butler package to be compliant."""
"DM-13612","Improvement","dax",2,"Upgrading SQLAlchemy from 1.0.8 to 1.2.2","""The third-party SQLAlchemy is being used in DAX and Sims.        FYI, release 1.2.2 is a 2+ year newer than 1.0.8, with lots of improvements and new features, as documented in this link:       [http://docs.sqlalchemy.org/en/latest/changelog/migration_12.html]        which would greatly aid the future work related to DB access in DAX services.            """
"DM-13609","Improvement","ip_diffim",1,"Undo EXTRACT_PRIVATE override in ip_diffim","""{{ip_diffim}}'s Doxygen settings were modified in 2014 to generate HTML documentation for both public and private members. Because of how the build system handles Doxygen overrides, this change had the (presumably unintended) consequence that the Stack-wide documentation also exposed private class members, whether or not they had documentation comments.    Per RFC-451, the override will be removed, so that both {{ip_diffim}}'s and the Stack's documentation includes only API members."""
"DM-13608","Story","stack release",2,"newinstall should force LANG=C","""[~sogo.mineo] notes that:    The easiest way to make sure that the diffs are always legible is to force {{LANG=C}} everywhere.    """
"DM-13630","Bug","Firefly",2,"Image distance tool fails in particular case where some images searched were not found","""When searching images, sometimes there are images that are not found or the area searched is not covered by the dataset chosen. Example: search for m34 on SEIP, see last image (MIPS24 is missing because no image is covering this target).    The result can be a mix of rendered images and failed images. When this happen, the following operations on images failed (maybe others): distance tool offset calculation andflipping around axis.    Ithappens in Firefly tri-view and IRSA apps (FC/IV)."""
"DM-13623","Story","Firefly",2,"Make the Ipac Jenkins send build messages to the IPAC slack","""The Ipac Jenkins currently send out email on build failures. Make it send message to a IPAC slack channel.        The message could contain at least (if possible):   * URL and dateof the build/console   * URL of the PR to test if build need to be tested   * Author of the last commit that trigger the build   * Last changes or gitlog"""
"DM-13638","Epic","Firefly|SUIT",100,"Allsky visualization in Firefly phase 2","""Phase two work for allsky visualization."""
"DM-13637","Story","pipe_tasks",5,"WarpCompare: Bad amps eat up temporal budget","""Overlapping bad amps eat up the temporalThreshold budget.    For example if a local region has 10 visits, and 3 of those visits are not included because of bad amps, then no candidates are clipped.  CLIPPED mask for {{/datasets/hsc/repo/rerun/private/yusra/RC/DM-13553+DM-134110}}: 9813, HSC-Z   !mask_DM-13553+DM-134110_9813HSC-Z.png|thumbnail!     Seen sinceDM-12692: Bad amps can be seen in this epochCountImage:    !Screen Shot 2018-01-25 at 12.20.55 PM.png|thumbnail!     If any detections the warpDiffs are entirely covered with the badPixelMask, then don't contribute to the rolling epochCountImage or clip. """
"DM-13635","Story","ap",3,"Test kafka mirrormaker service","""Set up a Kafka MirrorMaker service that is capable of making a copy ofall or a subset of data and topics in another Kafka cluster. This is useful forcopying aKafka service to external downstream brokers and potentially for our mini-broker if we have multiple Kafka clusters."""
"DM-13632","Story","Developer Infrastructure",1,"Add additional conda packages to the lsst-dev shared stack","""On Slack, [~tmorton] writes:    {quote}    Oh, and fastparquet  {quote}    [~hchiang2] says:    {quote}  Is it possible to install fastparquent in the shared stack at {{/software}}? It's used in {{pipe_analysis}}.  {quote}"""
"DM-13654","Story","pipe_tasks",1,"Set SENSOR_EDGE in coadds","""These nice before and after plots shown in DM-13410 were from a the pre-review test run. The version that got merged doesn't set SENSOR_EDGE (and consequently INEXACT_PSF) of the new EDGE pixels.    This has the effect that fewer sources measured on the coadd will have the inexactPsf_flag set. However, most (80-98%) of the EDGE pixels arealso BAD or INTRP which are then """"REJECTED"""" which then propagates to INEXACT_PSF:    !DM-13410_vs_08_SENSOR_EDGE.png|thumbnail!    !DM-13410_vs_08_REJECTED.png|thumbnail!    !DM-13410_vs_08_INEXACT.png|thumbnail!"""
"DM-13653","Improvement","Qserv",2,"Dynamic reconfiguration of the worker services when loading new catalogs","""In the present implementation of the catalog loading scripts Qserv worker services need to be restarted each time a database is added or removed to/from a worker node. The restart is made by the *wmgr* service upon a request from the loader script. This scheme causes inconveniences in certain deployments, including Kubernetes-based multi-node integration tests. Hence a goal of this ticket is to replace the hard restart with a request to dynamically reload databases sent from *wmgr* to the worker services. The implementation will be based on a mechanism added as per [DM-13303].    Additional requirements to the proposed change:  * it should not affect the single-node integration test  * it should not require any changes to the catalog loading procedure (script: *qserv-data-loader.py*)"""
"DM-13649","Story","Firefly",8,"deployment  of SUIT using Kubernetes in LSP ","""Deploy SUIT in LSP kubernetes cluster."""
"DM-13644","Bug","Continuous Integration|stack release",0.5,"weekly-release w_2018_08 failed","""{{w_2018_08}} failed building the py3 osx """"tarballs""""."""
"DM-13669","Improvement","jointcal",2,"Track and log measurement/reference outliers separately","""jointcal currently tracks the total number of outliers per minimization step (""""INFO: Total number of outliers 2578""""). We should change that to separately track measurement and reference outliers so that we can compare them independently.    With this, we can plot the number of each type of outlier that was removed per fitting step, which can help tell us something about how stable the fit is. (see the final plot in Dominique's {{Astrometry.ipynb}})"""
"DM-13656","Story","Stack Documentation and UX",5,"Implement Developer Guide Topic Reorganization","""Implement RFC-453. by reorganizing the topics in the Developer Guide. Redirection pages will also be implemented.    The basic structure proposed in RFC-453 (and given in attached map) is acceptable. There is some concern about the workflow topics, and where JIRA and GitHub fit. Well have to continue thinking about this as the reorganization shakes out."""
"DM-13686","Bug","astshim|starlink_ast",1,"Saving a particular FrameSet as FITS-WCS causes a segfault","""The attached FrameSet (string representation is in """"skyWcsFrameSet2.txt"""") causes a segfault in astshim when writing to an astshim FitsChan as FITS-WCS using the attached code """"example.txt"""".    I suspect the bug is in AST and have reported it to David Berry."""
"DM-13680","Improvement","afw",2,"SkyWcs(FrameDict) is not adequately tested","""The {{SkyWcs(FrameDict const&)}} constructor is not adequately unit-tested. It is exercised as part of a test, but not explicitly tested. Enhance test_skyWcs.py to explicitly test this constructor."""
"DM-13693","Improvement","astshim",1,"Use overload_cast in pybind11 wrappers to simplify wrapping overloaded functions","""pybind11's overload_cast can be used to simplify the wrapping of overloaded functions. It requires C+14 so we have not used it in the past. Convert astshim as a test case."""
"DM-13690","Story","butler",2,"Write up Gen3 Butler / obs_* package interface sketch","""Output will be a confluence page that describes what Gen3 Butler will expect from obs_* packages. Intended audience is [~krughoff] and the obs_* package working group.        Page is at https://confluence.lsstcorp.org/display/DM/Gen3+Middleware+Camera+Specialization+Interfaces"""
"DM-13688","Story","butler",2,"Write up design proposal for Registry/Datastore boundary","""This is a retroactive ticket to capture work already done: writing up    [https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73570480]    to guide a discussion on 2018-02-14."""
"DM-13698","Story","SUIT",3,"Update webpack/babel to use env for pollyfills and add webpack-visualizer-plugin","""Do following:   * for webpack/babel to use env for pollyfills   * add webpack-visualizer-plugin:Visualize and analyzethe Webpack bundle to see which modules are taking up space and which might be duplicates.   * experiment with usingbabel-plugin-lodash to treeshake lodash (_experiment failed, we can't use it_)   * remove fftools (we not longer us it)    """
"DM-13739","Story","Developer Infrastructure|Stack Documentation and UX",1,"Document github repo configuration","""In RFC-121 we adopted a policy of protecting master. This ticket is to add that documentation to the developer guide and include the settings needed to ensure that the pull requests are up to date with the base branch (which is our policy)."""
"DM-13734","Bug","Developer Infrastructure",1,"status.lsst.codes ssllabs check broken","""The nagios {{check-ssl-qualys.rb}} plugin has been broken for 63 days now.  It appears that the v2 api is gone and v3 has replaced it. Eg.,    https://api.ssllabs.com/api/v3/info  https://github.com/ssllabs/ssllabs-scan/blob/master/ssllabs-api-docs-v3.md"""
"DM-13757","Bug","jointcal",2,"enable jointcal config writing","""There is a block of code in jointcal that disables the persisting of the config and metadata. We should remove that code and add a dataset description for jointcal configs.    This is the block in question:    """
"DM-13756","Improvement","obs_base",1,"Add descriptions to datasets","""We have no descriptions for the existing butler datasets/exposure types, so nobody knows what they are."""
"DM-13755","Story","pex_config|Stack Documentation and UX",1,"Make pex_config generate reStructuredText-compatible docstrings","""We discovered that {{pexConfig}} objects create {{__doc__}} (docstring) attributes automatically based on information passed to configuration constructors. This means that configuration fields are documented in the attributes of configuration classes inside the regular API documentation.    This is great, but can also fail if the automatically-generated config field docstring is not reStructuredText/Numpydoc compatible.    This ticket is to change the {{__doc__}} generators of {{pexConfig}} fields so that they output Numpydoc/reStructuredText docstrings."""
"DM-13753","Story","daf_butler",2,"Enable sphinx doc building in daf_butler","""Turn on building of sphinx documentation. We already use numpydoc for docstrings but some may need tidying as a result of the documentation actually being built."""
"DM-13750","Story","afw",0.5,"Move Record printing to C++","""Current implementation is apparently super slow, and looking at what it's doing (constructing a new dictionary of all fields via {{extract}} just to get one element from it, for every field), I can see why.    That could be cleaned up in Python but a lot of it is more naturally and definitely more efficient in C+++,+ and doing that will give us a C++ {{operator<<}}, too, which is nice."""
"DM-13749","Story","Qserv",13,"Include error handling for antlr4 parser","""Error handling for the new antlr4 parser  specifically for conditions where tree-navigation does not have an error but the query is not sufficiently populated.        Hook up a disable able (ifdef?) code that allows the antlr4 caught exception's message to be returned to the user."""
"DM-13747","Improvement","ndarray",0.5,"Fix LSST's ndarray .gitignore to ignore build products","""The current .gitignore in our tarball release of ndarray is wildly inaccurate. Clean it up."""
"DM-13746","Improvement","astshim",0.5,"Modernize use of ndarray in astshim pybind11 wrappers","""Update the usage of ndarray in astshim to simplify the pybind11 wrappers and eliminate build warnings."""
"DM-13760","Story","pipe_analysis",1,"pipe_analysis needs updates for the wcs dataset name changes ","""Running the visit-level scripts using the current master of {{pipe_analysis}} ({{6b5727d}})  with the {{w_2018_10}} stack gave errors in getting the {{wcs}} dataset.             It needs updates for the dataset name changes of DM-11138.   """
"DM-13779","Improvement","Firefly",1,"the indication box for marker on image separates from marker as the size increases","""* Add a marker on an image, it is annotated as marker #1   * click on the marker, position the cursor at the corner of the indication box to increase themarkersize   * The distance between the box andthe marker increases as the marker size increases   * the annotation ends up pretty far from the marker, not very useful any more, especially if there are more than one markers.   * See the attachment, """"Marker #3"""" label is closer to the marker circle #2 than to #3.    Suggestion:    Keepthe distance between the marker and the indication box at a fixed number,e.g. 3-5 pixels.    Trey added: This issue stands out even more on HiPS displays."""
"DM-13768","Bug","SUIT",2,"Fix firefly_client uploads to work with server on https","""The Jellybean environment includes a Firefly server with an https url. Uploads are unsuccessful with the current firefly_client.       * Fix the upload functions to use the base url in the client   * Tag as a bug fix release   * Deploy to PyPI for pip installation   * Sync to the firefly_client repo on the LSST Github org   * In the {{lsst.display.firefly}}backend, remove the {{port}} argument   * Change docs and examples for {{lsst.display.firefly}} to remove the {{port}} argument   * Substantially shorten the Installation portion of the docs, now that {{lsst.display.firefly}} is included in {{lsst_distrib}}."""
"DM-13762","Story","DM Subsystem Science",0.5,"Write up description of DRP current and future test datasets","""As per this request from [~zivezic]:  {quote}We need to understand how much HSC data is processed  regularly, is that enough/too much, etc., and where to go from where we  are now. Please can you send half a page to a page summary of your  DRP-driven recommendations within a few days?{quote}  """
"DM-13790","Improvement","jointcal|meas_base|pipe_drivers|pipe_tasks|skymap",3,"Remove all use of the geom package","""Our stack has a very few bits of code that still use the {{geom}} package. In particular they use the {{convexHull}} function. {{geom}} has been superseded by {{sphgeom}} (which is written in C++ instead of python) and contains {{ConvexPolygon.convexHull}}. Update the code, paying careful attention to API differences, if any.    This is driven by a desire to repurpose the {{geom}} package for afw geometry primitives (RFC-460) and to retire obsolete and unmaintained code."""
"DM-13786","Bug","SUIT",0.5,"'FireflyClient' object has no attribute 'headers'","""I'm using commit {{bdd25c9}}on the {{DM-13768-https-upload}} branch.    I occasionally get the following exception:    !image-2018-03-13-09-55-24-833.png!    This is with the following code:    It's not clear to me how to reproduce this. It seems like it is more likely to happen when I've left for a while and come back."""
"DM-13809","Story","meas_modelfit",5,"Test the implemented Shape optimization algorithm","""Test the shape optimization algorithm by:  * Running the unit tests built during the coding of the algorithm  * Optimizing against a known elliptical Gaussian of differing S/N"""
"DM-13807","Story","meas_modelfit",2,"Plan API for Shape Algorithm Objects","""Plan out how best to implement the c++ classes which correspond to equations in [DM-13406|https://jira.lsstcorp.org/browse/DM-13406]"""
"DM-13799","Story","L1 Database",2,"Make l1dbprototype work with sqlite","""For simple tests it's useful to run prototype against local sqlite file. There is some code in prototype that cares about engine type, need to extend it to understand sqlite."""
"DM-13797","Story","SUIT",3,"Remove the HiPS Grid icon, Always add the HiPS grid layer with checkbox off","""Remove the HiPS gridicon from the toolbar. Then when a HiPS is added always add the HiPS grid layer with the checkbox turned off so that it is hidden by default. This way a user has access to it without it being on the toolbar.    Add support for calling the IRSA hipslist.    this involves:   - app.config & app.prop   - uniq creator_did   - if title is blank use creator_did, last parts   - irsa.hips.method and irsa.hips.url        See also:    [https://caltech-ipac.atlassian.net/browse/IRSA-1556#add-comment]"""
"DM-13796","Story","cat",1,"Fix minor issues in cat schema files","""Working on DM-13781 I tried to convert baseline schem to YAML and noticed some minor issues in that schema file:  * in some comments it uses {{</desc>}} instead of {{</descr>}}  * DiaSource index has a name IDX_DiaObject_htmId20   * DiaSource index IDX_DiaSource_filterName refers to non-existing field name    Also I need to verify that type of {{flags}} field in DiaForcedSource is correct (TINYINT)"""
"DM-13827","Story","meas_algorithms",0.5,"ScienceSourceSelectorTask is slowly appending to a table when it can simply do the selection","""ScienceSourceSelectorTask is slowly appending to a table when it can simply do the selection.  The loop at https://github.com/lsst/meas_algorithms/blob/f7dca96402cda034104c615be7ef821ab3aa9ea9/python/lsst/meas/algorithms/sourceSelector.py#L451 is unnecessary."""
"DM-13823","Story","utils",1,"Remove lsst.utils.multithreading","""Implementation ticket for RFC-461.    Remove {{python/lsst/utils/multithreading/}} and the associated unittests, {{test_sharedData.py}} and {{test_lockProtection.py}}. """
"DM-13822","Improvement","obs_lsstSim",1,"Remove python_mysqlclient dependency from obs_lsstSim and obs_sdss","""The dependency on {{python_mysqlclient}} in {{obs_lsstSim}} is cargo culted from {{obs_sdss}} and should be removed."""
"DM-13821","Improvement","Continuous Integration",2,"Coordinate sims builds with DM weekly releases","""The sims team would like to be building their stack on top of a weekly release.  Meet with the sims team (Scott Daniel) and iron out the actual needs."""
"DM-13835","Bug","ap_verify",2,"Cannot ingest empty data","""The {{_doIngest}} and {{_flatBiasIngest}} methods cannot handle empty lists of files to ingest, if such a file is passed in, the program crashes. This is clearly undesirable behavior; it would make more sense for these functions to silently do nothing.    Possibly obsolete after DM-13530, since the bug appears to be specific to the placeholder implementation."""
"DM-13834","Story","Alert Production",3,"Add minimum and maximum lambda to filter properties","""The DCR correction code needs to know the range of wavelengths permitted through a filter, not just the effective wavelength of the full band. I will add additional properties to `Filter` and define those properties for `obs_lsstSim` and `obs_decam`. Other packages should continue working as normal without being modified."""
"DM-13833","Story","Design Documents",1,"Update LDM-503 to use lsst-dm/milestones","""The [lsst-dm/milestones|https://github.com/lsst-dm/milestones] system was created to enable automatic generation of LDM-564 from a single PMCS export. Apply it to LDM-503 as well."""
"DM-13855","Technical task","Firefly",1,"Make proposal for summary information on HiPS maps to list in selection table","""Determine which fields from the HiPS {{properties}} files should be reflected in the HiPS-selection table in Firefly."""
"DM-13865","Story","L1 Database",1,"Configure L1DB implementation from pex.config","""Presently L1db configures itself from INI-style file using Python \{\{ConfigParser}}. For better integration with pipeline tools {{pex.config}} should be used instead."""
"DM-13864","Story","Science Platform",2,"Submit LSP Test Specification document LDM-540 to DM-CCB for approval","""Apply final polish and submit."""
"DM-13861","Story","L1 Database",1,"Make L1db spatial indexing more flexible.","""Current L1DB implementation assumes HTM-20 indexing for DiaObject/DiaSource tables. There is code in L1db class that depends on that when doing region-based selection. It would be better to make this more flexible and client-controlled so that other indexing models could be tested/employed."""
"DM-13879","Story","lsst_distrib|meas_mosaic",1,"Include meas_mosaic in lsst_distrib","""Implement RFC-462.    Also update meas_mosaic to optionally depend onobs_subaru."""
"DM-13878","Improvement","ap_verify",1,"Confirm that ap_verify's documentation is sphinx-buildable","""{{ap_verify}} added Sphinx documentation before the framework was fully finalized, and used a workaround script to test builds. Its documentation should be reviewed to confirm that it can be built as described in the [documentation hack day instructions|https://community.lsst.org/t/pipelines-package-docs-hack-day-instructions/2742], and any necessary changes made. In particular, {{doc/single-package.sh}} should be removed as obsolete."""
"DM-13875","Story","L1 Database",2,"Assist with L1db integration into AP pipeline","""l1dbproto should be more or less usable now for actual AP prototyping work.Integration issues related to that will be covered in this ticket."""
"DM-13872","Bug","Firefly",2,"Title of layer-selection dialog does not change with change of image","""When the (non-modal) layer-control dialog is visible in Firefly and the selected image is changed """"under"""" that dialog, by clicking in a different image, the _contents_ of the dialog seem to change appropriately, but the image title displayed in the title bar of the dialog is not updated.    Observed on {{http://irsadev.ipac.caltech.edu/irsaviewer/}} just now."""
"DM-13870","Story","SUIT",2,"Code clean up - remove xml xstream and old serialization ","""Code clean up - remove xml xstream and old serialization    Remove old, unused code.   * At one point during the the conversion we had 3 serialization techniques.   * We no longer use the XML based xstream code."""
"DM-13886","Improvement","afw",2,"Simplify Transform to contain a Mapping instead of a FrameSet","""At present {{afw::geom::Transform<FromEndpoint, ToEndpoint>}} contains an {{ast::FrameSet}}, although all it does is transform points, which is what {{ast::Mapping}} is for. As DM-13847 demonstrated, using a FrameSet slows down Transform. The workaround in that ticket was to hold onto both a FrameSet and a Mapping. This ticket is to intended implement a more logical but slightly more invasive solution.    I will file an RFC with more explanation."""
"DM-13897","Story","JupyterLab",3,"Write up development workflow for jellybean","""Document the notional development workflow in the JupyterLab environment."""
"DM-13907","Bug","Continuous Integration",1,"sandbox-stackbuild provisioning fails on DO","""The DO plugin is able to create droplets but the provisioning fails completely in the same way it used to with the aws plugin.  I suspect this is due to changes in the vagrant core over the last 8 months or so.        There is an upstream issue but this will be easier as a configuration fix.    https://github.com/devopsgroup-io/vagrant-digitalocean/issues/271"""
"DM-13904","Story","ndarray",0.5,"Specify Eigen directory in ndarray build","""An oversight our build script for ndarray can cause it to prefer a non-EUPS Eigen installed in a system include directory over a EUPS-provided Eigen."""
"DM-13919","Story","Firefly",2,"Add arcminute-scale range to HiPS image FoV display","""In the current irsadev version of the HiPS viewer, it appears that the FOV display is either in degrees or in arcseconds, represented by the '' and '""""' symbols, respectively.  It does not have an intermediate display of arcminutes.  Before we go on to apply this to all image viewers, not just HiPS, we should agree on what we want.    Personally I would go for adding the intermediate layer.  I find it a bit odd to see """" 2711"""" """" as a field of view, instead of """" 45' """".  Also in other Firefly and IRSA application contexts, such as the _selection_ of a field of view, the arcminute option is presented.    The same logic should apply consistently throughout the Firefly world, I think.    Specifically: when the value is between 1 and 59 arcmin, display it as arcmin (with the ' symbol) with two digits of precision, i.e, as 1.0' through 9.9' or 10' through 59'. But if there is existing practice for something slightly different elsewhere in Firefly, it would be reasonable to re-use existing behavior.    Derives from IRSA-1606 and IRSA-1628.    Aimed at the May 2018 release."""
"DM-13945","Improvement","stack release",0.5,"newinstall.sh could do a better job of reporting missing commands","""Notably, {{newintall.sh}} will without informative messages to the end user if certain commands are not available in the path. Eg.,    * the miniconda installer internal uses {{bzip2}}  * the eups build needs {{make}} and a c compiler"""
"DM-13961","Story","Qserv",13,"Run KPM30 tests at IN2P3","""Run KPM30 tests on LSST30 data on the lower half of IN2P3."""
"DM-13950","Story","pipe_tasks",2,"Convert assembleCoadd.py to numpydoc","""Finish porting pipe_tasks docs from doxygen to numpydocs following Jonathan Sick's hack day instructions."""
"DM-13976","Story","jointcal",2,"Rename jointcal.gtransfo","""jointcal's {{Gtransfo}} object (a mutable 2->2 transform designed for astrometry and optimized for being fit) should have a name that better matches our standards. I created {{PhotometryTransform}}, so I suppose an appropriate new name might be {{AstrometryTransform}}?"""
"DM-13969","Story","cp_pipe",0.5,"Resolve implied dependency of cp_pipe on eotest","""It turns out that {{cp_pipe}} has an implicit dependence on {{eotest}}.  Please resolve the dependence by including it in the table file.  This may also involve moving it into either {{lsst-dm}} or {{lsst}}."""
"DM-13989","Story","Firefly",2,"fixed hips cube issues and honor some HiPS properties","""_Do the following:_   # Cubes: fixed the bugs related to moving between HiPS cubes and regular hips   # Cubes: display the correct current plane number and the total plane number when switching between HiPS cube   # Cubes: honorthe data_cube_* properties and show information about the 3rd dimension   ** Use: {{value = crval3 + (cubeIdx - crpix3 ) * cdelt3}}   # Make field of view and target optional and then,if they are not specified by the user, default to the HiPS properties {{hips_initial_ra}}, {{hips_initial_dec}}, and {{hips_initial_fov}}. If neither are available show 180 degrees at 0,0."""
"DM-13979","Story","Qserv",8,"Remove dependency on qserv-run-dir","""qserv-run-dir and qserv-configure will no more be used in k8s setup."""
"DM-14007","Bug","skymap",0,"Fix py2 linter error in skymap","""Fix the following python 2 error:  """
"DM-14004","Bug","astshim",0.5,"Make astshim compliant with the -pedantic compiler flag","""astshim has a few C++ violations that are exposed using the {{-pedantic}} flag with the C++ compiler. Fix them."""
"DM-14001","Improvement","afw",1,"Make afw PEP8 compliant and enable auto testing","""Fix PEP8 warnings and enable automatic testing by scons and by Travis on github.    I also fixed the Doxygen warnings, as the warnings about duplicate section names were showing up when building other packages, which was very annoying. One change was to stop Doxygen from scanning any C++ source files in {{src/...}}. I moved the Doxygen documentation from files to the headers long ago, and scanning the source was a frequent cause of spurious Doxygen warnings."""
"DM-13998","Improvement","skymap",0.5,"Enable automatic flake8 testing in skymap","""Enable flake8 testing in skymap"""
"DM-13997","Story","Science Pipelines",0.5,"Enable numpydoc support for ip_isr","""This ticket is to enable the numpydoc conversion of ip_isr."""
"DM-14019","Improvement","ap_pipe",1,"Allow ap_pipe to skip association","""Once {{ap_association}} supports it, {{ap_pipe}} should query the association database to see if a dataId has already been processed. This will allow {{ap_pipe}} to skip all processing steps that have already been performed."""
"DM-14014","Improvement","Stack Documentation and UX",0.5,"Remove ""Keyword assignment operators SHOULD be surrounded by a space..."" from the Python style guide","""Implement RFC-471 by removing  this [rule|https://developer.lsst.io/python/style.html#keyword-assignment-operators-should-be-surrounded-by-a-space-when-statements-appear-on-multiple-lines] from the Python style guide:    Keyword assignment operators SHOULD be surrounded by a space when statements appear on multiple lines    we are using PEP8 instead and flake8 will enforce it    Also remove E251 from any list that suggests it as a rule to ignore"""
"DM-14012","Story","daf_butler",1,"Add helper container class supporting topologically sorted iteration over elements","""Add a {{ConnectedSet}} helper (name optional) that allows for insertion of elements and connections and iteration over them in topologically sorted order."""
"DM-14008","Technical task","obs_subaru",0.5,"Enable TransmissionCurve coaddition for HSC","""This should be disabled for most cameras, but we should definitely be running it for HSC."""
"DM-14029","Story","Firefly",5,"Improve table parsing and memory usage","""Refactor DataGroup   * DataGroup was written a long time ago as a table model torepresent and manipulate tabular data. Over the years is has gotten bulky and complicated.  Refactor it with emphasis on memory footprint and larger data set.    Table parsing   * Look into ways to improve table parsing, especially IPAC tables."""
"DM-14024","Story","Qserv",2,"Study current cluster setup scripts","""Study the current OpenStack cluster setup scripts to plan refactoring   * Use shade instead of nova,cinder and other low-level openstack python clients   * Remove deprecated bare metal commands"""
"DM-14046","Story","SUIT",1,"Cache HiPS list and properties search result","""In order to optimize the search of HiPS list and properties, create a method to cache the search result. The search result will be re-used repeatedly for any coming query and only be updated when the server have made any modification.        """
"DM-14075","Story","pipe_tasks",1,"Exclude bad mask plane in nImage for filtering artifact candidates","""Symptom: Artifact candidates are being clipped when there not sufficient epochs remaining to do so.     Cause:  A crude N-Image is passed to filterArtifacts to compute the maximum number of epochs a candidate can appear in and be clipped. If there are < 3 epochs it's zero. (i.e nothing should be clipped). This N-Image is too crude.    The actual N-Image can be lower due to recorded chip defects (everything in the bad mask plane).    NOTE: This only affects coadds with small numbers of epochs"""
"DM-14074","Story","Firefly",1,"Check Firefly access to the amiga.iaa.es HiPS maps","""Determine, on {{irsadev}} (which is why I can't do this now, because I'm offsite), whether the current Firefly HiPS code displays the http://amiga.iaa.es/hipslist maps in its index, and (whether or not they are in the index) whether it can display them."""
"DM-14072","Improvement","afw",1,"Add getCutout method to Exposure","""There are many instances when it would be helpful to have a simple way to return a postage stamp, or small cutout, of an exposure with some user-specified center and dimensions. This ticket is to create such a method, ideally in C++.    A preliminary python implementation lives in {{u/mrawls/exposure-cutout}}."""
"DM-14069","Story","Developer Infrastructure",1,"Update igprof on LSST (and Princeton) systems","""Per DM-14060, please install the new version of igprof on:    - All four lsst-dev stacks;  - Both Princeton Tiger stacks;  - Both Princeton Perseus stacks."""
"DM-14064","Bug","Continuous Integration|stack release",1,"lsst_dm_stack_demo failing with: ./bin/demo.sh: No such file or directory","""There are multiple reports on #dm-square this morning of the stack demo failing on same {{stack-os-matrix}} configurations with errors similar to:        The clean build of of {{lsst_distrib}} failed all configurations but had been passing for several days prior:    https://ci.lsst.codes/blue/organizations/jenkins/science-pipelines%2Flsst_distrib/detail/lsst_distrib/211/pipeline    There have been no changes merged to either https://github.com/lsst/lsst_dm_stack_demo or https://github.com/lsst-sqre/ci-scripts/blob/master/runManifestDemo.sh in the last couple of days."""
"DM-14082","Story","ap",0.5,"Update alert_stream for sims data","""Current alert_stream repo uses only a single template alert. We want to change this to be able to send and receive sims data, for use in filtering and for the end-to-end prototype."""
"DM-14079","Improvement","metaserv",3,"Add file logging to albuquery, aka dax db/metserv v1","""Need to add file logging to persist logs for debugging and tracking, as the default is going to console."""
"DM-14103","Bug","Firefly",2,"Cleanup code related to the coordinate grid that slow down the application","""i was testing and trying the feature match image to hips so i had 1 image and 1 hips map displayed. When i tried to overlay a grid on FITS image, the browser slow down and sometimes i have to reload the page. It looks to me that there is still a link between applying grid to hips that is not didabled once i removed but button form the toolbar for hips."""
"DM-14118","Story","Data Release Production",2,"Create Jupyter notebook summarizing cModel config results","""This notebook is to summarize the effects of changing the number of Gaussians in the initial fitting in the cModel task.    This includes running through the Jupyter workflow on lsst-dev, using the data butler, remembering how to process/plot data with Python and forgetting about R.    The notebook is currently at lsst-dev:/home/dtaranu/src/mine/cModelConfigs.ipynb and I will likely add it to a sensibly-named repository on lsst-dm."""
"DM-14116","Story","Data Release Production",2,"Learn how to rerun command-line drivers on lsst-dev","""Yusra showed me how to source the latest weekly build of the pipeline and running command-line tasks on HSC data on lsst-dev, e.g.:    source scl_source enable devtoolset-6; source /software/lsstsw/stack3/loadLSST.bash    setup lsst_distrib -t w_2018_14 # For that week    mkdir /project/dtaranu/cmodelconfigs/    multiBandDriver.py /datasets/hsc/repo --calib /datasets/hsc/repo/CALIB/ --rerun RC/w_2018_14/DM-13890:private/dtaranu/cmodelconfigs/w_2018_14 --id tract=9813 patch=3,4 filter=HSC-G^HSC-R^HSC-I^HSC-Z^HSC-Y^NB0921"""
"DM-14115","Bug","ap_verify",1,"ap_verify's metrics-file command-line argument not documented","""Following DM-13042, {{ap_verify}} takes the {{\-\-metrics-file}} command-line argument to override metrics output behavior. However, the ticket neglected to add documentation for this argument. Add a section to {{ap_verify}}'s command-line argument reference describing {{\-\-metrics-file}} and its intended use."""
"DM-14125","Story","SUIT",5,"Remove pre-multitrace chart code and server-side expressions","""Remove chart code supporting unused pre-multitrace architecture and server-side expressions.  Update the documentation for showChart parameters."""
"DM-14135","Story","afw",1,"Convert afw.geom to numpydoc","""Convert {{lsst.afw.geom}}'s Python to Numpydoc, following the guidelines on [community|https://community.lsst.org/t/2760]."""
"DM-14134","Story","Alert Production",1,"Enable Sphinx support for ip_diffim","""Enables Sphinx support by uncommenting `automodapi` and fixing the errors and warnings."""
"DM-14133","Story","meas_astrom",5,"Enable Sphinx support for meas_astrom","""Add Sphinx support to meas_astrom package."""
"DM-14129","Bug","DM",2,"Fix AuxDevice multiple forwarder issue discovered at April 4th Pathfinder","""This recent Pathfinder activity was the first activity where the AuxDevice was incorporated into the DM L1 code. The AuxDevice specifically handles tasks on the Auxiliary telescope. During the activity, it was discovered that the component was not handling forwarder fully qualified names properly. The fix during the exercise was to configure the device to use only one forwarder with no spare. This fix allows an arbitrary number to be used - which is how all of the commandable devices behave."""
"DM-14128","Story","Qserv",0.5,"Fix Qserv container builds","""Recent change to admin/tools/docker/1_build-image.sh seems to have broken automated Qserv container builds"""
"DM-14155","Story","jointcal",2,"Experiment with other source selectors for photometry","""The photometry failures may be related to not having""""appropriate"""" reference stars. I should try a few other source selectors, starting with the {{flaggedStarSelector}} (which uses bright PSF sources), to see if they are a better match than the astrometrySourceSelector.    I'll want to be able to count measuredStars (i.e. DM-14153) in order to tell whether the new source selector is picking enough sources to be useful."""
"DM-14154","Story","Qserv",8,"Setting up a Qserv and Replication cluster at IN2P3","""Set up a testing environment combining Qserv + the Replication system in the upper part of the IN2P3 cluster. This included the following nodes:  * *ccqserv125*: Qserv _czar_ and the Replication System's _controller_  * *ccqserv126* - *ccqserv149*: Qserv _worker_ servers and the Replication System's _worker agents_    Configure Qserv to use a separate set of ports and to use a separate data directories to avoid direct conflicts with the main stream (other) Qserv installation.    Preload the cluster with 1/6th of the following catalogs which are (as of now) being deployed at the NCSA's PDAC Qserv Cluster:  * *sdss_stripe82_01*  * *wise_00*    The data will be copied from the first 5 _worker_ nodes of that (source) cluster:  * *lsst-qserv-db01* - *lsst-qserv-db05*    The total amount of data to be transgferred from those 5 nodes is: *3.7 TB*    Extra actions to be taken in a context of this ticket will also include:  * building and deploying a specially configured version of the Qserv Docker container (to allow separate ports)  * packaging tools of the Replication systems into a separate container to be deployed at teh new cluster  * develop simple set of the management tools for starting/stopping the Replication System's services    Port number modifications in container image *qserv/qserv:tickets_DM-10424*:  {code:bash}  % cat admin/templates/installation/qserv-meta.conf    # Port number for worker management service  port = 25012    # Port number for cmsd server (not used in mono setup)  cmsd_manager_port = 22131    # Port number for xrootd server  xrootd_port = 21094    # Port number for mysql-proxy, this is the primary interface for qserv clients  port = 24040    # Port number for mysql server  port = 23306    /qserv/replication/  /qserv/replication/data/  /qserv/replication/log/  /qserv/replication/tmp/  {code}"""
"DM-14153","Story","jointcal",2,"Add warn messages for too few meas/ref sources per ccd","""After every outer outlier rejection loop, we should check the number of reference and measured sources per ccd, and issue a warning if they get too small (where """"small"""" is defined by a config parameter)."""
"DM-14152","Story","Data Release Production",1,"Investigate the spatial distribution of failed cModel fits","""A significant fraction of sources in HSC-R tract 9813 patch 3,4 have failed initial cModel fits (2.3% nan flux/objective, 10.2% negative flux), while 5.1% of dev/exp fits have nan flux/objective. After learning how to use the butler to display in ds9, I found that these failures come from a combination of sources near the edge of a patch, in/near the halos/diffraction spikes of bright stars, or from difficult/failed deblends, in roughly that order. I did not find any surprising failures - all of the failures also set a seemingly sensible failure flag.    The attached plot can be generated by the notebook created in DM-14118 (lsst-dev:/home/dtaranu/src/mine/taranu_lsst/cModelConfigs.ipynb)."""
"DM-14171","Story","obs_base",0.5,"Add descriptions for fgcm and transmission datasets","""There are a number of fgcm and transmission curve-related datasets in obs_base's {{policy/datasets.yaml}} and {{policy/exposures.yaml}} that need descriptions. See the descriptions that were added in DM-13756 for examples: a sentence or two describing what the dataset is and what might read/write it."""
"DM-14170","Story","obs_base",0.5,"Add descriptions for dcr datasets","""There are a number of dcr-related datasets in obs_base's {{policy/datasets.yaml}} and {{policy/exposures.yaml}} that need descriptions. See the descriptions that were added in DM-13756 for examples: a sentence or two describing what the dataset is and what might read/write it."""
"DM-14168","Story","Data Release Production",2,"Compare running times of cModel fits to individual objects with different parameters","""I examined the distribution of cModel running times for HSC-R 9813 3,4. Two things are apparent - with default settings, some faint sources (mag_psf > 26) take a long time to fit (>1 min); also, changing parameters like the number of initial components or the fit algorithm can exacerbate this problem.    The attached plots can be generated by the notebook created in DM-14118 (lsst-dev:/home/dtaranu/src/mine/taranu_lsst/cModelConfigs.ipynb). I have also put it up on [https://github.com/lsst-dm/modelling_research] (see test_lsst_cmodel.py and jupyternotebooks/lsst_cmodel_configs.py/.ipynb), which supersedes the local copy on lsst-dev."""
"DM-14162","Bug","starlink_ast",1,"Iterative inverse of radial transform not acceptably accurate","""A radial transform made with {{afw.geom.makeRadialTransform}} has a very inaccurate iterative inverse in some cases. Here is an example:      The error is most likely in AST's {{PolyMap}}. Note: when inverse coefficients are not provided (as in this case) {{afw.geom.makeRadialTransform}} constructs a {{PolyMap}} using options {{""""IterInverse=1, TolInverse=1e-8, NIterInverse=20""""}}.    When this is fixed, {{cbp}} test {{testSetFocalPlanePos}} in {{test_coordinateConverter.py}} can be simplified."""
"DM-14159","Bug","meas_mosaic|validate_drp",0.5,"Wrap matplotlib use in meas_mosaic","""{{meas.mosaic.utils}} does a module-level import of matplotlib and sets the backend to {{Agg}}.    a) Specifically the [{{matplotlib.use(""""Agg"""")}}|https://github.com/lsst/meas_mosaic/blob/master/python/lsst/meas/mosaic/utils.py#L30] line should be removed.    It has no effect if the user has already loaded a backend, and spews a big chunk of distracting warnings.    b) The overall import of matplotlib should not happen at the module level, because that code gets run when importing the module. Importing the module happens even just opening a Butler object view to the repo. Specifically, meas_mosaic gets imported by just the following code.        Philosophically I don't believe that opening a Butler should trigger setting up matplotlib.    Editorial: I believe that all plotting imports should be protected and separated from the data analysis. But this implies a refactoring that may not be justified given the imminent replacement by jointcal"""
"DM-14175","Bug","lsst_ci",2,"lsst_ci failing","""The weekly, nightly, and {{lsst_distrib}} clean build are failing due to the same error message from {{lsst_ci}}.      """
"DM-14197","Improvement","obs_test",2,"Make obs_test data ingestible","""The data in {{obs_test/data/input}} are provided in the form of a Butler v1 repository, which is sufficient for most testing purposes. However, the files cannot be used to test ingestion code: the files have minimal (and generic) FITS headers, and cannot be ingested using default configurations for {{IngestTask}} and {{IngestCalibsTask}}.    Known issues:  * The flats and biases do not have an {{OBSTYPE}} header keyword, so they cannot be ingested without {{\-\-calibType}} (or with it, given DM-13975).  * The default config for {{IngestCalibsTask}} does not list """"defect"""" as one of the data types to register  * Calibration files (or just defects?) cannot use the default columns in {{register.unique}}"""
"DM-14217","Bug","Qserv",1,"SHOW PROCESSLIST is broken in Qserv czar","""The master branch of package qserv seems to have a bug in an implementation of the 'SHOW PROCESSLIST' operation in Qserv czar. This statement always return an empty result set, while the underlying database table has multiple entries. Also there are messages in the proxy's log file *mysql-proxy-lua.log*:  """
"DM-14213","Story","ctrl_iip",1,"Discuss ATS system release plan with DM release engineer","""SSIA."""
"DM-14212","Story","ctrl_iip",1,"recompile and re-link DAQ code with new library version.","""The utility apps (such as catalog listing, image triggering, etc.) must be rebuilt as well as the DAQ Forwarder code."""
"DM-14211","Story","ctrl_iip",8,"ATS report telemetry design and implementation","""Build means to publish reports as telemetry. Reports may be work done, system warnings, etc."""
"DM-14210","Story","ctrl_iip",5,"Fine tune AuxDev ACK consumption and make more efficient.","""Implement a version of the progressive ACK timer that checks strictly for the one ATS forwarder response; these must be blocking ACKs, so proper ACKs should be identified quickly if received."""
"DM-14208","Story","ctrl_iip",2,"Update AuxDevice unit test","""Addition of Fault system added some messages that must be verified in the unit test."""
"DM-14223","Story","Qserv",2,"Set terraform in travis integration tests","""Use terraform in the CI build for creating the test cluster instead of installing it localy."""
"DM-14237","Improvement","obs_decam",1,"Change DecamIngestTask --filetype default from instcal to raw","""As discussed in RFC-478, {{DecamIngestTask}} requires a {{\-\-filetype}} argument to ingest raw data, something its supertask {{IngestTask}} does by default. Change the default of {{\-\-filetype}} to {{raw}} so that {{DecamIngestTask}} behaves like {{IngestTask}} when given the same arguments.    This work includes updating {{obs_decam}} documentation and updating any calls to {{DecamIngestTask}} that assume the old default."""
"DM-14236","Story","ap_association",8,"Incorporate l1dbproto into AssociationTask","""Take the existing AssociationTask functionality and get it running using l1dbproto (rather than SQLite) as a back-end.    (This can run on a standalone system; no need to deploy at LDF.)"""
"DM-14233","Story","meas_algorithms",0.5,"Remove secondMomentStarSelector","""Remove secondMomentStarselector, per RFC-475, and clean up any tests, etc. that refer to it."""
"DM-14244","Bug","Continuous Integration|stack release",1,"eups.lsst.codes backups not pruning promptly?","""Daily backups are supposed to be expire out of the s3 bucket at 8 days.  This appears to not be happening promptly.  This might be because s3 isn't doing this promptly or it might be because it is a versioned bucket.  This was noticed as the s3 usage has grown a bit faster than expected.        The metadata on the object itself seems to suggest that it will expire in ~9 hours:              """
"DM-14275","Improvement","afw",1,"The distortion in test_wcsUtils.py testDistortion is unreasonable","""The distortion model used in test_wcsUtils.py's testDistortion method is not reasonable (the distortion is far too much to be reasonable).    I noticed this when that test failed testing a fix to starlink_ast on DM-14162"""
"DM-14255","Improvement","sphgeom",0.5,"Add ConvexPolygon.intersects and related methods","""Add {{ConvexPolygon.intersects}} and the related methods {{contains}}, {{isDisjoint}} and {{isWithin}}. The region overloads can probably be implemented using {{ConvexPolygon.relates}} and the point overloads using {{ConvexPolygon.contains}}"""
"DM-14292","Story","Qserv",40,"Deploy replication service at PDAC","""Major milestones of this effort:  # upgrade Qserv installation in PDAC with the latest version of Docker containers based on MariaDB 10.2.14. The new containers are also needed to support the extended management protocol needed for cooperation between Qserv workers and the Replication system's Controllers when changes to replica disposition are made.  # Docker-based install and preliminary tests of the Replication system's tools on the cluster. At this stage a proper configuration of the Replication system will be devised and tested.  # Scalability tests of the main replication operations, including operations with persistent state of the operations (Replication _jobs_ and _requests_). Making improvements to the implementation of the system as needed.  # Implement the _Health Monitoring Algorithm_ for workers of both kinds (Qserv and the Replication system). Integrate this algorithm into the above mentioned _fixed logic Controller_. The initial version of the algorithm will be sending _probe_ requests to both kinds of workers and measure their responses (which must arrive within a reasonable period of time). This may also require to make some adjustments to the Replication system's Messaging Network to respect priorities of these requests. The current implementation has a plain queue. The new one should get a priority queue.  # Finalize and test the fixed-logic replication Controller  # when confident with the functionality, performance and robustness of the Replication system integrate the system with the existing Kubernetes infrastructure"""
"DM-14291","Improvement","astshim",0.5,"PolyMap.polyTran does not clear IterInverse","""{{PolyMap.polyTran}} replaces the forward or reverse coefficients with a fit. But if it is used to fit the inverse (as is typical) and the original {{PolyMap}} has an iterative inverse, the returned mapping will use that iterative inverse and ignore the fit coefficients.    I have asked David Berry if {{astPolyTran}} is behaving as it should by copying the value of {{IterInverse}} instead of clearing it. I am guessing it is intentional, in which case I can see three solutions:  - Have astshim clear {{IterInverse}} in the returned mapping when appropriate.  - Document the problem and allow {{PolyMap}} to be modified by setting {{IterInverse}} and, presumably, the two related properties, thus breaking the rule that mappings are immutable (other than Id and Ident). Allowing these properties to be set might be useful for tweaking behavior.  - Document the problem and be done with it. I feel this is too surprising to consider.    Of these I feel the first, clearing {{IterInverse}} when appropriate, is most appropriate and least surprising. However, it will require a bit of care, as the original mapping may be inverted and polyTran can fit either direction. I believe the logic is as follows:    If the mapping being fit has IterInverse set:      If the mapping being fit is not inverted and polyTran is fitting the inverse:          unset IterInverse in the returned mapping      if the mapping being fit is inverted and polyTran is fitting the forward direction:          unset IterInverse in the returned mapping    Which simplifies to:  If polyMap IterInverse is set and polyTran forward == PolyMap.isInverted():      unset IterInverse in the returned mapping    Independently it is worth considering allowing modifying the iterative inverse parameters but I'd like a clearer need before doing so.  """
"DM-14290","Bug","ctrl_provenance|ip_diffim|ip_isr|pipe_base|utils",2,"Do not raise generic Exceptions","""We have several bits of code that raise either {{Exception}} or {{lsst.pex.exceptions.Exception}}/{{pexExcept.Exception}}. We should replace all of those with an appropriately specific exception. The generic Exception should almost never be raised (or caught, but that's a different issue)."""
"DM-14280","Bug","Continuous Integration|stack release",0.5,"nightly-release d_2018_05_02 failed","""{{d_2018_05_02}} failed after 3 tries to build tarballs for {{centos-6.devtoolset-6.miniconda3-4.3.21-10a4fa6}}. The other two tarball configs were successful.    It looks like this may this may be some sort of cached state / pip 10.x upgrade problem but it also appears that the system python is incorrectly being used in the virtualenv.      """
"DM-14279","Bug","Continuous Integration",1,"upgrade blueocean to 1.5.0 (final) / broken links to triggered builds","""Blueocean {{1.5.0-beta-2}}, which was deployed on DM-13258, does add links to triggered builds.  However, these links are not properly URL encoded and are broken when linking to the build of any job that is nested in a cloudbees-folder.  This was fixed in the final release of {{1.5.0}}"""
"DM-14314","Story","metaserv",20,"Metaserv should return the metadata for WISE Tables","""Per [~tatianag], dax_metaserv should be populated for everything we are serving through PDAC.     http://lsst-qserv-dax01:5000/meta/v1/db/ should have one logical database entry for WISE with multiple schemas corresponding to each of the PDAC database described here:    https://confluence.lsstcorp.org/display/DM/PDAC+v2+data+list     (Similarly to how we have sdss_stripe82_01 in the schemas section returned by sst-qserv-dax01:5000/meta/v1/db/W13_sdss_v2/)    We should only populate metaserv with the data readily available from dbschema (""""name"""", """"datatype"""", """"nullable)"""". All other fields like """"ucd"""", etc. can be empty.    This would make it possible for SUIT to refer to WISE tables using logical database name rather than internal name like `""""//lsst-qserv-master01:4040"""".wise_00.allwise_p3as_mep` and make sure that WISE data can be discovered through TAP like services.    5/10/2018 tgoldina  Since there is no optimized way to get table column metadata via dbserv, this issue is a blocker for moving PDAC to dbserv v1 (albuquery). Please consider it when deciding on the priority of this ticket.     """
"DM-14313","Story","JupyterLab",0.5,"Add pyarrow to the jellybean install.","""Some of the QA tools now need pyarrow.  Please install pyarrow with the other third party modules."""
"DM-14311","Bug","ip_diffim",0.5,"Add subtractAlgorithmRegistry to __all__ in imagePsfMatch.py","""When DM-14134 added {{\_\_all\_\_}} to {{imagePsfMatch.py}},{{subtractAlgorithmRegistry}} was not included. This breaks {{imageDifference.py}} in {{pipe_tasks}} which expects to be able to import it."""
"DM-14307","Story","Data Release Production",2,"Review cModel logging setup","""I read the developer guide's logging docs and reviewed and tested cModel's logging. In short, the optimizer has detailed debug statements, but there is very little output from cModel itself describing the control flow. For example, one galaxy was running the double shapelet PSF fitting tasks but skipped the cModel routine, asmodelfit_CModel_flag_region_maxBadPixelFraction was set. I also spent some time (re)discovering that some ipython output gets sent to jupyter's stdout for reasons I don't understand (possibly this bug: https://github.com/gotcha/ipdb/issues/52)."""
"DM-14305","Story","eigen|ndarray",2,"Upgrade Eigen to 3.3.4","""Implementation of RFC-479.    For now, this is exploratory work, to see just how bad the changes to ndarray are going to be."""
"DM-14302","Bug","verify",0.5,"verify fails on master, possibly with unexpected Quantity repr","""In building {{verify}} package on my Mac with numpy 1.14.2 and astropy3 I get the following failure:  """
"DM-14299","Story","Stack Documentation and UX",1,"Remove Python2-isms from developer guide","""Now that Python 2 is not supported, we can remove all the items in the Python style guide talking about Python 2 and {{__future__}}/{{futurize}}."""
"DM-14334","Story","supertask",8,"Start implementing QuantumGraph building","""Logic is described by Jim in [https://dmtn-056.lsst.io/operations.html#supertask-pre-flight-and-execution.]There are many complications of course, e.g. what is Registry responsibility vs. Pre-flight responsibility. First implementation will likely be sub-optimal and ugly.    """
"DM-14333","Story","L1 Database",5,"Support Oracle dialect in AP prototype script ","""While Oracle RAC at NCSA is getting ready for testing I could spend some time totry running my prototype against Oracle in some other non-production setup. ap_proto uses sqlalchemy but it also hasdialect-specific SQLhandling for optimization purpose. I need to extend that backend-specific code to support Oracle as well.    I can think of few potentialthings that need different implementation for Oracle:   * multi-row INSERT, Oracle does not support syntax that is supported by other backends (\{\{INSERT INTO TABLE (columns) VALUES (data), (data), (data), ...}}) so I'll have to find some other mechanism for bulk row insert   * """"UPSERT"""" functionality should also be implemented differently in Oracle   * Case-sensitivity issue (probably minor)   * Usual DATETIME stuff is not very portable   * Anything else..."""
"DM-14325","Bug","obs_subaru",1,"deepDiff datasets not supported by HSC","""Trying to run {{imageDifference.py}} on an HSC dataset crashes with an error saying that the {{deepDiff_diaSrc}} dataset type does not have a template. Manual inspection of {{obs_subaru/policy/HscMapper.yaml}} confirms that there are no {{diaSrc}} or {{deepDiff}} datasets mentioned.    Please add the appropriate datasets so that we can do image differencing on HSC data."""
"DM-14320","Improvement","dbserv|metaserv",1,"dbserv (or albuquery) should include description column in the metadata result set","""Per [~tatianag],    The new version of dbserv, integrated with metaserv returns metadata for all columns in the result set. Currently, the """"columns"""" metadata fields are """"name"""", """"datatype"""", """"ucd"""", """"unit"""", and """"tableName"""".    Ideally, column metadata should contain all column metadata fields available via metaserv, including """"nullable"""" and """"description"""". (See http://dm.lsst.org/dax_metaserv/api.html#get--meta-v1-db-(string-db_id)-tables-(table_id)- for column metadata fields stored in metaserv.)     For WISE datasets, the 'description', 'unit', etc. can be empty (returned as empty strings) in metaserv. Expected columns, empty or not, should be propagated to the UI."""
"DM-14347","Story","Qserv",20,"Extend antlr4 integration test query parity ","""Start to go through the FIXME integration test queries and determine if they are FIXME because they fail to parse, or if they fail to run. Take notes on which is which. Make some effort to figure out why they don't run (with the acknowledgment that it may take 20 story points to chase down even 1 non-running query for a qserv novice).    The output of this will be compared with [query pages in TRAC|https://dev.lsstcorp.org/trac/wiki/db/queries] (being ported to Confluence by [~fritzm]), and stories to fix these stories will be created as appropriate."""
"DM-14345","Story","Requirements Documents",2,"Add LSP requirements to model and submit to CCB","""In DM-14335 the final list of requirements was submitted. They need to be transferred to the model and converted to a docgen for review by DM CCB."""
"DM-14336","Story","Qserv",5,"Unify k8s proxy manifest for worker and master pods","""Unify the k8s definition of the proxy container for worker and master pods."""
"DM-14366","Improvement","pipe_base|pipe_tasks",1,"Make pipe_base and pipe_tasks pep8 compliant","""Fix pep8 warnings and errors in pipe_base and pipe_tasks and enable automatic flake8 checking"""
"DM-14363","Story","afw",8,"Make afw::cameraGeom::Detector table-persistable","""In Gen3, we're planning to just persist Detectors with Exposures to make each Exposure more self-contained and avoid complex modify-on-load code (which would have had to get more complex than what we have now to handle camera versioning). This means we need a way to save a Detector inside an Exposure, and at least at present, that means making it inherit from {{afw::table::io::Persistable}}.    """
"DM-14360","Story","Stack Documentation and UX",0.5,"Pin pybtex/sphinxcontrib-bibtex dependencies in documenteer 0.2.x & dev guide update","""The Dev Guide suggests we use the following:        However, when I tried this with a recent sphinxcontrib-bibtex, I get:        I think this is due to changes upstream (I didn't track it down fully, but I note that both sphixcontrib-bibtex and pybtex have been making changes to the way they handle encodings in recent releases).    Simply removing the {{:encoding:}} line works fine for me."""
"DM-14359","Bug","ap_pipe|ap_verify",2,"Fix data ID handling in ap_*","""During investigation of DM-12672, I discovered several bugs in how {{ap_pipe}} and {{ap_verify}} handled data IDs:  * Most command-line tasks implicitly assume their {{run}} or {{runDataRef}} methods take a fully expanded data reference. This is provided by {{pipe.base.ArgumentParser}}, but {{ap_pipe}}'s task runner inadvertently bypassed the data ID expansion. In practice, this meant {{ImageDifferenceTask}} didn't have all the information it expected.  * The same bypass would have prevented {{ap_pipe}} from processing multiple datasets specified as {{visit=#}}, though {{visit=# ccd=1..62}} would have still worked.  * {{ap_verify}} always provided partial data references, because it assumed the run method (or, more precisely, its butler calls) would expand any unambiguous reference.  * The tests in {{test_ingestion.py}} were based on a naive view of how data IDs work, and most of the outstanding issues with the tests can now be fixed."""
"DM-14356","Improvement","daf_persistence",1,"Implement putting of matplotlib figures","""Make matplotlib figures {{butler.put()}}able.    [~jbosch] says on Slack:   > Basically, that involves grepping {{daf_persistence}} for {{FitsCatalogStorage}}, copying what you see and calling it {{MatplotlibStorage}}, and then adjusting it appropriately (i.e. call {{savefig}} instead of {{writeFits}}, raise an exception when trying to read).    [~price] notes that there are some gotchas involving the fact that the backend has to be set immediately after import, and this could prove tricky, especially if people want to combine this with pop-up style debug plots.. Some relevant info on this might be found in DM-14159.      """
"DM-14385","Bug","metaserv",2,"typo in metaserv return key","""metaserv return object for {{http://lsst-qserv-dax01:5000/meta/v1/db/W13_sdss_v2/tables/RunDeepForcedSource/}} has a key {{result:}} instead of {{result}}. Appears like a typo.  """
"DM-14378","Story","ci_hsc",2,"Add Gen3 conversion scripting and tests to ci_hsc","""Add gen3 conversion to the ci_hsc SCons build and test that we can use a Gen3 Butler to {{get}} Datasets {{put}} with a Gen2 Butler."""
"DM-14370","Story","ctrl_iip",2,"Modify SAL message emulator for Tucson turnkey system","""Before shipping the turnkey system to Tucson, a burn-in test must be run for 48 hours. This will require modification of the simple SAL message emulator used for in-house testing. The new emulator should include occasional start-ups and shut-downs of the ATS DM system, as well as randomly draw image_ids/catalog names from a set of 100 pre-triggered in the DAQ (triggering the images is not necessary for this test, and is only realistically done when Tony's CCS system is running as well.    As well as proper logging, the system should issue a 'result set' log report every time it is shut down."""
"DM-14369","Bug","Continuous Integration|stack release",1,"nightly-release d_2018_05_09 failed","""The nightly release failed due to fallout from DM-14138 merged yesterday. This is a simple id10t error in that I did not rebuild the {{lsstsqre/codekit}} image after making a new release of {{sqre-codekit}} to pypi, but updated the docker tag string in jenkins.    https://ci.lsst.codes/blue/organizations/jenkins/release%2Fnightly-release/detail/nightly-release/285/pipeline      """
"DM-14367","Improvement","ctrl_iip",1,"Remove cfitio headers and lib from git repo and system install these items.","""SSIA    For the Tucson turnkey system, but will be the same for overall system."""
"DM-14393","Improvement","dbserv|metaserv",8,"column datatypes returned by metaserv and dbserv should be consistent","""Column datatype returned in the metadata section of the result by dbserv in absence of metaserv data should be consistent with the column datatype in metaserv.    Currently, the dbserv returns """"string"""" datatype, while metaserv returns """"text"""".   Also for 'BIT', dbserv returns """"binary"""", while metaserv returns """"boolean"""", for TINYINT, dbserv returns """"int"""", metaserv returns """"short"""".    To facilitate debugging, please consider returning both dbserv and metaserv datatypes in the metadata section of the dbserv return.    Per [~kennylo],    column datatypes returned by metaserv  come from the conversion table in lsst/dax/metaserv/schema_utils.py:    {code:python}  MYSQL_TYPE_MAP = {      'VARCHAR': """"text"""",      'TIMESTAMP': """"timestamp"""",      'BINARY': """"binary"""",      'TINYINT': """"short"""",      'BIGINT': """"long"""",      'BIT': """"boolean"""",      'FLOAT': """"float"""",      'INTEGER': """"int"""",      'DOUBLE': """"double"""",      'CHAR': """"text""""      }    """
"DM-14392","Bug","Qserv",8,"Add userfriendliness for provision script","""Test will be run on NCSA openstack using 25 nodes and more..."""
"DM-14442","Epic","Qserv",3,"F18 Qserv Release Engineering","""This epic holds F18 effort budget for ongoing chores such as updating upstream packages in eups, Jenkins and Travis configuration maintenance, and compiler and platform compatibility fixes."""
"DM-14441","Bug","pipe_tasks",2,"{{detect_isPrimary}} is not consistently set","""Running to the end of the """"Getting Started with the LSST piplines"""" tutorials    https://pipelines.lsst.io/getting-started/multiband-analysis.html    I think I have encountered a bug in how {{detect_isPrimary}} gets set.  The documentation says that it is the union of {{deblend_nChild==0}} with {{detect_isPatchInner}} and {{detect_isTractInner}}, however:    {code}  >>> by_hand = (refTable['deblend_nChild']==0) & refTable['detect_isPatchInner'] & refTable['detect_isTractInner']    >>> np.where(by_hand != refTable['detect_isPrimary'])  (array([4708, 4709, 4711, 4712, 4713, 4714, 4715, 4716, 4717, 4718, 4720,         4721, 4722, 4723, 4724, 4725, 4726, 4727, 4728, 4730, 4731, 4732,         4733, 4734, 4735, 4736, 4737, 4738, 4740, 4741, 4743, 4744, 4745,         4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4755, 4756,         4757, 4758, 4759, 4760, 4761, 4762, 4763, 4764, 4766, 4768, 4769,         4770, 4771, 4772, 4773, 4774, 4775, 4776, 4777, 4778, 4779, 4780,         4781, 4782, 4783, 4784, 4785, 4786, 4787, 4788, 4789, 4790, 4791,         4792, 4793, 4794, 4795, 4796, 4797, 4798, 4799, 4800, 4801, 4802,         4803, 4804, 4805, 4806, 4807, 4918]),)  {\code}    where {{refTable}} is loaded as specified in the tutorial outlined above.    As always: let me know if you need more information to recreate this behavior.  It is not impossible that this is just user error."""
"DM-14440","Bug","dbserv",2,"dbserv v1: ParseException when spatial constraint is followed by other constraints","""In dbserv v1 (albuquery), if I add another constraint to the spatial constraint, the query fails. For example,        Without AND part it works fine. The query also works in dbserv v0.    [SLAC discussion|https://lsstc.slack.com/archives/C2B709EQK/p1526333780000583]"""
"DM-14438","Story","Firefly",8,"Load MOCs from other sources","""    We would like multiple MOCs to be able to be displayed at once.   * Load more MOCs with the upload panel   * -Load MOCs with the search panel the can search the CDS server.- _Moved to DM-15570_        For immediate implementation, we will put a test button at the top."""
"DM-14435","Story","Firefly",20,"Implement MOC overlay","""Implement the visual display of MOC data in Firefly    Initially, display the HEALPixels actually identified in the MOC (which is just a list of HEALPixel IDs in NUNIQ format) as polygons overlaid on a sky display in Firefly. Include this in the usual Firefly layer control behavior.   * We would like multiple MOCs to be able to be displayed at once, with selectable colors used.   * It may be useful to enable the control of both polygon boundary colors, transparency, etc._as well as polygon fill_with adjustable transparency.   * Be able to switch between outline (wireframe) and transparent color fill   * MOC show as a HiPS layer with checkbox off, should lazy load with any HiPS        Implementation technical Notes:   * We should read the table using our normal fits table reading and put all the rows (only one column) into the store.   * Each number (NUNIQ) can be translated to a HealPix level and number and then to 4 WorldPt corners using functions in HipsUtil and HealpixIndex   * We need to make new DrawObject will need to be created that can draw a filled polygon, fill with a transparent color for overlaying. Possibly we could modify FootprintObj or MarkerFootprintObj.   * If the points reduce to a single point (based on zoom level) it should draw a single point.   * The drawing layer should be able to change the color in our standard way.    """
"DM-14433","Epic","ap_pipe",40,"Perform forced photometry on visit images within the AP pipeline","""Perform forced photometry on the corresponding PVI for every DIASource produced by the Alert Generation pipeline. Ensure this design is captured in LDM-151."""
"DM-14459","Story","daf_butler",1,"Add check to (Posix)Datastore that prevents silent overwrite","""A {{Datastore.put}} should raise when the file already exists (perhaps adding an option to force it)."""
"DM-14458","Improvement","ctrl_iip",2,"Add Redis scoreboard for incrementing session_id, job_num, and ack_ids","""Since the principle components were built for level one image ingest and distribution, they have used ad hoc means for generating unique numbers and keeping track of the last number between restarts. With the development of the ATS Turnkey system, a redis conf file was produced that sets the default number of redis instances at 18 instead of 16, so there is room for an increment scoreboard. This is a much cleaner way of addressing this and with db dumps before shutting down and by not flushing the increment scoreboard class at creation, this need is finally, properly handled."""
"DM-14455","Epic","butler",20,"F18 Butler Gen2 Critical Support","""This epic holds the F18 effort budget for critical maintenance to Butler Gen 2."""
"DM-14474","Story","JupyterLab",0.5,"Add environment variables to Jupyterlab deployments for Firefly","""As part of the ease-of-use improvements in DM-14391, we would like to ask that two environment variables be provided in Jupyterlab deployments.    FIREFLY_URL = path to the default Firefly server    e.g. [https://lsst-lspdev.ncsa.illinois.edu/firefly]for the [https://lsst-lspdev.ncsa.illinois.edu/nb]environment. A trailing slash will work.    FIREFLY_HTML = default landing page for Firefly, which is appended to the URL.    We'd like this set to 'slate.html' as we intend to build around this view."""
"DM-14472","Story","supertask",2,"Integrate user expression parser into command line tool","""User expression parser is almost complete, it can now be integrated in supertask CLI. """
"DM-14471","Story","Firefly",2,"HiPS display test","""DM-14149 made it possible todisplay HiPS images at level 20 level by using JavaScript 56 bit integer. It created new methods to do bit-shift. This ticket to test the result from science point of view."""
"DM-14497","Bug","ap_pipe",1,"ap_pipe doesn't know filters for AssociationTask","""{{AssociationDBSqliteConfig}} now requires an observatory-specific filter list as part of its config. This issue adds the DECam value to {{ApPipeConfig.setDefaults}} as a quick fix; presumably the settings can be moved to an obs-specific config override file in DM-12315.    [Apologies for the edit wars; I had thought this could be fixed at the level of {{AssociationDBSqliteConfig}} itself]"""
"DM-14496","Bug","ap_verify",1,"test_association broken","""{{ap_verify}}'s {{test_association}} does not run with the latest version of {{ap_association}}, complaining about {{ap.association.DIAObject}} not existing. Please update the {{ap_verify}} tests so that they pass.    I have tried to update the tests to use source catalogs instead of {{DIAObjectCollection}} myself, but wasn't able to make a valid DIA Object catalog."""
"DM-14494","Bug","ap_pipe",1,"selectImages.py depends on defunct lsst.geom","""{{selectImages.py}} depends on {{lsst.geom.convexHull}}, which was removed in DM-13790. It should be rewritten to use {{lsst.sphgeom.ConvexPolygon.convexHull}} instead.    This issue is blocker priority because {{selectImages}} is included in all imports of {{lsst.ap.pipe}}."""
"DM-14491","Bug","SUIT",1,"FireflyClient display_url does not make weblink in Jupyterlabdemo","""The {{display_url}} method added to {{FireflyClient}} in DM-14391 should make a clickable weblink. This works in my classic notebook tests, but in the Jupyterlabdemo environment the URL is only being printed out. Some restructuring of the try/except block in this function will make it work."""
"DM-14490","Bug","Qserv",8,"Fix k8S virtual network for Qserv at CC-IN2P3","""Test will be run on NCSA openstack using 25 nodes and more..."""
"DM-14521","Story","QA",1,"Update qa_explorer for new coord types","""There are mentions of {{IcrsCoord}} in {{qa_explorer}}.  These need to be updated to the new coord objects."""
"DM-14520","Story","daf_butler",1,"Re-enable Dataset->DataUnit foreign keys","""Dataset's foreign keys to DataUnit have been commented-out in the schema file.    Uncomment them and get things working (actually, we'll need to update their representation in the schema in order to make them compound keys).    I've already started this in trying to get the schema on DM-12620 synced with master, and I think I'm pretty close, but it makes sense to split this off from that ticket."""
"DM-14517","Bug","ap_association",1,"Fix bug in schema alias mapping in ap_association.","""This work was originally on DM-14507 however it was found that the failure to use alias mapping was due to a bug and the originally alias mapping work. As such this ticket will fix the bug and create a new unittest testing the case of a miss matched schema in DIASource storage."""
"DM-14516","Story","Firefly",1,"bug fix: make region file parsing case insensitive","""When upload a ds9 region file to be overlaid on an image, the keyword is required to be lower-case characters. Lets make it case insensitive .    test:   * do image search on firefly on target (0,0, j2000) and upload footprint file from 'Load DS9 Region File' popup.   * go to firefly/demo/ffapi-footprint-test.html, and add footprint layer from the footprint tool page."""
"DM-14515","Story","Firefly",1,"Improvements to Firefly footprint menu","""Two suggestions (only!) for the footprint menu in Firefly:    # Make it hierarchical, so that, e.g., all the HST instrument footprints appear in a submenu.  (I would like to have at least three footprints for LSST, for instance.)  # Make its content part of the application configuration, e.g., controlled via the {{suit}} package for LSST or the {{ife}} package for IRSA.  The Firefly repo could still contain a standard set of footprint files, but more could be added in the application, and even some of the standard ones suppressed, perhaps?"""
"DM-14514","Improvement","Firefly",5,"Provide UI for uploading ""instrument footprints"" to Firefly (relocatable regions)","""Inside Firefly, there is a UI option to place """"footprints"""" (e.g., of astronomical instruments) over displayed images.  Footprints are created from region files in the Firefly repo (https://github.com/Caltech-IPAC/firefly/tree/dev/src/firefly_data/footprint) and appear to be treated by Firefly as standard DS9 region files where the ra,dec coordinate system is treated as having a relocatable origin and orientation (i.e., as field angles rather than true ra and dec).    It would be very nice to make this capability available (1) in the UI, for region data uploaded from a file by a user, and (2) in the API, for region data sent from the JavaScript and/or Python APIs.    For (1), one possibility would be that the region file upload dialog might get a check-box added to it saying """"make origin movable"""" or """"treat as footprint"""".  Alternatively, an """"upload footprint"""" element might get added to the existing footprint menu.    Please see also tickets I've filed in the IRSA system, including IRSA-1612 and IRSA-1613, regarding the treatment of footprints and their coordinates in the layer dialog."""
"DM-14512","Improvement","Firefly",3,"Remember filename of uploaded DS9 Region file","""I notice that (successful) region file uploads produce an entry in the layer dialog of the form """"REGION_PLOT_TYPE-(serial number)"""" (e.g., """"REGION_PLOT_TYPE-7""""). It would be helpful to the user if the filename of the uploaded file were retained and displayed in the layer dialog.    Since regions can be created by API, not just by file upload, the file name convention can't apply in all cases, so the """"serial number"""" approach may still be appropriate for API uploads. However, even in that case, I think a more user-friendly string than """"REGION_PLOT_TYPE"""" would be an improvement. Does the API allow regions to be given names that could then be shown in the layer dialog?        TODO in this ticket:   * use the file name as label in the layer dialog. In cases that the file name is too long, treat it the same way as uploading an image, use only the characters fit in proper length space, and display the full name as tooltip when mouse over it.   * make sure it behaves the same in API, providing a label field for caller to set the label for display. If there is no label supplied, use string """"ds9 region overlay-\{N}"""".N will start at 1, and increase by sequence as it does now.    Also implemented:   * File upload pane is also updated to show the long file name of the uploaded file in shorter style as that shown in the layer dialog."""
"DM-14510","Story","jointcal",8,"Implement line search","""[~astier] suggests that we should implement a [line search|https://en.wikipedia.org/wiki/Line_search] in jointcal, to deal with the non-linearities in the photometric model (and because we may eventually have those in astrometry, as the astrometry model gets more complex). He suggested using [Brent's method|https://en.wikipedia.org/wiki/Brent%27s_method], which is [available in GSL|https://www.gnu.org/software/gsl/doc/html/roots.html#c.gsl_root_fsolver_brent]. It might be easier to just take the code directly from GSL, instead of writing an interface layer, given the way the nature of the jointcal models.    At the top of the outlier rejection loop in {{FitterBase.minimize()}}, this would look something like:      """
"DM-14509","Story","jointcal",2,"Option to turn sparse matrices into dense ones to explore eigenvalues","""I need to explore the properties of the matrix and gradient in jointcal's {{ConstrainedPhotometyModel}}, but the sparse matrix code in Eigen doesn't include many options for doing so. To better facilitate this, [~astier] suggested outputting the matrix elements and creating a dense matrix from it. This ticket is just for the output and checking that it's sensible: detailed exploration will be in a different ticket.    A quick search suggests that one can pass the sparse matrix to one of Eigen's constructors to directly get the dense matrix. It might be easier to explore the matrix properties with numpy."""
"DM-14508","Story","scikit_learn",2,"Implement RFC-474 to allow use of scikit-learn","""Make a stub package for scikit-learn"""
"DM-14505","Bug","Firefly",3,"Fixed coverage and cache bugs","""[~tatianag] found several issues while working on DM-8215.    Fix the following:   * FITS Cacheing is not working for URL type WebPlotRequest   * In certain cases coverage drawing is not showing overlays for multiple catalog tables    Extra work done:   * removed FileHolder.java, a interface that was only implement by on class   * removed useHiPSForCoverage option, now the is always on.   * fixed a problem an exception when loading wise images from metaConvert   * remove CoverageChooser since it is not longer used.    _to test cache bug:_   * load a image using the URL option, such as [http://web.ipac.caltech.edu/staff/roby/demo/wise-m51-band2.fits]   * then load the same image again. It should come from the cache.    _to test coverage bug:_   * use wise to load two different results   * They should both be overlaid.    ----"""
"DM-14536","Story","SUIT",1,"Utilities to include in Firefly docker container","""Please add the following utilities to Firefly docker container:    - procps (http://procps.sourceforge.net/)  - wget  - emacs    These utilities will be helpful when debugging a dockerized Firefly deployment using kubectl."""
"DM-14534","Bug","Data Release Production",2,"Fix measurementInvestigationLib.makeRerunCatalog parent keys","""lsst.meas.base.measurementInvestigationLib has convenience functions for setting up catalogs to rerun measurement tasks. However, if you call makeRerunCatalog with an id list including children but not their parents, these children will be skipped by runPlugins (e.g. from    lsst.meas.base.SingleFrameMeasurementTask). makeRerunCatalog should offer options to either reset child objects' parent keys to zero if their parents are not in the list (the default) or add the parents to the id list."""
"DM-14533","Story","ci_hsc",1,"Remove geom from packages expected by ci_hsc","""Geom was removed from the dependency tree in a previous ticket.  ci_hsc still expects in its test that setup packages are recorded, causing a failure."""
"DM-14548","Bug","afw",2,"Many refraction functions are documented to return float but return Quantity","""The new refraction code in afw has many functions that claim to return float, but actually return astropy Quantity.    This has two issues:  - The code in refraction is hard to understand because atmosTerm1 and 2 have units of {{Pa / mbar}} but they are supposed to be dimensionless. It's hard to see how one gets radians from that. For clarity I think some values should be converted to floats instead of being left as Quantities.  - The documented return value is wrong for many of the functions.    I stumbled across this while implementing DM-14429 and had some trouble figuring out what was going on."""
"DM-14545","Story","daf_butler",0.5,"Add test for composite calexp to Butler","""Add test for composite calexp to Butler"""
"DM-14543","Story","daf_butler",0.5,"Fix DatasetType registration","""* Automatically register components, and  * Allow for duplicate insertion only if identical."""
"DM-14542","Story","Qserv",3,"Separate cluster provisioning and k8s setup","""Separate the cluster provisioning (terraform) from k8s setup"""
"DM-14560","Story","Qserv",13,"Assist with KPM30 tests.","""Debug Qserv shared scan scheduling and related issues for KPM30."""
"DM-14558","Story","ap_association",2,"Load all DIASources at once in AssociationTask.update_dia_objects","""Currently, the update_dia_objects method within AssociationTask performs separate loads for each DIAObject it updates. This ticket will change this to one access to the database for all DIASources that are associated with the updated DIAObjects."""
"DM-14557","Story","ap_verify",3,"Add package docs to datasets","""The {{ap_verify}} dataset framework is currently documented in the Sphinx documentation for {{ap_verify}}. This documentation assumes that individual datasets will at least have documentation of their GitHub repository, so that the pages can be linked from lists of known datasets or from examples. However, no such documentation has been written yet.    This issue adds a documentation placeholder to {{ap_verify_dataset_template}}, and standardized package documentation to {{ap_verify_hits2015}}, {{ap_verify_testdata}}, and any other datasets existing at the time of work. It will *not* move the documentation of the dataset framework from its current location in {{ap_verify}}."""
"DM-14554","Story","pipe_supertask|supertask",2,"Produce GraphViz plots from existing or example QuantumGraph","""`stac` can make GraphViz files but `stack` is currently nit working - `run` command depends on a Butler and I need to update it to work with new repos. It would be useful to be able to generate GrpahViz plots from existing QGraph withoutexecuting stuff, will try to see how itcan be done with the existing options."""
"DM-14572","Story","Stack Documentation and UX",0.5,"Modernize documenteer package deployment","""Modernize Documenteer's PyPI deployment by:   * switch to setuptools_scm (common standard)   * use conditionals for PyPI deployment so only one matrix job deploys to PyPI."""
"DM-14580","Story","Science Pipelines",2,"Create tests for BestSeeingWcsSelectImagesTask.","""Due to travel it was preferable to review DM-11953 without a unit test.  This ticket is to create the missing tests, possibly with advice from [~rowen]."""
"DM-14593","Improvement","ap_verify",2,"Clarify use of repo subdirectory in ap_verify_hits2015 dataset","""The README of ap_verify_hits2015 currently says the following about the {{repo}}subdirectory: """"Butler repo into which raw data can be ingested. This should be copied to an appropriate location before ingestion. Currently contains the appropriate DECam {{_mapper}} file.""""    While this text does suggest a user should copying {{repo}}to a new location and then somehow make ingestion happen, it would benefit from clarification. Specifically:    1) The README should make it clear that the {{repo}} directory should not be altered in-place, as edits to a local copy of ap_verify_hits2015 would prevent users from git-pulling any changes,    and    2) Documentation about ingestion for this specific dataset should be added/linked appropriately (presumably via ap_verify's ingest_dataset.pyscript)."""
"DM-14592","Story","JupyterLab",0.5,"Add default .user_setups file to Jupyter environment","""It would be very helpful if the jupyter environment had a {{.user_setups}} file by default, with just a comment saying what the purpose of the file is."""
"DM-14612","Bug","jointcal",0.5,"Fix race condition in new jointcal matrix dump test","""[~rowen] discovered a race condition in {{test_jointcal_cfht_minimal.test_jointcalTask_2_visits_photometry()}}, because the deletion of the files being tested (added in DM-14509) occurs in {{tearDown}}. Easiest fix is to delete the files after they've been checked for."""
"DM-14597","Story","pipe_drivers",3,"Multiband driver uses wrong method signature in runDetection","""Multiband driver can run detection on a coadd, but this code path is rarely exercised. The method signature to detect coadd sources in pipe_tasks has changed, but was not updated in pipe_drivers. This ticket should fix the call to runDetection in detectCoaddSources"""
"DM-14594","Story","Qserv",1,"Refactor Terraform ressources creations","""Refactor TF setup for ease of use and edge cases"""
"DM-14630","Story","Qserv",2,"Use overlay2 on openstack","""Some tuning is required to use overlay2 on Centos7. It will be done on openstack testbench."""
"DM-14628","Bug","meas_astrom",0.5,"meas_astrom pytest setup is missing E266","""The setup.cfg file is correct for flake8, but not for the flake8 extension of pytest. This apparently causes building meas_astrom to fail on my Mac, but not on lsst-dev.    More generally, it would be good if there were a way to insist the flake8 exclusions were identical to the pytest flake8 exclusions to prevent this kind of problem. That's outside the scope of this quick fix ticket, however."""
"DM-14627","Story","SUIT",2,"Firefly performance test and analysis through NB ","""This is to capture the workeffort in testing the performance of FIrelfy image display in NB deployed atKubernetes commons in NCSA.        The work and suggestions are here:    The performance study was prompted by demos of the qa_explorer notebook at the DMLT, with the ginga and the Firefly backends. Using the lsst-lspdev notebook environment and Firefly server, I checked the performance of Firefly panning at zoom level=1 on a 4k by 4k image. Panning to a new position typically took 5-10 seconds but occasionally as long as 20. There is a strong caching effect when panning to a position previously visited, as then the pan typically took between 0.2 and 1 second.    With assistance from Simon, I was able to install the qa_explorer notebook and operate its interactive feature of selecting a star or galaxy from a scatter plot, and zooming and panning to its location on the closest coadd image. The ginga backend typically took a few to 5 seconds to display the desired location. The Firefly backend typically took 15-20 seconds for the display, zoom and pan.    The Firefly display backend always shows the entire image fit to a frame, before zooming and panning to the desired location. Performance could be improved by batching together the initial display, zoom and pan. Alternatively, if DAX imageserv were available it would be more efficient to make a cutout at the desired location and then display it  a solution we used in our forced photometry demo on the PDAC.    The show_fits method of FireflyClient will take an initial zoom level as an argument. For the qa_explorer application, it would be better to set the initial zoom level to 1, to skip the time-consuming display of the entire image. Currently the afw.display abstraction doesnt support this  it was developed for ds9 where zooming is easy. The mtv method of afw.display could be modified to take optional arguments like zoom level and a position on which to center the display.    """
"DM-14625","Improvement","meas_extensions_psfex|meas_extensions_simpleShape|meas_modelfit|meas_mosaic|shapelet",1,"Fix ndarray compiler warnings","""Fix ndarray compiler warnings in the few remaining packages that have not been updated.    This consists of removing         and import of numpy headers from pybind11 wrappers"""
"DM-14620","Story","ap_association",2,"Move ap_association DIA schemas their own module","""Incorporating l1dbproto into ap_association requires definitions and mappings between afw schemas and db schemas. This ticket will expand the methods make_minimal_dia_*_schema to more closelyapproximate that of l1dproto and the DPDD. This will also create mappings between the ip_diffim schemas input into association and the DIA schemas."""
"DM-14648","Story","Data Release Production",2,"Add GalSim support to pyprofit","""pyprofit previously exclusively used libprofit to generate models; I added support for integrating and convolving with empirical PSFs using galsim. Analytic PSFs are a WIP.    Changes are mainly in make_model_galsim: [https://github.com/lsst-dm/pyprofit/blob/master/python/profit.py]    Pycharm run configurations for HSC tests are available here; this will be kept up to date (see DM-14647):    [https://github.com/lsst-dm/pyprofit/blob/master/.idea/runConfigurations/pyprofit_fit_hsc.xml]    At the time of writing, the command to run the HSC example is    python3 $PROJECT_DIR$/examples/hsc.py    Galaxy cutout arguments:    -radec 134.67675665 0.19143266 -size 19.9asec    Enable galsim:    -galsim 1"""
"DM-14637","Story","Data Release Production",2,"Test using Tractor for source modelling","""Tractor ([http://thetractor.org|http://thetractor/], [https://github.com/dstndstn/tractor/]) is a python/C++ package for Bayesian source modelling, much like ProFit ([https://github.com/icrar/ProFit)|https://github.com/icrar/ProFit).]. However, Tractor has a number of extra useful features, including support for multi-band fitting, integration with astrometry.net and built-in descriptions of multi-component models. I installed Tractor and adapted the existing SDSS test to fit HSC images via the quarry tool ([https://hsc-release.mtk.nao.ac.jp/das_quarry/|https://hsc-release.mtk.nao.ac.jp/das_quarry/)]); the script is attached. Unfortunately, I found Tractor to be rather sparsely documented and not entirely intuitive to use, with custom optimizers that would be difficult to maintain. Furthermore, it has a lot of python2-isms and some C++ code wrapped with Swig which would require significant effort to make compliant with LSST standards, and so I don't think it's worth pursuing further. It may be worth contacting the Tractor authors (mainly Dustin Lang), though."""
"DM-14636","Story","Data Release Production",3,"Test ProFit and GalSim galaxy modelling speed and accuracy","""I wrote and ran some systematic tests in pyprofit to compare the accuracy and speed of galaxy profile integration and convolution using pyprofit/libprofit and GalSim. When evaluating the profile and convolving with an analytic PSF, GalSim is considerably faster for n<4 and more accurate in most cases, especially for small axis ratios. However, ProFit can be faster for large Sersic indices (n>4) and supports an essentially infinite range, whereas GalSim is limited to 0.3<n<6.2. Furthermore, the tests I ran used 3x oversampling in libprofit, which has further room for optimization - as does libprofit's profile integration scheme. Thus, it's worth keeping support for libprofit in the future.    pyprofit code: [https://github.com/lsst-dm/pyprofit]    pyprofit arguments to generate a table of benchmarks (in pycharm run configuration format, which is human-readable xml): https://github.com/lsst-dm/pyprofit/blob/master/.idea/runConfigurations/pyprofit_bench_integ_long.xml    benchmarking notebook: [https://github.com/lsst-dm/modelling_research/blob/master/jupyternotebooks/pyprofit_benchmarks_plot.ipynb]    The plots should render better in a browser now, but I attached some copies anyway."""
"DM-14635","Story","Data Release Production",2,"Add support for pagmo2 optimizers in pyprofit","""The pyprofit ([https://github.com/lsst-dm/pyprofit)] code originally supported only the optimizers from scipy.optimize, using L-BFGS-B by default. I added support for using pagmo2 ([https://github.com/esa/pagmo2/|https://github.com/esa/pagmo2/)]), an optimization library with a wider array of optimizers and interfaces to other libraries, as well as both python and C++ interfaces. I tested a few examples and L-BFGS-B with numerical gradients seems to work better than derivative-free optimizers for N<20 parameters, but it remains to be seen how general that result is.    Pycharm run configurations for HSC tests are available here; this will be kept up to date (see also DM-14647):    [https://github.com/lsst-dm/pyprofit/blob/master/.idea/runConfigurations/pyprofit_fit_hsc.xml]    At the time of writing, the command to run the HSC example is    python3 $PROJECT_DIR$/examples/hsc.py    Galaxy cutout arguments:    -radec 134.67675665 0.19143266 -size 19.9asec    Arguments to test pagmo vs scipy optimize (enabling automatic gradients for pagmo):    -optlib pygmo -grad 1    -optlib scipy    The -algo <algorithm> flag can be set, but valid arguments depend on the optlib:    [https://esa.github.io/pagmo2/docs/python/algorithms/py_algorithms.html#pygmo.cmaes]    [https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html]"""
"DM-14674","Improvement","Qserv",1,"Extend class Chunker in package sphgeom to validate chunk numbers","""Extend class Chunker of package sphgeom with a method testing chunk validity for a given partitioning configuration. This method is needed by Qserv replication system."""
"DM-14673","Bug","Firefly",3,"Label for marker disappears when it should not","""# Display an image   # add a marker   # make the marker bigger   # move it around   # Please notice when any edge of the indication box is out of image, the label disappears.    Fix suggestion:    Check the preference of where the indication box should be, when that corner(plus some margin) is in the image, the label should be displayed.        Copied from GitHub: (6/13/2018):    This development fixes the following issues,   * when the marker/footprint is moved towards the edge of the display area, the label for the marker/footprint disappears.  fixing: showing the label when the marker/footprint is moved out of plot area and showing the label in alternate corner location in case the label is being moved out of plot area.   * when the marker/footprint is relocated farther from the center or the target of the HiPS, the footprint is shown out of shape as the image is zoomed.  fixing: instead of translating each region component on image domain as regular image, each component is re-rendered in world coordinate per original region description.    test:  start image search  add a marker or footprint overlay  move the marker/footprint to anywhere close to the plot border and view the text display    start HiPS search (no FOV entered)  add a footprint overlay  click (relocate) at a point close to the curved border of the HiPS  zoom the image to see more detail of the footprint by zooming and rotating the HIPS"""
"DM-14668","Story","templates",1,"Templates for EUPS table files should not include versions","""We no longer recommend the use of versions in the {{setupRequired}} or {{setupOptional}} statements in hand-written table files. Those table files are automatically expanded to include exact versions when products are installed, which provides much more rigorous dependency version handling. The version inequalities we used to include manually never provided much rigor, and provide none now that stack packages are versioned together."""
"DM-14695","Story","display_firefly|Firefly",2,"Mask overlays missing with more than one call to mtv on the same display object","""When using the Firefly backend for {{lsst.afw.display}}, the first {{MaskedImage}}or {{Exposure}}displayed via {{Display.mtv}}has a wonderful mask overlay (much better than DS9's!).    Unfortunately, if I call {{mtv}} a second time on the same {{Display}} instance, the mask overlays do not appear, even though the image itself is updated.    If I close the image window in Firefly itself before calling {{Display.mtv}}, things work as expected.    If a quick fix is possible, it'd be great to get it in this week so I can avoid demoing the workaround at LSST@Europe3 next week (but it's not a terrible workaround if quick fix is not possible)."""
"DM-14694","Story","Firefly",2,"Pixel coordinates off by half in Firefly relative to LSST conventions","""When using {{lsst.afw.display.dot}} with the Firefly backend, positions appear at a half-pixel offset from where they should; LSST convention is to label the *center* of thelower-left pixel (0, 0).    I also see the same half-pixel offset in the mouse pixel coordinates displayed in the upper right corner of the Firefly GUI, so I'm guessing this is just because Firefly (presumably) using a coordinate convention in which integers are pixel boundaries rather than pixel centers. If it's possible to address that, it'd be very nice to also include the """"xy0"""" offset our image objects carry as well (note that{{dot}}already takes care of this offset correctly, presumably by removing it in Python before passing the position to Firefly).    I'd really appreciate a quick fix so I don't have to work around this in the tutorial notebooks for LSST@Europe3 next week. If the only short-term options is a workaround for {{dot}}in the display_firefly Python code, I can do that much myself; please let me know if I should."""
"DM-14690","Improvement","geom",2,"Add ability to construct centered boxes","""As discussed on [GitHub|https://github.com/lsst/afw/pull/357#discussion_r192899255], it would be useful if {{Box2I}} and {{Box2D}} had methods for creating boxes centered on a particular (fractional) point.    Given that the {{Box*}} classes cannot afford more constructors, and we still don't have a good way to discover functions, this capability is best implemented as static factory methods:      I do not plan to add a {{Box2I::makeCenteredBox(Point2I, Extent)}} method: I'm worried that it might lead to confusion with {{(Point2D, Extent)}}, and as [~jbosch] pointed out it's not clear what the best behavior is for even-sized boxes.    The desired functionality is already present in the implementation for {{Exposure::getCutout}}, so this work is just a matter of factoring the code, writing new unit tests, and being very careful about the distinctions between {{Box2I}} and {{Box2D}}."""
"DM-14685","Story","ap_association",2,"Replace afw.geom with lsst.geom in ap_association","""DM-14429 moved afw.geom into lsst.geom. Since ap_association is not yet part of lsst_distrib this change did not propogate through the package. This ticket will change app instances of afwGeom to geom."""
"DM-14712","Story","L1 Database",20,"PPDB Performance test on NCSA Oracle instances","""Run ap_proto against Oracle instance at NCSA and extract some performance numbers from these tests."""
"DM-14699","Story","meas_deblender",0.5,"Silence NumPy FutureWarnings in meas_deblender","""NumPy is changing the default behavior of {{numpy.linalg.lstsq}}'s {{rcond}} parameter, and now warns on any call that uses the default. meas_deblender does that extensively, resulting in lots of warnings."""
"DM-14727","Story","Requirements Documents",2,"Add header service requirements into model and make RFC","""Take the requirements spreadsheet from [~felipe], add it into the MagicDraw model in LDM-638, make the document, and submit to CCB for review."""
"DM-14725","Improvement","afw|ip_diffim|meas_astrom|meas_base|meas_modelfit|shapelet",1,"Eliminate explicit use of ndarray::EigenView in C++ code","""ndarray::EigenView relies on undocumented internals of Eigen. Stop using it, in order to allow upgrading Eigen.    The full conversion consists of two parts:  1) Stop using {{ndarray::EigenView}} explicitly in C++ code. That is what this ticket is about.  2) Stop using {{ndarray::EigenView}} indirectly via {{ndarray::Array::asEigen}} by having that function return an {{Eigen::Map}}. That is DM-14728"""
"DM-14715","Story","Developer Infrastructure",0.5,"Fix deployment issues for recent tech notes","""Please sort out travis and deployment for recent tech notes: DMTN-080 (which was created manually), 81, 82, and 83, 84. The latter 4 were created by sqrbot but deployment credentials were not created (I did turn on travis manually)."""
"DM-14742","Improvement","ap_verify",2,"Let ap_verify run ap_pipe with dataset-specific configs","""{{lsst.ap.verify.DatasetIngestTask}} currently accepts configs from a dataset, allowing for dataset-specific file masks and similar features. It would be useful for {{ap_verify}}'s calls to {{ApPipeTask}} to have the same capability, so that dataset-specific options (for example, the distinction between """"deep"""" and """"goodSeeing"""" templates) can be set for the instance(s) of {{ApPipeTask}} created by {{ap_verify}}.    Unlike {{DatasetIngestTask}}, {{ApPipeTask}} does not need special support for obs-specific configs as it already provides them automatically as a {{CmdLineTask}}."""
"DM-14741","Story","Firefly",1,"Set Cores for Firefly docker container","""Until we go to Java 10 we need a way to control the number of cores the firefly docker container uses.        The docker container will name allow for a environment variable JVM_CORES"""
"DM-14734","Improvement","display_firefly|SUIT",2,"Allow zoom to be set before mtv in afw Displays for Firefly backend","""A common pattern for using {{afw.display}} is to display an image with a zoom level. With the Firefly backend, currently it is necessary to {{mtv}} (display) the image and then issue a zoom command. This displays the entire image, which can take some time for large images, and then applies the zoom. This improvement is for the backend to keep track of the last commanded zoom level, and to include it in the call to {{FIreflyClient.show_fits}}."""
"DM-14732","Bug","display_firefly|SUIT",2,"Regions appear on subsequent afw Displays with Firefly backend","""When symbols are overlaid on an{{afw.display.Display}} with the Firefly backend, subsequent {{mtv}} commands will have the regions layer from the first display also overlaid. This regions layer is not removed by using {{erase}}.    """
"DM-14763","Improvement","SUIT",2,"Improve region ID handling in display_firefly","""When a display is redefined, the region layer Id is set to None. When a display is erase, the region layer Id is also set to None. When a display is redefined and then a region is added, the previous regions show up as well.    Since for {{afw.display}} we always use """"lsstRegions"""" plus the frame number, there is no need to set the regionLayerId to None.    Alternatively, if a display is not re-defined in a Python session then the problem is avoided."""
"DM-14759","Story","SUIT",2,"Support XY0 for image readout and make it the default in slate.html","""Add support for XY0 using LTV1/2 or CRVAL\{1/2}A.    XY0 will be default for slate.html entry point. Therefore it will be the default for the API."""
"DM-14758","Story","Firefly",1,"Text defined in region 'text' is not displayed","""the following region text sample has no text display:    text 2101 2131 """"my label"""""""
"DM-14749","Story","Qserv",1,"Update Qserv deploy documentation","""Update READMEs and cleanup examples"""
"DM-14747","Story","webserv",2,"Change Timeouts for webserv to 2 hours","""Make sure the blocking timeout for webserv is close to 2 hours."""
"DM-14774","Story","SUIT",8,"Upgrade Plotly library","""We are usingplotly-1.28.2.min.jsAs of today, the latest release is plotly-1.38.3.min.js.    A lot of bugs in scattergl have been fixed, we might want to use scattergl for larger scatters.    One of the bugs still present in scattergl is disappearing error bars on relayout. For this reason, we might not want to use scattergl as a default plot when the number of points is reasonably low."""
"DM-14772","Story","Stack Documentation and UX",0.5,"Allow ""."" and ""_"" in LTD edition names for LSST Science Pipelines EUPS tags","""Allow """"."""" and """"_"""" in LTD edition names since those are used for Git and EUPS tags by the LSST Stack (LSST Science Pipelines). This is needed to properly version and deploy pipelines.lsst.io from the LSST Science PIpelines' code base."""
"DM-14781","Improvement","eigen",1,"Upgrade Eigen to 3.2.10","""As part of DM-14305 upgrading Eigen to 3.3 we need to transition to a version new enough that pybind11 supports it. The earliest version of Eigen that our pybind11 supports is 3.2.7. This intermediate step is required in order to release a version of ndarray that no longer uses EigenView for pybind11, and thus allows us to switch to the standard pybind11 wrappers.    I will go to 3.2.10, the latest 3.2 release, in order to get as many bug fixes and other improvements as we can."""
"DM-14780","Bug","SUIT",2,"Data values in lower and upper range are not mapped correctly for power law and asinh stretch","""The attached screenshot shows the problem caused by the bug:    data values <= Lower range should be black, data values >= Upper range should be white."""
"DM-14779","Story","Firefly",2,"make last Git commit ID available in Firefly build","""As we have more projects using Firefly at different stages of its development, it is necessary for project to know which version of Firefly it is using. Git commit ID uniquely identifies the point of the build.   * provide an API call to get the commit ID string   * display the commit ID as part ofthe build information   ** dev currently: """"v1.0.0_Development-0 Built On:Sat Jun 09 18:05:11 PDT 2018""""   ** IRSA ops: v3.0.0_Final-2629 Built On:Tue May 15 16:07:17 PDT 2018    We may want more discussion on how/where to display this in operations.    Implemented as the following:    Show a detail view of the version info when the shorten version is clicked.   * click on the version info on the lower-right corner to see the details    Exposes the same information via the JS API as well as from Java server-side environment.   * In JS, open a demo page, open console. In console, enter {{> window.firefly.util.getVersion()}}"""
"DM-14778","Bug","Firefly",8,"Fix asinh ","""We still do not have asinh quite right, the following should be done:   * Determine what is wrong, maybe why it is wrapping?   * Understandwhyhave a beta parameter exposed to the user and not a Q parameter. You might want to talk to Lijun about this since she did the original work but no longer works for LSST.   * From the UI- determine if we we need a slider entry instead of a number text box entry. Note- when asinh was originally done wehad not yet brought in a slider component. It makes more sense now.   * Work with [~shupe] to validate the implementation plan   * FitsRead.java has most of the stretch code as static methods. Move these out of FitsRead.java into a Stretch.java   * [~shupe] thinks we have the same problem with Power law Gamma. If that is a simple fix after the above work then fix it, otherwise we will make a second ticket.    6/25/2018    This ticket will deal with changing asinh algorithm to be consistent with asinh stretch implemented in [https://github.com/lsst/afw/blob/master/python/lsst/afw/display/rgb.py] and [https://github.com/astropy/astropy/blob/master/astropy/visualization/lupton_rgb.py]    The parametrization using Q is explained in the footnote on page 3 of [https://arxiv.org/pdf/astro-ph/0312483.pdf]    The algorithm will accept Q parameter from 0.1 to 10, which should be controlled by a slider.   The mapping from flux to color value is {{255 * 0.1 * asinh(Q*(x-xMin)/(xMax-xMin)) / asinh(0.1*Q)}}    Below xMin, the color will be 0; above xMax, the equation has to be applied and then clipped to 244 (because we use 255 for blank pixel).    Per [~shupe]  {quote}Zscale + linear is often used with CCD images to show faint features. I am thinking of Luptons asinh as keeping zscale + linear at low values, and bending the stretch function over at intermediate and large intensities. It uses only a fraction of the color range for the max value from zscale; but it will show brighter features above zscale.   Luptons formulation assumes that xMax is far below the bright features in the image.He wants to see the features above xMax as computed by zscale. This is different from how I have traditionally thought about these stretches.  {quote}     ________________    The first and last items in the original description above were fixed by DM-14780.      Stretch code will stay in FitsRead.java to avoid conflicts with Lijun's IRSA-1498 ticket, which takes care of code refactoring.    Per [~shupe], it would also be helpful to display boundaries, calculated by z-stretch algorithm rather than the original data boundaries. I will see if I can add the calculated values to z-stretch dialog."""
"DM-14785","Story","Notebooks",0.5,"Make sure .user_setups lands in the right place","""Currently, the system looks for a the {{.user_setups}} file in {{$HOME}} and adds a template file there if it doesn't exist.  It should, instead, be looking in {{$HOME/notebooks}} as that is where the file is actually sourced."""
"DM-14806","Story","lsst_dm_stack_demo",5,"convert stack demo to be a regular eups product","""The """"demo"""" currently exists as a special snowflake feature of jenkins jobs and is not packaged as an an eups product. A script is currently invoked by the CI machinery after an {{lsstsw/lsst_build}} or {{eups distrib install}} has completed which downloads the demo repo from github as a tarball.    An unfortunate consequence of this implementation is that changes on the master branch of the demo result in previous git tags no longer working with the demo when built by {{ci-scripts/lsstsw}} and requires knowledge of the correct git ref to use after a direct {{eups distrib install}}. This also presents an irritation when tagging an official release as there is no source of truth as to where the tag should be located, requiring human intervention. For at least the third time, the demo on master has changed during the release process and now fails with the current release candidate.    A much less error prone solution would be to convert the demo into a regular eups product, which is a dependency of either {{lsst_distrib}} and/or {{lsst_ci}}. This would result in demo metadata being incorporated into eups distrib tags and solving the science-pipeline/demo version mismatch problem both for end users with a local installation and under CI.    I believe the basic tasks to accomplish this would be:   - convert {{lsst/lsst_dm_stack_demo}} into an eups product  essentially add a {{ups}} dir and a table while which depends on {{lsst_apps}}   - add {{lsst_dm_stack_demo}} as a dependency of {{lsst_ci}} and/or {{lsst_distrib}}   - add a test script under {{lsst_ci/tests/}} to trigger a demo run   - remove {{lsst-sqre/ci-scripts/runManifestDemo.sh}} and update {{lsst-sqre/ci-scripts/lsstswBuild.sh}} to not run the demo   - update various jenkins jobs in {{lsst-sqre/jenkins-dm-jobs}} to {{setup lsst_dm_stack_demo}} rather then invoking {{runManifestDemosh.sh}}"""
"DM-14804","Story","verify",0.5,"SelectionSet.load_single_package fails silently","""When reading in the attached file via _lsst.verify.SelectionSet.load_single_package_, it returns an empty set. This means there is something wrong with the file, but the load fails silently. It should yell at me as to the issue with what I'm passing it."""
"DM-14794","Epic","JupyterLab",40,"Notebooks and Scientific Input for SQuaRE Science Platform services","""This epic covers scientific input into SQuaRE Science Platform services including the development of example notebooks appropriate to Commissioning and other early users,and science-level design inputon aspects of SQuaRE developed services."""
"DM-14827","Story","SUIT",1,"Update WISE table references to use logical db name from metaserv","""Test WISE metadata and updatethe references to WISE tables to use logical db."""
"DM-14824","Story","pipe_supertask",2,"Add syntactic sugar for ConfigFields of *DatasetConfigs","""As we discovered in the SuperTask conversion kickoff meeting, writing (e.g.)    is much too verbose.    Add custom {{Field}} objects so the above can be written as  """
"DM-14822","Story","daf_butler",2,"Gen3 get/put with DatasetRef only","""We've accidentally made it a bit painful to use the DatasetRef and Butler classes together, because Butler's {{get}} and {{put}} interfaces require one to unpack the contents of a DatasetRef.    Make sure {{Butler.get(datasetRef)}} and {{Butler.put(obj, datasetRef)}} work.    Note that the former is not just a renaming of {{Butler.getDirect}}; it should not permit loading datasets outside the {{Butler}}'s collection, and it should not require the {{DatasetRef}} to have already been associated with a dataset_id (though it should take advantage of one, if present).    """
"DM-14819","Story","meas_algorithms",8,"Refactor LoadReferenceObjectsTask for SuperTask compatibility","""Some of the work currently done by LoadReferenceTask - the actual lookup of which shards overlap an area of interest - will be done by preflight (outside Task code) in the Gen3 era. That will ultimately let us greatly simplify it, but in the meantime we will need to make sure it provides APIs appropriate for both CmdLineTask usage and SuperTask usage.    Reference catalogs also have a lot in common with catalogs of simulated objects we might want to insert into real images - they'll have different columns, but we'd want to shard them and look them up the same way. We should look for opportunities in this refactor to support that use case as well.    """
"DM-14814","Improvement","afw",2,"Change invalid pixel handling by Exposure::getCutout","""Currently, {{Exposure::getCutout}} returns """"blank"""" pixels (in the sense of e.g. {{Exposure(dimensions)}}) for parts of the cutout that extend off the edge of the original image. The more natural behavior to veteran stack users is to fill the off-image pixels with the value of [{{afw::math::edgePixel}}|http://doxygen.lsst.codes/stack/doxygen/x_masterDoxyDoc/namespacelsst_1_1afw_1_1math.html#a44ebf02a4fe421404fe9cbd6e9a6f699].    I propose that, if the {{NO_DATA}} flag has been deleted (e.g., with {{Mask::removeMaskPlane}}), {{getCutout}} should return edge pixels with a blank mask but with value and variance conforming to {{edgePixel}}'s behavior. However, I'm open to throwing an exception instead.    This ticket shall modify {{getCutout}} as described and add unit tests for pixel values, which we neglected to do before."""
"DM-14812","Story","ap",0.5,"Make alert printer print every Nth alert","""Current alert_stream alert deserializer/printer will print all received alerts to stdout, which will overwhelm the logs. Change this to every Nth alert as a command line argument."""
"DM-14849","Bug","ap_verify",2,"Metadata-based metrics not measured","""Integration tests of {{ap_verify}} produce all expected metrics extracted from the Butler repository or the association database, but none from {{ApPipeTask}} metadata -- not even timing measurements. Find out what is going on and add integration tests and, if possible, regression tests to {{ap_verify}}."""
"DM-14848","Bug","ap_verify",1,"ingest_dataset.py must be run from final working directory","""{{ingest_dataset.py}} internally uses relative paths for calibration files, causing failed defect lookups if later tasks are run from a different directory than {{ingest_dataset.py}} was. Use absolute paths throughout and test that the resulting repositories can be passed as-is to {{ap_pipe}}."""
"DM-14847","Bug","ap_verify",1,"Missing keys in association DB","""The changes to the DB schema in DM-14620 have invalidated -flux handling in {{ap_pipe}} and- metrics computations in {{ap_verify}}. This prevents {{ap_verify}} or its tests from running. Fix things so that all unit and integration tests pass."""
"DM-14846","Story","display_ginga",1,"display_ginga won't build","""The {{display_ginga}} package has configuration issues that prevent it being built.    Specifically, there is a missing import and a missing package setup."""
"DM-14844","Bug","afw",0.5,"Two FITS tests in afw assume they run relative to AFW_DIR","""Tests in test_propertyListPersistence.py and test_footprint.py assume that test FITS files are in {{tests/data}} rather than looking for them relative to the location of the test file. This breaks them if you attempt to run the afw tests from outside AFW_DIR. The fix is to use {{__file__}}. There may also be an executable C++ test that fails in the same way."""
"DM-14842","Improvement","afw|meas_algorithms|meas_astrom|meas_base|obs_base",3,"Fix deprecation warnings from PropertyList/Set.get","""Fix deprecation warnings from PropertySet.get and PropertyList.get by switching to getScalar or getArray"""
"DM-14841","Improvement","utils",0.5,"NERSC password file has moved so fd leak checker fails tests","""As reported on Slack, {{pipe_tasks}} is failing to build at NERSC with:      {{utils}} has a filter for {{/var/lib/sss/mc/passwd}} (from DM-7186) so it seems that file moved in the past few weeks. Update the filter to be more general."""
"DM-14840","Story","afw|display_firefly",3,"Make mask transparency and color ""sticky"" in display_firefly","""{{afw.display}} provides methods for setting mask plane colors and transparencies. These should be """"sticky"""" in the display_firefly backend, meaning that once they are set for a Display object, they should be applied when an image is sent again to that display.    The display_firefly backend also needs to ignore masks whose color is set to """"ignore"""" or """"IGNORE"""".    Related to this, {{afw.display}} provides {{setDefaultMaskTransparency}} and {{setDefaultMaskPlaneColor}} which are used when Display instances are created. Fix a small bug in {{setDefaultMaskTransparency}} and verify that both of these work with the display_firefly backend."""
"DM-14837","Story","display_firefly|SUIT",1,"Firefly improvements to intro-with-globular notebook","""Some improvements are available for the Firefly parts of[~jbosch]'s intro-with-globular notebook used in the Lyon 2018 hands-on session and later demos.   * Define the Display so the proper URL is available before the IFrame cell, so that `lsp-demo.lsst.codes` need not be hardcoded into the notebook   * Dial down mask transparency via afw.display   * Show how the {{firefly_client.plot}} convenience module can upload the catalog and overlay on the images."""
"DM-14834","Improvement","afw|geom|ndarray",2,"Use pybind11's native Eigen wrapping instead of ndarray EigenView","""Update our pybind11 wrappers as needed to use pybind11's native Eigen support. This is necessary in order to upgrade to Eigen 3.3.    Changes include:  - Build ndarray without EigenView support and with native pybind11 Eigen support. The latter is not necessary but avoids the need to change all our wrappers that wrap code that uses Eigen to explicitly import pybind11/eigen.h  - Update code and tests and needed. For example {{geom}} has one failing test because pybind11's Eigen wrappers are more lenient than ndarray, so it is now possible to construct an lsst.geom.Extent2I from an lsst.geom.Extent2D."""
"DM-14861","Improvement","obs_base",1,"Disable CC requirement for obs_base","""Remove the need for a C++ compiler as it's python-only."""
"DM-14867","Bug","Firefly|SUIT",1,"Firefly API: user can't replace a failed image coverage","""When using Firefly API (i.e. Gator case), if the image search fails, then the user can't replace the image anymore because toolbar is not accessible anymore.    To test the problem: Go to Gator, do a 100"""" search on WISE around position '298.0 29.87' and change coverage image with SDSS u band then try to change back again.    Please fix, thanks."""
"DM-14863","Story","Requirements Documents",1,"Place initial data backbone requirements in model and generate document","""[~mgower] has sent me an initial set of requirements for the Data Backbone Services. I will put them in the model and upload an initial draft to DocuShare."""
"DM-14874","Bug","pipe_analysis",5,"Add options to select against duplicate coadd sources","""We should only ever be plotting the """"primary"""" sources for coadd QA-ing. The description for the *detect_isPrimary* flag is:    We are currently selecting on *deblend_nChild* *= 0* (which is appropriate at the visit level)."""
"DM-14870","Bug","Continuous Integration|stack release",1,"eups.lsst.codes sync from s3 does not update objects of identical size","""[~fritzm] reported yesterday that the {{qserv-dev}} eups distrib tag was not updating after being published.  The s3 object was confirmed to be correct but was not syncing to the k8s service.  It was assumed at the time that this was a random case of s3 eventual consistency taking an excessively long time and the k8s pod was always getting an old version of the object.  However, > 12 hours seems excessive for this.    Upon further investigation this morning, it appears that {{aws s3 sync}} from {{awscli}}, which is used to to perform the sync, *does not* checksum the local file to determine if it is in-sync with s3.  All it does it look at the file size by default, and can optionally compare timestamps (which isn't enabled) -- there is no option to force checksums (ie., {{rsync -c}}).  This is rather unfortunate as s3 does have an {{ETag}} (md5) for all objects. Eg.,        Demonstration that the s3 object and the stale eups.lsst.codes file are the same size:        """
"DM-14878","Bug","Systems Engineering",1,"generateAcronyms.py seems to not complain on missing acronym ","""I noticed that the acronym DBA did not show up in my generated acronyms. There is a lot of output which is not needed so it may have complained.    When I added it to myacronyms.txt it showed up fine .. now I wonder if I am missing others ...    [~tjenness] I may try to look at this next week :) unless its just too verbose output"""
"DM-14886","Bug","Firefly",3,"multiple filters on a heat map failed ","""reproduce   # do a search on WISE Multiepoch photometry table with the example polygon:20.7 21.5, 20.5 20.5, 21.5 20.5, 21.5 21.5   # use the rectangle filter over the image, a tiny rectange returned about 2000 entries   # do any filter on image, table column, or on plot, it will fail. Error message look like this   Column not found: decimate_key(ra,dec,20.5099374,20.500176,100,100,0.00990003299934003,0.009995321952220013)    Analysis guess:    This onlyhappens when the plot is heatmap."""
"DM-14885","Bug","ap_association",2,"Use either nanoseconds or MJD in PPDB CcdVisit table","""The prompt product database currently has a column calledexpMidptMJD which is in units of seconds. These timestamps are constructed via {{exposure.getId().getVisitId().getDate().nsec() * 1.e-9}}, which means zero seconds corresponds to the daf_base DateTime nanosecond zeropoint. However, none of this is clear without some digging.    Since this field has MJD in the name, it would make sense to have MJD as units here. Another option would be to return nanoseconds and change the column name accordingly, since that is the default time unit for our daf_base DateTime objects. Either way, MJD should be a float and nanoseconds should be an int in order to have consistent behavior with DateTime."""
"DM-14879","Story","Qserv",2,"Use last Qserv version in Qserv deploy","""Update Qserv version with the last container image in Qserv deploy tool"""
"DM-14910","Bug","Firefly|SUIT",2,"Firefly zscale differs from other implementations","""The upper output (z2)of Firefly's zscale implementation is often significantly greater than z2 from other implementations, including those in ds9, astropy and lsst.afw.display.    Comparison on coadd file calexp-HSC-I-9813-4,4.fits:  ||Implementation||Contrast (%)||Nsamples||Samples_per_line||z1||z2||  |Firefly|25|600|120|-0.0491993|0.409582|  |ds9|25|600|120|-0.0491993|0.145803|  |lsst.afw.display.displayLib|25|600|N/A|-0.0577342|0.155637|  |astropy.visualization|25|600|N/A|-0.0550090|0.170189|  |Firefly|25|1000|120|-0.0487988|0.951774|  |ds9|25|1000|120|-0.0487988|0.15138|  |lsst.afw.display.displayLib|25|1000|N/A|-0.0577120|0.165587|  |astropy.visualization|25|1000|N/A|-0.0535599|0.171046|  |Firefly|80|600|120|-0.0379127|0.132309|  |ds9|80|600|120|-0.0373926|0.0524557|  |lsst.afw.display.displayLib|80|600|N/A|-0.0392628|0.0535469|  |astropy.visualization|80|600|N/A|-0.0437599|0.0578543|    """
"DM-14894","Story","ap_association",1,"Add pipeBase.timeMethod to score and match methods in AssociationTask","""Timing the match scoring and matching methods would be useful in the context routing out slow downs in the association step of ap_pipe."""
"DM-14921","Story","Stack Documentation and UX",0.5,"Remove Python 2 references from pipelines.lsst.io","""With the {{v16_0}} release, the LSST Science Pipelines don't support Python 2.7 anymore. Thus we need to remove references to Python 2.7 from the installation documentation."""
"DM-14919","Bug","ap_verify",2,"Pointer file error in ap_verify_testdata","""I re-downloaded {{ap_verify_testdata}} and got the following error:    -The file is treated as an invalid symlink by unix.- The file is downloaded correctly, but Git will refuse to make (or even revert) any changes to it.    This appears to be a [bug in how the repository was created|https://github.com/git-lfs/git-lfs/issues/1828] in the first place. Fix {{ap_verify_testdata}} as described in the linked discussion, and re-download the other datasets to make sure they haven't been corrupted in the same way."""
"DM-14915","Story","ctrl_orca",1,"rewrite_shebang is not run in ctrl_orca  ","""For some reasons {{ctrl_orca}} is missing the {{bin}} folder, at least in recent releases (e.g. docker images v15, w_2018_23, ...).  Usually a {{bin}} folder is created for packages with a {{bin.src}} folder during the build process. But the {{bin}} folder is not made in {{ctrl_orca}}; {{rewrite_shebang}} is not run in the build process.   This is also true in {{lsstsw}} build and the shared stack in {{/software}} on LSST machines.  Manually {{scons}}-ing it works. """
"DM-14914","Bug","Continuous Integration",1,"ccutils from ci-scripts appears to be unsetting error exit","""I've seen build failures a few times over the last several month that should have died earlier then then did.  This was observed again last night with a tarball build and my theory is that {{ccutils}} from {{ci-scripts}} is unsetting {{errexit}} as an accidental side effect (the tarball build would have failed either way from what appears to be a broken eups install).    From https://ci.lsst.codes/blue/organizations/jenkins/release%2Ftarball/detail/tarball/2958/pipeline :      """
"DM-14932","Story","afw",2,"Add utility functions for creating SkyWcss from boresight/rotator + cameraGeom","""Given an accurate boresight and rotator angle from a camera, we should be able to construct our best initial estimate of the WCS for a sensor by combining that information with our own camera geometry, as this will probably produce better results that relying on any WCS provided directly by the camera. In fact, for LSST, it's not clear that there even will be a sensor WCS provided directly by the camera, because LSST raw data has amps in different HDUs and no full-sensor HDU that could unproblematically hold a full-sensor WCS.    To do without using astshim code directly, we should provide utility functions in afw with something like the following signatures:  """
"DM-14928","Bug","validate_drp",1,"Fix error in DM-14765 implementation","""Had forward reference to extracting instrument name.  Instrument name extraction wasn't using getCamera() but instead incorrectly treating object as its name.  Instrument name should be upper-case to match {{verify_metrics}} package definition."""
"DM-14999","Improvement","stack release",1,"conda bleed package list should not be code","""The conda """"bleed"""" package list is inline in {{lsstsw/bin/deploy}} as """"code"""", which it is merely """"data"""" which should be editable without modifying """"code""""."""
"DM-14998","Story","afw",1,"Document schema naming conventions","""Schema naming conventions changed from """".""""-separated with no case consistency to """"_"""" and camelCase with the introduction of meas_base. I remember writing the new conventions down somewhere, but the first two places I looked:    - afw::table::Schema class docs    - afw::table overview page in Doxygen    ...document the old convention.        Fix those, ideally by locating the original text (maybe Confluence somewhere?) and transferring it to those locations.    """
"DM-14993","Epic","Alert Production|ap_pipe|ap_verify",40,"Process DES SN field on lsst-dev in automated way; produce basic metrics","""In previous epic, I was able to process DES SN field from raw/cals through ccd, coadd and difference processing. Now we want to automate biweekly difference image processing to study changes in the pipeline. This will sometime involve full end-to-end processing as above and sometimes be just difference imaging, depending on which parts of the pipeline need to be tested. I will also add some basic metrics/evaluation of this process."""
"DM-15011","Story","jointcal",2,"implement separate Visit and Chip fitting for photometry","""While doing additional testing of DM-14510, I noticed that the astrometry model fit could be thrown off by doing a line search during the initialization {{DistortionVisit}} fit step. This reminded me that I haven't implemented the separate """"Visit"""" and """"Chip"""" fitting option for Photometry: it may help things by pushing the toward the global minimum on the first step (as it does in astrometry). It should be very easy to implement."""
"DM-15010","Story","Continuous Integration",1,"Add a sims build triggered by the lsst_distrib weekly build","""The sims team would like an automatically built weekly sims version that is built on the weekly build of {{lsst_distrib}}.  They would like the result to be a binary distribution that would allow end users to install a full stack of sims plus DM dependencies that are all consistent with the weekly build.  I.e.      This is currently possible to do by hand, but it would be useful to them to have it automatically build.  They are very clear that a failing {{lsst_sims}} weekly build should not imply a failing {{lsst_distrib}} build."""
"DM-15008","Bug","meas_extensions_astrometryNet",2,"anetAstrometry.py uses self.distortionContext, which does not exist","""James Mullaney reported the following bug on [confluence|https://community.lsst.org/t/bug-report-in-meas-extensions-astrometrynet/3013]:       We're using the astrometry.net extension to perform astrometry. In v15 and v16 of the stack, I've noticed that meas_extensions_astrometryNet/python/lsst/meas/extensions/astrometryNet/anetAstrometry.py refers to self.distortionContext (see [here|https://github.com/lsst/meas_extensions_astrometryNet/blob/519ff978fa8fd669da3308833b2808ba4e3ed595/python/lsst/meas/extensions/astrometryNet/anetAstrometry.py#L227]). However, it seems that the distortionContext function was removed on the 4th of November, 2017 by [this commit|https://github.com/lsst/meas_extensions_astrometryNet/blob/519ff978fa8fd669da3308833b2808ba4e3ed595/python/lsst/meas/extensions/astrometryNet/anetAstrometry.py#L227]. I may be mistaken, but this seems to be a bug introduced by not catching all references to distortionContext when making that commit."""
"DM-15007","Story","Stack Documentation and UX",1,"Add ability to exclude packages/modules from package-toctree and module-toctree","""Add the ability to exclude named packages and modules from the piplines.lsst.io documentation through a """"skip"""" field in the package-toctree and module-toctree directives.    The """"skip"""" field takes a comma-delimited list of names.    This field is useful for temporarily removing packages that break the documentation build."""
"DM-15014","Bug","Qserv",1,"Write error when creating k8s manifests","""Qserv_deployt try to write to a root owned folder when creating Qserv k8s manifests for the first time"""
"DM-15023","Story","meas_modelfit",0.5,"meas_modelfit is not compatible with Eigen 3.3.4","""meas_modelfit has some issues with Eigen 3.3.4. I am making this a separate ticket from DM-14305 in hopes that these can be fixed in a way that is backwards compatible.    The first issue is that this does not compile:    but the solution to that is trivial: swap {{component._sigmaLLT.matrixL()}} and {{\_workspace}}, though [~jbosch] suggested a solution that reduces duplication with nearby code.    A more serious concern is that the following code in {{TruncatedGaussian.cc}} {{TruncatedGaussian::maximize}} raises an assertion error that a matrix is empty when {{running tests/test_truncatedGaussian.py}}:    To fix that problem [~jbosch] suggests returning a vector of all zeros if n == k."""
"DM-15043","Bug","meas_algorithms",0,"Broken build in meas_algorithms","""A last-minute change for DM-9937, combined with sloppy testing, caused non-compiling C++ to get committed to {{master}}. This ticket is to fix the broken code."""
"DM-15036","Improvement","dbserv",1,"Restore MariaDB JDBC driver to latest 2.2.5 after mysql-proxy protocol fix","""[~salnikov] has upgraded the MySQL protocol support in mysql-proxy, so CLIENT_DEPRECATE_EOF is now being handled properly through the proxy.    So no need to use the older JDBC driver anymore - it's time to 'undo' DM-14924."""
"DM-15044","Bug","Developer Infrastructure",3,"Seemingly Large demo change with bleeding edge pipelines build","""In testing a bleeding edge conda install on my Mac, which includes numpy 1.14, astropy 3.0.3 and matplotlib 2.2.2, lsst_distrib builds fine but when I run lsst_dm_stack_demo I get nearly 100,000 failures, 8000 of which are failing at the 1e-06 level. I have no idea whether this is reasonable but it sounds very large. The detected-sources txt file is attached.    I have not tested ci_hsc or lsst_ci. I will see if I can run lsst_ci on this system."""
"DM-15049","Story","supertask",8,"Continue QuantumGraph implementation","""This is a continuation of work started in DM-14334. Main goal of this ticket is to extend preflight solver with joins between skymap units and camera units so that we have more or less completesolution for building quantum graphs."""
"DM-15084","Story","Qserv",0.5,"Enable extra checks/warnings in qserv compilation","""We do not have every possible check enabled during C++ compilation, adding {{-Wextra}} to compilation flags should help us to uncover possible problematic code."""
"DM-15082","Story","obs_base|obs_cfht|obs_comCam|obs_decam|obs_lsst|obs_lsstSim|obs_monocam|obs_sdss|obs_subaru|obs_test",2,"Switch to YamlStorage instead of BoostStorage in all obs packages","""Now that YamlStorage has been implemented, we should use it."""
"DM-15072","Bug","Stack Documentation and UX",0.5,"Kombu error with LTD Keeper 1.11.0","""There may be an incompatibility in an implicit dependency found through Celery that is preventing the LTD Keeper workers from booting up:        https://console.cloud.google.com/logs/viewer?project=plasma-geode-127520&authuser=1&_ga=2.223555801.-353975650.1530195679&pli=1&minLogLevel=0&expandAll=false&timestamp=2018-07-09T22%3A49%3A09.738000000Z&customFacets&limitCustomFacetWidth=true&dateRangeStart=2018-07-09T21%3A49%3A09.990Z&dateRangeEnd=2018-07-09T22%3A49%3A09.990Z&interval=PT1H&resource=container%2Fcluster_name%2Flsst-docs&scrollTimestamp=2018-07-09T22%3A36%3A18.000000000Z&advancedFilter=resource.type%3D%22container%22%0Aresource.labels.pod_id%3D%22keeper-worker-deployment-5457bf656-zrpmf%22%0Aresource.labels.zone%3D%22us-central1-b%22%0Aresource.labels.project_id%3D%22plasma-geode-127520%22%0Aresource.labels.cluster_name%3D%22lsst-docs%22%0Aresource.labels.container_name%3D%22keeper-worker%22%0Aresource.labels.namespace_id%3D%22ltd-prod%22%0Aresource.labels.instance_id%3D%2244590524507142367%22%0Atimestamp%3D%222018-07-09T22%3A36%3A18.000000000Z%22%0AinsertId%3D%22towqstg1iy3niu%22    Appears with LTD Keeper 1.11.0.    The tickets-DM-14122 Docker image deploys ok. But the 1.9.0 image does not.    1.9.0 was built retroactively much later than the associated ticket was merged (and tickets-DM-14122 was built).    This means I think there was a change in kombu that we're picking up as a floating implicit dependency of the pinned celery dep."""
"DM-15090","Bug","coadd_utils|display_ds9",0.5,"Stop using file in Python code","""We are still using the old `file` class in some Python code, even though it is not available in Python 3. It should be replaced with `open`.    Also, pep8 catches this so I suggest making the packages pep8 compliant, enabling automatic checking and removing python 2 support (all of which should be trivial)."""
"DM-15085","Bug","ci_hsc",1,"Fix gen3-middleware ci_hsc SConscript","""From [~salnikov] on Slack:  {quote}OK, I think I know what is happening. If I do `rm DATA/gen3.sqlite3 DATA/butler.yaml; makeButlerRepo.py DATA; bin/gen3.py` then it runs successfully (or it fails with different exception). If I do `rm DATA/gen3.sqlite3 DATA/butler.yaml; scons gen3repo` then it fails with the above exception (no such table: Camera). I watched DATA directory and I see that `gen3.sqlite3` is removed between execution of `makeButlerRepo.py` and `gen3.py`. Looking at SConscript I think this happens because scons believes that `gen3.sqlite3` is produced by `gen3.py` when in reality it is produced by `makeButlerRepo.py` and updated by `gen3.py`. Scons by default removes target file before rebuilding it, so it does that before executing `gen3.py`.  I'm not sure what is the best way to fix this but scons has `Precious` function to prevent removal of target before rebuilding (https://scons.org/doc/3.0.1/HTML/scons-user.html#chap-file-removal), maybe we should use that  {quote}"""
"DM-15109","Story","pipe_analysis",3,"Adapt pipe_analysis to RFC-498 implementation","""Adapt the {{pipe_analysis}} scripts to be compatible with the changes coming out of RFC-498.  Also make accommodations for it to be backwards compatible with catalogs run on older, pre-RFC-498, processed catalogs."""
"DM-15105","Story","obs_subaru",0.5,"Fix bare except in obs_subaru and other pep8 fixes","""obs_subaru has many bare {{except}} usages. Fix these and make the codebase pass flake8."""
"DM-15104","Story","meas_deblender|pipe_drivers|pipe_tasks",8,"Move SourceDeblendTask out of MeasureCoaddSources","""Currently the deblender is run as part of the {{MeasureCoaddSources}} task. In order to make it easier to swap out the current and future deblenders , {{SourceDeblendTask}} should be pulled out and placed in a new {{DeblendCoaddSourcesTask}}, along with an option to run {{MultibandDeblendTask}} instead. The current version of SCARLET also needs to be added to the stack as a 3rd party package."""
"DM-15098","Story","daf_butler",8,"Add Registry.getRegion(DataId)","""Add {{Registry.getRegion(DataId) -> sphgeom.Region}} that returns the intersection of all regions associated with the {{DataUnit}} in the {{DataId}}."""
"DM-15133","Story","pipe_analysis",2,"Empty matches in coaddAnalysis.py at COSMOS field?","""Using {{w_2018_28}} and {{pipe_analysis}} at commit {{ebd48cf}}, {{coaddAnalysis.py}} failed in the COSMOS tract=9813 filters HSC-G, HSC-R, HSC-Z, and HSC-Y:         The command I ran was   {{coaddAnalysis.py /datasets/hsc/repo/ --calib /datasets/hsc/repo/CALIB  --rerun RC/w_2018_28/DM-14988  --id tract=9813 filter=HSC-G -c doWriteParquetTables=True}}   (and 3 other filters)"""
"DM-15152","Bug","ip_isr",1,"crosstalk correction was moved above assembleCcd, which broke it","""Incc1e91fc90, running the crosstalk task was moved above assembleCcd, which broke the crosstalk correction in ip_isr. Due to the fact that HSC uses a custom ISR this fact was not visible in ci_hsc, and in fact no tests were checking for this error. The tests of the crosstalk task itself were unaffected by changes in {{isrTask}}. The problem only showed up when we started processing lsstCamera data (ts8 and in particular phosim) through {{obs_lsstCam}}.    I propose that we revert this change. It was made to support DECam, but I do not understand why it was necessary so I think it's better to fix {{obs_decam}} than {{ip_isr}}, but would like to understand why the DECam code was written this way before taking a final decision. In discussion, Meredith pointed out that she didn't want to have to assemble CCDs to process inter-CCD crosstalk, but I don't think that this would be necessary (you'd use the {{Detector}}to iterate over the amplifier segments, applying suitable flips as described in the {{Detector's amplifier objects)}}"""
"DM-15139","Story","afw|astshim|geom",2,"Rename invert() and getInverse() to inverted()","""Implement RFC-500 by renaming the {{invert}} method of geom {{AffineTransform}}, geom {{LinearTransform}} and afw {{GridTransform}} and the {{getInverse}} method of afw {{Transform}} and astshim {{Mapping}} to {{inverted}}.    Also rename the {{simplify}} method of astshim {{Mapping}} to {{simplifed}} for the same reason. Note that this is little used outside of astshim."""
"DM-15138","Bug","ap_verify",1,"Incorrect instructions in ap_verify readme","""The {{ap_verify}} readme says to run {{python/lsst/ap/verify/ap_verify.py}}, even though this file has not been executable for almost a year. While the Sphinx documentation has been kept up-to-date, it appears the readme has bitrotted.    Correct the example command line, and proofread the readme for any other out-of-date or missing information."""
"DM-15169","Improvement","dax",3,"Replace all use of ""mock"" with ""unittest.mock""","""We have Python code in using the {{mock}} package, which is a 3rd party library. Change this to use {{unittest.mock}}, which is part of the standard library."""
"DM-15162","Improvement","pipe_base",0.5,"Improve documentation for DataIdContainer","""Enhance the documentation for {{DataIdContainer}} to document the fields and expand the documentation for the methods. For example what does """"castDataIds"""" actually do -- what does it mean to cast a data ID to the correct type?    Also either explain why the user cannot set the dataset type in the constructor or else add that capability."""
"DM-15179","Story","Firefly",3,"Table: Do not send ROW_IDX and ROW_NUM columns when not requested","""Currently, columns ROW_IDX and ROW_NUM are sent to the client for every table request.    It's only used in a few cases.  Change it so that these columns are only sent if requested and not by default."""
"DM-15178","Story","meas_deblender",5,"Investigate position errors in scarlet blends","""Lorena Mezini, an undergraduate working with Erin Sheldon, noticed that when scarlet fits positions,the mean position errors are ~{{0.15}} in both x and y (see attached plot). What's stranger is that one of the objects in her simulations seems to have a mean positional error of 0 in x and y while the other shows the offset.    Her dataset were generated using galsim, with very low noise and fixed bounding boxes (25 pixels) on single band images. The sources both have very small ellipticity (~.01) with random orientations, the same shear, and identical FWHM. The plot shows an example with 100k blends, each with 2 sources separated by 11 pixels.    This ticket is to investigate this behavior to understand the conditions that lead to two seemingly identical objects being deblended differently."""
"DM-15177","Story","SUIT",1,"Data display bug in SUIT caused by wrong datatype in JSON ","""During the test of the newly deployed lsst-pdac/portal/suit, I stumbled on something that is obviously wrong. A position search on""""NEOWISE-R Year 1 Single Exposure (L1b) Source Table"""" at(0.014937 -0.008658) with radius 10"""" returned data with w1flux and w1sigflux empty while w1mpro and w1sigmpro both have data.        Upon further study, the w1flux and w1sigflux columns seem to have """"char"""" as data type, while the meta data showed that they should be """"float"""". We need further investigation into this.        The downloaded data is attached.        7/25/2018    Further investigation revealed that those two fields had datatype """"UNKNOWN"""" when returned from DAX API dbserv V1. Ticket DM-15206 has been created for this.        8/28/2018    An unknown datatype's value could not be passed properly and displayed. Firefly does not need to be modified."""
"DM-15190","Story","ip_diffim",0.5,"Fix ip_diffim FutureWarning","""After upgrading to numpy 1.14, `lsst.ip.diffim.dipoleFitTask` raises a new error:    {code:python}  python/lsst/ip/diffim/dipoleFitTask.py:303: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.  To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.  {code}    It was suggested by [~jbosch] that we simply set `rcond=-1`."""
"DM-15187","Improvement","sphgeom",0.5,"Modernize sphgeom pickle support for pybind11 2.2","""In DM-14828 I missed the fact that the pickle support ({{\_\_getstate\_\_}} and {{\_\_setstate\_\_}}) in sphgeom needed updating. Do that on this ticket branch."""
"DM-15183","Improvement","Stack Documentation and UX",0.5,"Update developer guide for pybind11 2.2","""Update `dm_dev_guide` for changes in pybind11 2.2"""
"DM-15182","Story","display_matplotlib",1,"Add facility to change matplotlib colormap","""On https://github.com/lsst/display_matplotlib/issues/1, the request is:    {quote}  Would it be possible to give the user control over the colormap used to display images? I see that this is currently set to cmap=pyplot.cm.gray.  {quote}"""
"DM-15201","Story","pipe_base",1,"Forward python logging to lsst.log in pipe_base","""In RFC-29 we allowed Python {{logging}} to be used in Python code so long as the log messages were forwarded to {{lsst.log}} whenever C++ logging is a possibility. A forwarder does exist as {{lsst.log.LogHandler}} and instructions for its use are available at https://github.com/lsst/log/blob/master/doc/mainpage.dox#L59    To enable science pipelines to forward these Python log messages we need to setup this log handler in {{pipe_base}}."""
"DM-15194","Story","display_matplotlib",1,"display_matplotlib: dot fails to plot ellipses","""From https://github.com/lsst/display_matplotlib/issues/2:    {quote}  I've tried to plot source catalog objects as ellipses using the display.dot function and passing source.getShape as the first argument:        However I get the following error:        I've confirmed that {{matplotlib.patches.Ellipse}} does expect the width and height arguments (at least in recent versions).  {quote}"""
"DM-15208","Bug","validate_drp",0.5,"validate_drp skipTEx is being ignored","""During the port to the verify system,  support for the {{skipTEx}} option was broken in {{matchreduce.py}} (it was permanently set to False)."""
"DM-15206","Bug","dbserv",2,"dbserv_v1 mapping float to Uknown for DS_wise table","""Per [~xiuqin], the query results from dbserv_v1 is returning 'Unknown' as datatype for column that's actually 'float'.    Example 1 query on PDAC:    url -o q3_result.json -L [http://lsst-qserv-dax01:8080/api/db/v1/tap/sync/] -H """"Accept: application/json"""" -d 'query=SELECT * FROM DS_wise.neowiser_yr1_00.neowiser_yr1_p1bs_psd WHERE w1flux > 0 LIMIT 1'    Output section with incorrect datatype:    \{ """"datatype"""": """"UNKNOWN"""", """"description"""": """""""", """"name"""": """"w1flux"""", """"tableName"""": """"result_11899"""", """"ucd"""": null, """"unit"""": null }, \{ """"datatype"""": """"UNKNOWN"""", """"description"""": """""""", """"name"""": """"w1sigflux"""", """"tableName"""": """"result_11899"""", """"ucd"""": null, """"unit"""": null },        Example 2 query from SUIT:    curl -o neowiseY1.json -d query=SELECT+count(*)+FROM+DS_wise.neowiser_yr1_00.neowiser_yr1_p1bs_psd+WHERE+qserv_areaspec_circle(10.68479,41.26906,0.02777777777777777); [http://lsst-qserv-dax01:8080/api/db/v1/tap/sync|http://lsst-qserv-dax01.ncsa.illinois.edu:8080/api/db/v1/tap/sync]    """
"DM-15204","Story","daf_butler",8,"Add chained datastore support to butler","""An in memory datastore was added in DM-13363. Now we need to support chaining of datastores such that the in memory datastore can be used as a cache.    This will include modifications of the configuration system to specify these relationships and the creation of at least one special datastore class for chaining.    per-datasetType Cache expiry may be included."""
"DM-15225","Bug","Firefly|SUIT",3,"SUIT and Firefly container should not run as root by default","""There are two Firefly servers running in lsst-lspdev k8s cluster environment. IT was discovered that the Firefly server were running as root after they were deployed by k8s. The container settings need to be changed so that the server is not started as root.        Also configure the proxy to not require the trailing slash in URLhttps://lsst-pdac.ncsa.illinois.edu/portal/suit/"""
"DM-15222","Story","SUIT",2,"firefly_client updates for new asinh stretch","""Update firefly_client to accept Q parameter for asinh stretch algorithm. When no value is specified, 'NaN' (case sensitive) should be passed in serialized range string to Firefly. (This would make Firefly to pick up a reasonable default based on stretch and data range.)    Update the documentation for set_stretch.  """
"DM-15220","Story","pipe_supertask",2,"Moving SuperTask to pipe_base","""We have ~agreed on a better name for SuperTask class, {{PipelineTask}} looks like a better one for everyone. We should rename the class and move it to {{pipe_base}}in preparation to merging all gen3 stuff with master."""
"DM-15217","Story","daf_butler",0.5,"Rename sha1 to general hash in Butler schema and API","""On the PR for DM-15098 [~tjenness] noticed we are explicitly specifying{{sha1}} where we should (probably) use a more general {{hash}} in both {{schema.yaml}} and the Butler API. Fix this."""
"DM-15215","Technical task","Firefly",2,"Provide parameters for initial pan position in pixels when displaying image","""For DM-14736 we want to be able to apply a pan position in pixels at the time of displaying an image with {{afw.display}}. """
"DM-15213","Bug","display_firefly",2,"display.dot of ellipses fails with display_firefly when buffering","""When using {{afw.display}} with the Firefly backend, writing ellipses with buffering does not draw ellipses:    {code:python}  with display.Buffering():      for record in src256[::10]:          display.dot(record.getShape(), record.getX(), record.getY())  {code}    It works without the buffering."""
"DM-15212","Story","daf_butler",2,"Improved transactions and ingest-with-transfer for datastores","""This is a spin-off of DM-15189 containing (hopefully all of) the supporting work in daf_butler for that ticket, separated into this ticket to merge it sooner and avoid conflicts with other daf_butler development."""
"DM-15210","Story","daf_butler|Design Documents",2,"Update registry schema (and documentation thereof) following review","""Make adjustments to the schema to incorporate feedback from RFC-484 and the associated review.    Should also sync the technote with the schema YAML on daf_butler master (only very minor and structural changes so far).    """
"DM-15233","Bug","Firefly",2,"ds9 region global coordsys statement support","""Currently we don't support """"global coordsys"""" statement in the region file. We need to support it so user can define one global coorsys and only declare a few if they are different from the global coordsys.    We will support the following coordinate system:    {{FK4, B1950     }}  {{FK5, J2000}}  {{GALACTIC}}  {{ECLIPTIC}}"""
"DM-15232","Story","display_firefly",1,"Add parameters for asinh and power law_gamma to display_firefly","""With support for {{asinh_q_value}} and {{gamma_value}} added to {{firefly_client.FireflyClient.set_stretch}}, make these available in the {{display_firefly}} backend as {{Q}} and {{gamma}}."""
"DM-15230","Story","afw",2,"Fix MultibandExposure initialization","""When a new {{MultibandExposure}} is initialized using the {{fromExposures}} method, it doesn't pass the {{psf}} from each {{Exposure}} into the new objects. To fix this, {{afw.image.multiband.fromTriples}} should be updated to take keyword arguments that can be used to pass additional parameters to the new multiband objects."""
"DM-15241","Improvement","jointcal",0.5,"log error when final chi2 is large","""For some reason, PDR1 tract 15832 HSC-Y got a chi2/ndof of 827 for astrometry, with validate_drp agreeing that the fit was poor, but no obvious """"this fit might have trouble"""" message was logged. We should log an error message for all jointcal final fit results that have {{chi2/ndof >= X}}, where X might be 5 or 10 (as a first guess at """"possibly bad"""" chi2). """
"DM-15237","Story","daf_butler",2,"Ensure StorageClass singleton is append-only.","""Make sure new storage class registrations cannot modify old ones.        To make the discussion on this ticket readable for posterity, the original ticket description was:  {quote}Having all consumers of StorageClasses (which includes any code that wants to create a DatasetType) responsible for constructing a StorageClassFactory (from a config file, since they don't know if the singleton already exists) is not tenable. StorageClasses are global state, and they need to be available at module-import time.    That also means we should move them out of the configuration for Butler, which makes sense, because Butlers don't get to pick their StorageClasses    This is probably also a good time to make sure we don't have any custom StorageClasses in tests, or if we do, make sure they are run in a way that prevents them from ever polluting the real set of StorageClasses in other tests.  {quote}"""
"DM-15252","Story","metaserv",8,"columns and types returned by metaserv should match db","""We need an automated way to verify that the columns and data types returned by metaserv match the columns and types in DB, for all tables returned by metaserv.    Currently, it's not the case. Here is an example:    For _DS_wise.wise_00.allwise_p3am_cdd_, metaserv returns """"double"""" for all types that should be """"int"""" or """"long"""" in db: _band_, _naxis_, _naxis1_, _naxis2_- these are all """"int"""" fields in DB, _cntr_- is """"long"""".    SUIT uses _band_to construct WISE image URL, wrong type results in wrong URL."""
"DM-15249","Story","firefly_client",2,"Extend catalog upload to allow specifying a list of columns","""The {{firefly_client.plot}} module includes a method for uploading and showing a table in Firefly. Add options for specifying the columns from the table that appear, as well as filters."""
"DM-15248","Story","display_firefly|Firefly",3,"Support textangle in ds9 text regions in Firefly","""When {{textangle}} is provided in a region description, Firefly does not draw the associated region. The {{afw.display.dot}} method allows specifying the textangle, but when this argument is provided, the region is not displayed.    Example of region text generated by {{afw.display.dot}} that does not display:      The format we need to support for angle is {{textangle=}} after the hash symbol."""
"DM-15246","Story","meas_deblender",3,"Add scarlet as a 3rd party package to the stack","""Per RFC-504, scarlet will be added as a GitHub fork to the stack."""
"DM-15245","Bug","display_firefly",2,"bug fix in regions API: draw the correct regions, discard the wrong ones","""DM-15213 is fixing the bug in Python calling function for LSST. We need also to fix it in the JS API.    I checked region file upload in current dev version. The non-parsable regions are ignore already in UI. API should behave the same.    """
"DM-15244","Improvement","afw",5,"Change fluxSigma to fluxErr and similarly for apCorr and covariances","""Change fluxSigma to fluxErr, apCorrSigma to apCorrErr and similarly for the diagonal elements of covariance matrices. This includes variable names, argument names and afw table field names. This is necessary in order to implement RFC-333.    Change {{afw::table::CovarianceMatrixKey}} to use """"Err"""" as a suffix rather than """"Sigma"""".    Update the FITS catalog persistence as follows:  - Bump the schema VERSION constant from 1 to 2 in SchemaImpl.h  - When reading version 1 catalogs make a {{fooErr}} as an alias to every {{fooSigma}} field  - When reading version 0 catalogs make {{Err}} aliases instead of {{Sigma}} aliases.  """
"DM-15243","Story","Stack Documentation and UX",1,"LSST the Docs Keeper features for Notebook-based report system (nbreport)","""Add features to LTD Keeper that are needed by the notebook-based report system's API server (as developed in DM-15199):    * {{autoincrememnt}} feature for edition slugs so that LTD Keeper can create editions with monotonically increasing integer edition numbers that serve as notebook report instance IDs.  * {{manual}} tracking mode for editions so that the nbreport server can manage the updates of new editions with builds."""
"DM-15275","Story","JupyterLab",1,"Communicate with users about Emacs in Jellybean","""I communicated with Alex Drlica-Walker about best practices for interacting with Emacs in the JupyterLab terminal emulator.  See [here|https://github.com/LSSTScienceCollaborations/DMStackClub/issues/56] for conversation.    Relatedly, I made my first attempt at using the new lspdev on-boarding procedure.  Procedure emailed to [~frossie].    I also set up my duo account."""
"DM-15272","Story","Firefly",2,"UI design proposal for table option pop-up","""Gregory and Vandana will discuss the table pop-up options need from science user point of view, make a design proposal for developers."""
"DM-15268","Story","ci_hsc|obs_subaru|skymap",1,"Merge gen3-middleware branches to master","""Rebase and merge these branches after making sure they work. Will require daf_butler to be added as a dependency of at least some of these packages.    """
"DM-15255","Story","squash",0.5,"Metric description does not update","""On the monitor app (sandbox deployment) the metric description does not update when the verification package changes."""
"DM-15286","Bug","ctrl_iip",1,"Change way DMCS informs the ocs_bridge the current state","""Return state string rather than integer."""
"DM-15278","Improvement","ctrl_iip",1,"Re-allow file checksumming before moving file and verifying after","""Most of the needed code is present - this just turns it back on in preparation for C++ checksum calculation in a separate branch."""
"DM-17276","Story","ts_main_telescope",5,"XML - Update MTMount XMLs to conform to Naming Conventions","""Once the software is officially delivered to LSST, it will be necessary to update the design and code to conform to SAL constraints and conventions, as defined in [https://confluence.lsstcorp.org/display/SYSENG/SAL+constraints+and+recommendations]    This includes:   * Naming conventions   * Enumeration definition   * Implementation of all standard commands and events."""
"DM-15320","Story","Qserv",1,"Merge Qserv code performance updates","""This ticket is concerned with merging changes to the code made to improve performance. There was a large drop in performance between KPM20 and KPM30 in the cluster at in2p3. Performance was restored to previous level for the LSST dataset, but only in the case where join queries were not included in the batches of test queries. Single join queries run quickly, but when run with a group of queries the entire system slows down significantly. This is thought to be caused by MariaDB not having sufficient resources and is still being sorted out. MariaDB optimizations should improve the situation. The number of computers in the cluster at in2p3 may simple not have enough resources to meet the KPM30 requirements.    Code was modified to add instrumentation for diagnosis and other changes were made to improve performance. Most of the changes were in qdisp (where the threading model was changed significantly between KPM20 and KPM30), wsched (as testing showed some significant problems), and memman (used by wsched and its mlock calls took significant time).    Part of the performance issue was configuration values appropriate for the PDAC were applied to the in2p3 cluster. Configuration files are part of the container. Kubernetes has tools for writing the appropriate configuration files to individual systems and they should be used as soon as practical."""
"DM-15311","Story","ip_isr",2,"Refactor MeasureCrosstalkTask per RFC-352","""Implementing RFC-352  prepping for the PipelineTask fka SuperTask conversion in two stages. DM-2639 changed the TaskRunner to call a Task's runDataRef method.  During code review [~rowen] points out that  {{MeasureCrosstalkTask}} would be a simple refactor. The {{run}} method is essentially the currently public-interfacing function {{extractCrosstalkRatios}}.  """
"DM-15310","Story","meas_base",2,"Refactor ForcedPhotImageTask (and children) per RFC-352","""Implementing RFC-352 prepping for the supertask conversion in two stages. DM-2639 changed the TaskRunner to call a Task's runDataRef method. During code review [~rowen] points out that {{ForcedPhotImageTask}} (and its children {{ForcedPhotCcdTask}} and {{ForcedPhotCoaddTask}} would be simple to refactor."""
"DM-15341","Story","ip_diffim",2,"Write unit test for `applyDcr`","""Several methods of the new {{DcrModel}} class need unit tests written for them."""
"DM-15337","Bug","Qserv",1,"mysql-proxy logger still logs after changes in log4cxx config","""While running no-logging tests at IN2P3, it was noticed that altering {{log4cxx.czar/worker}}configuration to {{ERROR}} level still produces mysql-proxy log messages even after qserv is restarted.    It seems that proxy logger (name """"mysql-proxy"""") is initialized sooner than we read log4cxx config so it is initialized with default {{INFO}} level, while all other loggers use {{ERROR}}."""
"DM-15333","Story","display_firefly",2,"Apply pan and scale at time of image display in display_firefly","""To improve performance of image display in Firefly, allow an afwDisplay instance with the Firefly backend to track {{display.scale}} and {{display.pan}} settings that precede {{display.mtv}}, and apply these at the time of image display. Also add a small correction to the pan method so that it uses the LSST pixel coordinate convention.    Implemented:    Modify the {{display_firefly}} backend to remember the results of scale (stretch) commands, and to apply scale and pan parameters when displaying an image with {{lsst.afw.display.mtv}}.   * Remember and apply the serialized RangeValues string that Firefly uses   * Correct pan command by 0.5 pixels to follow LSST convention   * Apply the remembered pan position when using {{mtv}}   * Make {{'slate.html'}} the default if it is not passed explicitly or if the environment variable {{FIREFLY_HTML}} is not defined. This is necessary for Firefly to show readout of LSST pixel convention."""
"DM-15332","Story","display_firefly|firefly_client",3,"Create prototype of JSON for afwDetect footprints","""Create a prototype JSON representation of all the footprints in an LSST SourceCatalog, for the regular footprints only (excluding heavy footprints), for use in Firefly.    Include bounding box information as well as the details of the individual pixels included in each footprint. Coordinate with development of DM-15326."""
"DM-15355","Bug","ci_hsc",2,"ci_hsc failure: aperture correction fields for PsfFlux not present","""ci_hsc is failing with the following error, almost certainly due to DM-15244:  """
"DM-15353","Story","JupyterLab",1,"Detail process for self serve LSP accounts","""Describe the process for getting an LSP account at the LDF by the self registration mechanism."""
"DM-15350","Story","sphgeom",1,"Fix segfault in sphgeom::HtmPixelization::pixel","""After merging DM-15098 it was found that {{sphgeom::HtmPixelization::pixel}} causes a segfault when called on Linux.  Some investigation has shown that this bug was prexisting (and not unit tested) and caused by an upstream pybind11 bug (https://github.com/pybind/pybind11/issues/1132).  Until that is fixed, work around it by changing the holder type of all {{sphgeom::Pixelization}} subclasses to {{std::unique_ptr<T>}}."""
"DM-15377","Story","daf_butler",3,"Handle parameters robustly for get()","""So far we are not using parameters for datastore.get. This will have to change if we wish to support efficient subsetting of large datasets.  To be able to handle ChainedDatastores properly, parameters will need to be able to be handled by formatters, and generically by using code in StorageClass assembler classes. This requires that the formatter (which will be called first) has to be able to indicate which parameters it has already handled before the remaining parameters are passed to the assembler class."""
"DM-15374","Story","daf_butler",3,"Per dataset allow/deny lists for datastores","""It is necessary for a datastore to be able to specify a list of datasetTypes that are supported, or a list that are unsupported. For posixdatastore this can currently happen by a StorageClass not being listed as a formatter, but a more general approach is needed. In particular, it may be that an InMemoryDatastore should only cache a subset of datasettypes when used as part of a ChainedDatastore.    I think we need to support allow lists and deny lists, although it only makes sense to specify one of those options in a particular configuration (allow means only those listed should be allowed so deny becomes superfluous)."""
"DM-15372","Story","daf_butler",1,"Race conditions in daf_butler tests","""Some of the butler/datastore tests use a fixed name for the datastore root. Now that we are regularly building daf_butler on Jenkins we are getting test failures due to race conditions since now test methods using the same root are running in parallel. Modify the tests to use a different root in {{setUp}}."""
"DM-15365","Story","daf_butler",1,"Move SqlRegistry API back down into Registry","""For expediency we (mostly me) haven't been as diligent in making sure our {{Registry}} ABC stayed up to date with changes to {{SqlRegistry}}.  Update it."""
"DM-15400","Story","galsim",0.5,"Galsim does not work with boost 1.68","""Bost 1.67 renamed the boost python library to {{libboost_python36}}. This leads to Galsim 1.66 to fail to build because it can't find that library. The SConstruct needs to be patched to add the new name as an option."""
"DM-15399","Story","Firefly",1,"MOC display doesn't show  correctly in Glalatic coordinate system","""The MOC display doesn't show correctly when 'Galactic' is selected from the image viewer.        Implemented:    this development fixed the MOC display bugs in Galactic coordinate system by converting the world point with the same coordinate system as that of the project center while finding some pixel alongside the great circle passing the given projection center and a world point.    test:  do hips image search and get moc display in galactic coordinate system."""
"DM-15394","Story","afw",1,"afw does not work with Boost v1.68","""When testing Boost 1.68 in DM-15385, afw fails to build almost immediately because of failures in {{lsstGil.h}}.        In v1.68 {{GIL_DEFINE_BASE_TYPEDEFS}} gains a new argument in the middle:    {code:c}  // B - bits size/signedness, CM - channel model, CS - colour space, LAYOUT - pixel layout  // Example: B = '8', CM = 'uint8_t', CS = 'bgr,  LAYOUT='bgr_layout_t'  ...  #define GIL_DEFINE_BASE_TYPEDEFS(B, CM, CS)  {code}    This is not documented as a breaking change so I wonder if we are using internal APIs here. The immediate fix would be to add the channel model definition to our header file, but it would be preferable to use a public API if one exists since that might also work for boost 1.66 (that we are currently using).  """
"DM-15390","Story","sconsUtils",1,"FutureWarning in sconsUtils with python 3.7","""Using sconsUtils with Python 3.7:  """
"DM-15389","Story","Third Party Software",0.5,"Update PyYAML package to v1.13","""PyYAML 1.11 does not seem to build with Python 3.7. v1.13 does build fine."""
"DM-15385","Story","Third Party Software",0.5,"Update boost to v1.68","""Upgrade boost to v1.68 -- this will enable boost-python to build with python3.7 (we still need boost-python for galsim)."""
"DM-15402","Story","daf_butler",2,"Enhance tests for setConfigRoot","""[~jbosch] reports that he may be seeing cases where {{setConfigRoot}} is not updating anything, resulting in the temp directory from DM-15372 being ignored.  Investigate this problem and add more tests. Also investigate removal of an unnecessary line in config.py constructor that may be confusing things."""
"DM-15414","Story","Stack Documentation and UX",0.5,"Deploy a proof-of-concept notebook-based test report resembling the characterization report","""This ticket is to deploy a proof-of-concept report to show off the notebook-based reporting system. [~krughoff] created a notebook based on the characterization report that consumes data from the SQUASH API (https://gist.github.com/SimonKrughoff/0ada129d858dd92e9a46acea310612b2). I'll use that as the starting point. """
"DM-15417","Story","afw|geom",1,"Remove deprecated getInverse and invert methods","""DM-15139 standardized the method for returning an inverse transform to {{inverted}} but left the old {{getInverse}} and {{invert}} methods for backwards compatibility (even though all DM stack code was updated).    Please remove the deprecated methods after a suitable time period has elapsed, e.g. after the next major release."""
"DM-15424","Story","daf_butler",3,"Revisit LimitedRegistry concept","""In discussions with [~mgower] about temporary-scratch-repo use cases, we identified that it would be nice to have a Registry implementation that supports only generalized get and put (not expressions), and hence does not need DataUnit tables. This is similar in functionality (but not implementation) to a previous LimitedRegistry concept that we envisioned not using SQL at all; the new concept would use SQLite, but would have only a subset of the full Registry schema.    Whether there are any non-DataUnit tables we could drop from LimitedRegistry is an open question; one possibility is that it could also only represent a single Collection, and hence have no need for DatasetCollection either."""
"DM-15421","Improvement","jointcal",1,"Change to use constrained models by default","""Now that there is a working constrained photometry model, I believe it is time to switch jointcal's default config to use the constrained models instead of the simple models. The rationale is that all of the """"important"""" cameras we work with are mosaic cameras (the constrained model doesn't make sense for single chip cameras), and the constrained model is a better model of the system behavior than the simple model."""
"DM-15420","Story","ctrl_iip",2,"Methods for checksumming finished up.","""Finished up csum methods in Forwarder, on branch jbparsons_csum_additions."""
"DM-15419","Story","utils",0.5,"utils cache tests fail in python 3.7 and boost 1.68","""Testing the stack with Python 3.7 fails when building {{utils}}.    Python 3.7 requires boost 1.68 (DM-15385). To reproduce:    * Install lsstsw using {{bin/deploy -b}} to get the """"bleeding edge"""" conda packages.  * Rebuild utils with boost 1.68: {{rebuild -r tickets/DM-15385 utils}}    This will hang during the utils {{test_cache.py}} tests. The hang occurs even with optimization disabled in {{utils}}. I have not tried to disable boost optimization."""
"DM-15435","Improvement","pex_config|pex_exceptions|pex_policy",0,"Remove python 2 support from pex packages","""Remove python 2 support from the pex packages, make pep8 compatible and enable automatic pep8 checking"""
"DM-15450","Story","pipe_base|shapelet",0.5,"Update deprecated use of time.clock()","""In running some tests involving pipe_base I got this warning:      Not urgent yet but the Python developers have now given an explicit timeline for when it will become a problem."""
"DM-15448","Story","Verification",2,"Add datasets document information to DMTN-091","""Add the dataset definitions and identifications from the SST-based document by Bellm, Bosch, Ivezic, Slater, and Wood-Vasey to DMTN-091."""
"DM-15443","Story","Third Party Software",2,"Update mpi4py","""mpi4py 2 does not build with python3.7. Update to v3.0.0."""
"DM-15442","Improvement","ap_verify|coadd_utils",0,"Remove python 2 support to more packages and add pyList=[]","""For packages with automatic flake8 testing the file tests/SConscript should contain     but some packages are missing {{pyList=[]}} so the tests are not being run"""
"DM-15440","Improvement","sconsUtils",0,"Update sconsUtils to not use python_future","""Remove python 2 support from sconsUtils and update to not use python_future"""
"DM-15438","Story","display_firefly",0.5,"display_firefly setMaskTransparency is backwards","""setMaskTransparency(100) in display_firefly makes makes mask overlays fully opaque, while the the documention (and the behavior of the same call in display_matplotlib, at least) suggest it should make them fully transparent."""
"DM-15457","Story","Stack Documentation and UX",1,"Create a template for nbreport projects (LSST2018 hack)","""Create a template in [https://github.com/lsst/templates]for nbreport projects (see [https://nbreport.lsst.io).|https://nbreport.lsst.io)./]    This is an LSST2018 hack project"""
"DM-15455","Bug","daf_butler",0.5,"Error in Gen3 Butler when template format ends in a literal","""Using w_2018-32.    From butler.yaml:      """
"DM-15452","Story","obs_base|pipe_tasks",2,"Fix DCR multiband bugs introduced by new deblender","""The recent changes to the deblender broke multiband source measurement on DCR coadds. This ticket is to identify and fix the breakages."""
"DM-15451","Bug","Continuous Integration",0.5,"nightly-release d.2018.08.16 failed due to disk fulll","""All three canonical {{rebuild}} build attempts failed with {{OSError(28, 'No space left on device')}}.    [https://ci.lsst.codes/blue/organizations/jenkins/release%2Fnightly-release/detail/nightly-release/396/pipeline]    * [https://ci.lsst.codes/blue/organizations/jenkins/release%2Frun-rebuild/detail/run-rebuild/958/pipeline/]  * [https://ci.lsst.codes/blue/organizations/jenkins/release%2Frun-rebuild/detail/run-rebuild/959/pipeline/]  * [https://ci.lsst.codes/blue/organizations/jenkins/release%2Frun-rebuild/detail/run-rebuild/960/pipeline/]    """
"DM-15459","Story","daf_butler",2,"Make dependencies optional  in sets-of-DataUnits lookups","""In the various places where we look up DataUnit information (joins, regions) for different sets of DataUnit [names], we are not consistent about whether dependencies should be included in those sets. We should make sure all APIs support any amount of included dependencies (including optionals).    While I'd originally wanted to do this on DM-15034, and I still expect that to provide the best solution, some functionality is currently broken, so we can't afford to wait to do *something* about it."""
"DM-15458","Bug","Qserv",1,"Qserv does not build with boost 1.68, compiler warnings","""Testing qserv with the new boost it fails:      Also, fix compiler warnings for the following (and similar) statements:    And for this warning as well:      See https://ci.lsst.codes/blue/organizations/jenkins/stack-os-matrix/detail/stack-os-matrix/28425/pipeline/45"""
"DM-15478","Story","afw",1,"Exceptions from importing lsst.afw.image cause SIGABRT","""If astropy.units fails to import and a raises an exception (eg if warnings are converted to errors) when being imported via Schema.cc during import of {{lsst.afw.image}} an abort signal is received:        Stepping through schema.cc the line triggering this is:        Something in the pybind11 layer is failing to catch the python exception and forward it on.    Depending on your system this can be reproduced with:  {code:python}  import warnings  warnings.simplefilter(""""error"""")  import lsst.afw.image  {code}    Given the reference to schema.cc and {{__contains__}} I initially thought this was related to DM-15406 and there is some commentary there."""
"DM-15477","Story","ctrl_iip",1,"Rename DAQForwarder and create Forwarder.h","""Cleaning up the Forwarder directory before moving it."""
"DM-15471","Story","daf_butler",3,"Control composite disassembly at butler level","""Following discussions at LSST2018 last week, we have decided that controlling whether a composite should be disassembled or not should be a butler configuration level item and not a storage class item. This allows disassembly to be controlled by datasetType or StorageClass name. There will be a new top level butler configuration item, name TBD."""
"DM-18266","Story","ts_main_telescope",1,"Begin TMA software FAT ","""Travel to Spain for Mount FAT campaign"""
"DM-15500","Story","afw",2,"Add FITS image, catalog readers that infer types from file","""As they're implemented in C++ and return non-polymorphic types, all of our FITS readers coerce the on-disk object to a specific type. Gen3 Butler code could be greatly simplified by providing Image, Mask, Exposure, and Catalog readers that return infer the template specialization from what's actually in the file."""
"DM-15498","Bug","Firefly",1,"MOC display doesn't show up when the image is zoomed in with FOV around 1 degree","""view HiPS image by unchecking 'IRSA featured' and selecting image 'HST/NICMOS' which is with 'hips_order = 16'.    Get the MOC display and zoom in the image until the MOC display hangs at some point where fov is about 1 degree or less.        Implemented:    This development fixes the MOC display bug by using 'division' instead of 'right shift' to calculate 'npix' of lower tile where the higher order tile is nested in. This change is due to the fact that Javascript bitwise operation treats the operands as a sequence of 32 bits, the result will become inaccurate if doing bit shift on 'npix' of some higher order tile.    test:  searching HiPS 'HST/NICMOS - all bands' by un-checking IRSA Featured and selecting the last image from the list.  check 'MOC' layer  zoom in the image  the MOC of all levels (up to order 16) will be shown as image is zoomed in with smaller fov."""
"DM-15494","Story","qa_explorer",1,"Pyarrow segfaults on shared stack on lsst-dev","""When I try to run {{writeObjectTable.py}} on lsst-dev, it fails with a segfault & long backtrace, starting like:      The script I am running is the following:      I can run the identical script in the jupyterlab environment container and everything is great.    I think this is related to the fact that I can run the qa_explorer tests on the JL env but not lsst-dev, where it hangs with a segfault as well (DM-14224).  It is making testing of DM-14289 difficult, since I can't do it on lsst-dev."""
"DM-15492","Story","Science Platform|SUIT",0,"Create prototype of Portal's generic table-browsing interface, based on TAP","""*(Editing not finished, please wait before responding, etc.)*     With {{dbserv}} now converging on providing a TAP service, it's time to implement the """"generic table browsing"""" feature that we need in the Portal so that we don't have to implement custom screens for every table.    The """"generic browsing"""" screen should take a TAP endpoint as a parameter (this may come from a configuration parameter of the Portal in LSST's standard usage, or it may come from a """"higher level"""" search facility that interacts with the VO Registry).    Given this parameter, it should use {{TAP_SCHEMA}} and/or the {{.../tables}} endpoint of the TAP service to obtain a list of tables, and display this list to the user."""
"DM-15491","Story","Qserv",8,"Parenthesis are ignored in the WHERE clause of qserv queries","""In a query such as    the second query should have returned only objectId417853073271391, because the ra_PS value for objectId399294519599888 is below the comparison value (of 359.5).    Based on initial research, it appears that the parenthesis are getting dropped from the query during processing in the Czar; the mysql-proxy-lua.log shows:    (note that in """"1st parallel statement"""", the parens are omitted)        """
"DM-15490","Story","Firefly|SUIT",8,"Modify behavior of 2D-histogram (heatmap) fallback in Firefly","""The Firefly science advisory panel has discussed the desired behavior for Firefly across multiple applications in respect of the toolkit's ability to fall back to creating a 2D histogram (""""heat map"""") in cases where a user requests too many points for a scatterplot.    We recommend the following for implementation:     If the user explicitly requests a 2D histogram (heat map), via API or UI action, they get that no matter what.  It never changes to a scatterplot.   If the user requests a scatterplot, but there are more than {{N_hist}} (an application-configurable parameter) rows in the associated table, the plot is generated and displayed as a 2D histogram, but it is internally marked as really being a scatterplot.   Then if, as a result of filtering or some other action that changes the size of the table, the number of points falls back to or below {{N_hist}}, the plot is regenerated and displayed as a scatterplot.   This applies regardless of whether the filter is applied to some other variable(s) in the table or to the plotted variables themselves.  Thus, for example, if the user draws a selection rectangle on the 2D histogram - effectively zooming in on a region - which selects {{N_hist}} or fewer points, and clicks on the filter button on the plot, the selected region will be re-drawn as a scatterplot.   There may be a second application-configurable size-limit parameter, less than or equal to {{N_hist}}, which Ill call {{N_GL}}, which controls a transition between traditional Plotly scatterplots and Plotly WebGL scatterplots, with the latter used when the number of points exceeds {{N_GL}}.  The parameterization must allow an application to set {{N_GL = N_hist}} or use some equivalent means of requiring that the WebGL scatterplot never be used.  (Eventually, however, we hope that the WebGL scatterplots become a complete replacement for the traditional ones.)    This issue has already been through """"FireflyCCB-D""""-style review and we are requesting implementation.    The schedule should be discussed at today's CCB meeting.  [~gpdf], at least, views this as a high-priority item, with the current behavior leaving an unfavorable impression of Firefly's ability to handle large datasets."""
"DM-15486","Bug","ImgServ",2,"ImageServ not logging to file","""During k8s tesing, [~cbanek] saw the nginx log showing ImageServ can't open its log file:       /var/log/imageserv.log    Further diagnosis indicates the /var/log directory has write permission for root only, whereas ImageServ is running as webserv.    The proper fix is to move the log file to location where webserv has write permission."""
"DM-15513","Bug","jointcal",0.5,"jointcal test outputs collide","""It appears that at least two jointcal tests write to {{.test/JointcalTestCFHTMinimal/run/verify}}. This may be due to an incorrect {{caller}} in https://github.com/lsst/jointcal/blob/master/tests/test_jointcal_cfht_minimal.py#L155"""
"DM-15509","Story","obs_lsst",1,"Fix bitrot due to premature merge of DM-13293 in obs_lsstCam","""TL;DR - Merlin messed up and merged early (there were reasons at the time), so this ticket is to apply the changes necessary here to deal with the changes to {{cp_pipe}} from review comments."""
"DM-15504","Story","Firefly",3,"Separate a local firefly work area from a shared work area","""Firefly will get better performance when it can use local disk (SSD drives are even better) for cache. Since in the multi server environment we only need to share a small amount of work area we need to change the system to have both a work area and a shared work area. The shared work area will be for uploads and staging. The work area is for everything else."""
"DM-15502","Story","obs_comCam",1,"rsync data and support test stand data ingestion better","""Some headers seem to be missing, set defaults where it's safe, and do whatever else is necessary within reason."""
"DM-17337","Story","ts_pointing",2,"Work with PTG release v0.1","""Perform some initial evaluation of release:    'ts_pointing_common' tagged it as v0.1."""
"DM-15527","Bug","dax",1,"Albuquery returns 400 when qserv is down.","""Kenny noticed that when qserv was down, albuquery was returning a 400 as a response. This is tricky because a 400 class response implies that something was wrong with the request, or the person making the request. A 500 class error seems more appropriate, although you can still do a retry on a 500, which isn't exactly perfect either. But at least a specific error code with a better message while a database is down is probably a good idea."""
"DM-15523","Story","geom",0.5,"geom has random failure on macOS in polynomials test","""Some builds are failing on macOS in test_polynomials. It seems that the test is unstable in that it sometimes passes and sometimes fails.    Example failure:        Master does seem to build fine some of the time. Running the test gives a different answer each time so there seems to be a repeatability issue."""
"DM-15537","Story","daf_butler",2,"Rename Sensor to Detector in Gen3 schema","""Detector is the name already heavily used throughout afw.cameraGeom in particular, and we should adopt that terminology in Gen3 rather than trying to change the existing codebase."""
"DM-15536","Story","daf_butler",8,"Add level of indirection in defining Visits from Exposures","""In discussions with [~rhl], we decided that it would be best for multiple mutually-inconsistent associations of exposures (snaps) into visits should be permitted in the same Gen3 data repository. We cannot assume that we will be able to do that association in advance and not want to revisit it in later reprocessing.    On the database side, I think we'd need to add a field to the visit table indicating which of several named systems the visit belongs to, while ensuring that visit IDs are unique across all systems. We'd select exactly one system via configuration to be used by any butler client, though we'd need to think about when we'd have to be able to refer to other systems instead of relying on that selection (e.g. when interacting with datasets produced on some other system). We'll also need to move the{{exposure.visit}} field into a separate join table.    The way information about visits will be transmitted from the LSST hardware is via a """"GROUP"""" header card; to make use of that, we should:   * propagate that through ObservationInfo into the exposure table during raw ingest;   * remove visit definition (and all of the stuff dealing with visit regions) from raw ingest;   * add a new task to be run after ingest that creates visits (with regions, where appropriate) from groups of exposures with the same GROUP value. That would involve generating visit IDs and names from GROUP via some algorithm.    For instruments that want visits to be 1-1 with exposures, we'll just define GROUP accordingly. If we ever want to define a set of visits that isn't strictly derived from GROUP, we can write an alternate version of the task that populates the same tables via some other means."""
"DM-15534","Story","pipe_drivers",3,"Undefined variable names in MultibandDriver","""DM-15104 introduced some undefined variable names into MultibandDriver.py. Because there are no automated checks in in place for pipe_drivers (no unit tests or Travis) these were missed.    {{--reuse deblendCoaddSources}} will not work:  https://github.com/lsst/pipe_drivers/blob/master/python/lsst/pipe/drivers/multiBandDriver.py#L419"""
"DM-15533","Story","daf_butler",3,"Allow StorageClasses to define an inheritance tree","""It would be useful to be able to define a hierarchy of StorageClasses in Python so that checks isinstance() checks can work and we can define related storage classes across different configuration files (currently YAML reference syntax only works within the single file)."""
"DM-15529","Story","daf_butler",0.5,"Allow datastores to disable default file templates","""Following a discussion in DM-15189, we need to be able to turn off default file name templating in local datastore configurations. A default is provided in the base configuration but there is currently no way to turn this off without putting in a dummy string that will cause a confusing error message."""
"DM-15561","Story","daf_butler",3,"Rationalize Composites/Formatter/Template access to use DatasetType","""Currently the getters for formatters and templates use a name string to determine which formatter/template to use. It would be better to match the CompositesMap interface and allow DatasetType to be given."""
"DM-15558","Story","Continuous Integration|stack release",1,"re-enable osx tarball builds","""EUPS binary/tarball builds on osx were disabled many weeks ago due to strange problems with eups https downloads from {{eups.lsst.codes}} hanging. Since that time, the sqre osx environment has been """"white-listed"""" with the NOAO traffic mangler  it needs to be determined if this has resolved the problem and if not, the root cause needs to be identified."""
"DM-15544","Story","afw",2,"ExposureCatalog should support new photoCalib objects ","""Currently, {{ExposureCatalog}} supports old {{Calib}}calibration objects. However, for use with {{jointcal}} or {{fgcmcal}} these need to support new {{PhotoCalib}} calibration objects. This will also allow multiple {{PhotoCalib}} objects to be bundled into one persistence file (per visit, for example, the number of required inodes would be reduced by a factor of 100 for HSC data for {{fgcmcal}} outputs)."""
"DM-15543","Story","ctrl_iip",2,"Test for zero-length header skels and other related issues","""Prevent the Forwarder from tanking if something is amiss when forwarding.    NOTE: This ticket does +not+ check the FITS cards against an inclusion list or such. It merely catches problems that upset FITSIO."""
"DM-15563","Story","afw",2,"Refactor Mask global state and make it thread-friendly","""This is a spin-off from DM-15500: I needed to move some code out of Mask.cc; in order to do that, I needed to refactor it a bit, and from there it snowballed into a near rewrite of one corner of Mask's implementation, including adding a mutex to guard access to global state. Since that brings it pretty far from DM-15500's original goal, it makes sense to make that a separate review and merge.    The end result is intended to be entirely backwards compatible with the old Mask API and behavior, and that takes some other cleanup work off the table. But I think the result is still a much safer and easier-to-understand implementation."""
"DM-15587","Bug","Continuous Integration",0.5,"jenkins ""ALPN callback dropped"" error message in logs","""This error message is reported over and over again in the jenkin's master logs, which is is an irritation:    """
"DM-15577","Bug","geom",0,"Fix typo in PackedIndex.h header guard","""PackedIndex.h has a typo in its header guard which produces a clang warning    LSST_AFW_MATH_POLYNOMIALS_PackedInded_h_INCLUDED should be LSST_AFW_MATH_POLYNOMIALS_PackedIndex_h_INCLUDED    That is the only compiler warning I see on clang"""
"DM-15576","Story","ctrl_iip",2,"Unique names for ATS archive image dirs each day","""The target location for an assembled and formatted image file is currently specified within the L1 system config file, as a directory path. This ticket is for the addition of a way to automate the target directory. The L1 system config file will still include a path to the archive location, but the software will append the day-month-year string to the path.    This is an initial and probably temporary measure, but as Patrick and Robert take test images with the ATS camera, they need some way to easily distinguish which images were taken on which day. Eventually, the archive will work hand in hand with the Data Backbone; and this may require a change when it arrives."""
"DM-15574","Story","ctrl_iip",2,"Amend DM ATS system l1d check services script","""The check services script in the start_up dir currently dumps systemctl details to the screen. This means that there are_active_ AND_running_ states listed for each of the 7 services. This may be daunting or confusing for an end-user. While this capability is needed at times, it should require a `-v` for verbose switch on the command line of the script. The non-switch default running of the script should simply list each DM service and state whether it is running or not.        The script should also call redis-cli and determine what OCS command state the system is currently in, and print that to the screen by default as well - whether the -v switch is used or not."""
"DM-15606","Story","obs_subaru",3,"Add jointcal config defaults to at least obs_subaru","""Add reference catalog defaults to at least obs_subaru to facilitate running jointcal on the HSC biweeklies.     [~Parejkoj]  I assigned it to you, but I can just as easily do it if one of you sends me the command to run jointcal on the RC2 dataset so I can test that the configs make it do what we expect.  """
"DM-15613","Bug","afw",1,"Unsigned, uncompressed FITS images written with incorrect BZERO","""Writing an uncompressed Image with an unsigned integer type to FITS with our code results in a BZERO value one less than what CFITSIO or astropy write (without our code intervening in the cast of CFITSIO), and this confuses CFITSIO, astropy, _and_ our own code about the type of the pixels when reading the image back in (because the convention is to use BZERO to distinguish between signed and unsigned types).  I'm not sure if the same problem appears in compressed images or not.    I *think* this can be fixed by modifying the Bzero traits class in fitsCompression.cc, and if that's right most of the work here will just be test code."""
"DM-15646","Story","astro_metadata_translator",20,"Rewrite header translation infrastructure for butler Gen 3","""As decribed [on confluence|https://confluence.lsstcorp.org/display/DM/Observational+Metadata+Data+Structures+and+Extraction] we need a set of classes and methods for taking a PropertyList, extracting the relevant information and creating an object summarizing that information in a standard form. Cameras can implement their own subclasses to override specific information, with the intent to reuse code wherever possible when a header has the same definition across multiple cameras.    We have not yet decided whether this should go into obs_base or be a standalone infrastructure package."""
"DM-15641","Story","Stack Documentation and UX",1,"Reviews and consulting for numpydoc conversion work","""This ticket covers work associated with reviewing tickets and advising with regards to numpydoc conversions. Primarily for DM-15347."""
"DM-15634","Story","ip_diffim|pipe_tasks",8,"Fix DcrCoadd variance plane bug","""The variance planes of DcrCoadds have unusual-looking double lobed features near most bright sources. This ticket is to investigate the variance planes to determine the cause of the feature, and fix it if it is a bug. Additionally, investigate the impact of the variance plane on source measurement."""
"DM-15659","Story","ap_association",1,"Change AssociationL1DBProtoConfig's default `dia_object_index` to ""baseline""","""Recent changes to l1dbproto's DiaObjectLast table have caused issues within ap_association. Since ap_pipe does not not currently utilize the full features of l1dbproto it seems safer to switch this default to """"baseline"""" instead."""
"DM-15653","Story","daf_base",1,"Add native yaml serialization support to daf_base","""In DM-14503 support for YAML serialization of PropertySet and PropertyList was added to daf_persistence.  To allow gen3 butler to serialize these using YAML it makes sense to move the YAML support directly into daf_base.  This would require a pyyaml dependency on daf_base but we already use yaml in many places and it's in the core python dependency list. YAML support could be optional in the sense that it is only enabled if yaml can be found."""
"DM-15652","Bug","obs_decam",0.5,"Add missing calexp_camera dataset template to obs_decam","""The dataset template {{calexp_camera}} is required to use {{visualizeVisit.py}} in pipe_drivers. This ticket is to add an appropriate template for obs_decam."""
"DM-15682","Improvement","afw",1,"Add str() for afw::Image and afw::Mask","""It would be a useful convenience to not have to always append {{.getArray()}} when wanting to print an {{afw::image}} when debugging. It should be simple to add a {{std::cout}}/{{str()}} method that delegates to the existing {{.getArray()}} and adds the xy0/origin, and other relevant (short) metadata (not the maskPlaneDict for Masks though)."""
"DM-15678","Story","Design Documents|Science Pipelines",2,"Outline DMTN for Alert Distribution Design Doc","""This ticket is to create a skeleton design document for Alert Distribution as a DMTN."""
"DM-15677","Story","Requirements Documents",3,"Update DPDD to specify contents of DIAForcedSources and include them in alerts","""Implementation ticket for RFC-517."""
"DM-15676","Story","daf_base",2,"Make PropertySet/List more dict-like","""Whilst working on DM-15653 it became clear that test code would be significantly simplified in places if more dunder methods were implements in PropertySet and PropertyList. This would also simplify the work on obs_metadata and make that less dependent on the LSST FITS header representation in DM-15646.    For this ticket dict-like dunder methods will be added as well as others such as eq."""
"DM-15707","Story","astro_metadata_translator",1,"Get instrument, telescope, and DATE-OBS working in obs_metadata","""Write a prototype obs_metadata implementation that can translate FITS standard header cards for instrument, telescope and observation date."""
"DM-15705","Story","daf_base",0.5,"Create an RFC for a dict-like interface to PropertySet/List","""Before finalizing DM-15646, we should get feedback from the DM developers on exactly what the interface should look like."""
"DM-15695","Story","jointcal",2,"Measure jointcal acceptance statistics","""Now that we have reliable output from jointcal+validate_drp, we need to compute the final summary statistics described on the [acceptance test|https://confluence.lsstcorp.org/display/DM/JointCal+Acceptance+Tests] page. This is probably most easily added as a final step of jointcal_compare's {{summarizePerformanceRst.py}}."""
"DM-15694","Improvement","ImgServ",3,"Problem running the integration tests with missing config","""[~cbanek] reported that integration tests can't be run, and the problem encountered was missing imgserv_conf.json.    Turns out the tests still referred to the old """"settings.json"""" that only exists in my dev/testing environment."""
"DM-15693","Bug","SUIT",2,"RadioGroupInputField: options modified in reducer function are not always rendered correctly","""Firefly allows to maintain the state of the field in reducer function.    When the number new options is smaller than the number of previous options, the extra options are still displayed.    The culprit is smartMerge in FieldGroupCntlr.fireFieldsReducer - it's not correct to merge oldFields and newFields here , the new fields that have changed should replace the old."""
"DM-15691","Story","obs_lsst",1,"The raw_visit table in obs_lsstCam registry is not optimized","""As is in obs_lsstCam, the {{raw_visit}} table in registry.sqlite3 has the same per-file informarion as the {{raw}} table. But it should bejust the visit information for optimization in obs_base.     I think this is to fix {{config.register.visit}}in obs_lsstCam config/ingest.py        """
"DM-15689","Bug","Middleware",1,"Fix for PreFlight needed after schema migration","""DM-15336 changed API of the DataUnits which breaks PreFlight. Apparently unit tests that we have for PreFlight in daf_butler do not catch this sort of change. Need to check unit test to see if it can cover something like this. And fix the issue of course."""
"DM-15688","Bug","Qserv",1,"Qserv testQDisp unit test is broken in master","""Building qserv from master on CentOS7 (against current `qserv-dev` tag) fails in testQDisp unit test:      Full log with DEBUG messages is attached too."""
"DM-15724","Story","SUIT",2,"Test plan for milestone DM-SUIT-6 (LSSTCam data display and visualization)","""Write the test plan for milestone DM-SUIT-6,    LSSTCam data display and visualization    Dec. 12, 2019 update:    Test case LVV-T368 includes the test case for Firefly   * That results can be displayed in the Firefly display tool.    DMTR-112 covered testing the display with Firefly Python API firefly_client."""
"DM-15721","Story","daf_butler",1,"Config __delitem__ doesn't work","""Config inherits from UserDict and hence gets a lot of dict-like methods. They don't all seem to work; {{get}} didn't until DM-15424, and {{del}} doesn't seem to work either, at least when nested below the top level.    We should probably add tests for all dict-like operations.    As an alternative, I've been working around these issues by just working directly with the {{data}} attribute, which really is a nested dictionary (with some lists). I'm finding that much more pleasant. Perhaps we should expose that more directly, and remove more of Config's implementation, i.e. make it so the children of a Config are not themselves expected to be Configs."""
"DM-15719","Story","afw",1,"afw's test testReadFitsWithOptions needs afwData","""The test {{testReadFitsWithOptions}} in {{test_maskedImageIO.py}} assumes that {{afwData is available, so it needs a}}    decorator"""
"DM-15713","Story","jointcal",1,"Run jointcal comparison with higher order polynomial","""To see whether it improves the outlier rejection fraction, I'm going to increase the visit polynomial order by 2 (from 5 to 7) and see if that helps. It's just CPU time: don't have to make any real modifications to the execution scripts."""
"DM-15735","Story","Infrastructure",2,"Notebook for Super Computing 2018","""Create a notebook for Jeff to display every nth image comming into some dir."""
"DM-15728","Story","ctrl_iip",2,"Get next ACK_ID message","""The OCS_Bridge has a very occasional need for a unique number from a sequence. Rather than including an OTS in-memory DB like the type that the python components use (Redis), or fabricate one, the OCS_Bridge could simply request a unique number from the DMCS via an internal message...as the DMCS has a scoreboard class specifically for number sequences. This would not be a resource drain or a possible introduction of latency, because these values would only be requested at startup, when the internal message network is at its most quiet.        This ticket, if pursued, has two parts; one is the addition of a simple handler for the new message in the DMCS, and the other part is the generation of the request in the OCS_Bridge and the handling of the response."""
"DM-15743","Story","DM",3,"Prepare Talk for Brazil ","""DM overview and status , a bit of LSST status as well."""
"DM-15740","Story","DM",1,"Monthly report ","""Write summary for Monthly report"""
"DM-15764","Story","obs_lsst",2,"fail to retrieve calibration data with obs_lsstCam","""obs_lsstCam calibrations policy uses as {{date}} as {{obsTimeName}}, not {{dateObs}}.     """
"DM-15757","Bug","ap_pipe|obs_decam",0.5,"obs_decam's apPipe config should default to CP calibs for now","""For now, the majority of ap_pipe use cases with obs_decam use community pipeline (CP) bias and flat calibration products. It is well known that these require a separate set of processCcd configs, and when running processCcd from the command line, users typically provide the {{obs_decam/config/processCcdCpIsr.py}}file.    However, the {{obs_decam/config/apPipe.py}}file (which ap_pipe automatically uses! no command-line config specification required!) presently points to {{obs_decam/config/processCcd.py}}. This causes the infamous """"No locations for get: bias"""" error because there are no biases, there are instead cpBiases.    This ticket is to switch the default in {{obs_decam/config/apPipe.py}}to point to {{obs_decam/config/processCcdCpIsr.py}}and add a comment so future ap_pipe users are hopefully less confused than I was."""
"DM-15756","Story","cp_pipe",5,"biasCorr calculation code results disagrees when using main task code","""  and    differ, and they shouldn't. Investigate and fix.        Furthermore, as per what was originally DM-15401: something seems to not be quite right in the calculation of cross-correlations in {{MakeBrighterFatterKernelTask}}, as the sum of the cross-correlations are coming out much higher than they should be (I think, based on the code it was ported from at least).    Find out why, and once that's done, put the config value{{xcorrCheckRejectLevel}} back to the nominal value of 0.2 (or was it 0.1, check Will's code), if appropriate.    Given that these may be related, these are being combined."""
"DM-15751","Story","pipe_tasks",2,"Configure ability to build coadds with either Jointcal or meas_mosaic","""John, I added you as a watcher in case I was duplicating effort.    Plan is to make lightweight task that can """"applyJointcalResults"""" to calexps (based on [https://github.com/lsst/jointcal/blob/master/python/lsst/jointcal/jointcalCoadd.py)] and make choice of meas_mosaic or jointcal retargetable. Need to add the ability to do apply the photometric calibration in addition to the WCS (like [https://github.com/lsst/meas_mosaic/blob/master/python/lsst/meas/mosaic/updateExposure.py#L47)]        Outstanding question: do we want to be able to mix and match? Photo from one and WCS from another?    """
"DM-15786","Story","DM",2,"Take any comments and update September 2018 Brazil talk ","""do any needed updates"""
"DM-15785","Story","Science Platform",1,"Figure out if and where to document local Jupyter","""Agree with [~jsick] where to document local jupyter even if it is NOT SUPPORTED. We need a place for hacks and things people will do .."""
"DM-15776","Story","daf_persistence",1,"Reimplement FitsStorage support for direct PropertyList reads","""The move of the implementation of FitsStorage on DM-15599 neglected to include support for reading PropertyLists directly from FITS. This is somewhat understandable; we had no test coverage for that functionality and it was used in only one place (obs_lsstCam) that's not yet in CI. Should be easy to add it back in."""
"DM-15774","Story","Stack Documentation and UX",3,"Initial Sphinx-based Task documentation for packages","""Implement initial Task documentation in packages (such as {{lsst.pipe.tasks}}) based on the in-development template ( DM-15422) and using the custom Sphinx roles and directives (DM-15472 )."""
"DM-15772","Story","cp_pipe",1,"Rename cpTask.py","""Task is misnamed - should be called something like `runEotestTask.py`. Nobody uses this at the moment, so no RFC should be required.    Also, add Travis checking and reformat docstring for flake8."""
"DM-15771","Story","ctrl_orca",1,"Remove unused remnants of pex_policy","""Remove remnants of pex_policy, which was long ago shifted to used {{pex_config}}.    The main things being gotten rid of are:    Commands:    killcondor.py - used the old style pex_policy job description to identify and kill jobs.  writeNodeList.py - this was required in an early version of ctrl_orca to enumerate the nodes used (in pbs jobs, I believe).  ProvenanceRecorder.py - This was used to make database records for policy files used in a run.  This was in addition to the provenance information that used to be recorded via the provenance package, which is also obsolete, since it also used pex_policy.  I don't think a replacement was ever made for that package.    lsst/ctrl/orca:    PolicyUtils.py - used to get all file names listed in a policy    The ups/ctrl_orca.table needs to have pex_policy removed as a required setup."""
"DM-15795","Story","ap_pipe",5,"Create DiaForcedSourceTask","""Create a task to force photometer difference images and PVIs at DiaObject locations. This ticket only creates the task. Further tickets will integrate it into ap_association and ap_pipe."""
"DM-15794","Story","ap_association",1,"Change fluxSigma to fluxErr in ap_association","""The change in variable names from Sigma to Err where not caught in ap_association as it not currently part of lsst_distrib. This ticket makes that change in package."""
"DM-15789","Story","ndarray",1,"Fix symbol visibility warnings in ndarray pybind11 converters","""    I had thought these would go away with DM-15151, but I guess not, and it's probably better for us to fix them in the code anyway."""
"DM-15801","Story","pipe_supertask",1,"Detect loops in QuantumGraph","""It looks like in current implementation of graph builder it is possible to make graphs containing loops. Simplest example that was observed already is when pipeline of a single task reads and writes into the same dataset type. We are already supposed to have loop detection when we build Pipeline, maybe logic there is not robust enough and needs a small fix."""
"DM-15800","Story","ap_association",1,"Rename flux to instFlux in ap_association","""DM-10302 changed the names of `flux` columns to instFlux. As ap_association isn't currently in distrib the change was missed on the package. This ticket will modify the names of the columns ap_association expects from flux to instFlux"""
"DM-15799","Story","ctrl_iip",2,"Remove STOP command from OCS_Bridge","""SSIA"""
"DM-15796","Story","Stack Documentation and UX",0.5,"Update documentation to reflect flux->instFlux change","""Now that the code has been updated from {{_flux}} to {{_instFlux}} in schemas, we should do a minimal pass over our documentation to bring it up to date. [~wmwood-vasey] had some suggestions of where we should look in that regard, on DM-10302"""
"DM-15809","Story","utils",0.5,"Replace boost::regex in utils package","""The utils package uses boost::regex for sexagesimal string parsing and for demangling. Neither of these examples need the power of boost::regex and std::regex can be used instead."""
"DM-15831","Story","afw|obs_ctio0m9|utils",1,"Remove unused ra/dec angle handling methods from afw and utils","""Following RFC-528, remove the unused sexagesimal angle routines from utils and afw. obs_ctio0m9 needs fixing since it is the only package that uses the utils routines. Replace that with astropy usage."""
"DM-15829","Bug","sconsUtils",1,"Fix shell handling inside sconsUtils commands to be Bourne compatible","""The commands inside the sconsUtils test module should be written for bourne shells and not bash shells. """
"DM-15837","Story","meas_mosaic",1,"mosaic.py error ""Field with name 'i_fluxErr' not found"" ","""With {{w_2018_38}}, {{mosaic.py}} failed with many errors such as:      Then          It looks related to the changes of DM-10302? """
"DM-15836","Story","utils",1,"Add helper code for invoking C++ templates from Python dtype arguments","""In C++, it's natural to require an explicit template argument for templated functions whose template parameters only affect their return type.  That doesn't work when wrapping normally with pybind11, which just sees a set of equivalent overloaded functions and blithely selects the first one defined.    The [Num-]Pythonic interface for functions like this would take a {{dtype}} argument to select the type returned, and this ticket will provide a helper class that makes that easy to implement.    This is a spin-off from DM-15500, where this helper code is now almost complete.    I'm calling this gen3-middleware because that's why I'm doing DM-15500, even though this ticket is a few steps removed from the core gen3 work.  TCAMs are welcome to reclassify."""
"DM-15838","Story","cp_pipe",3,"Modify Ack Timer for AuxDevice wait for xfer_params ack","""There have been issues with getting a successful transfer of readout params to the forwarders. This seemed a sometimes intermittent problem that was caused by    not getting a proper ack from the forwarder about 10% of the time. After analysis, the xfer_params ack is returning SO quickly that calling the 'clear_forwarder_response_state'    method immediately after publishing the xfer_params message left too litle time for the ack response code to begin listening, as the response is returned in another thread. The fix here was simple, and painfully obvious in hindsight - clear the state first and then publish the xfer_params message. The debug timer has also been replaced with a progressive ack timer.  This is an important fix, because a FAULT state is entered when time exceeds the limit for the xfer_params_ack to return."""
"DM-15853","Story","obs_lsst",0.5,"obs_lsstCam default processCcd config needs updates","""processCcd.py an imSim image with the master obs_lsstCam and the w_2018_38 stack failed with:    """
"DM-15850","Story","daf_butler",1,"Standard StorageClasses should always be loaded","""Currently the default Storage Classes are loaded whenever a Butler is created. Supertask needs to know about Storage Classes without an associated butler. To allow this to work change StorageClassFactory so that it always tries to load the definitions from the daf_butler/config directory.    PipelineTask may still need to provide a way for people to define non-standard StorageClasses but that is out of scope of this ticket."""
"DM-15849","Story","Stack Documentation and UX",2,"Cleanup Calib and zero point references in documentation","""The pipeline user documentation talks about using the {{Calib}} object and """"coadd's zeropoint"""", with some particular details that only apply to the old {{Calib}}. We should clean that up, and any other user docs, so they refer to the new {{PhotoCalib}}."""
"DM-15848","Improvement","Science Platform",1,"Add Temporary LDAP group for access to LSPdev at LineA","""I hear that we need to temporarily add a new LDAP group for access to LSPdev for demos at LineA (Brazil) later this week. The new LDAP group is 'lsst_int_lspdev_linea2018'.    Adam is out of the office this week and suggested we coordinate with Simon.    I think this needs to be in place ASAP, for onsite testing ahead of Wil's presentation tomorrow morning."""
"DM-15869","Bug","pipe_analysis",3,"Fix for renaming *_flux to *_instFlux ","""{{pipe_analysis}} scripts (visitAnalysis and compareVisitAnalysis at least) failed with {{w_2018_38}}. It looks like {{pipe_analysis}} may need some updates for the DM-10302 changes:      """
"DM-15865","Bug","daf_base",0.5,"PropertyList __copy__ is broken","""The new {{__copy__}} method in PropertyList is broken (there were no tests). Fixing it is trivial. I will also add a test."""
"DM-15862","Improvement","ip_isr|obs_decam|obs_subaru",8,"Reduce ISR code duplication between ip_isr, obs_subaru, and obs_decam","""In sorting out tests for `ip_isr`, I've noticed that there is duplicated code between that package and `obs_subaru`. There is additional ISR related code in `obs_decam`. The goal is to unify as much as possible into the default `ip_isr` processing, with the `obs_*` packages only modifying methods when needed."""
"DM-15858","Bug","Developer Infrastructure",1,"copyright.py breaks on Python 3.6+","""Running the {{copyright.py}} file provided at https://developer.lsst.io/legal/copyright-overview.html#background gives the following exception:      Adding an explicit encoding to the call that creates {{log}} fixes the problem."""
"DM-15857","Bug","jointcal",2,"jointcal of w_2018_38 fails to run","""Running w_2018_38 jointcal with HSC-RC2 data failed, as follows:        The command I ran to get the above error was:       The config override file has:       """
"DM-15887","Story","pipe_supertask",2,"Make Pipeline work with non-standard storage classes","""Pipeline builder needs to instantiate DatasetTypes which depend on StorageClass (and they both are configured via task config). We want to keep pipeline builder independent of butler but that means that initialization ofStorageClassFactory becomes an issue. DM-15850 adds support for loading all standard StorageClasses (which come from a standard YAML config) but any non-standard configuration will become an issue in this approach.    I want to see how we can solve this problem by either pre-loading non-standard config for the factory or avoiding its use entirely."""
"DM-15871","Story","daf_butler|utils",0.5,"Move daf_butler's doImport function to utils","""daf_butler has a really nice, robust function for importing a symbol given a string. I want that in afw for importing PupilFactory classes in cameraGeom, so I can replace a Python class object with a string when moving Camera to C++."""
"DM-15897","Story","pipe_base",1,"Pipelinetask init should take kwargs","""Pipeline task init method should take kwargs that that in cases where a pipeline task is used as a subtask all arguments are appropriately forwarded to all constructors."""
"DM-15908","Bug","Firefly",1,"Firefly target input field/validation is broken","""In dev, when i start typing a target name in target panel, the validation fails and overwrite my key strokes.    Start typing 'ngc 7009' it doens't work, the cursor goes back and forth...        I think it could be this change but i'm not sure:    [https://github.com/Caltech-IPAC/firefly/commit/8074feeecc8584c0b9cbc6306c8e8ec56246a774]    Console error includes:        Please fix. Thanks."""
"DM-15899","Story","DM",2,"Check Done Epics","""Check quality of Done epics as per LDM-294"""
"DM-15923","Bug","Third Party Software",0.5,"doxygen does not build on macOS Mojave","""[~bvan] reported that doxygen does not build on macOS Mojave. The problem turns out to be that doxygen tries to be compatible with OS X 10.5 but the Mojave compilers no longer support anything older than 10.9. The fix is to force doxygen to target OS X 10.9."""
"DM-15916","Bug","meas_mosaic",2,"Make meas_mosaic backwards compatible with *_flux --> *_instFlux rename","""The implementation of RFC-322 in DM-10302 saw the renaming of the flux fields in the catalogs from *_flux to *_instFlux along with an increment in the afw table VERSION to 3. Aliases are added on read of catalogs that have VERSION < 3 for backwards compatibility. However, the getFluxKeys() function in meas_mosaic cannot take advantage of these aliases as written, so meas_mosaic is currently broken for VERSION < 3 catalogs. This needs to be fixed."""
"DM-15975","Bug","Firefly|SUIT",1,"Firefly: mouseover help for ""zoom to fit"" and ""zoom to fit width"" buttons is inadequately distinguished","""The Firefly image toolbar has a """"fit image to frame"""" button (with four arrows in a magnifier) and a """"fit image width"""" button (with just a left-right double-ended arrow).  The mouseover help for these buttons is not helpful in distinguishing them:    fit-to-frame: """"Zoom the image to fit into the visible space""""  fit-width: """"Zoom the image to Fill the visible space"""" (capitalization: sic)    The first should say """"Zoom the image to fit entirely within its frame"""" and the second """"Zoom the image to fill its frame horizontally""""."""
"DM-15974","Story","meas_base|Stack Documentation and UX",1,"Provide intro text for meas_base","""I wrote a brief orientation guide to meas_base. Include it in the meas_base Sphinx documentation."""
"DM-15928","Story","Science Pipelines",8,"Propagate DIASource flags into PPDB","""Currently flags are not being copied from the DIASource catalogs into the PPDB.  This ticket is to do so."""
"DM-15925","Story","ctrl_iip",2,"Add Archive Controller to Tucson system service dependency schema","""SSIA."""
"DM-16018","Bug","geom",1,"assertAnglesAlmostEqual fails for NaN angles","""In removing VisitInfo creation from obs_subaru and moving it to obs_base, all the tests passed in test_repository.py despite me not yet calculating an ERA. Turns out that {{geom.Angle(NaN)}} compared to a finite Angle is always fine. Fix the assert to trap NaN in either argument."""
"DM-16012","Bug","SUIT",2,"Firefly fails to load a table with '\n' and '\r' characters in a cell","""An attached table is binary VOTable from Gaia query      It has '\n'  and '\r' characters in the description column of row indexes 3 and 4.    Starlink parses this table successfully, and it is successfully converted into _DataGroup_.  However _IpacTableWriter.save_ produces invalid table. It looks like the control characters are not escaped, and the description column is not formatted correctly.      """
"DM-15983","Story","ap_verify|Continuous Integration",2,"Create a Jenkins job for ap_verify","""{{ap_verify}} will be most useful for integration testing if it can be run as a nightly job in Jenkins. Please create a job that exercises {{ap_verify}} on the {{ap_verify_ci_hits2015}} dataset. A solution that can be easily extended to additional datasets would be preferred.    Once the HiTS dataset is downloaded and set up, it can be run using {{run_ci_dataset.sh -d CI-HiTS2015}}."""
"DM-15982","Bug","SUIT",1,"Firefly fails to load a table with a quoted column","""Attached is the IPAC table, which is a result of conversion of CADC """"columns"""" table from VOTable format to IPAC format. It has one quoted column - """"size"""".    I am getting """"Invalid Statement:"""" when trying to load this table into Firefly.    """
"DM-16025","Bug","Third Party Software",0.5,"DESC coord package doesn't build on macOS Mojave","""The DESC coord package does not build in our anaconda system because anaconda by default tries to build macOS binaries targeting OS X 10.7.  Mojave refuses to support that:      The fix is to force MACOSX_DEPLOYMENT_TARGET to be at least 10.9."""
"DM-16023","Story","afw|meas_astrom",2,"Include alias maps in output schema when denormalizing matches","""There are two functions in the stack that effectively generate a denormalized catalog of matches. The matches between areference and source catalog are """"joined' into a single """"match"""" catalog, putting a {{ref_}} or {{src_}} prefix on the field names for the reference and source fields, respectively. However, when the schema for the match catalog is created, it does not propagate any aliases that may be set, which will then break any code looking for a field by its alias name (often happens with aliases set for backwards compatibility). This ticket is to update the following functions to include the aliases from the individual catalogs in the schema for the matched catalog:    - {{matchesToCatalog}} in {{afw}} ([here|https://github.com/lsst/afw/blob/master/python/lsst/afw/table/catalogMatches.py#L101])  - {{denormalizeMatches}} in {{meas_astrom}} [(here)|https://github.com/lsst/meas_astrom/blob/master/python/lsst/meas/astrom/denormalizeMatches.py]    I will leave it for a future tickets whether these two very similar functions should be consolidated into one."""
"DM-16021","Story","Firefly",20,"Create a Jupyter extension to start Firefly slate in a tab","""Add a command on the sidebar, when the user clicks then show Firefly slate in a tab. The extension will server as the basis for doing more advance interaction with the python api."""
"DM-16020","Story","ctrl_iip",1,"Decouple EndReadout ack from Fault state notification","""During recent stress testing, it was found that if many exposures are taken very quickly one after the next, the Forwarder may get behind by 15 seconds or more. This will delay the acknowledgement that the readout is complete and the file has been processed and sent to archive. One solution is to extend the max time that the ATS CSC will wait for a response - which will allow even more delay to accumulate - then if the max time is exceeded, the system is put in Fault state as there is no response ACK.    Another solution is to NOT make the CSC dependent on the ACK arriving within a prescribed window of time, and simply address the result set information in the ACK when it arrives.[1] There is already an Forwarder health check every exposure, as well as a check that the transfer params were received by working Forwarders - both of which will send the system to FAULT state in no Forwarders are available to work...if a Forwarder dies during EndReadout, the AT CSC will know that an ACK was +never+ received. Then the health state of the Forwarder will be checked on the next exposure.    [1] If checksum verification of archived files is selected to be used, the 'result set' is a struct that includes the path to the file on the Archive and the checksum calculated for the file before it was sent. When the file is verified as existing and its checksum is correct, the ArchiveController issues a receipt for that image file and the receipt is sent to the DMCS bookkeeping database."""
"DM-16040","Bug","templates",0.5,"Remove E251 rule from the stack_package template's setup.cfg","""The E251 rule exception is not longer in the developer guide, but it's still in the templates. This ticket will fix that.    (This was started by [~jcarlin], I'm just finishing it up now)"""
"DM-16037","Story","Firefly",0,"Refactor some searchProcessor code to not use the file as source of data","""During the discussion of DM-15826, the team realized there are several searchProcessors in Firefly will get the table data from a file in IPAC table format persisted by Firefly before the Firefly internal DB was introduced. With the augmentation of DataGroup required by keeping more meta data from ingesting VOTable, this practice will cause problem. We need to refactor the code of the old search processors not to write out the data result to IPAC table and access it later.    In particular, the classTableFromSource.java has to be refactored first.    Also UserCatalogQuery.java"""
"DM-16034","Story","Firefly",2,"TabPanel's state may get out-of-sync when tabs are removed","""selectedIdx is a state kept by TabPanel. It's possible that selectedIdx is greater than the number of tabs due to adding and removing tab dynamically.    Currently, this condition is handled in the render function of the component. This visually appears correct, but the state is out of sync."""
"DM-16043","Story","afw",0.5,"Revert accidental dependency on numpy 1.14","""Fixing some warnings on DM-15500 that looked like some that were safely fixed in meas_* accidentally brought in a requirement on numpy >= 1.14. Revert that.    """
"DM-16077","Story","pipe_supertask",2,"Fix multi-process setup for CmdLineFwk","""I did not check multi-process option for some time and now it breaks:      Need to fix it ASAP  """
"DM-16070","Story","meas_base|meas_deblender",3,"Implement RFC-534: Update naming of base_Blendedness fields","""The implementation of this RFC includes:   # strip """"_instFlux"""" from the base_Blendedness_raw_instFlux and base_Blendedness_abs_instFlux names   # move """"_instFlux"""" to the end of the name in the fields with actual flux units, thus   # base_Blendedness_raw_instFlux_child --> base_Blendedness_raw_child_instFlux   # base_Blendedness_raw_instFlux_parent --> base_Blendedness_raw_parent_instFlux   # base_Blendedness_abs_instFlux_child --> base_Blendedness_abs_child_instFlux   # base_Blendedness_abs_instFlux_parent --> base_Blendedness_abs_parent_instFlux   # an update to the doc strings to make a clear distinction/description between """"raw"""" and """"abs"""""""
"DM-16069","Story","DM",1,"Create tickets for Test Specs","""create Jira tickts for the test specs assigned to relevant people with reasonable dates on them .. tagged so we can find them easily .. ?"""
"DM-16068","Bug","meas_algorithms",1,"Some flux fields are not getting their units set","""Since the flux-> instFlux name change of DM-10302, some backwards compatibility issues with older catalogs were revealed and *thought* to be fixed on DM-15857. The idea was to set aliases for all flux fields, identifying them by their units: any field with unit """"count"""", """"dn"""", or """"adu"""" gets an alias set. This relies on the proper units having been set for all flux fields in the catalog. I have just found several cases (two very important ones!) where units are not being set:    As a result, we currently (with {{w_2018_40}}) can't even read in an older coadd catalog as a butler.get throws with:    This needs to be fixed for future processing, but still needs a workaround for old catalogs that do not have the units set properly."""
"DM-16082","Story","afw|daf_persistence|pipe_tasks",1,"nopytest_test_coadds.py throws warnings, and should be fixed","""nopytest_test_coadds.py throws the following warnings in many places:    {code:cpp}  lsst.afw.image WARN: Could not parse options; writing with defaults:    File """"src/PropertySet.cc"""", line 189, in T lsst::daf::base::PropertySet::get(const string&) const [with T = std::shared_ptr<lsst::daf::base::PropertySet>; std::string = std::basic_string<char>]      image not found {0}  lsst::pex::exceptions::NotFoundError: 'image not found'  {code}    This seems to be coming from:  https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/posixStorage.py#L642  which calls and executes to:  https://github.com/lsst/afw/blob/a4679bc1e1d40d112e1484359a353fee477c1331/python/lsst/afw/image/image/fitsIoWithOptions.py#L97    Where it expects a property of the property set to be called `image`. However, the options that are passed through the call chain are:  `  ['visit', 'ccd']  `    This optional prameter is generated:  https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/posixStorage.py#L637  and that variable comes from:  https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/posixStorage.py#L249  which in turn comes from the butler here:  https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butler.py#L1421  the location variable is created here:  https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butler.py#L1297  That optional data ultimately is initialized here:  https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butlerLocation.py#L207  So whatever is creating butler locations (Some repository or mapper) is not adding the correct fields, or afw should be looking for different things to write.    These are just notes for what I have found so far, to help anyone who gets to this ticket. I am tagging [~price] because I think he was the last one to work with the additionalData code, and [~jbosch] because he may be familiar with this work, or how it impacts gen3 middleware and will know if this is even worth pursuing. Also tagging [~yusra], as I am not sure if I put this in the right epic.    """
"DM-17162","Story","ts_auxiliary_telescope",3,"Handle Basic standard behavior for AtHexapod CSC ","""To have this task done, the CSC should:   * read configurations from configuration files   * publish settingsApplied for configurations used   * publish settingsAppliedMatchStart when applies   * publish settingVersions when first running the CSC   * publish detailedState   * Publish telemetrypositionStatus with current position   * accept and execute commands: moveToPosition,applyPositionLimits,applyPositionOffset,stopAllAxes,pivot   * Publish detailedState when the state change   * Publish settings Applied for:settingsAppliedPositionLimits,settingsAppliedPivot,settingsAppliedTcp   * PublishpositionUpdate when position command change try to move"""
"DM-17161","Story","ts_auxiliary_telescope",3,"Develop GUI and Unittest or ATHexapod","""Develop GUI and Unittest for ATHexapod.    This task should deliver:   * set of unittests to test the behavior of the CSC   ** values out of range   ** state transitions   ** try position limits   ** move command   ** offset command   ** stop command   ** settingsApplied events   ** appliedSettingsMatchStart   ** settingsVersions   * A very *basic* GUI to control the CSC"""
"DM-16160","Bug","daf_butler",1,"Fix constraint check in associate method","""My first attempt to implement constraint check in associate() method (DM-15686) apparently broke everything (DM-16159). Looks like code in obs_subaru depends on uniqueness check to be done in addDataset() method. My commit moved that check to associate() which is apparently too late, tha fix for that it to leave the test in addDataset(). IT would be interesting to also understand what is going on in obs_subaru because in the future we'll probably switch to table-level constraints and that can break things again."""
"DM-16159","Bug","daf_butler",0.5,"Revert DM-15686 to un-break obs_subaru master","""The change to how we detect uniqueness violations in associate broke the Gen3 ingest tests in obs_subaru, because those rely (probably unwisely) on detecting the conflict *before* a transaction rollback is initiated.    The correct fix for this may be in obs_base (where most of Gen3 ingest is implemented), but if so, it's non-trivial, and master is broken right now. The easy way to un-break it is to revert the merge of DM-15686 is daf_butler.    """
"DM-16135","Story","Firefly",1,"Add LongString type to DataType","""Add a LongString data type into table data model to indicate a very long string.    This is a way to optimize storage and limit capability."""
"DM-16131","Story","afw",2,"Add a unittest to address the issue of DM-16068","""Clearly we have no current test that would catch this, please add one (which, on the current {{w_2018_40}} weekly would fail). See DM-16068 for details."""
"DM-18210","Improvement","ts_middleware",2,"Please have salgenerator return a non-zero exit code as soon as a step fails","""It would be helpful if {{salgenerator}} would reliably halt with a non-zero exit code at the first failure. That would make it much easier to see problems, and for automated scripts that run multiple steps, it would avoid trying to continue to later steps (e.g. {{salgenerator <foo> sal python}} after a failed {{salgenerator <foo> sal cpp}}), or even an attempt to build any libraries after validation fails."""
"DM-16168","Bug","validate_drp",0.5,"Update matchedVisitsMetricsTask ","""While trying to run validate_drp on the jointcal DC1.2 output, I found that the {{_makeArgumentParser}} needs to be updated to use the new jointcal_wcs name."""
"DM-16170","Story","meas_mosaic",1,"mosaic.py error ""Field with name 'i_instFlux' not found""","""With {{w_2018_41}}, {{meas_mosaic}} fails with errors like        and then Segmentation fault from zero matchList ({{Mosaic INFO: len(matchList) = 0 []}} )      One (longer than necessary) command to reproduce is         The same command (with the same input data) works using the {{w_2018_39}} stack. """
"DM-16197","Story","Science Pipelines",2,"Create test plan for LDM-503-11b (Pipelines Release Fall 2019)","""Pipelines Release Fall 2019  Science Pipelines release in support of operations rehearsal LDM-503-11. Release contents described in LDM-564. Will be accompanied by a characterization report."""
"DM-16184","Story","DM",1,"Monthly report","""DO management seciton and summary."""
"DM-16183","Story","pipe_drivers",1,"w_2018_41 coaddDriver is broken with detectCoaddSources API changes","""Looks like the API change in DM-15663 broken coaddDriver and gave the following error:          One command to reproduce is:    """
"DM-16180","Bug","Test Data",2,"TSSW Jenkins Test servers not responsive","""I am not familiar with DM's components, so that section should be changed to the appropriate item.    TSSW's AWS server with our test suite running Jenkins is completely non-responsive. We have been not been receiving emails when code is checked in and the webpages current give a 502 bad gateway error. Here is the URL I am using:    [https://ts-ci.lsst.codes|https://ts-ci.lsst.codes/]    It is my understanding that this functionality is necessary for our code development and is currently hindering us on progressing as such."""
"DM-16179","Story","meas_deblender",1,"Change log level to WARN for the footprint skipping","""The current log level for noting that a footprint is getting skipped is at {{log.trace}}, sothis information does not get printed to the logs.  This is an useful and important piece of processing information, so should be set to WARN at these two locations:  https://github.com/lsst/meas_deblender/blob/master/python/lsst/meas/deblender/deblend.py#L297  https://github.com/lsst/meas_deblender/blob/master/python/lsst/meas/deblender/deblend.py#L302  See DM-16151 for more details."""
"DM-16224","Improvement","Qserv",0.5,"Reduce excessive database traffic from the Replication Controller","""A development effort associated with this ticket is meant to address one of the side-effects introduced during the code review of [DM-14262]. The new version of the code (which is now formally correct) puts too much unnecessary load onto the MariaDB service when updating persistent states of the Replication-Qserv synchronization requests. This results in million rows of mostly unneeded data stored in the databases each time such synchronization is happening. Each such row contains names of a databases and chunk numbers which are sent from the Replication system to the Qserv workers. Another problem with the implementation is the rapid growth of the database space used by the Replication system (roughly 200 GB over 48 hours).    In this ticket the detailed reporting of the database names and chunks numbers will be replaced with a simple counter of replicas sent to Qserv workers by each such request.    The second improvement is to be made in the default configuration of the master Replication Controller. The frequency of checks made by the Cluster Health Monitoring and Replication threads is going to be significantly reduces."""
"DM-16208","Improvement","afw",2,"Add magnitudeToInstFlux method that takes a Point to PhotoCalib","""For fake source injection, we should be able to place a source at a specific pixel location, which means we need a way to convert a magnitude to an instrumental flux at that location. The existing {{magnitudeToInstFlux}} method only works with the mean calibration, but should be overloaded to also take a Point (the desired location of the fake source)."""
"DM-16206","Story","Third Party Software",1,"Make new EUPS release for v17.0","""There has been a request to make a new release of EUPS so that it can be included as a dependency for the v17.0 pipelines release.  This ticket is to create the new EUPS release.  Further tickets are needed to change lsstsw/newinstall to use it and to enable to new shebangtron support."""
"DM-16235","Story","jointcal",8,"Jointcal PhotoCalib returns negative calibrations","""  """
"DM-16246","Bug","dax_ppdb",1,"Ppdb attempts to create duplicate columns when an AFW and Ppdb yaml column have same name.","""When creating a new table with Ppdb using an afw schema, Ppdb attempts to create a duplicate column if an afw column has the same name as the Ppdb column specified in the yaml file. The error output below shows this failure for the IxxPSF column but the error has been duplicated the other columns in the DiaSource table. The problem likely occurs in the following code block:[https://github.com/lsst/dax_ppdb/blob/5768c874b9fc52b6e9c3e9dab5f534ae8e636085/python/lsst/dax/ppdb/ppdbSchema.py#L542]    The DiaObject table seems to behave as expected and does not create the duplicate column. Using the afw-schema.yaml file prevents the duplication in the DiaSource table.        Unittest below was executed with the tickets/DM-15588 branch of ap_association.  """
"DM-16261","Story","obs_lsst",1,"obs_lsst code review","""Look at obs_lsst with [~tjenness] - perhaps after [~krughoff] adds some tests ...    1 point enough ??"""
"DM-16259","Story","DM",1,"cookie cutter and tex changes for PSTN","""Added PST and PSTN to the texmf"""
"DM-16284","Story","DM",1,"Kavli workshop telecons and prep","""At least one telecon and trying to sort out the invitee list"""
"DM-16277","Story","Qserv",8,"Generate metadata and chunklists for WISE and KPM30","""Worker level data exists in the cloud, but deploying it in a new cluster requires regenerating CSS metadata, schema, secondary index and chunks lists."""
"DM-16276","Story","Qserv",8,"Move data to Qserv node disks from bucket storage","""Move data from bucket storage to qserv-ready persistent disks on the k8's cluster for both WISE and KPM30"""
"DM-16275","Story","pipe_base",1,"PipelineTask should always use overridable methods to get DatasetTypes","""It looks like PipelineTask.runQuantum (at least) uses iteration through the Config instance to find all of the input and output DatasetTypes. This at least partially ignores the get*DatasetType methods, which should be permitted to add and modify the set of DatasetTypes processed.    Fixing this may involving changing the signatures of the get*DatasetType methods a bit - there is at least some information (e.g. """"scalar"""") that is currently only available from the configs, and that probably needs to be forwarded through the get*DatasetType methods so they can be considered the final source of truth by PipelineTask and all activators.    """
"DM-16274","Story","DM",1,"Tidy code on Demo noteook for Supercomputing","""There seems to have been a merge conflict on the notebook in    [https://github.com/womullan/watch]        I got Jeff to check out an old one which is fine for now,    There is also some code in the notebook which should just be in a python file."""
"DM-16291","Bug","afw",2,"str(Image) tests too strict about formatting","""While the changes introduced in DM-15682 passed formal testing, I discovered that they do not pass if {{afw}} is built against NumPy 1.13 -- that version of numpy includes more whitespace in the array than the test expects:    While the build failure can be worked around by upgrading NumPy to 1.14 or later (which will soon be required anyway), the consensus on [#dm-build-problems|https://lsstc.slack.com/archives/C4RKBLK33/p1540325009000100] was that any future formatting changes in NumPy would break the test again.    Please modify the tests so that they're less sensitive to NumPy's formatting decisions, preferably while keeping some diagnostic of whether the array is included in the string."""
"DM-16286","Story","Third Party Software",0.5,"Update version checks in EUPS stub packages to match lsstsw minimums","""In DM-14011 the lsstsw conda packages were updated.  This technically did not change the baseline for minimum supported package versions but after some debate (RFC-537) it is deemed desirable that Jenkins should always track our minimum version baseline.  If we say it's a minimum we should be testing that minimum.    This ticket will update the EUPS stub packages for astropy, numpy, matplotlib, and scipy to match those set in DM-14011."""
"DM-18223","Bug","ts_middleware",1,"Functions that get or put topics should raise an exception if resources not setup","""At present some or all SAL functions that get or put topics (telemetry, events and commands) segfault if the appropriate function has not been called to set up resources:{{salTelemetryPub}}, {{salTelemetrySub}} and the corresponding pairs of functions for logevents and commands.    Please make the commands raise an exception if the necessary resources have not been set up.    Please also have them raise an exception if the the resources are gone, e.g. if {{salShutdown}} has been called.    The SALPY unit tests I wrote have a test case for the first of these, but not the second."""
"DM-18209","Bug","ts_middleware",3,"Make topic get and put functions safe for nullptr / None","""At present SAL commands that get and put data take the data as a pointer argument and segfault if {{nullptr}} is used as the argument (or {{None}} in Python).    If practical, I strongly suggest making these functions take a reference instead of a pointer. That is the preferred C++ technique for a writable argument when {{nullptr}} is not allowed because it completely eliminates the possibility without any testing needed in the code. It also clearly expresses the need for an argument, whereas a pointer suggests that nullptr is a useful alternative.    If that is not practical for some reason (e.g. if the pointer has to be passed on down to DDS code) then please add explicit tests to the C++ which raise an exception if the data argument is {{nullptr}}."""
"DM-16305","Story","jointcal",8,"Implement bbox integrator for PhotometryTransform","""I implemented a stop-gap solution to DM-16235 (using the original calibration for the mean calibration so that mean calibrations are never negative). This ticket is to finish the integration code that was started there, so that we can compare the jointcal means with the original processCcd calibration means.    [~jbosch] suggests using the Chebyshev1dBasis in {{lsst.geom.polynomials}} to help implement the integration code."""
"DM-16304","Story","DM",1,"Update overview paper ","""Update Gaia performance in overview paper - include new references."""
