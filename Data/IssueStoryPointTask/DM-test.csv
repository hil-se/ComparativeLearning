"issuekey","type","components","storypoint","title","description_text"
"DM-21368","Story","ts_auxiliary_telescope",1,"Check that exposure time is in valid range","""While discussing failure modes, we realized that the only user-configurable parameter in the `expose()` command is the exposure time, which has a vendor-specified range 0.002ms-600s). We should check that the requested exposure time is in this range, before we ever attempt to configure the measurement, and raise an exception early if it is not.    We can make this a custom exception so that the CSC doesn't go into FAULT in this instance (vs. what happens when there is an internal error to the spectrograph during an exposure)."""
"DM-21366","Improvement","ts_auxiliary_telescope",1,"Release new versions of ts_salobj, ts_ATDome, ts_scriptqueue once SAL 4 is released","""Given the delay in releasing SAL 4 I am going to merge a series of tickets that rely on it to develop (in hopes that no last minute changes to SAL 4 require significant changes to Python).    This ticket is to cut releases of all these packages, after applying any last-minute changes. If the software can be released with no changes then simply merge the code from develop to master. Otherwise use this ticket branch for cleanup work.    Packages include:  * ts_salobj  * ts_scriptqueue  * ts_ATDome"""
"DM-21364","Story","ts_calibration",2,"Unit tests for chillermodel","""Chiller model needs unit tests. Write some. """
"DM-21363","Story","daf_base",1,"Fix semantics of PropertySet.update","""In DM-19873 I added {{PropertySet.update}} but I misunderstood the internal semantics of {{PropertySet.combine}}.    It turns out that {{combine()}} effectively adds values into the PropertySet so if you have matching keys you get an array item in the combination. This is not what {{update}} is semantically required to do which is effectively to overwrite existing values ({{set}} semantics).  I need to remove the special case call of {{combine}} inside the {{update}} method."""
"DM-21360","Story","Qserv",0.5,"Repair Qserv container builds","""Qserv container builds are busted since rh-git29 scl package has disappeared from distribution servers.    Roll up to rh-git218.  Roll up to devtoolset-8 while we are at it."""
"DM-21359","Story","Qserv|xrootd",0.5,"Update XRootD from upstream","""Update to latest upstream XRootD.  Should address issue with binary characters in log messages."""
"DM-21358","Story","ts_auxiliary_telescope",1,"Only allow changing simulation mode in STANDBY state","""Currently, one is allowed to change the simulation mode of a CSC in either STANDBY or DISABLED states (see {{base_csc.py:272}}), while the change from STANDBY to DISABLED is when the device connection should occur. This makes it more difficult to implement library mocks as I have done for the fiber spectrograph: the mock cannot patch over an already loaded library.    If we only allow changing the simulation mode in STANDBY, then these mocks are trivial to implement, and I believe it is safer overall as well: you don't want to start simulating over the top of an already existing connection."""
"DM-21384","Story","Design Documents",5,"Write a tech note on OCS triggered data processing","""Write a technote [DMTN-133|https://dmtn-133.lsst.io/v] outlining how we think that OCS triggered data processing will happen."""
"DM-21378","Story","templates",1,"Support technote_aastex in templatebot","""DM-21317 adds the {{technote_aastex}} template to https://github.com/lsst/templates.    This ticket is to add support for this new technote type to the lsst-templatebot-aide project and to commission the template for production."""
"DM-21374","Story","HeaderService",2,"Test and deploy HeaderService with ts_xml 4.2.0","""A new version of {{ts_xml 4.2.0}} has been released. This new version and the accompanying new meta-data  need to be tested."""
"DM-21373","Story","ts_auxiliary_telescope",1,"Add an internal timeout counter to the spectrograph polling","""After discussion with [~rowen], we decided that we should have some internal polling timer to allow the device controller to cancel the PollScan after some amount of time. We'll have to decide how long is """"too long"""". If this timer is exceeded, the controller should call {{stop_exposure}} and raise either {{asyncio.CancelledError}}, or some other error to let the CSC know that the exposure was automatically (as opposed to user) aborted.    5 seconds is my first guess for this timer: the readout should be a fraction of a second, so this should only be relevant if the spectrograph internals get into some """"stuck"""" state, which we should know about after a second or two.    This is also a usecase for the {{TIMEDOUT}} ExposureState."""
"DM-21392","Story","DM",3,"Note for google pitch ","""Rob pike suggested a short write up for google to see if we can make a deal .."""
"DM-21407","Story","meas_astrom",0.5,"Remove unneeded dependency on astrometry_net in meas_astrom","""According to its table file meas_astrom still depends on astrometry_net even though that dependency was removed in DM-2186.  """
"DM-21401","Improvement","ts_auxiliary_telescope",0,"Write a Watcher config file for the summit","""Write a config file for the Watcher appropriate to the current SAL components running on the summit. Tiago reports they are as follows:  """
"DM-21400","Improvement","ts_auxiliary_telescope",0,"Update ts_ATDome for simplified simulation mode DM-21358","""Take advantage of the simpler simulation mode support in salobj DM-21358 to simplify the implementation of simulation mode in ts_ATDome.    Instead of code that changes the existing connection when simulation mode is changed, just make the connection when in DISABLED or ENABLED state."""
"DM-21399","Improvement","ts_auxiliary_telescope",0,"Add an enum to Test in ts_xml","""Add an enum to the Test SAL component in ts_xml.    See DM-20432 to update ts_sal's unit tests to use it instead of the enum(s) in Script."""
"DM-21398","Story","ip_diffim",1,"Change background handling defaults in imageDifference.py","""This ticket is to implement the background handling changes approved in RFC-630"""
"DM-21422","Story","afw|ip_diffim",2,"Fix ip_diffim mosaic debug plots broken by Mosaic.makeMosaic signature change and compiler warning","""The {{frame=}} arg has been removed from {{afwDisplay.Mosaic.makeMosaic}}.    {quote}Robert Lupton 17:30    Use    disp = afwDisplay.Display(frame)  mos.makeMosaic(display=disp, title=""""Kernel Basis Images"""")  {quote}"""
"DM-21421","Story","ctrl_mpexec|pipe_base",20,"Create a system to define pipeline level execution and configuration","""This ticket will design and create the machinery necessary to define """"top"""" level workflow pipelines and their associated configurations. This is envisioned to be a set of tasks commonly run together in a manor similar to how pipe_drivers currently groups tasks. However, this is not intended to be tied to concrete tasks in the way pipe_drivers is, but a framework for users to specify processing pipeline definitions so that they can be reusable and revision controlled.    Jim and Andy I am adding you as watches so that if you have any thoughts on this you can comment."""
"DM-21420","Bug","ap_verify",1,"ap_verify datasets have out-of date refcat configs","""As described on [Community|https://community.lsst.org/t/3854], the reference catalog configs recently chagned to require that users specify both Gen 2- and Gen 3-style configs. This change breaks the configs shipped with {{ap_verify}} datasets, which only have Gen 2 style configs:      Update the configs for {{ap_verify_ci_hits2015}} and {{ap_verify_hits2015}} so that {{ap_verify}} runs again."""
"DM-21419","Story","ts_auxiliary_telescope",0,"The definition of which timestamp the EFD uses should be done by the SAL Kafka producer ","""In the future, we'll record EFD data in multiple stores like InfluxDB, Oracle, Parquet etc    Kafka replicates data using connectors, right now the decision of which timestamp is used as the InfluxDB time is done in the connector configuration, by a KSQL query:        a similar configuration would be done in the Oracle connector to define which timestamp field should be indexed.    To avoid making this decision in different connectors and potentially in different deployments of the EFD, the definition of which timestamp to use in the EFD should be done in the SAL Kafka Producer instead.     There are different ways to accomplish this.    The easiest one is to create a new field in the Avro schema called, for example, {{private_efdStamp}} which is a copy of whatever timestamp field we should use. Initially, that can be hardcoded to use {{private_sndStamp}}.    The other way is making use of """"aliases"""" in Avro:    https://avro.apache.org/docs/1.8.1/spec.html#Aliases    that create an alternate name {{private_efdStamp}} for the timestamp field we want to use.     NOTE: we assume aliases work the way we expect but that needs to be tested. In the above KSQL query {{SELECT * FROM mytopic}} ensures that all fields in {{mytopic}} will be inserted as fields in InfluxDB with their original names and  {{WITHTIMESTAMP private_efdStamp}} will use the alternate name to use the right timestamp as the InfluxDB timestamp.    Either way, the different connectors always use {{private_efdStamp}}.    Another benefit of doing this in the SAL Kafka producer code or in the Avro schema is that changes to the code or to the Avro schema are versioned, while changes in the connector configuration are not.     This ticket is not blocking anything in the moment. But having the {{private_efdStamp}} would make the EFD configuration more realiable."""
"DM-21411","Story","ts_aos",0,"Update AOS Package to Use the Scientific Pipeline w_2019_38","""Update AOS package to use the scientific pipeline w_2019_38. This is a preparation to update ts_MTAOS to use the salObj 4."""
"DM-21410","Story","ci_hsc|ci_hsc_gen3",1,"Turn ci_hsc into a metapackage for ci_hsc_gen2 and ci_hsc_gen3","""We need to do this before DM-17023 lands or the nightly ci_hsc builds (which are still running the old ci_hsc package) will be broken.    Only tricky bit is the question of how gracefully LFS handles being removed from the master branch of a repo."""
"DM-21437","Story","ts_auxiliary_telescope|ts_calibration",1,"Match up spectrograph index to serial number","""Once Patrick sends the serial numbers of the spectrographs and their """"names"""" (e.g. MTRed: """"1234567""""), we can figure out which SAL index corresponds to which serial number, and have the CSC use the index to connect to the correct device.    [~pingraham]: might as well attach the serial number information/photos to this ticket."""
"DM-21431","Improvement","ts_auxiliary_telescope",0,"Tag release candidates for code waiting for SAL 4","""Tag release candidates on develop for all my packages that are waiting for SAL 4 for formal releases."""
"DM-21429","Story","daf_butler",0.5,"Stop S3-backed butler tests from attempting import/export","""DM-17023's addition of import/export functionality included a test that is intended to be run only on PosixDatastore-backed butlers, because that's the only datastore that implements export at present.  However, the S30-backed butler test class inherits from the PosixDatastore-backed test class, so when the (optional) moto/boto3 dependencies are present, the import/export test is attempted there, too, and fails.    The right fix appears to be changing the inheritance relationship so that S3 and PosixDatastore butler tests both inherit from a common base class, mirroring the inheritance relationship of the datastore classes themselves."""
"DM-21426","Story","ci_hsc",0.5,"Remove expectation that wcslib is in package provenance in ci_hsc_gen2","""ci_hsc_gen2 includes a check that the package provenance recorded by the CmdLineTask machinery includes a few packages, and that list includes wcslib.  Since our own WCS classes now use AST instead, whether wcslib appears depends on whether other optional stack packages that still use wcslib are set up, and that makes this test fragile."""
"DM-21424","Story","ts_main_telescope",2,"Remove the Hard-Coded Data in Middleware","""Remove the hard-coded data in middleware by Moog. Consider to add the configuration file. Use the path variable is also a solution. Need to check the yaml support in c language."""
"DM-21423","Story","ts_environment",1,"Setup dimm CSCs on tower DIMM server","""Setup two DIMM CSCs on tower DIMM server."""
"DM-21458","Bug","ts_auxiliary_telescope",0,"Fix a failing unit test in ts_ATDomeTrajectory","""Using the SAL 4/salobj 5 release candidates ts_ATDomeTrajectory has a failing unit test:  test_simple_follow in test_dome_trajectory.py"""
"DM-21454","Bug","daf_butler",3,"Foreign key error when running makeButlerRepo.py against Oracle","""Running with daily stack d_2019_09_26 + master ci_hsc_gen3 + Oracle.  Start with clean local dir and clean Oracle db.   scons dies in makeButlerRepo.py     See end of description for full traceback.  Ran it with sqlalchemy echo=True and then looked for run_dataset_fkey in output:    Full traceback      """
"DM-21453","Story","ip_diffim",1,"Remove extra sdssCentroid plugin from default DipoleTask plugin list","""There seems to be an duplicate sdssCentroid plugin run in ip_diffim. This ticket will remove it."""
"DM-21451","Story","daf_butler",3,"Remove DatabaseDict and vectorize Datastore/Butler ingest APIs","""From #dm-middleware on slack:  {quote}I'd like to get Datastores using the new schema stuff I added recently (TableSpec/FieldSpec) for anything they want to keep in the registry database, and I want to stop using a dict interface, as it's hard to map __setitem__ to insert and update, especially for bulk operations.  I'm thinking of:   * Removing DatabaseDict and DatabaseDictRecordBase entirely.   * Add abstract methods to StoredDatastoreItemInfo to translate to/from dictionaries that correspond to records to be saved.   * Moving the logic for inserting and retrieving StoredDatastoreItemInfo from the database directly into GenericDatastoreBase.  That would probably be _insert_info and _fetch_info methods that replace _info_to_record and _record_to_info.   * Overriding _insert_info and _fetch_info in InMemoryDatastore to save into a dict instead of letting GenericDatastoreBase's implementations write to the database.{quote}"""
"DM-21450","Improvement","ts_auxiliary_telescope",2,"Add a clock monitoring rule to the Watcher","""Add a rule to the Watcher that reports if the clock is off for a given CSC. I suggest using the heartbeat event for this, in anticipation that such an event will eventually be available from all CSCs.    It will probably be safest to compare private_sndStamp to private_rcvStamp since the latter is set when DDS reads the sample for the Watcher (eliminating one source of delays in processing the data).    Potential issues:  - If DDS samples are ever delayed significantly then we may get false alarms. Though we probably want to know about that.  - If the Watcher's clock is off then *all* CSCs will appear to have incorrect clocks."""
"DM-21466","Story","Developer Infrastructure",1,"Update developer guide to reflect change to devtoolset-8","""Now that we are using devtoolset-8 everywhere we need to update the developer guide and pipelines.lsst.io."""
"DM-21465","Story","ts_middleware",1,"Add moto to T&S docker for unittesting s3 connections","""Please add the {{moto}} python module to the telescope and site docker container, so that we can use it to unittest the salobj code that will write to the newly-planned LFA. It is pip-installable.    https://github.com/spulec/moto"""
"DM-21464","Story","ts_aos|ts_main_telescope",3,"Update the MTAOS to use SALOBJ 5.0.RC.2 in Phase 1","""In this task, I will begin to update the ts_MTAOS to use the salobj 5.0. It is working with salobj 3.x right now. At this moment, I have only the salobj 5.0.RC.2 (RC: release candidate). The configuration file should be put in ts_config_mttcs."""
"DM-21463","Story","ts_main_telescope",5,"Test the Middleware Code by Moog","""I this task, I will test the TCP/IP message from middleware code in the googletest framework. The unit test of function will be implemented as well. I also need to make the Makefile can be switched between production and development modes."""
"DM-21472","Improvement","ts_auxiliary_telescope",1,"Please include conda-build in Docker containers","""Please include conda-build in Docker containers (at least those intended for development work). It is installed using:      Also building conda recipes requires a conda version of {{pytest-flake8}}, which is apparently not what is in the Docker image, alas. That can be installed using the following, but it's probably only safe to have that one or the pip version, not both:    [~ecoughlin] and others are trying to make our T&S packages conda-installable and we need these packages for that.    @"""
"DM-21488","Bug","afw",0.5,"Using asAstropy() on a BaseCatalog will raise an exception unless lsst.daf.base has been imported","""If you try to use {{asAstropy()}} (for conversion or pretty printing) on a {{BaseCatalog}} then an exception will be raised unless {{lsst.daf.base}} has been specifically imported by the user.  Thanks to [~jbosch] for noticing the key package.    {code:python}  import lsst.afw.table as afwTable    schema = afwTable.Schema()  schema.addField('test', float)    cat = afwTable.BaseCatalog(schema)  rec = cat.addNew()  rec['test'] = 0.0    print(cat)  {code}    raises """"TypeError: Unable to convert function return value to a Python type!""""  """
"DM-21486","Story","ap_pipe",2,"October reprocessing of HiTS data","""This ticket is to perform the regular monthly reprocessing of the HiTS dataset."""
"DM-21480","Story","JIRA",1,"Connect lsst-ts github group to Jira for branch/PR links","""It would be very helpful for the telescope and site developers if we could have the same branch & PR auto-linking to Jira that happens for the DM github group. Could you please configure Jira to link to the {{lsst-ts}} group on github?"""
"DM-21499","Improvement","ctrl_iip",2,"Add configurable  timeout values for ACK messages","""Messages between components have a hard-coded time associated between when the message is sent and when and ACK is received;  this should be configurable."""
"DM-21491","Improvement","ts_auxiliary_telescope",0,"Update ATDome and ATDomeTrajectory to use  salobj angle_diff and BaseCsc.disabled_or_enabled","""Update ts_ATDome as follows:  * Replace locally defined {{angle_diff}} and {{assertAnglesAlmostEqual}} with the versions from salobj.  * Use {{BaseCsc.disabled_or_enabled}} instead of the custom {{want_connection}} property which provides exactly the same information."""
"DM-21490","Bug","ctrl_iip",2,"correct async issue with message handler","""async/await directives are required in part of the handler code."""
"DM-21515","Story","technote",3,"Update texlive and texmf containers for new tooling","""The {{db2authors.py}} tool uses python f-strings and {{pyyaml}}.  This requires the texlive container to be upgraded to python > 3.6.  Additionally, we need to install the {{pyyaml}} package in the texmf container."""
"DM-21505","Story","ts_arch",2,"Write conda development procedure","""Write a conda development guide and procedure."""
"DM-21503","Bug","ctrl_iip",0,"Add forwarder heartbeat timeout to detect dropped connection to ATArchiver","""The Forwarder needs to detect that an anticipated heartbeat was missed in it's heartbeat thread, and re-advertise it's availability to redis if a heartbeat is missed."""
"DM-21526","Story","ts_main_telescope",0,"Prepare the Docker Image of Middleware Code","""This task will prepare the docker image of middleware code."""
"DM-21524","Improvement","Qserv",40,"Extend the core Replication Framework to support operations on behalf of the Ingest system","""The main objective of the development is to make extensions to the existing Replication System's framework to support the new Ingest system. Specifically, the following changes have been made in this context:   * extend the *Protobuf*-based protocol to support operations with the Qserv worker databases (inspecting, creating databases and tables, granting/revoking access privileges, operations with MySQL partitions, etc.)   * changes in the database schema and the *DatabaseServices* class to support super-transactions and chunk replicas in the """"being ingested"""" state   * implement a group of SQL requests and the worker-side support for them as per the above mentioned protocol extensions   * refactor and extend class *Controller* to support new types of requests   * extend the *ControllerApp* to allow testing new requests and the updated API of the *Controller*"""
"DM-21686","Story","ts_environment",8,"Generate events and commands XML files for HVAC system - 1","""Continue generation of XML files needed to control the HVAC system. The new files consist of the events and commands. For the events, an analysis will be performed on the actions to be taken associated with alarms in the system."""
"DM-21537","Epic","ts_main_telescope",20,"TMA Work Phase 2","""TMA Training & Review of Labview-based vendor software in Tucson & Spain.    Also any on-going work & support regarding the TMA.    This is a continuation of DM-19848"""
"DM-21536","Epic","ts_environment",20,"EAS Work Phase 3","""This epic is used to hold all stories associated with the Environmental Awareness System (EAS).   This is to continue work from:   * DM-17215   * DM-18732   * DM-20197"""
"DM-21531","Story","meas_extensions_scarlet",1,"Update scarlet to latest version","""To prepare for the scarlet mini-sprint we need to pull the latest version from scarlet/master to the LSST fork and test with Jenkins."""
"DM-21694","Story","ts_main_telescope",8,"Write an MT rotator CSC in Python","""Write an MT rotator CSC in Python, including a basic simulation mode.    Note that the simulator is the hard part. I plan to start with a very elementary model (no slewing) in this ticket, then refine it in another ticket."""
"DM-21691","Story","pipelines_lsst_io",1,"Update references to calib_psfCandidate in pipelines.lsst.io","""pipelines.lsst.io still references {{calib_psfCandidate}}. Should be updated to {{calib_psf_candidate}} """
"DM-21724","Bug","ctrl_mpexec",1,"Unpickling error reading qgraph with DimensionUniverse","""If I create a QuantumGraph and then try to read it, there's an error.  Originally got the same error using just BPS code, but this can be reproduced just using pipetask commands.  Using w_2019_40 + master ci_hsc_gen3.    Create QuantumGraph      Try to run using the QuantumGraph:  """
"DM-21719","Improvement","templates",1,"DDS packages need some extra env vars to run tests","""Packages that use OpenSplice DDS need some environment variables that scons does not normally see. Please consider adding the following to {{tests/SConscript}} for T&S packages:        I consider this moderate priority since I keep getting bitten by it (pytest works and everything seems fine, but scons fails)."""
"DM-21718","Story","templates",0.5,"Consider eliminating the ups cfg file for a pure python package","""A pure python package """"foo"""" does not need {{ups/foo.cfg}} if SConstruct specifies {{noCfgFile=True}}, e.g.:      Consider whether to take advantage of this and eliminate the unnecessary file. I admit it'll be harder to add C++ code later, but it's already a bit of a chore and not a common change.    I consider this a """"nice to have"""" since the current system works just fine."""
"DM-21716","Story","ts_auxiliary_telescope",0,"Modernize setup.cfg in salobj","""The setup.cfg file in ts_salobj has gotten a bit stale. Update it."""
"DM-21711","Story","afw",1,"Remove cameraGeom interfaces deprecated in DM-18610","""This includes (at least):   * {{Amplifier.getHasRawInfo()}}         This ticket should not be merged until after the 19.0 release."""
"DM-21702","Story","ip_diffim",0,"Investigate the cause of the high number of false sources in convolveTemplate=False image differencing","""{{ip_diffim}} has the bool configuration option {{convolveTemplate}} implemented. With {{convolveTemplate=False}}, it switches the roles of the science and template images and performs the AL convolution of _the science image_ to match _the template_. For cases when the science image is sharper than the template {{convolveTemplate=False}} and {{doDecorrelation=True}} setup should perform as well as the """"baseline"""" case when the template is the sharper one and it is convolved.         The resulting difference image is bad quality, indicated by an order of magnitude (~ 10 times) more sources detected (half positive, half negative approximately).    This ticket covers the work by [~gkovacs] to investigate the cause of this bug."""
"DM-21701","Story","pipe_tasks",1,"Rebase and update with deblender sprint code","""{{pipe_tasks}} changes made during the deblender sprint were never merged to master, so it still does not support {{meas_extensions_scarlet}}. This ticket is to rebase the branch and merge changes, confirming that it properly runs the latest version of {{meas_extensions_scarlet}}."""
"DM-21738","Story","pex_config",1,"Put Dual License on pex_config so it can be distibuted under bsd clause 3. ","""Change the license associated with pex_config:    * Change LICENSE to state dual license and then refer to BSD and GPL license files.  * Remove GPL short license from all files and refer to LICENSE file.  """
"DM-21737","Story","Alert Production|Science Pipelines",8,"Issue Call for Proposals for Community Brokers","""Write a call for broker proposals and clear it with the SAC."""
"DM-21736","Story","dm_dev_guide",1,"Add setup information enabling Vim file type recognition to the dev guide","""The DM dev guide contains useful setup information on how to configure Vim to be consistent with LSST coding standards, but by default, Vim will not use that setup without an appropriate entry in the ~/.vimrc file. A few extra lines in the dev guide are required to explain this. """
"DM-21734","Story","ts_middleware",1,"Add new events to SALGenerics.xml","""A _settingsApplied_ and _softwareVersions_ event need to be added to the _SALGenerics.xml_. See the section [Results from Group Discussion|https://confluence.lsstcorp.org/display/LSSTCOM/Commissioning+Activities+2019-05-14+Meeting+notes] for specification of the events and attributes."""
"DM-21732","Story","ts_main_telescope",3,"Test the Updated Middleware with Bare Rotator","""Test the software with the bare rotator in SLAC. The followings are my plan there:    1. To be familiar with the rotator behavior by some simple SAL commands by the original SAL version 3.5.1.    2. Install the SAL 3.10.0 and update middleware code in the mangement PC. In this step, I will need to stop the running middleware (in SAL 3.5.1) and backup the data in """"/nfsdemo"""" directory.    3. Test the rotator hardware behavior by SAL 3.10.0 and do the record. If there is any document of rotator behavior recorded already in SLAC, I will be happy to read. I also want to talk to the users of rotator to see there is any bug found or not. This should be recorded and fixed in the following update.    4. Discuss with the developer of CCS to see how the CCS works with the rotator. Since I might be one of the client of CCS (I am responsible of the active optics), I do want to know how the CCS works."""
"DM-21745","Improvement","ts_middleware",1,"Please allow enumerations with arbitrary values in our XML files","""Please allow us to specify values for enumeration constants in XML files. This has two advantages:  * It allows us to specify mask bits using enumeration constants. This can greatly simplify documentation and use of bit masks in SAL messages.  * Enumerations can start at 0. Use cases for this include the MT rotator which outputs several enumeration values that start at 0 (and is vendor code so we can't fix that) and the ScriptProcessState for which Tiago has found a use for 0=unknown.    I suggest that if any value is specified then all values must be specified. That should simplify the code that interprets the XML, make it easier for a reader to be confident of the values, and prevents accidental omission from messing up mask enums.    One possible implementation is the obvious:  <Enumeration>EnumName_AValueName=5, EnumName_AnotherValueName=7...</Enumeration>"""
"DM-21744","Bug","ts_auxiliary_telescope",0,"ts_watcher v0.2 requires salobj v5 but claims to support salobj 4","""ts_watcher v0.2 claims to be compatible with salobj v4.5 but the new Clock rule uses a feature only found in salobj v5."""
"DM-21742","Story","ts_auxiliary_telescope",2,"Write Auxiliary Telescope operations documentation.","""Write initial version of Auxiliary Telescope operations manual. """
"DM-21741","Story","ts_auxiliary_telescope",1,"Improvements on attcs class","""Implement some improvements to ATTCS class with lessons learned on recent Auxiliary Telescope on-sky activities. """
"DM-21780","Story","ts_auxiliary_telescope",1,"Make a few simple scripts that exercise the MT Rotator and Hexapod","""Make a few simple command-line scripts that exercise the MT Rotator by talking to the Rotator CSC. This is intended to help [~ttsai] shake out the MT Rotator at SLAC, especially my new Python CSC."""
"DM-21779","Story","ts_auxiliary_telescope",1,"Test new enumerations with values","""Test the new SAL support for enumerations with values by adding such an enumeration to Test and updating ts_sal tests to test for the existence and value of the enumerations in SALPY."""
"DM-21772","Story","mops",2,"Merge upstream changes to LSST oorb","""Merge (major) upstream changes to OpenOrb, resolve any conflicts, and update the eups build scripts to work with the new OpenOrb build system."""
"DM-21768","Story","daf_butler",2,"Vectorize dataset insert API","""Update the public and internal APIs for dataset insertion in Registry, but only use bulk insert operations where trivial (i.e. not when autoincrement IDs and hence DM-21203 are in play)."""
"DM-21766","Story","daf_butler",0,"Add per-dataset-type tables to Registry","""Move dimension foreign key fields to separate, per-dataset-type tables.  Duplicate primary key fields and optionally (via configuration) duplicate other fields.    This should move the schema to something like the """"Partition datasets (only)"""" design on [https://confluence.lsstcorp.org/display/DM/Dataset+and+Collection+Table+Reorganization|https://confluence.lsstcorp.org/display/DM/Dataset+and+Collection+Table+Reorganization]."""
"DM-21762","Story","mops",20,"Analyze options and select a fast algorithms for mock catalog generation","""The problem this issue concerns is as follows:    > Given orbits (state vectors) for M objects, and times, centers, and fields of view for N visits, find all visits where objects M would appear.    This is a fundamental algorithm for:   * Mock catalog generation   * Population debiasing applications   * Precovery applications (finding which older visits could plausibly contain newly discovered objects)    Existing algorithms take ~weeks on O(100) cores to compute O(100k) orbits. Need to speed this up to O(1hr) on O(20) cores to comfortably fit within the computational budget for precovery.    This ticket is to track the exploration of various options."""
"DM-21758","Story","ts_auxiliary_telescope",3," Electrometer CSC Hardware integration Phase 1","""Re-implement hardware communication for Electrometer CSC phase 1: Electric Boogaloo         Revamp serial communication."""
"DM-21751","Story","Developer Infrastructure|ts_environment",3,"Update SAL SDK for rPI to lastest SAL and DDS","""Build the latest OpenSpliceDDS Community Edition to run on the new Raspberry Pi 4 platform. Generate a SAL/DDS SDK image for use by the EAS contractor."""
"DM-21748","Bug","daf_butler",1,"oracle ci_hsc_gen3  sqlalchemy.exc.ObjectNotExectuableError","""Doing the weekly ci_hsc_gen3 run with Oracle throws an error during registerInstrument.py.  Using stack w_2019_41, ci_hsc_gen3 master  (sqlalchemy 1.3.8 from stack).  I do not see the following error if use sqlite3.  Verified get same error message using stack built on lsst-dev + oracle.  Verified I do not get the error message if using w_2019_40.    """
"DM-21747","Story","ts_middleware",2,"Coordinate the v4.4.0 Release of XML","""Reivew pull-requests, update tests and push out the RPMs for the XML v4.4.0."""
"DM-21797","Story","ts_auxiliary_telescope",3,"Add standard WCS to FiberSpectrograph","""DM-21263 packages the wavelength in output FITS files as a separate data array semantically distinct from the primary data. This ticket changes the output FITS files to store the wavelength using the FITS -TAB standard format as documented in FITS paper III."""
"DM-21795","Story","daf_butler",2,"Rework Registry provenance objects to match prototype","""(original description is no longer accurate; see comments)    -Registry's provenance tables - execution, run, and quantum - can't currently be fully populated without having database updates.  For example:-   * -you can't insert a dataset until after its run has been inserted;-   * -you can't insert a run until you've inserted the execution it inherits its ID from;-   * -you can't insert an execution until after it's completed, because it has an end timestamp field.-    -Work through low-level use cases for these tables and ensure we can actually have all of their values when it's time to insert them, splitting up tables as necessary.-    [~mgower]-,- [~cs2018]-: this ticket exists because I'm assuming updates are a problem.  Please let me know if they aren't or if you have any expections/requirements/wisdom on when various provenance records should be inserted relative to the datasets they refer to.-"""
"DM-21781","Improvement","ts_main_telescope",1,"Update MT Rotator and Hexapod to use XML enumerations with specified values","""Update the XML for the MT Rotator and Hexapod to take advantage of the new capability in SAL 4 to specify values for enumerations. The desired changes are as follows:  * Update ts_xml to use 0 as the starting value for the State, OfflineSubstate and EnabledSubstate enumerations.  * Rename State to ControllerState to match the field name.  * Update ts_xml to include enumerations for the mask values for the applicationStatus field of controllerState event.  * Update ts_xml documentation for the controllerEvent fields accordingly.  * Update ts_idl Rotator and Hexapod enums to match the changed and new enums in ts_xml.  * Update ts_rotator and ts_hexapod to stop incrementing the values of the controllerState fields (except application) and to use the enums in ts_idl directly instead of making copies that are 0-based."""
"DM-21808","Story","meas_extensions_scarlet",2,"Add missing commits from May deblending sprint","""Somehow a number of changes made on May 16 in the {{deblender-sprint}} branch on {{meas_extensions_scarlet}} did not get merged into DM-19991 with the rest of the deblender sprint tickets. This ticket is to re-implement those changes, which includes    * adding a blank source for point sources that fail to initialize (this is only temporary, since a more permanent solution will be implemented in DM-19790  * fix bug that prevents PSFs that are different sizes in each band from being combined into a multiband PSF (to be implemented in {{afw}} with DM-19789)"""
"DM-21807","Story","ts_main_telescope",2,"TMA Software Preparation","""1) Identify and gather software related wants from out team. Aside from the obvious SAL update, branstorm with Dave and other relevant members what is expected for me to be able to do with the software.    2) After identifying a few items attempt to understand the code BEFORE the visit to spain. This will produce nots and questions    3) Prepare and make these notes public or if useful put them down on confluence or an lsst.io page to begin documentation on this software. Perhaps talk to Andrew Serio since he has a way we should be organizing our documentation.     4) Put all of this preparation in a Confluence page and create some collaborative information."""
"DM-21813","Story","obs_lsst",0.5,"The ""filter"" should only be set for raw ccds and not for raw amps in obs_lsst","""With DM-21048 it is possible to read in raw data even when the filter is not listed in the obs package, although a warning is given.  This can be annoying because currently a warning is given for each amplifier, although it is unnecessary to set/check the filter when reading in amps, it only needs to be done (and is done!) when assembling the ccd.    It appears as though the place to put the change is in https://github.com/lsst/obs_lsst/blob/aeaebe9ad92137ac7a57e2bd580746e2cbffe16f/python/lsst/obs/lsst/lsstCamMapper.py#L393 where the call to {{self._standardizeExposure}} should have {{filter=False}}."""
"DM-21830","Story","HeaderService",1,"Run the ATHeaderService from a container in the NCSA Test Stand","""The ATHeaderService has been """"dockerized"""" and can be run a service from inside a container. However, the container version has not been tested outside docker at the NCSA test stand and need to be deployed and test communication with other CSCs on the same network."""
"DM-21828","Story","dax",1,"Create a notebook to determine if tokens are expired","""So, tokens expire in the notebook all the time, and aren't refreshed.  This causes no end of confusion, and it's hard to tell when someone's token is busted.  Create a notebook to help debugging of token issues."""
"DM-21826","Story","dax",3,"TAP availability endpoint returns a 503","""Fritz, Gregory, and I have all seen that /availability throws a 503.  Here's the stack trace, looks like its trying to look up some java class and not finding it:         2019-10-18 17:39:58.231 TAP ObsCore [http-nio-8080-exec-8] ERROR AvailabilityServlet  - BUG    java.lang.NullPointerException    at java.lang.Class.forName0(Native Method)    at java.lang.Class.forName(Class.java:264)    at ca.nrc.cadc.vosi.AvailabilityServlet.doGet(AvailabilityServlet.java:126)    at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)    at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:496)    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)    at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:650)    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1468)    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)    at java.lang.Thread.run(Thread.java:748)"""
"DM-21843","Bug","ctrl_mpexec",0.5,"pipetask runner fails at constructing qgraph dot files","""Attempting to generate a qgraph dot file to examine the quantum graph fails with traceback:      The quantum graph is being generated, as issuing a """"run"""" command to pipetask completes correctly."""
"DM-21836","Story","astro_metadata_translator|daf_butler",1,"Add OBSTYPE/purpose to Gen3 Registry exposure table","""We need to make sure the type of exposure (e.g. """"science"""", """"bias"""", """"flat"""") is extracted from metadata and put into the registry's exposure table in ingest.  I think this is what's called OBSTYPE in FITS, and I'm not sure if ObservationInfo already includes it and we drop it on the floor in ingest, or if we need to add it to astro_metadata_translator (either way, I'm sure that's on [~tjenness]'s radar).    In any case, this is becoming particular important as we prototype Gen3 CPP pipelines, which we of course want to run only on raws with specific types."""
"DM-21877","Story","ap_pipe|obs_base|verify",3,"Create ""marker"" Butler dataset for PPDB","""Discussing the Gen 3 migration of {{lsst.ap.pipe.ApPipeTask}} and {{lsst.verify.tasks.PpdbMetricTask}} on [#dm-science-pipelines|https://lsstc.slack.com/archives/C2JPMCF5X/p1571778136107700], [~jbosch] and I concluded that the cleanest trigger for running a {{PpdbMetricTask}} would be to provide a dataset that indicates that the database contains all information for a particular data ID. I believe this can also simplify the problem of providing Butler-like input to {{PpdbMetricTask}}.    Prototype this sytem in a Gen 2 pipeline by doing the following:   * Create a new dataset type ({{ppdbConfig}}?), with visit+ccd granularity (matching the units of work of {{ApPipeTask}}).   * Make {{ApPipeTask}} dump its PPDB config at the end of DB-related processing for a particular data ID. Note that while the DB config is fixed, we still should have a dataset for each data ID so that Gen 3 code could know which units of processing are """"DB complete"""".   * Create a new Task for creating a PPDB from a {{ppdbConfig}}, then configure {{PpdbMetricTask}} to use it in {{ap_verify}} runs.    These steps should test all aspects of the system except for tracking dependencies between pipeline and metric tasks, which is a Gen 3-only feature."""
"DM-21875","Story","daf_butler|verify",2,"Add StorageClass and Formatter support necessary to persist lsst.verify.Measurement in Gen3 repos","""Make it possible to persist and unpersist {{lsst.verify.Measurement}} objects via the Gen3 Butler."""
"DM-21874","Story","ip_diffim|pipe_tasks",0,"Create PipelineTask version of backward compatible ImageDifferenceTask","""Create one or more PipelineTasks that allow us to run any image-differencing functionality we need to continue to support in Gen3.  My understanding is that this means we need all calexp-template differencing functionality, but not necessarily pairwise calexp-calexp differencing (I'm hoping [~swinbank] and/or [~ebellm] can confirm).    I'm creating this now and assigning it to the AP team for middleware planning purposes, with a wild guess at SPs.  We'll of course have some DRP team members helping out with the work (probably [~yusra] and/or [~nlust]).  People doing the work are welcome to turn this into an umbrella ticket in the future with no SPs or branches of its own, but please link blocker tickets to this one so the middleware team can easily track progress towards deprecating Gen2."""
"DM-21873","Story","ts_aos|ts_main_telescope",0,"Install the Docker in PhoSim Server","""Install the docker in PhoSim server and change the image pull position setting. Record the steps to let Bo have the idea to follow on his server."""
"DM-21862","Story","obs_decam",8,"Extend Gen3 butler support for obs_decam","""obs_decam now has basic Gen3 butler support (sufficient for ingest), but we'll need to expand that to get to the point where we can run single-frame processing (IsrTask, CharacterizeImageTask, and CalibrateTask) via Gen3 on it.  That will include, at least:   * implementing {{writeCuratedCalibrations}} in the instrument class;   * specializing (and modifying, as necessary) the instrument-specific hooks for the gen2to3 tool, at least to the point where we can write scripts like the ones in ci_hsc_gen3/bin.src to make a fully-usable Gen3 repo.    I'm assigning this to [~Parejkoj] and the AP team for now, in the hopes it might be possible for him to finish the work he started with the initial DECam conversion.    A useful concrete end-point for this task would be a CI package that creates a Gen3 repo containing the HiTS (2015) raws, master calibrations, reference catalogs and runs the aforementioned tasks as a Pipeline."""
"DM-21860","Story","obs_cfht",2,"Add basic Gen3 butler support to obs_cfht","""Add an Instrument class and PipelineTask config overrides sufficient to ingest CFHT data into a Gen3 butler repository."""
"DM-21859","Bug","pipe_base",2,"Multiple PrerequisiteInput quanta are clobbered by a single value.","""Attempting to make a quantum graph that has multiple PrerequisiteInput entries of the same type results in one of the entries being processed N(=number of unique entries) times."""
"DM-21855","Story","daf_butler|obs_base",1,"Move daf.butler.instrument to obs_base","""This move has long been planned.  Time to do it."""
"DM-21853","Bug","obs_lsst",1,"error occurring when ROTANGLE isn't set","""There's currently a test which checks the date to see if the camera is up on the mountain, which masked a possible bug that [~tjenness] uncovered:    {quote}I think there's actually a logic error in the translator. The intent is that this should only get upset if it's a science observation and on the mountain and missing ROTANGLE. Instead it's getting upset with an """"unknown"""" observation which is probably a dark or a flat which should never have a rotation angle set anyhow. The is_on_mountain check has been masking the other logic bug.{quote}    It might be a good idea to re-think the """"on the mountain"""" logic (if it's actually important to differentiate being on the mountain... I'm not sure it is....), and set this as a configuration parameter, since we won't always be running this code """"on the mountain""""."""
"DM-21846","Bug","SUIT",2,"Firefly TAP UI on LSST Portal is not defaulting to the correct TAP service","""When the Portal (""""suit"""" application) is started up on the {{lsst-lsp-int}} instance of the LSST Science Platform, the initial TAP screen comes up pointed at the {{lsst-lsp-stable.ncsa.illinois.edu}} TAP service.  Both the {{-stable}} and {{-int}} services are configured into the TAP service menu, which used to work semi-accidentally, but now that authorization is fully enabled, only the matching TAP service will be accessible (-stable Portal must talk to -stable TAP, -int Portal must talk to -int TAP).    This """"instance matching"""" has been in the design all along.    The TAP service list is currently statically configured in https://github.com/lsst/suit/blob/master/src/suit/js/SUIT.js    Can we change this code to get the LSST TAP service URL by extracting the base URL from the URL of the currently displayed page?  (Technically, by extracting everything before """"/portal"""".)    We need this change not only to get `-int` working properly by default, but also to get this working on cloud-based LSP deployments.  Whatever the Portal URL is, let's say """"https://lsst.codes/lsp/portal"""", the TAP service URL needs to be """"https://lsst.codes/lsp/api/tap""""."""
"DM-21917","Story","pipe_tasks",8,"Convert DCR templates to PipelineTasks","""The DCR template generation code inherits from {{AssembleCoaddTask}} which has already been converted to a PipelineTask, so it should hopefully not be too much extra work to update {{DcrAssembleCoaddTask}}. I expect the majority of the work will involve adding a {{runQuantum}} method and a {{DcrAssembleCoaddConnections}} class."""
"DM-21912","Story","verify",1,"Implement PpdbMetricTask.runQuantum","""{{lsst.verify.tasks.PpdbMetricTask}} must take a single database as input, but may compute a more fine-grained metric. Therefore, its {{run}} method takes the output data ID as a keyword argument. Create a custom {{runQuantum}} method to support this argument; it should be identical to {{PipelineTask.runQuantum}} except for the extra keyword."""
"DM-21910","Story","verify",1,"Move lsst.verify.gen2tasks.MetricTask to lsst.verify.tasks","""The migration plan alluded to in [DMTN-098|https://dmtn-098.lsst.io/], and researched in DM-16503, involved creating separate Gen 2 and Gen 3 {{MetricTasks}}. This plan was motivated by the assumption that metrics would be in wide use by the time of the migration, making writing a class adapter for each and every metric impractical. However, {{MetricTask}} has seen limited uptake, making the careful approach unnecessary.    The new plan is to follow the process the Middleware group has been using, and retrofit Gen 3 functionality onto {{MetricTask}} directly. The only loose end is the current use of {{gen2tasks.MetricTask}}.    Move {{gen2tasks.MetricTask}} to {{tasks.MetricTask}}, keeping the old name as a deprecated alias (much as we did when we created the new {{geom}} package from {{afw.geom}}). Update known MetricTasks to use the new name immediately."""
"DM-21909","Story","DM",2,"Orgainse DM session at PB2Science 3 in Boston","""contact speaks and put agenda together (even if I am not attending !)"""
"DM-21900","Story","daf_butler",1,"More functionality for filename template generation","""We'll have use cases (at least from HSC, but probably for LSST as well) for being able to include dimension metadata fields that aren't themselves the primary keys of other dimensions (e.g. {{detector.name_within_raft}}).  We may also (after DM-21773) want to be able to use per-dataset metadata fields as well.    This of course has implications for our ability to validate that templates with generate unique filenames, but I _think_ we already have cases where we trust the user because it's not practical for the system to be able to verify it.  If not, I think we'll want that here."""
"DM-21890","Story","ctrl_mpexec",2,"Make command-line option command-line parsing order-independent.","""It'd be very nice if at least most {{pipetask}} options could be passed before or after the subcommand, instead of requiring users to remember which options go where.    It's entirely possible this is a fundamental limitation of Python's argparse, but if that's the case I think we should strongly consider some way to mitigate the problem, perhaps even by duplicating all current top-level options for each subcommand so options always go after the subcommand."""
"DM-21889","Story","ctrl_mpexec",2,"CmdLineActivator reuses command-line argument options in different sub-commands","""The one I'm particularly aware of is {{-t}}, which is used in one context for TIMEOUT and another for Tasks.  We should do a sweep for others.    This may be best handled as part of an overall re-think of the command-line interface that maximizes consistency with other tools (DM-15257), but we should make sure to get it done one way or another."""
"DM-21886","Story","ap_pipe",8,"Create PipelineTask driver for ap_pipe tasks that interact with the APDB","""Create a {{PipelineTask}} whose {{runQuantum}} method includes all of the logic in {{ApPipeTask.runAssociation}}.    This should probably be done after DM-21877, so it can use the same approach to signal completion of APDB writes to downstream PipelineTasks.     It's not clear what to do about ownership of {{ApPipeTask.ppdb}}. It must belong to the new task in Gen 3, but doing so will break config overrides in Gen 2 (and the DB location is _always_ overridden)."""
"DM-21885","Story","ap_verify|verify",0,"Convert concrete MetricTasks to PipelineTasks","""The {{lsst.verify.MetricTask}} system was designed to be as forward-compatible with PipelineTask as possible, so it should be straightforward to convert it, its subclasses, and any related tasks that are still needed in Gen3.    This is an umbrella ticket for all of that work; I don't know exactly what that would entail, but would like to have any relevant tickets linked here somehow.  I've taken a wild guess at SPs, but would love to have that updated by someone who actually has a decent basis for estimation."""
"DM-21883","Bug","ts_auxiliary_telescope|ts_main_telescope",0,"Rotator and Hexapod settingsApplied events renamed","""In DM-18424 the Rotator and Hexpod settingsApplied events were renamed to settingsAppliedLimits. This will break the vendor's CSC code and my own new CSC code. My code will be trivial to fix, but I worry about the vendor's code.    In addition the alias was not updated, so it does not match.    I suspect the driver was so we can use a standard settingsApplied event. But I don't think we can afford to break the vendor's code yet. We need to be sure that my new CSC code works first."""
"DM-21882","Story","ts_aos|ts_main_telescope",0,"Hot Fix of Version Check in runIsr.py of ts_wep Repository","""The version check is added in runIsr.py in the new LSST stack version. Since the binary file of """"tests/testData/bsc.db3"""" will change when running the comcamCloseLoop.py in lsst-ts/ts_phosim, the continuous run of runIsr.py will fail in the same rerun/run1 directory."""
"DM-21951","Story","ts_main_telescope",1,"Support November 1 rotator tests at SLAC","""Support testing my rotator CSC code on the rotator at SLAC.    This testing was originally scheduled for Monday, October 28 but was moved to November 1.  """
"DM-21950","Story","validate_drp",2,"Update validate_drp to work with fgcmcal calibrations as an option","""In order to test the performance of fgcmcal calibrations, validate_drp needs to be updated to read fgcmcal and fgcmcal_tract photoCalib files if configured to do so.    Additionally, post metrics for running fgcmcal on RC2."""
"DM-21949","Bug","ts_main_telescope",0,"Only output tracking and trackLost events when newly true","""ts_rotator should only output the tracking and trackLost events when they are newly true. Note that these events will not be truly useful until the XML is cleaned up in DM-21699, but this is better than nothing."""
"DM-21948","Bug","ts_auxiliary_telescope|ts_main_telescope",0,"The watcher needs ts_salobj in its ups table","""The ts_watcher package depends on ts_salobj but does not list it in its ups table file."""
"DM-21947","Story","DM",1,"Prepare for DMLT Oct 2019","""slides and stuff"""
"DM-21946","Story","Developer Infrastructure",5,"Implement code inspector to generate CSC RPM dependencies","""Write code inspector scripts to parse CSC code in C++, Java, Python, LabVIEW  to determine interdependencies, and generate RPM dependency list for use  with CSC RPM builders"""
"DM-21942","Story","Developer Infrastructure",5,"Update SAL runtime RPMS for CentOS 8","""Update the RPM generation for the SAL runtimes to be compatible with CentOS 8"""
"DM-21941","Story","Developer Infrastructure",5,"Update SAL for CentOS 8","""Update the SAL SDK for CentOS 8, build and test CSC's against it for  C++, Python (pybind11), Java, LabVIEW"""
"DM-21937","Story","verify",0,"Create new error-handling protocol for MetricTask","""Currently, running a {{MetricTask}} may either return a {{Measurement}}, return {{None}}, or raise an exception (preferably {{MetricComputationError}}). More details can be found [in the documentation|https://pipelines.lsst.io/v/v18_1_0/modules/lsst.verify/tasks/lsst.verify.gen2tasks.MetricTask.html#error-handling].    [~jbosch], in the DM-21885 discussion, said:  bq. I think we'll want to take a look at the expected-failure modes for {{MetricTasks}} you refer to in #3 as use cases for {{PipelineTasks}} in general, and define some rules that would allow them to work with generic activators.  We've done a tiny bit of work in that area so far, but have long known that we need more sophistication in classifying and handling failures.    Depending on how much these rules change the existing behavior, we may need to change the implementation of every concrete {{MetricTask}}, so story points are hard to estimate."""
"DM-21936","Improvement","ts_auxiliary_telescope|ts_main_telescope",2,"Make new package containing actuator simulators written in Python","""Many CSC packages contain a simulation mode that relies on a simulated actuator, including ts_ATDome, ts_ATMCSSimulator, ts_rotator and ts_hexapod.    Most of them rely on a simulated point to point actuator but ts_ATDome also has a simulated slewing/tracking actuator that could be useful for ts_rotator.    Copy both the point to point actuator and tracking actuator to a new package named \{\{ts_simactuators}}. Then on a separate ticket update the packages that use simulated actuators to use the new package."""
"DM-21932","Improvement","ts_middleware",2,"Please support topics with no public fields","""If practical, it would be helpful to allow topics that have no public fields (no <item>s in the XML). This would avoid the need for garbage fields that we ignore, making the intent clearer.         Obvious candidates include: the heartbeat event and most state transition commands (enterControl, enable, disable, standby, exitControl)."""
"DM-21931","Epic","ts_main_telescope",20,"Develop and Test the Hexapod and Rotator Software Phase 1","""This epic will maintain, develop, and test the software of Hexapod and Rotator contains the middleware, GUI, and wrapper code in cRIO.    This will include testing of the CCW and Camera Hex/Rot on the Camera Cart at the Summit.  This testing is currently slated for the first two weeks of December."""
"DM-21930","Epic","ts_aos|ts_main_telescope",20,"MT AOS Development & Testing Phase 3","""This epic will have the stories for the development and testing of the main telescope active optics system (MTAOS).    This is phase 3 of [DM-20178|https://jira.lsstcorp.org/browse/DM-20178].   """
"DM-21973","Story","HeaderService",1,"Update Docker information for atHeaderService","""The Docker configuration for the {{ATHeaderService}} is now defined in the repo  https://github.com/lsst-dm/sal_Dockerfiles    Moreover, the {{ATHeaderService}} now can run as a service on a docker container."""
"DM-21972","Story","ts_auxiliary_telescope|ts_main_telescope",2,"Create simple code to simulate script loading","""Create a simple set of code that simulates loading scripts and can be used to quickly try different solutions to speed up script loading.    This continues the work started in DM-21175 to speed up script loading.  """
"DM-21970","Story","HeaderService",2,"Mini integration test for ts_xml 4.4.0 and ts_sal 3.10.0 at the NCSA Test Stand","""A new version of {{ts_xml 4.4.0}} has been released. This new version rpms/repo and the accompanying new meta-data need to be tested at the NCSA Test Stand. The test should include {{ATCamera}}, {{ATArchiver}} and {{ATHeaderService}}."""
"DM-21969","Improvement","ts_main_telescope",2,"Replace simulated actuator in ts_rotator with a tracking actuator","""ts_rotator's mock controller uses a point to point actuator to model the rotator. That is not a very good fit (though tolerable given the frequency of tracking updates).    ts_simactuators includes TrackingActuator which is a much better model. Switch to that."""
"DM-21960","Story","ts_main_telescope",1,"Ship the Management and Diagnostic PC to Chile","""This task will ship the management PC and diagnostic PC (ThinkPad) of hexapod and rotator to Chile.    The story point of this task contains the work in DM-21959."""
"DM-21959","Story","ts_main_telescope",0,"Test the Middleware of Hexapod and Rotator with SAL 4.0","""This task will test the middleware code with SAL 4.0. The previous test in SLAC is SAL 3.10.0. T&S team plans to use the SAL 4.0 in the integration test in Dec."""
"DM-21958","Story","ts_aos|ts_main_telescope",3,"Upgrade the M2 Control System to LabVIEW 2018","""This task will upgrade the M2 control system from LabVIEW 2016 to 2018. This task will try to fix some minor bugs as well.    This is a follow-up task of [DM-21158|https://jira.lsstcorp.org/browse/DM-21158]."""
"DM-21957","Story","ts_auxiliary_telescope",1,"Update AT packages to use ts_simactuators","""Update packages that have simulated actuators to use ts_simactuators. These include:    * ts_ATDome  * ts_ATMCSSImulator"""
"DM-21953","Story","Documentation",1,"Create Community post about new Gaia refcat","""To close out DM-19473, we need a Community post announcing the new refcat so people can use it. I will write that post now and declare the epic finished."""
"DM-21995","Story","ts_qa",2,"Plan the end-to-end build/deploy/test effort","""The goal of this effort is create a Confluence page that outlines the steps needed to complete the end-to-end automated build/deploy/test infrastructure.  It will include estimates of the time and resources needed.  At the end, this will feed a Jira Epic and its Tasks that will track this effort.    After the initial page is created, I will meet with stakeholders ([~aclements], [~tribeiro], [~rhl], [~mareuter], etc) to get by-in and approval of the plan."""
"DM-22021","Story","ts_middleware",1,"Please allow unlimited Domain Participants in our OpenSplice configuration","""Please add the following to the ospl.xml configuration file in the {{<DDSI2Service name=""""ddsi2"""">}} section:      so the ScriptQueue can load more than 9 scripts at one time."""
"DM-22019","Story","ts_auxiliary_telescope",1,"Electrometer CSC Hardware Integration Phase 3","""Documentation."""
"DM-22018","Story","ts_auxiliary_telescope",2,"Electrometer CSC Hardware integration Phase 2","""Unit Tests and Jenkinsfile."""
"DM-22017","Story","ts_aos",2,"Testing M1M3 Cell phase 5 part 1","""Continuing testing the M1M3 Cell according Jira test plan for it."""
"DM-22016","Story","ts_ait",1,"Deploy xml 4.4 on Tucson Test Stand. ","""Ticket to track work for deployment on Tucson Test Stand. """
"DM-22015","Story","Developer Infrastructure",3,"Add <LanguageSupport> to SALSubsystems.xml","""Add a new tag to SALSubsystems.xml to allow the selection of which languages are required to be supported per CSC.     Values allowed include """"c++,python, idl,java,labview""""  """
"DM-22005","Story","SUIT",1,"Renew lsst-demo SSL certificate - Fall 2019","""This ticket records that the lsst-demo server SSL certificate was renewed by [~loi]."""
"DM-22003","Story","HeaderService",1,"MTHeaderService: Rename settingsApplied event","""In order to implement the changes ratified in the [settingsApplied|https://confluence.lsstcorp.org/display/LSSTCOM/Commissioning+Activities+2019-05-14+Meeting+notes#CommissioningActivities2019-05-14Meetingnotes-settingsApplied] discussion, the similarly named CSC specific event needs to be renamed or removed. Please see the generic event attributes to make that decision.    This is a child of CAP-365"""
"DM-22002","Story","HeaderService",1,"ATHeaderService: Rename settingsApplied event","""In order to implement the changes ratified in the [settingsApplied|https://confluence.lsstcorp.org/display/LSSTCOM/Commissioning+Activities+2019-05-14+Meeting+notes#CommissioningActivities2019-05-14Meetingnotes-settingsApplied] discussion, the similarly named CSC specific event needs to be renamed or removed. Please see the generic event attributes to make that decision.    This is a child of CAP-357"""
"DM-21999","Story","Continuous Integration",3,"Jenkins fails to build macOS binaries","""The Jenkins nightly and weekly release builds are failing to build binary packages for macOS (although Linux is fine).    For example, look at [nightly #792|https://ci.lsst.codes/blue/organizations/jenkins/release%2Fnightly-release/detail/nightly-release/792/pipeline] or [weekly #256|https://ci.lsst.codes/blue/organizations/jenkins/release%2Fweekly-release/detail/weekly-release/256/pipeline/176].    In both cases, the pipeline superficially appears to have completed successfully. However, in fact the “build eups tarballs” stage failed on {{osx-10.14.clang-1000.10.44.4.miniconda3-4.5.12-f032070}} with the (repeated) message:    then eventually      This error is due to a failure to find a dylib in the astshim package:      However:    * I am able to build astshim, using the same {{eups distrib}} incantation as Jenkins, on my macOS laptop with no problems;  * Jenkins has itself built this version of astshim in an equivalent Conda environment as part of the stack-os-matrix — this failure appears to be peculiar to the release pipelines.    """
"DM-22027","Bug","meas_algorithms",1,"Re-make Gaia refcat to fix epoch","""[~eggl] just pointed out to me that the time epoch expressed in the gaia catalog are given in TCB, not UTC as I had thought. This results in a ~50s systematic offset of all of the epochs (all Gaia DR2 epochs are J2015.5). Although 50s probably doesn't matter for LSST parallax/PM calculations (which we're not doing yet anyway), it's easy enough to fix the ingest config and re-process the data. I can set that to run this weekend.    While I'm at it, I will correct the meas_algorithms """"how to make a refcat"""" guide to have the updated config too.    Once it's generated and on lsst-dev, I'll have to re-request permission to copy it into place. Since the catalog is so new, I'll just overwrite the existing one entirely."""
"DM-22026","Story","DM Subsystem Science",1,"Present LOY1 alerts strategy to Science Collaborations","""Present the strategy outlined in LSE-459 to the science collaborations at a PST talk 20 Nov.   LSE-459 should be reviewed and agreed by the DM-SST/PST/SAC prior to giving this talk"""
"DM-22044","Story","ts_auxiliary_telescope",1,"Upgrade ATMonochromator CSC to salobj 4 and make it configurable","""Just realized that ATMonochromator needs to be upgraded to salobj 4 and to become a configurable CSC."""
"DM-22041","Story","Qserv",2,"Improvements to the deployments scripts to support the new Ingest system","""The main goal of the effort is to improve the deployment & management scripts to support the new Ingest system at {{lsp-int}} (former {{PDAC}})  """
"DM-22037","Improvement","ts_auxiliary_telescope|ts_main_telescope",1,"CSCs should automatically wait for their remotes to start","""ts_salobj Controller, BaseCsc, etc. should wait for remotes to start in the {{start}} method. This reduces the danger of a CSC trying to use a remote before it is ready and eliminates the need for the CSC to explicitly wait for its remotes (a step that is easy to forget).    Note: automatic wait is impossible for remotes that are constructed with {{start=False}}; if you create one of those then you must handle starting it yourself. Fortunately the only use case (so far) is the SAL/Kafka producer.    Also fix a bug in handling the {{LSST_DDS_IP}} environment variable: the value was translated to an unsigned long which might be too large to fit into the {{private_host}} field of topics, which is a signed long. This resulted in mysterious failures to output any DDS samples. Fixed by casting the value to a signed long. I added a test for this casting."""
"DM-22034","Improvement","ts_auxiliary_telescope",0,"ATDomeTrajectory should wait for its remotes to start","""The ATDomeTrajectory should wait for its remotes to start before trying to do anything else."""
"DM-22062","Story","daf_butler",2,"Add parquet support to Gen3 Butler","""Port formatters for Parquet files to Gen3, including support for lazy loading of columns."""
"DM-22061","Story","ts_main_telescope",1,"ts_xml another iteration","""This task is to remove the developers that are no longer on the team from the ts_xml salsusbsystems table.     I imagine it will take a few iterations before completing the table, therefore it makes more sense to update the table now having no information rather than misinformation.    Along with removing old developers, I will focus on updating these rows."""
"DM-22069","Story","afw",2,"Add lazy-product BoundedField class","""[~erykoff] would like a BoundedField implementation that simply multiplies two other BoundedFields, and I've long said I'll add it as soon as it becomes a pressing need - that kind of composition is something I've always had in mind for BoundedField but hadn't prioritized.     """
"DM-22068","Story","daf_butler|ip_isr|obs_subaru",1,"Add ABC, StorageClass, and Formatter for stray-light correction","""In order to support butler I/O for HSC's bespoke stray-light correction files, we should:   * Add an abstract base class for camera-generic stray light correction information to ip_isr, and make the implementation in obs_subaru inherit from it.   * Add a StorageClass to daf_butler for the abstract base class.   * Add a formatter to obs_subaru for the concrete HSC class.   * Add code and possibly a script to ingest the stray light data into a Gen3 repository."""
"DM-22067","Story","ts_main_telescope",2,"Diagnose failure to command rotator","""In rotator testing at SLAC DM-21951 we discovered that commands from the Python CSC were being ignored.    This ticket is to diagnose the problem. I propose to make use the fake cRIO controller in the ts_rotator package to talk to the real vendor's CSC, monitor the data in the commands sent by that CSC, and compare it to the data in the commands sent by the Python CSC."""
"DM-22066","Story","ts_main_telescope",1,"Fix issues discovered in SLAC rotator testing","""In SLAC rotator testing today we discovered several issues that need fixing:    * The {{counter}} field was the wrong type for Command and Header (should be uint, not ushort).  * The rotator and hexapod CSCs have no heartbeat output. This strongly suggests we should have a base class for both CSCs.  * The rotator commander outputs too much noise because of encoder jitter (not a surprise). This is likely an issue for the hexapod commander as well.    Note that we still were not able to command the rotator: the commands were ignored. Fixing that is a different ticket.    I have attached a file that shows some binary telemetry data we read from the rotator, and how the Python code parses it."""
"DM-22070","Story","afw",2,"Add unnormalized (but continuous) version of PixelScaleBoundedField","""PixelScaleBoundedField is a bit inconvenient to use in full-focal-plane contexts (the only contexts in which we expect to use it) because it normalizes by the area of the origin pixel in order to yield a unitless quantity, and that origin pixel is a per-CCD quantity, resulting in a discontinuous combined field over the focal plane.    Duplicate and adjust it to define a new PixelAreaBoundedField class; I'll RFC deprecating and removing the original in a separate RFC to avoid worrying about code duplication in the interim.  Also make sure the new class is persistable (the original is not).     """
"DM-22093","Improvement","ap_pipe|verify",2,"Store begin/end times of ap_pipe in ap_verify","""[~cmorrison] asked to get time stamps for the start and end of an {{ap_verify}} job (excluding metric calculation, if possible). Find a way to do so; probably the {{StartUtc}} and {{EndUtc}} values logged by {{pipe.base.timeMethod}}."""
"DM-22089","Story","DM Subsystem Science|Requirements Documents",1,"Update LDM-503 to clarify requirements verification using available data","""As discussed at DMLT F2F 2019-10-28, LDM-503 needs to be updated to reflect policy around which requirements can be verified within the DM subsystem, based on available data. """
"DM-22079","Story","afw",1,"Linearity input bug in DM-18610","""An oversight in DM-18610 prevents linearity type and coefficients from being read correctly from FITS.  Fix is trivial."""
"DM-22076","Story","ts_main_telescope",0,"Setup the Linux Laptop","""Setup the Linux laptop that will be used on the summit for the test."""
"DM-22073","Story","daf_butler",1,"Add matplotlib (output) support to Gen3 butler","""Port Gen2's write-only support for writing matplotlib Figures to (at least) PNG to Gen3."""
"DM-22110","Story","HeaderService",1,"Update HeaderService docker image for ts_sal 4.0.0","""SAL_VERSION=4.0.0  SALOBJ_VERSION=5.0.0  XML_VERSION=4.4.1  IDL_VERSION=1.0.0        """
"DM-22109","Improvement","ts_main_telescope",0,"Updating LOVE and Script to use generics post-SAL-4.1","""The LOVE_Events.xml currently defines the logMessage event, but this is now a Generic event.  It just needs to be removed from the LOVE_Events.xml file."""
"DM-22107","Story","ts_auxiliary_telescope",2,"ATHexapod CSC: Revamp for salobj 4/5","""Revamp athexapod CSC for Salobj 4/5 and ConfigurableCSC support."""
"DM-22104","Improvement","ts_main_telescope",2,"Refactor ts_rotator and ts_hexapod to put more common code in ts_hexrotcomm","""There is too much duplication between the ts_rotator and ts_hexapod CSC and mock controllers. Refactor more of the common code into ts_hexrotcomm. I will do this work as part of DM-22066."""
"DM-22103","Improvement","ts_main_telescope",0,"Please uncomment some logging statements in the MT Rotator cRIO","""Please enable the logging statements at lines 400, 403 and 408 in rotator/targetx2/commanding.c: the commented-out syslog calls in:    Please also look for and enable similar messages in the hexapod commanding.c    This will help us diagnose when the rotator or hexapod cRIO decides to ignore commands from the CSC.    Note that any command from the """"GUI"""", which is what we call the Engineering User Interface (EUI), will reset gCommandSourceDDS to 0, making the CSC unable to command the cRIO. That is based on different code in rotator/targetx2/cmdClientSocket.c:    This looks like a bug or misfeature to me (unless it also changes the state to Offline/PublishOnly, which I strongly doubt).    I would expect the CSC to always be able to control the rotator except in Offline/PublishOnly mode.   * This task will try to understand the logging mechanism and log the useful information. This will be helpful for the following debug."""
"DM-22102","Story","ts_ait|ts_main_telescope",2,"Camera Hex/Rot Software Setup","""Any assembly/testing needed at the summit for the Camera Hex/Rot to be ready for the individual functional testing as well as the Camera Rot/CCW/Camera Cart integration testing.  Will be working in tandem with IT (IT-1145) in regards to this process.    Will probably need switches and/or UPS from IT to complete this task."""
"DM-22122","Story","ts_auxiliary_telescope|ts_main_telescope",2,"Add a showAlarms command to the watcher","""The INRIA group requested a command that will show all currently active alarms (those not in the nominal state). This will allow the Watcher user interface to """"catch up"""" when it starts.    They also requested that the ConfiguredSeverities cycle forever."""
"DM-22120","Bug","ap_verify|verify",2,"ap_verify scales poorly to large runs","""[~cmorrison] reports that {{ap_verify}} can time out when run over large datasets on {{lsst-dev}}. This is partly because of the time needed to run the pipeline itself, but also the time needed to iterate through all metrics (since {{MetricsControllerTask}} was never parallelized). {{ap_verify}} does not offer any error recovery options beyond rerunning the entire pipeline.    Both {{ap_verify}}'s current control system and {{MetricsControllerTask}} will become obsolete with Gen 3, where responsibility for workflow management (and any checkpointing) will lie with the pipeline activator. Rather than try to design proper restart behavior into {{ap_verify}} now, provide a {{\-\-skip-completed}} command-line flag that does the following:  * runs {{ap_pipe}} with the {{\-\-reuse-outputs-from all}} command-line argument, which skips completed pipeline steps (currently, up through {{association}}).  * makes {{MetricsControllerTask}} check for a job file associated with each data ID, and skips processing that data ID if the file already exists    This flag should be enough to let us retry large runs efficiently until Gen 2 is retired."""
"DM-22141","Story","System Integration and Test",3,"Backup m1m3 test campaign EFD data, and make available in Tucson EFD","""Backup the data from the M1M3 test campaigns and copy to NCSA and   make available access to the  live M1M3 EFD instance (mysql) from Tucson"""
"DM-22140","Story","Developer Infrastructure",1,"Add language support selection to SALSubsystems.xml","""Add a tag to the SALSubsystems.xml to allow specification of which languages we need to build support libraries and tests for.  e.g.     <Languages>cpp,java,python,pydds,labview</Languages>  """
"DM-22139","Story","ap_pipe",2,"AP association bug with >1000 diaSources","""I'm seeing a bug in {{ap_pipe}} when running association if the number of diaSources is large (>1000). I've posted the log starting with image differencing for one observation where the bug appeared, though this was not the only observation that failed. Other observations that had only ~980 or fewer diaSources ran successfully, while every observation with more than 1000 diaSources that I looked at failed.    I took my best guess at the story points and epic, so please correct those if I got them wrong!    {code:}  apPipe.differencer INFO: Subtracting images  apPipe.differencer.subtract INFO: Template Wcs : 2.619998,0.050177 -> 2.614735,0.052809  apPipe.differencer.subtract INFO: Science Wcs : 2.614754,0.052794 -> 2.619984,0.050191  apPipe.differencer.subtract INFO: Astrometrically registering template to science image  apPipe.differencer.subtract INFO: templateFwhmPix: 4.78053065883556  apPipe.differencer.subtract INFO: scienceFwhmPix: 3.957219530945321  ip.diffim.generateAlardLuptonBasisList INFO: Target psf fwhm is the greater, deconvolution mode  apPipe.differencer.subtract.selectDetection INFO: Detected 1020 positive peaks in 898 footprints to 10 sigma  apPipe.differencer.subtract.selectMeasurement INFO: Measuring 898 sources (898 parents, 0 children)   apPipe.differencer.subtract INFO: Growing 898 kernel candidate stars by 21 pixels  apPipe.differencer.subtract INFO: Selected 272 / 898 sources for KernelCandidacy  apPipe.differencer.subtract INFO: Matching Psf FWHM 4.78 -> 3.96 pix  ip.diffim.generateAlardLuptonBasisList INFO: Target psf fwhm is the greater, deconvolution mode  apPipe.differencer.subtract INFO: Final spatial kernel sum 26.409  apPipe.differencer.subtract INFO: Spatial model condition number 6.205e+09  apPipe.differencer.subtract INFO: Doing stats of kernel candidates used in the spatial fit.  apPipe.differencer.subtract INFO: 272 candidates total, 16 rejected, 237 used  apPipe.differencer.subtract INFO: Spatial kernel model well constrained; 237 candidates, 3 terms, 30 bases  apPipe.differencer.subtract INFO: Spatial background model appears well constrained; 237 candidates, 6 terms  apPipe.differencer INFO: Computing diffim PSF  apPipe.differencer.decorrelate INFO: Running A&L decorrelation: spatiallyVarying=False  ip_diffim_decorrelateALKernel INFO: Using matching kernel computed at (1024, 2048)  ip_diffim_decorrelateALKernel INFO: Variance (science, template): (92.492551, 0.004940)  ip_diffim_decorrelateALKernel INFO: Variance (uncorrected diffim): 98.240851  ip_diffim_decorrelateALKernel INFO: Variance (corrected diffim): 97.975441  apPipe.differencer INFO: Running diaSource detection  apPipe.differencer.detection INFO: Detected 7429 positive peaks in 1708 footprints and 139 negative peaks in 56 footprints to 5 sigma  apPipe.differencer INFO: Merging detections into 1228 sources  apPipe.differencer INFO: Running diaSource measurement: newDipoleFitting=True  apPipe.differencer.measurement INFO: Measuring 1228 sources (1228 parents, 0 children)   apPipe.differencer.forcedMeasurement INFO: Performing forced measurement on 1228 sources  apPipe INFO: Running Association...  apPipe.associator.diaCalculation WARN: Input diaSourceCat is indexed on column(s) incompatible with this task. Should be indexed on 'multi-index, ['diaObjectId', 'filterName', 'diaSourceId'].  apPipe FATAL: Failed on dataId={'ccdnum': 5, 'filter': 'g', 'visit': 288970, 'date': '2014-03-01', 'hdu': 31, 'object': 'Blind14A_04'}: KeyError: 124094082061435674  /software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/pex_config/18.1.0-5-gc286bb7+4/python/lsst/pex/config/config.py:1279: FutureWarning: Config field ccdProcessor.isr.doAddDistortionModel is deprecated: Camera geometry is incorporated when reading the raw files. This option no longer is used, and will be removed after v19.    FutureWarning)  /software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/ap_association/18.1.0-14-g371438c+2/python/lsst/ap/association/mapApData.py:185: YAMLLoadWarning: calling yaml.load_all() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.    table_list = list(yaml.load_all(yaml_stream))  /software/lsstsw/stack_20191101/python/miniconda3-4.5.12/envs/lsst-scipipe/lib/python3.7/site-packages/astropy/units/function/logarithmic.py:46: RuntimeWarning: invalid value encountered in log10    return dex.to(self._function_unit, np.log10(x))  Traceback (most recent call last):    File """"/software/lsstsw/stack_20191101/python/miniconda3-4.5.12/envs/lsst-scipipe/lib/python3.7/site-packages/pandas/core/indexes/base.py"""", line 2657, in get_loc      return self._engine.get_loc(key)    File """"pandas/_libs/index.pyx"""", line 108, in pandas._libs.index.IndexEngine.get_loc    File """"pandas/_libs/index.pyx"""", line 127, in pandas._libs.index.IndexEngine.get_loc    File """"pandas/_libs/index.pyx"""", line 153, in pandas._libs.index.IndexEngine._get_loc_duplicates    File """"pandas/_libs/index_class_helper.pxi"""", line 122, in pandas._libs.index.Int64Engine._maybe_get_bool_indexer  KeyError: 124094082061435674    During handling of the above exception, another exception occurred:    Traceback (most recent call last):    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/pipe_base/18.1.0-9-gee19f03+2/python/lsst/pipe/base/cmdLineTask.py"""", line 388, in __call__      result = self.runTask(task, dataRef, kwargs)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/pipe_base/18.1.0-9-gee19f03+2/python/lsst/pipe/base/cmdLineTask.py"""", line 447, in runTask      return task.runDataRef(dataRef, **kwargs)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/pipe_base/18.1.0-9-gee19f03+2/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/ap_pipe/18.1.0-4-gcd8f52c+37/python/lsst/ap/pipe/ap_pipe.py"""", line 218, in runDataRef      associationResults = self.runAssociation(calexpRef)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/pipe_base/18.1.0-9-gee19f03+2/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/ap_pipe/18.1.0-4-gcd8f52c+37/python/lsst/ap/pipe/ap_pipe.py"""", line 306, in runAssociation      results = self.associator.run(dia_sources, diffim, self.ppdb)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/pipe_base/18.1.0-9-gee19f03+2/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/ap_association/18.1.0-14-g371438c+2/python/lsst/ap/association/association.py"""", line 139, in run      ppdb)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/pipe_base/18.1.0-9-gee19f03+2/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/ap_association/18.1.0-14-g371438c+2/python/lsst/ap/association/association.py"""", line 315, in update_dia_objects      filter_name)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/pipe_base/18.1.0-9-gee19f03+2/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/ap_association/18.1.0-14-g371438c+2/python/lsst/ap/association/diaCalculation.py"""", line 331, in run      filterName)    File """"/software/lsstsw/stack_20191101/stack/miniconda3-4.5.12-4d7b902/Linux64/ap_association/18.1.0-14-g371438c+2/python/lsst/ap/association/diaCalculation.py"""", line 392, in callCompute      objDiaSources = diaSourceCat.loc[objId]    File """"/software/lsstsw/stack_20191101/python/miniconda3-4.5.12/envs/lsst-scipipe/lib/python3.7/site-packages/pandas/core/indexing.py"""", line 1500, in __getitem__      return self._getitem_axis(maybe_callable, axis=axis)    File """"/software/lsstsw/stack_20191101/python/miniconda3-4.5.12/envs/lsst-scipipe/lib/python3.7/site-packages/pandas/core/indexing.py"""", line 1913, in _getitem_axis      return self._get_label(key, axis=axis)    File """"/software/lsstsw/stack_20191101/python/miniconda3-4.5.12/envs/lsst-scipipe/lib/python3.7/site-packages/pandas/core/indexing.py"""", line 141, in _get_label      return self.obj._xs(label, axis=axis)    File """"/software/lsstsw/stack_20191101/python/miniconda3-4.5.12/envs/lsst-scipipe/lib/python3.7/site-packages/pandas/core/generic.py"""", line 3585, in xs      loc = self.index.get_loc(key)    File """"/software/lsstsw/stack_20191101/python/miniconda3-4.5.12/envs/lsst-scipipe/lib/python3.7/site-packages/pandas/core/indexes/base.py"""", line 2659, in get_loc      return self._engine.get_loc(self._maybe_cast_indexer(key))    File """"pandas/_libs/index.pyx"""", line 108, in pandas._libs.index.IndexEngine.get_loc    File """"pandas/_libs/index.pyx"""", line 127, in pandas._libs.index.IndexEngine.get_loc    File """"pandas/_libs/index.pyx"""", line 153, in pandas._libs.index.IndexEngine._get_loc_duplicates    File """"pandas/_libs/index_class_helper.pxi"""", line 122, in pandas._libs.index.Int64Engine._maybe_get_bool_indexer  KeyError: 124094082061435674  {code}  """
"DM-22128","Story","HeaderService",2,"Remove salpytools dependency from the HeaderService","""The transition to ts_salobj has been fully vetted and therefore there is no need to continue carrying salpytools and its dependencies into the HeaderService. Therefore all  salpytools dependencies need to be removed from the HeaderService."""
"DM-22157","Story","ts_qa",5,"Convert XML RobotFramework tests in to pure python - part 2","""This task covers the time needed to complete the XML test conversion.  See DM-22032."""
"DM-22155","Story","ts_main_telescope",1,"MTVMS_Telemetry.xml does not conform to Topic Naming Conventions","""After updating the XML tests, it was found that the MTVMS_Telemetry.xml file defines three topics that do not conform to naming standards as defined in    [SAL_Recommendations|https://ts-xml.lsst.io/sal_constraints_and_recommendations.html] page.    The topics MTVMS_M1M3, MTVMS_TMA and MTVMS_M2 should be renamed to MTVMS_m1m3, MTVMS_tma (or MTVMS_mtmount) and MTVMS_m2, respectively."""
"DM-22151","Improvement","ts_middleware",0,"Rewrite make_idl_files to take advantage of DM-21106 to speed up file generation","""Rewrite the code that generates IDL files to take advantage of DM-21106 to speed up the code. Call the new salgenerator command that only generates IDL files instead of the old command that generates additional code. Note that the deletion code can probably be simplified as well -- there is no point deleting files that make_idl_files does not create."""
"DM-22150","Improvement","ts_main_telescope",1,"The Rotator and Hexapod CSCs should reject all commands when the device is not commandable","""The Rotator and Hexapod CSCs should check the state of `commandableByDDS` and reject *all* commands if the CSC is not allowed to control the device. This will prevent a major source of confusion: commands that fail or are silently ignored for no obvious reason.    I hope I can do all the work in ts_hexrotcomm, but will update ts_rotator and ts_hexapod as well, if necessary."""
"DM-22149","Story","ts_main_telescope",0,"Draft the SAL Functional Test Plan of Hexapod","""Draft the hexapod test plan in SAL level.    The followings are suggested by [~rowen]:       Informally I would say that the same tests we proposed as for the rotator would be relevant here:  * Check that the state transition commands work as we think they were coded to (not exactly as per our standards). In particular I think clearError will send the CSC to OFFLINE/PUBLISH_ONLY, though I would love to be wrong about that.  * Check that the motion commands work as expected — to within a tolerance we can reasonably measure. I think trying to measure with high accuracy will be beneficial at some point (to understand what the hexapod is truly capable of), but I think our initial focus should be on sanity checking motion rather than trying to measure precision of motion."""
"DM-22147","Story","afw",2,"Add python-only function to ChebyshevBoundedField to approximate another BoundedField","""At the current moment the {{PixelAreaBoundedField}} (and the {{PixelScaleBoundedField}} that it is replacing, see RFC-644) are too slow (by a couple orders of magnitude) to use in coaddition via a {{PhotoCalib}}.  [~jbosch] says that this is a non-trivial fix (DM-22071).    However, for many purposes, it is possible to use a {{ChebyshevBoundedField}} to approximate a {{PixelAreaBoundedField}} (or other {{BoundedField}}).  Provided the field to approximate is smooth, preliminary tests show that (e.g.) a typical HSC WCS can be approximated at the 1e-7 level with plenty of speed, which is sufficient for use in a {{PhotoCalib}}.      This ticket is to add a python-only {{approxBoundedField}} method to {{ChebyshevBoundedField}}.  Tests will be written by approximating {{PixelAreaBoundedField}} (the primary use case) so this requires DM-22070 to be completed first."""
"DM-22146","Story","ts_main_telescope",2,"Test the Rotator/ Hexapod CSC based on ts_salobj","""This task will test the new CSC codes by Russell to see why the rotator cRIO in SLAC can not receive the command. This is a follow-up task of DM-21951, DM-22104, DM-22066, and DM-22067."""
"DM-22145","Story","ts_main_telescope",3,"Upgrade the M2 Control System to SAL 4.0 in Phase 2","""This is a continued task of phase 1: DM-22144."""
"DM-22144","Story","ts_main_telescope",3,"Upgrade the M2 Control System to SAL 4.0 in Phase 1","""This task begins to update the M2 control system to the latest SAL version. The original SAL version is 3.5.1. On the summit, only the telemetry and event can work for M2 control system. It can not be commanded by the SAL commands. This task will try to fix this bug as well."""
"DM-22166","Bug","ctrl_mpexec",1,"Fix pipetask --show=pipeline option","""After all recent changes --show=pipeline does not work anymore:    """
"DM-22162","Story","ctrl_mpexec|pipe_base",2,"Add metadata writing to PipelineTask execution logic","""PipelineTask execution should automatically write a metadata dataset for each Quantum.  We want that to appear in the QuantumGraph as well, so downstream PipelineTasks can use these as inputs.     """
"DM-22177","Bug","ctrl_mpexec",1,"ctrl_mpexec calls non-existent Pipeline.addConfigOverrideFile method","""Running pipetask commands with the w_2019_45 weekly results in:  `Failed to build pipeline: 'Pipeline' object has no attribute 'addConfigOverrideFile'`  This method does not exist, but a similar `addConfigFile` does."""
"DM-22174","Story","ts_aos|ts_main_telescope",0,"Attend the DM Boot Camp 2019","""Attend the DM boot camp 2019. The agenda is [here|https://community.lsst.org/t/dm-boot-camp-2019/3887].    I am interested in:    1. System Architecture (2:30 EST, 12:30 PM in Tucson) at 11/12    2. All courses at 11/13 (begin from 2:00 EST, 12:00 PM in Tucson)    The meeting room will be in the Workroom (229) for this meeting.         Lectures will be remotely streamed: [https://princeton.zoom.us/j/5752451825]"""
"DM-22172","Story","ts_auxiliary_telescope",2,"ATHexapod CSC: Controller Integration Phase 3","""Add documentation support to repo. Fix docstrings to comply with numpydoc format."""
"DM-22171","Story","ts_auxiliary_telescope",2,"ATHexapod CSC: Controller Integration Phase 2","""Add Jenkinsfile."""
"DM-22170","Story","ts_auxiliary_telescope",2,"ATHexapod CSC: Controller Integration Phase 1","""Finish implementing CSC. Add mock controller and add unit tests."""
"DM-22195","Story","ts_environment",8,"Continue generation of HVAC XML files","""The MQTT based generated list of HVAC parameters, will be verified for completeness by comparing with the Windows server list and, then proceed with the final generation of XML telemetry, alarms and commands files."""
"DM-22193","Story","DM Subsystem Science",1,"Updates DMTN-107 ","""Following the LOY1 alerts meeting, DMTN should be updated to include:   * references to the official pre-operation data previews  * a clear statement that we will use templates from the DPs will be used to generated LOY1 alerts. """
"DM-22192","Story","afw",1,"Remove PixelScaleBoundedField","""Will be deprecated on DM-22070, which will probably make it into 19.0, so we'll assume for now that this can be removed after 19.0 and must be removed before 20.0."""
"DM-22191","Story","ip_isr|obs_lsst",2,"isr for yaml cameras is broken due to zero value for suspectLevel","""I think that DM-18610 changed the default value for {{amplifier.getSuspectLevel()}} from Nan to zero, and this means that isr now masks out all amps built from yaml cameras.    This could be fixed many ways - getting all yaml cameras to specify it, getting the yaml camera builder to default it to nan in obs_base, having a failsafe in isr, because zero is never a legit value (if all values above zero are suspect you've got some serious problems that we can't help with, after all).    Some of these are more sensible than others, and yet more probably exist. I'm about to go on vacation so can't sort this out right now, but it seems quite urgent to me."""
"DM-22190","Story","atmospec",5,"Perform end-to-end analysis of a visit with Spectractor shim","""Take a visit that we have, and which Jérémy has analysed, and perform end-to-end extraction, getting roughly comparable results, _i.e._ something which looks like a legit extracted spectrum.    It doesn't have to be perfect (or even very good) yet, but something that isn't garbage-in, garbage-out, showing that the interface is working properly."""
"DM-22209","Bug","afw",2,"Fix pipelines_lsst_io bug from d_2019_11_06","""    https://ci.lsst.codes/job/sqre/job/infra/job/documenteer/668/display/redirect"""
"DM-22207","Story","dm_dev_guide|utils",1,"Update dev guide and deprecate_pybind11 message to reflect the fact that it works on classes, top","""See [https://lsstc.slack.com/archives/C2JPL2DGD/p1573657708086900]    More pair-coding between [~lguy] and [~jbosch]."""
"DM-22231","Story","ts_qa",1,"Update XML tests for the new InfluxDB limitations","""With the move to InfluxDB, the column number and byte size limitations imposed by MySQL are removed.  This means the current suite of tests to very topics don't exceed those limitation are no longer necessary.  Additionally, InfluxDB introduces a new set of Reserved Words, see DM-22216.    This ticket tracks the work needed to remove the topic size tests, update the Reserved Words tests, as well as acts as documentation for this change.         The SAL Constraints documentation will also need to be updated:    [https://ts-xml.lsst.io/v/tickets-dm-20234/sal_constraints_and_recommendations.html#sal-topic-sizes]"""
"DM-22229","Story","ts_qa",2,"Write XML schema validation tests","""Testing the XML files as well-formatted and against a schema file requires an additional python tool, probably lxml.  This task covers the work necessary to update the docker image to install this tool and write the tests and test generator scripts, as well as implement those tests in the build."""
"DM-22219","Story","dm_dev_guide",1,"Add vscode configuration notes to dev guide","""Like the title says.  Hopefully in time for bootcamp."""
"DM-22218","Bug","Qserv",1,"Fix a bug in a configuration of the multi-master container","""Host name substitution in file:    doesn't follow changes in:     As a result of this the *{{mysql-proxy}}* service at *{{NCSA PDAC}}*  (*{{lsp-int}}*)  failed to start. This was also followed by this messages reported in the *{{xrootd}}* log file:    The further analysis has revealed that the host name of the master service in the template-based configuration file of the *{{xrootd}}* service was set incorrectly as:    In stead of the name of an actual host where the Qserv master container was being run (in a specific deployment at *{{NCSA}}*):                    """
"DM-22217","Bug","obs_lsst",1,"Do not over-fix obs_lsst detector bbox","""This is related to DM-18610.  While updating that, I mistakenly reset the detector BBox to the sum of the amplifier RawBBox values.  This is unneeded, and creates the over-padded images."""
"DM-22236","Story","ts_calibration",3,"Test whitelight CSC with real KiloArc","""Connect the Kiloarc lamp to ADAM    read the status lights on the KiloArc, which will be published as telemetry    verify that hitting the e-stop button results in an error status signal from Kiloarc, and this sends the CSC to fault state."""
"DM-22235","Story","base|meas_base",0.5,"Fix deprecated collections imports","""A couple of our packages are importing Mapping or Iterable from collections rather than collections.abc. Fix these."""
"DM-22258","Story","ap_pipe",1,"Monthly November ap_pipe HiTS rerun","""It is November? Time to reprocess the full HiTS dataset with ap_pipe. Stick with the higher-res templates until DM-21330 is complete."""
"DM-22254","Story","Requirements Documents",2,"File LCR to address LIT-292, removal of ""LSSTC Board"" language in LSR and OSS; flowdown to DMSR","""Refer to LIT-292 for the substance."""
"DM-22253","Story","pipe_analysis",2,"Audit usage of butler.get() in pipe_analysis scripts","""As an initial setup towards Gen3-ification of the {{pipe_analysis}} scripts, audit all usage of {{butler.get()}} to get a feeling for how easy it will be to convert them to Gen3-land."""
"DM-22275","Improvement","ts_main_telescope",1,"Filter telemetry in command_hexapod.py","""Ignore telemetry that change only slightly in {{command_hexapod.py}}. Add some jitter to the mock controller to exercise this change."""
"DM-22269","Improvement","ts_auxiliary_telescope|ts_middleware",0,"Add S3 support to salobj","""Add S3 support to salobj.    My plan to add the code I wrote as part of DM-21974 to salobj more or less """"as is"""" and update the documentation."""
"DM-22265","Bug","ts_main_telescope",0,"BaseMockController CLEAR_ERROR command broken","""Tiago reports:    The rotator CSC went to FAULT state... when trying to run the clearError  command I get the following:  """"Failed: module 'lsst.ts.hexrotcomm.enums' has no attribute 'CommandCode'"""""""
"DM-22260","Bug","afw",1,"Metadata is not persisted when persisting an ExposureCatalog to fits","""When writing an {{ExposureCatalog}} to FITS, the metadata property list is not persisted.  When writing a test case for this I ran into the problem that the case of the property list values is not always round-trippable ( https://community.lsst.org/t/fits-and-lowercase-header-keys/1184/3 ) but by looking at the header of the persisted file I see that this is unrelated to the current issue.  That is, the metadata is not persisted to the FITS file for an {{ExposureCatalog}} with any case.      {code:python}  import lsst.afw.table as afwTable  import lsst.daf.base as dafBase  import lsst.geom    name = 'TEST'    schema = afwTable.ExposureTable.makeMinimalSchema()  cat = afwTable.ExposureCatalog(schema)  cat.reserve(1)  rec = cat.addNew()    plist = dafBase.PropertyList()  plist.addDouble(name, 1.0)    cat.setMetadata(plist)    print(cat.getMetadata()[name])    cat.writeFits('%s_expcatalog_metadata.fits' % (name))    cat2 = afwTable.ExposureCatalog.readFits('%s_expcatalog_metadata.fits' % (name))    print(cat2.getMetadata()[name])    {code}  This results in a {{KeyError: 'TEST not found'}}.  """
"DM-22285","Story","pipe_analysis",1,"Update ups table in pipe_analysis to no longer require meas_mosaic","""{{meas_mosaic}} is not required to be setup for the {{pipe_analysis}} scripts. At present, one can still explicitly ask for {{meas_mosaic}} calibrations to be applied with the config {{useMeasMosaic=True}} (default is {{False}}), but should give you a helpful error message if you do ask for it and it’s not setup (i.e. {{import}} is in a {{try:}}).  The {{ups}} table needs to be updated to reflect this."""
"DM-22284","Improvement","ts_auxiliary_telescope|ts_main_telescope",2,"Implement RFC-639: Stop supporting changing simulation mode after a CSC is running","""Drop support for the {{setSimulationMode}} command.    * Add {{BaseCsc}} constructor argument {{simulation_mode}} and deprecate the old argument  {{initial_simulation_mode}}, but allow it to be specified for backwards compatibility.  * Update the documentation and unit tests accordingly.  * Update {{Controller}} to allow {{do_setSimulationMode}} to be missing This will allow me to remove the command from XML generics without breaking any code.  * File tickets to switch to the new argument in existing packages.  * File a ticket to remove the {{setSimulationMode}} command from the generic XML after the deprecation period expires  * File a ticket to remove the {{initial_simulation_mode}} argument from {{BaseCsc}} and a few subclasses after the deprecation period expires."""
"DM-22278","Improvement","ts_auxiliary_telescope",0,"ATDomeTrajectory: Rename settingsApplied event","""Implement CAP-356"""
"DM-22293","Improvement","ts_auxiliary_telescope|ts_main_telescope",2,"Make units and description available in salobj topics.","""SAL 4 includes units and description metadata for each field (as a comment appended to the line), as well as SAL and XML versions.    Parse these in salobj and:  * Make the units and description available as metadata from topics  * Make the SAL and XML versions available from SalInfo"""
"DM-22307","Improvement","ts_auxiliary_telescope|ts_main_telescope",0,"Test descriptions for arrays topics once DM-22303 is fixed","""test_idl_parser.py has a test for topic metadata with a code block that is disabled because description data is missing for arrays topics DM-22303.    The fix made it into ts_sal 4.1. Once that is accepted as the current version then this ticket can safely be implemented."""
"DM-22304","Improvement","ts_auxiliary_telescope|ts_main_telescope",0,"Delete the char0 field from Test arrays topics","""The char0 field should never have been part of the arrays topics for the Test component because char is a synonym for string and arrays of strings are not allowed.    I have slowly removed all code that requires char0 to be present. At this point I believe there is just one unit test in ts_salkafka that needs it, and I will fix that on the same ticket.    There is also some code in ts_salobj that handles char0 if present, but should work if the field is absent."""
"DM-22367","Story","ts_qa",1,"Create tests for the <RuntimeLanguages> tag in SALSubsystems.xml","""Add tests for the new tag in SALSubsystems.xml to allow specification of which languages we need to build support libraries and tests for.   e.g.    <RuntimeLanguages>cpp,java,python,pydds,labview</RuntimeLanguages>"""
"DM-22364","Bug","daf_butler",1,"Gen 3 Butler cannot be created using daf.butler.Config","""Trying to create a Gen 3 repository and a Butler to it using the idiom  {code:py}  config = Butler.makeRepo(root)  butler = Butler(config, run=""""test"""")  {code}  fails with an {{sqlalchemy.exc.OperationalError}} complaining that a {{run}} table does not exist. This behavior is surprising, as {{Butler.makeRepo}} is documented to return """"The updated {{Config}} instance written to the repo."""", while the {{Butler}} constructor is documented to take a {{Config}}.    In contrast, calling the {{Butler}} constructor with {{root}} in the above example does work."""
"DM-22363","Story","daf_butler",1,"Add ability for defefredDatasetHandles to retrieve dataset components","""If a task uses a deferredDatasetHandle, it should have the ability to fetch a component of the dataset if the handle wraps a composite object. Add that ability."""
"DM-22340","Improvement","ts_auxiliary_telescope",0,"Change ATDome and ATMCSSimulator to not need scons","""Change ts_ATDome and ts_ATMCSSimulator to not need scons.    Also fix a bug in ts_ATMCSSimulator: the TPVAJ.pva method mis-computes velocity and acceleration."""
"DM-22334","Story","ts_main_telescope",3,"TMA Preparation Week 1","""This task is to capture the work done in preparation for the TMA integration on December 2. """
"DM-22385","Story","ts_main_telescope",0,"Some tests are failing in ts_hexapod v0.2.0","""4 unit tests are failing in ts_hexapod v0.2.0. The cause is that I added jitter to the measured positions and didn't relax the comparison tolerances in the tests to accommodate."""
"DM-22382","Story","ts_middleware",1,"Add Configurable attribute to SALSubsystems XML","""A new Configuration attribute should be added to the SALSubsystems.xml file. The values of the attribute should be a single character of Y if a CSC is configurable and N if not."""
"DM-22379","Improvement","ts_middleware",1,"Implement RFC-643: make Version and Alias tags option in our XML","""Implement RFC-643: make the Version and Alias tags optional in ts_sal.    If possible please continue to check them as they are checked now, if present (in particular the Alias must match the topic name)."""
"DM-22378","Story","Third Party Software",0.5,"Allow rc version numbers in astropy eups package","""The check version script in the eups package of astropy does not understand release candidate version numbers. Fix it so that  trailing characters are ignored."""
"DM-22392","Story","ts_main_telescope",2,"Support the Hexapod Test on Summit","""Support the hexapod Test on summit."""
"DM-22389","Bug","verify",2,"verify fails with Astropy 4","""Doing a build with Astropy4 I now get failures from {{verify}} package relating to YAML serialization.     This works fine with the same version of YAML on Astropy 3 but fails on Astropy 4.    """
"DM-22388","Story","Third Party Software",2,"Investigate Astropy 4","""We have been asked to test Astropy 4 with the stack. Do some builds and see if anything breaks.    To do the install I:  * Made a fresh lsstsw deployment  * Removed astropy  * Updated pytest and pytest-* packages to get v5.3  * Followed instructions on https://github.com/astropy/astropy/wiki/v4.0-RC-testing to install astropy 4.0rc1  * Ran rebuild lsst_distrib"""
"DM-22386","Story","jointcal|Third Party Software",1,"Jointcal fails unit tests with Astropy 4","""I tested a stack build with Astropy 4.0rc1 and that resulted in jointcal failing unit tests.    To do the install I:    * Made a fresh lsstsw deployment  * Removed astropy  * Updated pytest and pytest-* packages to get v5.3  * Followed instructions on https://github.com/astropy/astropy/wiki/v4.0-RC-testing to install astropy 4.0rc1  * Ran rebuild lsst_distrib    The failures in jointcal all relate to numerical changes in the final chi2 for astrometry and photometry, e.g:        Jointcal passes with the default conda and pytest 5.3."""
"DM-22407","Story","ts_documentation",2,"Document Labview Steps & other steps","""Begin the documentation on the ts_sal repository. Currently there only exists PDF's outside of the repo. This is to create the SAL User Guide which will exist as a tech note. """
"DM-22406","Story","ts_auxiliary_telescope",2,"Assist in mass IP changes","""There is a rework going on with IT that will require the IP changes of many machines. [~ecoughlin] and I have split the machines on what is most relevant to our work. The table of machines that need IP changes is here [https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=LTS&title=Auxiliary+Telescope+Temporary+Deployment]"""
"DM-22404","Improvement","Qserv",8,"More efficient implementation of the replica management algorithms in Qserv Replication system","""The current implementation of algorithm *{{FixUpJob}}* puts too much stress on the underlying infrastructure by launching all required _fix-ups_ (request objects of class *{{FixUpRequest}}*) at once. This overloads the persistent database of the Replication/Ingest system where the state of the system is maintained. This also results in a significant (and unneeded) traffic between the Replication Controllers and Replication workers.    Hence, the first goal of this development is to implement a {{flow control}} within the algorithm, so that only a limited number of request were {{in-fight}} at a time.    The second task is to make the algorithm more stable if more than one catalog needed rebalancing. The current implementation's _iterative_ approach results in excessive number of replicas created by the job.    A similar problem exists with the replica purging algorithm *{{PurgeJob}}*. This needs to be addressed as well."""
"DM-22409","Story","meas_extensions_scarlet|pipelines_lsst_io",1,"Include meas_extensions_scarlet in pipelines.lsst.io","""As summary."""
"DM-22427","Bug","obs_lsst",0.5,"latitude and longitude are transposed in AUXTEL_LOCATION in obs_lsst","""Similar to DM-21990, the auxtel longitude and latitude are swapped in latiss.py:   [https://github.com/lsst/obs_lsst/blob/74b9cd0735010b908c28591630d1b55b21330d12/python/lsst/obs/lsst/translators/latiss.py#L30]"""
"DM-22426","Story","ts_auxiliary_telescope|ts_main_telescope",1,"Improve CSC startup and shutdown","""Improve CSC startup by not starting the heartbeat pulse until after the CSC is ready to receive commands. Make sure that the initial summary state is delayed until then, as well (but I think it already is).    Improve close methods on Domain, SalInfo and Controller so if close is called multiple times the later calls wait for closing to finish. This avoids nasty messages from asyncio in unit tests. Also improve SalInfo.close by giving time for the read loop to terminate.    Reduce duplication in ReadTopic.close by making a new private method to cancel callbacks."""
"DM-22417","Story","obs_base",1,"Remove python future from obs_base","""In DM-22234 I knew that obs_base used {{from past}} but it seems that I lost track of fixing it. Do the fix (again) here."""
"DM-22413","Story","ts_main_telescope",1,"Add error handling to XML parsing when loading setting files","""When loading XML setting files there is no check if the file is correctly loaded. This caused me to debug the code for a good amount of time, because it was causing a segmentation fault. I propose to add some error handling everywhere this files are loaded so that end users can easily notice this kind of issues, of example if files are corrupted or moved to another location."""
"DM-22412","Story","ts_main_telescope",1,"Bump OpenSplice version from 6.4.1 to 6.9","""Just to change makefiles from OpenSplice version from 6.4.1 to 6.9 to match the current version of ts_sal@v4.0"""
"DM-22460","Story","Science Pipelines|Verification",1,"Review test cases in S19 science pipelines acceptance test","""Review test cases proposed for the S19 science pipelines acceptance test campaign"""
"DM-22455","Story","Science Platform|SUIT",2,"Create a proper release of the Portal application","""Use the new Firefly build script feature in release-2019.3.2 to create a Portal application (""""suit"""" package) release as agreed with [~gcomoretto].    Fine-tune messages if there is a problem constructing the LSST TAP service URL."""
"DM-22453","Bug","validate_drp",1,"Update load to safe_load for yaml reading in validate_drp","""Update YAML loading to use {{safe_load}} in {{validate_drp}}.    1. Make trivial change to {{python/lsst/validate/drp/util.py}}.  Two lines.  2. Actually make sure the {{safe_load}} works beyond just making sure the Jenkins run passes.  Check to make sure the the yaml loading didn't change the logic of what validate_drp actually tries to do -- it still might succeed but it might skip half the tests.   Read the outputs, etc. to really make sure it's the same.  """
"DM-22479","Bug","verify",2,"SQuaSH being spammed with timestamps","""DM-22093 added a """"Task finished"""" timestamp to the metadata for all {{verify}} timing metrics. This inadvertantly caused the timestamps to be treated as tags in SQuaSH (see attached image), and will eventually bog down the server.    Change the timestamps from metadata to extras, which are not uploaded to SQuaSH. This is a breaking change, and will make accessing the data a bit clunkier:  {code:py}  measurement.notes[""""end""""]  measurement.extras[""""end""""].quantity  # yes, still a `str`  {code}"""
"DM-22474","Bug","ts_auxiliary_telescope",0,"run_atmcs_simulator.py is not executable","""bin/run_atmcs_simulator.py in ts_ATMCSSimulator is not marked as executable. Fix that with chmod +x."""
"DM-22473","Story","lsp-landing-page|Science Platform",2,"Landing page message note","""I know you’ve been looking at the landing page. Can you put something equivalent to this:        into the framing material of the page so that I don’t have to replicate it in each new MOTD text?  No rush at all on this."""
"DM-22469","Story","fgcmcal",3,"Add fgcmcal documentation tree","""{{fgcmcal}} does not currently build documentation that will go on https://pipelines.lsst.io . Add this directory and template files."""
"DM-22504","Improvement","ctrl_mpexec|Middleware",1,"Support for lsstDebug functionality in Gen3 middleware","""Following up the zoom session today, this ticket is about the support of {{--debug}} Gen2 command line option in the Gen3 middleware.    While it may not be a good idea to have interactive, execution blocking displays in pipeline code in the long term, there are some display implementations around. We need at least one execution mode (laptop activator; single process; via Jupyter?) when the existing lsstDebug based code can be run."""
"DM-22493","Story","Requirements Documents",1,"Release new version of LSE-61 (LCR-1933/LCR-1664)","""Make new release of LSE-61 with LCR-1933 and LCR-1664 included."""
"DM-22490","Improvement","ts_auxiliary_telescope|ts_main_telescope",1,"Please allow the Alias tag to be missing in ts_xml unit tests","""SAL 4.1 will allow the Alias tag to be missing from command and events. Please update the ts_xml unit tests to permit this."""
"DM-22487","Story","daf_butler",8,"Prototype Registry architecture for schema changes and (eventually) multiple layers","""Work is done (see [https://confluence.lsstcorp.org/display/DM/Architectural+Prototype+for+the+New+Gen3+Registry]); creating this ticket belatedly to record effort involved.     """
"DM-22485","Story","daf_butler",0.5,"Fix docstring heading to make example appear","""The example in the documentation for Butler.export doesn't appear in HTML because the heading is """"Example"""", not """"Examples""""."""
"DM-22481","Story","daf_butler",2,"Do not delete datastore directory on error","""[~dinob] discovered that two things go wrong when the datastore runs out of disk space:    1. The file partially written by the datastore does not get deleted.  2. If a directory was created by the put it tries to delete the directory but can't because the file is still there.    Item 1 should be fixed since we do not want partially written files left over in the datastore when a put fails.  Item 2 should be removed since it is possible that some other process is actively writing to the datastore and using that directory. The implication is that we should never try to remove directories if a transaction fails, solely files that are only under our control.  """
"DM-22520","Story","dm_dev_guide|templates",1,"Document topic support for pipeline tasks","""Documenteer has a {{lsst-pipelinetasks}} directive that works analogously to {{lsst-cmdlinetasks}}. However, it is not mentioned in either the [module topic documentation|https://developer.lsst.io/stack/module-homepage-topic-type.html] nor in the [package templates|https://raw.githubusercontent.com/lsst/templates/master/project_templates/stack_package/example/doc/lsst.example/index.rst]. As a result, tasks that get converted to {{PipelineTask}} will drop off the module documentation.    Add a {{lsst-pipelinetasks}} section to the template (possibly before {{lsst-cmdlinetasks}}, which is still relevant until the migration is complete) and update the developer guide to match. Updating the {{index.rst}} files of individual packages is out of scope for this issue."""
"DM-22517","Improvement","ts_middleware",1,"Please add metadata for the <name>ID field (i.e. a description).","""If it's not too much work, I would appreciate having descriptive metadata for the <name>ID field (e.g. TestID or ScriptID) in topics in the IDL file. It is conspicuous as the only field with no @Metadata comment.    We know what it is for, but I think many readers might not, as the name is not self-descriptive."""
"DM-22537","Bug","documenteer",0.5,"Update pyyaml.load usage in documenteer 0.4.x and 0.5.x","""[documenteer#63|https://github.com/lsst-sqre/documenteer/issues/63]:    {quote}  When running documenteer 0.4.5 with PyYAML 5.1 I get the following warning:    lsstsw3/miniconda/envs/lsst-scipipe/lib/python3.7/site-packages/documenteer/sphinxconfig/technoteconf.py:65:      YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.    _metadata = yaml.load(meta_stream)  Please update Documenteer's YAML usage accordingly (assuming that doing so wouldn't cause a PyYAML version conflict, of course).  {quote}    We'll release 0.4.7 and 0.5.5 with update {{yaml}} usage."""
"DM-22529","Story","ts_main_telescope",5,"Dome Software Deliverables document II","""This is continuation of DM-22451"""
"DM-22559","Story","Science Platform|SUIT",2,"Complete milestone DM-SUIT-8 - SUIT Portal integrated with workspace","""Verify that the SUIT Portal application has been integrated with the WebDAV-based workspace interface."""
"DM-22558","Improvement","ts_auxiliary_telescope|ts_main_telescope",0,"Remove the initial_simulation_mode argument from ts_salobj","""Remove the initial_simulation_mode argument from ts_salobj (constructors of BaseCsc, ConfigurableCsc and TestCsc) and delete existing unit tests that exercise it.    This argument is deprecated in ts_salobj 5.2 so I suggest not removing it until a few months after that is released."""
"DM-22557","Improvement","ts_auxiliary_telescope|ts_main_telescope",0,"Remove the setSimulationMode command from SALGenerics","""Implement RFC-639 by removing the generic setSimulationMode command.    Support for the setSimulationMode command was only implemented by ts_salobj and it was removed in 5.2, with a deprecation warning.  After a suitable deprecation period remove the setSimulationMode command from SALGenerics.    At this time ts_xml 4.5.1 is current so I suggest waiting for at least ts_xml 4.7 to be released before making this change.    ts_salobj 5.2 must be also released before making this change, but I expect that to occur shortly."""
"DM-22555","Improvement","ts_auxiliary_telescope",0,"Update ts_salobjATHexapod to use simulation_mode instead of initial_simulation_mode","""Update ts_salobjATHexapod to use simulation_mode instead of initial_simulation_mode because the latter is deprecated in ts_salobj 5.2.  """
"DM-22554","Improvement","ts_aos|ts_main_telescope",1,"Update ts_MTAOS to use simulation_mode instead of initial_simulation_mode","""Update ts_MTAOS to use simulation_mode instead of initial_simulation_mode because the latter is deprecated in ts_salobj 5.2. I am happy to do the work if you prefer; just reassign the ticket to me.    This ticket will also update some changes from the xml update (DM-22618)."""
"DM-22543","Story","HeaderService",2,"Create xml for CCHeaderService","""The xml code for ComCam HeaderService (CCHeaderService) needs to be revised to be compatible with ComCam"""
"DM-22579","Story","mops",2,"Implement and Test Curtis's IOD Iterator","""In testing and validating Gauss's method for IOD we found that the initial guess of the orbit could be off by as much as ~10,000 km (idealized inputs with no astrometric error). Gauss's method is fundamentally not closed-form and uses an approximation to compute a potential target's state vector.  To improve the initial orbit, some astrodynamics textbooks suggest iterating over the initial orbit (for example, using the guess of the state to compute the 'exact' equations for the Lagrange coefficients). We selected Howard Curtis' algorithm for iterative improvement and need to test if it will work as an additional component of IOD. """
"DM-22576","Story","astro_metadata_translator",2,"Add programmatic header fixups to astro_metadata_translator","""In DM-22550 a bunch of files had the wrong filter. This could be fixed by the current scheme of per-file fixups but during that I realized that LSST_NUM is missing for the entirety of November. Providing a fixup file seems like the wrong answer to fix a month of data.    This ticket experiments with adding programmatic fixups as well as the existing scheme. The downside of programmatic fixups is that we might end up with every header having date strings parsed twice -- once to see if a date of interest is in play for header fix up, and again when the fixed header is translated."""
"DM-22575","Story","ts_calibration",1,"MTAlignment CSC: Mock T2SA Server Skeleton","""simple tcp server that will emulate the T2SA application for testing"""
"DM-22567","Story","ts_auxiliary_telescope",0,"Make GenericCamera Pip installable","""Make GenericCamera package pip installable."""
"DM-22566","Story","ts_middleware",1,"Create SAL artifact yum repo on nexus server","""A yum repository for SAL artifacts needs to be created on the new nexus server. The yum repo should be able to receive release (master) and develop artifacts."""
"DM-22565","Improvement","ts_auxiliary_telescope|ts_main_telescope",0,"Further cleanups in ts_simactuators","""I missed some cleanups in ts_simactuators 0.1. Use """"position"""", """"velocity"""" and """"acceleration"""" reliably and replace """"direction"""" with """"direction_factor""""."""
"DM-22603","Story","ts_calibration",2,"unit tests for mtalignment","""unit tests for MTAlignment Model, and the mock controller underneath. """
"DM-22602","Story","ts_calibration",2,"Alignment model, add support for basic commands","""add support for commands to model"""
"DM-22601","Story","ts_calibration",1,"MTAlignment Model skeleton","""build a skeleton model for the alignment CSC"""
"DM-22600","Story","ts_calibration",2,"Mock T2SA, docstrings and expand set of supported commands","""now we have a skeleton, flesh out the documentation a bit and add support for more of the API"""
"DM-22599","Story","pipe_base",8,"Develop PipelineTask unit test framework","""Most of our new pipeline tasks' functionality can be tested by writing unit tests against {{run}} or more specific methods (in theory, these tests should be identical to those from the Gen 2 era). However, such tests do not verify:   * whether a task's {{Connections}} are correctly written and whether they match the inputs and outputs of the {{run}} method   * any logic in a custom {{runQuantum}} method   * configuration logic, such as optional or alternative inputs or outputs    Since the Gen 3 API is unfamiliar to us, these aspects of a {{PipelineTask}} are the ones that are most likely to have bugs.    Currently, the only way to test these features is in large-scale runs on Gen 3 repositories (e.g., HSC). Such tests, while valuable, can only exercise a small subset of conditions (e.g., configs), can be expensive to debug (e.g., due to cascading failures), and do not protect against regressions (no CI). A {{pytest}}-compatible framework that lets us test those parts of a {{PipelineTask}} that lie _outside_ {{run}} will let us catch problems much faster.    As part of DM-21875, I created a prototype [test framework for direct Butler I/O|https://github.com/lsst/verify/blob/b3f960befa179cee8050cdf380fd16c8a2acbafd/tests/butler_utils.py] and used it to verify that datasets could be stored to and retrieved from a dummy, obs-agnostic repository. I believe the same approach can be used to test {{PipelineTask}} functionality without the need to simulate a """"realistic"""" Butler or depend on {{obs}} packages.    Desired features:   * a natural way for the test author to provide mock data IDs for the repository. The appropriate IDs will depend on the task being tested. It should be possible to simplify this from the prototype code, since most of the complexity of the Gen 3 Dimensions system is not needed for most tests; an exception may be {{ImageDifferenceTask}}'s mix of detector-level and patch-level inputs.   * a simple activator that calls {{runQuantum}} without modifications other than mocking {{run}}   * a way to test that the desired inputs get passed to {{run}}, including self-consistent use of config flags -and templates-. This will probably involve mocking {{run}} and may involve mock datasets, which are more technically challenging.   * a way to verify the output of a (real) {{run}} call against a configured connections object   * -analogous support for {{\_\_init\_\_}} inputs and outputs, which I'm less familiar with-"""
"DM-22584","Story","dm_dev_guide",1,"Update developer guide to refer to “milestone” issue type","""We seem to have grown a new issue type. Let's make sure people don't use it."""
"DM-22621","Bug","ts_main_telescope",1,"MTM1M3 - use of InfluxDB Reserved Words","""The MTM1M3 Telemetry XML file uses the InfluxDB reserved word MEASUREMENT, one or more times."""
"DM-22618","Bug","ts_main_telescope",0,"MTAOS - use of InfluxDB Reserved Words","""The MTAOS Telemetry XML file uses the InfluxDB reserved word DURATION, one or more times."""
"DM-22647","Bug","ip_isr",1,"Bug in isrMock.getCamera's use of CameraWrapper","""There's a bug in {{IsrMock}}'s use of {{CameraWrapper}}: CameraWrapper takes three kwargs, the last of which is {{isLsstLike}}, but it's only passing {{isLsstLike}} as a single arg. If we ever set that to be False, this would fail immediately. Instead, it's always forcing the plateScale to be 1.0.    See isrMock.py line 502 and compare that with {{CameraWrapper.\_\_init\_\_}}."""
"DM-22644","Story","Third Party Software",1,"Add torr unit to Astropy","""CAP-396 requires torr unit support in Astropy. File a one line pull request with Astropy."""
"DM-22643","Improvement","pipe_drivers|pipe_tasks",2,"convert visualizeVisit to gen3","""The current gen2 visualizeVisit.py is not a valid pipelineTask, and does not conform to gen3 defaults.  Implementing this as a pipelineTask allows binned focal plane images to be appended to other pipelines."""
"DM-22641","Bug","ap_verify",1,"ap_verify CI broken","""Recent Jenkins runs such as [scipipe/ap_verify#438|https://ci.lsst.codes/blue/organizations/jenkins/scipipe%2Fap_verify/detail/ap_verify/438/] have been failing with the following error:      This bug was most likely introduced by DM-21911, specifically by not testing {{ap_verify}} after [lsst/verify@e1015bc|https://github.com/lsst/verify/commit/e1015bc09cccfe6ddbaed01d077b604cddc7609b]. Update the {{ap_verify}} default configs to match."""
"DM-22677","Story","daf_butler",1,"Modernize python scripts in daf_butler","""The three python scripts in daf_butler use the old style approach of parsing arguments directly.  This is now deprecated and we should instead move all the code to the python module and have one line in the scripts themselves.    This allows for:    1. Unit testing of more of the code  2. Inclusion of scripts in sphinx documentation."""
"DM-22676","Story","ap_verify",2,"Create gaia dr2 refcat for ap_verify_hits2015","""I'm using {{ap_verify_ci_hits2015}} to test my gen2->gen3 repo converter code, and I ran into a problem due to the use of the gaia dr1 refcat, which uses htm depth=8. Gen3 repos all have to use depth=7 for the moment. The easiest solution is to just extract the necessary pixels from the new gaia dr2 refcat and replace the old one in ap_verify_hits. That also gains us an upgraded reference catalog.    This should be an easy change to {{scripts/gaia_HiTS_2015.py}} and then a bit of processing on lsst-dev."""
"DM-22673","Story","ts_main_telescope",2,"Format ts_m1m3support code to DM guidelines","""The code should be formatted in agreement with https://developer.lsst.io/cpp/style.html, and therefore the Google Style Guide (https://google.github.io/styleguide/cppguide.html). This will make it easier to work with this codebase."""
"DM-22662","Bug","ts_main_telescope",0,"Fix error in hexapod telemetry structure","""The Telemetry struct in ts_hexapod has an error: the {{application_status}} should be of type {{uint32}} but is defined as {{uint16}}."""
"DM-22661","Bug","ip_isr",2,"isrTask failed to find master flat due to filter difference","""I'm working on analyzing the spot data from the BOT. I have a notebook at /home/cslage/BOT/notebooks/Ingest_BOT_ITL_Spots_16Dec19.ipynb that ingests the data, creates the calibration products and then does the ISR on a spot image. Everything is working except when isrConfig.doFlat=True. Then I get an error that says:    The master flat was successfully created, and is there in the CALIB directory, but it can't find it.  Apparently the problem is that the filters used for the flats include neutral density filters, which aren't used for the spots.  The filter for the flat appears to be:  SDSSi+ND_OD0.5, and the filter for the spots should be SDSSi, although it appears that it wasn't set so it returns NONE.  I tried setting isrConfig.fallbackFilterName='SDSSi+ND_OD0.5', but it still couldnt find the master flat.     """
"DM-22656","Improvement","Qserv",3,"Improved Configuration service of the Replication System","""The current API of the Configuration system has a number of the property *set*(-ing) methods which modify both the transient state of the configuration of a process and the persistent state of the system-wide configuration. For example:  {code:C++}  class Configuration: public ConfigurationIFace {  public:      ...      unsigned int controllerRequestTimeoutSec() const final;      void setControllerRequestTimeoutSec(unsigned int val) final;      ...  };    The default value of the parameter would leave the behavior of the existing applications intact. Only those applications which are not supposed to modify the persistent state will need to be migrated to explicitly avoid updating that state.    Migrate the following controller applications to the extended interface:  """
"DM-22708","Story","daf_butler|Middleware|obs_base|obs_decam",8,"Fix decam gen3 ingest","""It turns out the work I did on decam for DM-20763 was not complete: I only tested that one dataId could be retrieved from the ingested raw data, but there are two ccds in that file in two different HDUs and the second one is not actually getting ingested. The gen2 CameraMapper path for a decam raw looks like {{decam%(visit)07d.fits.fz[%(hdu)d]}}, so the hdu number is baked in there.  As far as I can tell, gen3 doesn't have any way to encode hdu number. Maybe this has to be a further specialization in the RawFormatter. File paths that go into butler.ingest have to actually exist, so we will have to do something to the raw paths that we pass into `butler.ingest`.    The gen2 butler registry has an `hdu` field that encodes which hdu to get that raw from. It doesn't look like there's an equivalent `hdu` field anywhere in the gen3 registry: could we add an extra `hdu` field to the `posix_datastore_records` table? That's my best guess as to where it should live."""
"DM-22704","Improvement","obs_lsst",1,"filter 'diffuser' cannot be read","""For the gen3 middleware demo, I needed to add     {code:python}  if self.observationInfo.physical_filter == 'diffuser':                                         lsst.afw.image.utils.defineFilter(""""diffuser"""", 555.0)  {code}  to lsst.obs.base.fitsRawFormatterBase.FitsRawFormatterBase.makeFilter() to make reading raw data work."""
"DM-22702","Story","ts_deployment",1,"Deploy T&S Components at NCSA.","""Task to finalize deployment of T&S components at NCSA"""
"DM-22700","Story","ts_aos",1,"Include command to add offsets to the lookup tables in ATAOS. ","""One of the things we figured we may want to do with the ATAOS is to be able to apply offsets on the current look up tables. This task is to include a command on ATAOS to enable that capability."""
"DM-22688","Bug","ts_main_telescope",1,"CLONE - MTM1M3 - use of InfluxDB Reserved Words","""The MTM1M3 Telemetry XML file uses the InfluxDB reserved word MEASUREMENT, one or more times."""
"DM-22727","Story","ap_association",2,"Add numpy warnings catch to DiaCalculationPlugins","""Some DiaCalculation plugins throw numpy warnings while calculating results that are unnecessary. But such clauses in a context manager to catch and ignore these warnings."""
"DM-22726","Improvement","ts_middleware",1,"Please allow empty topics in our SAL XML files","""Please allow our SAL XML files to define topics with no fields.    This is much cleaner than defining a field whose sole purpose is to be ignored. Furthermore [~tjohnson] has a use case for ignoring such fields and it takes specially coding to handle it. If the field was simply absent he could presumably drop that code."""
"DM-22714","Bug","ts_auxiliary_telescope|ts_main_telescope",0,"Fix warnings.warning","""Adopt improvements from DM-22627."""
"DM-22731","Story","ts_deployment",1,"Redeployment of summit components","""After the last run with the AT there where some bug fixes and configuration changes needed. Most of the work was done on DM-22531. This task is to clean up all the components that where deployed with non-tagged repositories and also to switch up the kafka producers to publish data to the new EFD deployment. """
"DM-22729","Story","ap_pipe",8,"Monthly December ap_pipe rerun","""This is the ~monthly ap_pipe rerun of the HiTS 2015 dataset (all 3 fields). For the first time, I will use templates with the DECam instrumental pixel scale (0.26""""/pixel). The rerun will be in {{/project/mrawls/hits2015/rerun/cw_2019_12}} and an accompanying """"quick look"""" analysis notebook will be made."""
"DM-22748","Story","ts_aos|ts_main_telescope",1,"Restrict the Command in Specific State for MTAOS","""Need to restrict the command to be only available on the specific state. For example, some commands are only allowed in Enabled state."""
"DM-22747","Story","ts_aos|ts_main_telescope",2,"Support the Log File for MTAOS","""The MTAOS does not support the logging file now. I realized this should be helpful to debug in the test with multiple components."""
"DM-22766","Improvement","ts_auxiliary_telescope|ts_main_telescope",1,"Add an unacknowledge command to the Watcher","""Add an """"unacknowledge"""" command to the Watcher CSC.    This is easy because the Model already supports it.    LOVE will have to be updated in order to actually use it, but there's no rush on that."""
"DM-22764","Bug","ts_auxiliary_telescope|ts_main_telescope",0,"Watcher event timestamps must be double, not float","""The Watcher event's timestamps are float, which does not have enough precision to do the job. Use double instead."""
"DM-22770","Story","obs_base|pipe_tasks",1,"Remove duplication of BaseMapper","""pipe_tasks' {{tests/test_read_CuratedCalibs.py}} contains a copy of {{BaseMapper}} from obs_base's {{tests/test_cameraMapper.py}}. Not only is that ugly, it's also fragile (see DM-22769).    Rearrange things so that pipe_tasks can import {{BaseMapper}} from obs_base directly."""
"DM-22774","Improvement","ap_verify|Continuous Integration",1,"Store APDB in ap_verify Jenkins artifacts","""The {{ap_verify}} CI job creates SQLite databases in {{<dataset-dir>/association.db}}. These databases contain valuable debugging information that can't be represented by metrics (e.g., individual source IDs and locations). It would be useful if these database files were stored for later analysis.    [~krughoff] pointed to [ap_verify.groovy|https://github.com/lsst-dm/jenkins-dm-jobs/blob/master/pipelines/scipipe/ap_verify.groovy#L391-L394] as the code that needs changing."""
"DM-22773","Story","ts_main_telescope",1,"Review the Document of Simulink Model by Moog","""Review the document of Simulink to have the understanding of model for the debug of rotator track issue."""
"DM-22780","Improvement","ts_middleware",1,"ts_sal IDL generation mis-handles topics whose names differ only in case","""I modified Rotator_Telemetry.xml to have both the old {{Application}} topic, with fields names that started with uppercase, and a new {{application}} topic, whose field names start with lowercase:      The resulting IDL file combined these two topics into a single topic:    which, strangely, has the field names from one and the topic name from the other, thus matching neither.    I realize that having two topics that differ by case is rare, and I'm not convinced we should allow it at all. But if we prohibit it, then could you please reject the XML? Or if you think we should support it, then please fix the IDL generator."""
"DM-22779","Story","ts_main_telescope",1,"Organize and Clean the Code of Rotator GUI","""Organize and clean the code of rotator GUI. The code delivered by Moog contains everything (middleware, hexapod and rotator GUIs, simulink model, and hexapod and rotator wrappers in PXI) and hard to update the code. This task will separate the rotator GUI code to a single repository and organize the VIs in the project. This will help for the future's update."""
"DM-22784","Story","ts_main_telescope",0,"Take the Onramp Course of Simulink on MathWork Website","""Take the onramp Simulink course on MathWork website to have the initial understanding of the use of Simulink. This should be helpful to review the model by Moog for the control algorithm. """
"DM-22783","Story","ts_main_telescope",3,"Fix the M2 Control Code for SAL Command Phase 1","""Fix the M2 control code to be able to feedback the SAL command. It looks like the M2 control code will reject all received SAL command. Need to figure out the reason. This is the phase 1."""
"DM-22782","Story","ts_main_telescope",1,"Organize and Clean the Code of Hexapod GUI","""Organize and clean the code of hexapod GUI. The code delivered by Moog contains everything (middleware, hexapod and rotator GUIs, simulink model, and hexapod and rotator wrappers in PXI) and hard to update the code. This task will separate the hexapod GUI code to a single repository and organize the VIs in the project. This will help for the future's update."""
"DM-22796","Story","pipe_tasks",1,"pipe_tasks installs 200MB of temporary test output","""When pipe_tasks runs its tests it generates a single temporary output directory containing 200MB of files. These are installed. They serve no useful purpose in the installation.    I propose that we clean up the temp directory when the tests complete successfully and leave it around if the tests fail (much like we do with lsst_ci; see DM-22305)."""
"DM-22794","Story","obs_base",1,"obs_base tests should not use daf_butler test configs","""[~swinbank] has noted that obs_base tests depend on a private butler config test file in DAF_BUTLER_DIR/tests/config.  Those configs are not meant to be used outside of daf_butler since they contain unexpected formatters and storage classes designed specifically for internal daf_butler tests.  obs_base should not be relying on those configurations.  It should be sufficient for obs_base to use a default configuration made by {{Butler.makeRepo}}.    I'm not entirely sure whether I should fix this or whether this should be handled by science pipelines."""
"DM-22792","Story","ts_qa",2,"Define the AuxTel CSC build and packaging process","""I need to meet with Tiago and discuss exactly the process for building and packagin the AT CSCs.   * What is pulled from Nexus   * Build steps   * Unit testing   * Packaging details (format)"""
"DM-22791","Story","ts_qa",1,"Update Jenkins jobs to point to the Nexus3 production server","""Various Jenkins jobs were pushing to the temporary Nexus3 repo.  Now that the production server, [https://repo-nexus.lsst.org/nexus/], has been created, update the jobs to use this server.    This task covers the work to update the Jobs and run them to ensure they work."""
"DM-22790","Story","pex_config",0.5,"pex_config FutureWarning reports wrong line number","""The {{warnings.warn}} call in pex_config that warns about a deprecated config item, reports a line number inside pex_config when it should be reporting a line number in user code. Add stacklevel=2 to the call."""
"DM-22789","Epic","ts_qa",40,"End-to-End Build/Deploy/Test","""Clean up and update the SAL/XML Jenkins jobs and processes for a full build/test/deploy process.    for more details, please see [https://confluence.lsstcorp.org/pages/viewpage.action?pageId=120783026]     """
"DM-22788","Story","verify",1,"Responses tests fail with modern responses and old requests","""The test_squash.py is failing for me locally because I have responses installed on my stack but this does not play well with the old EUPS requests package. If I unsetup requests and let the code use my conda requests the tests pass without a problem.    I think [~gpdf] has been worrying about our old {{requests}} package for a while now. Since {{requests}} is formally listed in the conda baseline and since no other package in lsst_distrib uses requests,  I think the easiest fix is to remove requests from the table file for verify."""
"DM-22810","Story","Science Platform",2,"Run bokeh app from within nublado","""Since JupyterLab proxies ports out of the container, it should be possible to access bokeh apps running from within a JL container."""
"DM-22803","Story","validate_drp",1,"validate_drp and numpy1.17/astropy4/matplotlib3.1 fails","""I'm testing the science pipelines with numpy1.17/astropy4/matplotlib3.1 and validate_drp fails:        The root cause seems to be that in {{plotPhotometryErrorModel}} the {{mmagRmsHighSnr}} variable is empty because there are no high signal to noise measurements.  For the current astropy/numpy/matplotlib this triggers:      but continues regardless. With newer versions it fails badly in Astropy with an index lookup gone bad.  This is arguably a bug in Astropy that should be a bit more defensive, but it also seems to me that we shouldn't be asking matplotlib to calculate a histogram with no data in it.    The quick fix would seem to me to be to not try to plot the histogram if there are no data. Is that acceptable?  Are we expecting there to be any numbers from the bright mask?    This does make the tests pass:  {code:diff}  diff --git a/python/lsst/validate/drp/plot.py b/python/lsst/validate/drp/plot.py  index 36a3cff..3ab6c58 100644  --- a/python/lsst/validate/drp/plot.py  +++ b/python/lsst/validate/drp/plot.py  @@ -118,8 +118,9 @@ def plotAstrometryErrorModel(dataset, astromModel, outputPrefix=''):          ax[0].hist(dist, bins=100, color=color['all'],                  histtype='stepfilled', orientation='horizontal')  -    ax[0].hist(dist[bright], bins=100, color=color['bright'],  -               histtype='stepfilled', orientation='horizontal')  +    if len(dist[bright]):  +        ax[0].hist(dist[bright], bins=100, color=color['bright'],  +                   histtype='stepfilled', orientation='horizontal')          ax[0].set_ylim([0., 500.])       ax[0].set_ylabel(""""Distance [{unit:latex}]"""".format(unit=dist.unit))  @@ -307,10 +308,11 @@ def plotPhotometryErrorModel(dataset, photomModel,       ax[0][0].hist(mmagRms,                     bins=100, range=(0, 500), color=color['all'],                     histtype='stepfilled', orientation='horizontal')  -    ax[0][0].hist(mmagRmsHighSnr,  -                  bins=100, range=(0, 500),  -                  color=color['bright'],  -                  histtype='stepfilled', orientation='horizontal')  +    if len(mmagRmsHighSnr):  +        ax[0][0].hist(mmagRmsHighSnr,  +                      bins=100, range=(0, 500),  +                      color=color['bright'],  +                      histtype='stepfilled', orientation='horizontal')       plotOutlinedAxline(           ax[0][0].axhline,           mmagrms_median.value,  {code}"""
"DM-22798","Story","fgcmcal",1,"Remove (unused) ability for fgcmcal to run on a full repo without specifying any ids","""In the course of finishing DM-20163, I realized that the functionality in {{fgcmcal}} to run on a full repo without specifying any {{--id}} on the command line was only being used by the test code, and not in general use (or by the cookbook).  This removal of functionality and clarification of the cookbook and documentation has been split out from DM-20163 since it is logically distinct.  This update will also make it easier to convert {{fgcmcal}} to a {{PipelineTask}}."""
"DM-22851","Bug","ctrl_mpexec",1,"Remove extraneous line breaks in pipeline --show=config output","""The output from {{pipeline ... --show=config}} occasionally can contain some extra newlines in it, here are examples.    This is an expected output:      and this one shows those extra line breaks:      Difference between two commands is a filter added to --show=config option, I guess there is a code that is broken when tat filtering option is used."""
"DM-22824","Story","obs_lsst",2,"Add QE, gain, read noise to as built camera.","""This requires two things.      First, moving QE curves measured in the ts8 to the appropriate location for the as installed rafts.    Second, updating the camera geometry files with the as built electronic properties.    This issue will implement this for one raft and document the process.  Then, it should then be repeated for the other rafts as they become available."""
"DM-22821","Bug","ts_auxiliary_telescope|ts_main_telescope",1,"Cannot create a Controller for a component with no commands","""It turns out not to be possible to create a salobj Controller for a SAL component that has no commands. salobj complains that there is no ackcmd topic (and indeed there is not).    LOVE is the component that showed this problem."""
"DM-22819","Story","ts_auxiliary_telescope|ts_main_telescope",0,"Add logLevel event to LOVE XML","""The LOVE XML needs a logLevel event in order for INRIA to create a LOVE Controller."""
"DM-22818","Story","fgcmcal",1,"Matplotlib 3.1 bug triggered by fgcmcal on macOS","""I'm testing an updated conda environment. fgcmcal didn't work because it got into an infinite cycle of C++ exceptions.      This was when running {{tests/test_fgcmcal_hsc.py}}."""
"DM-22955","Story","obs_subaru",1,"Add spatially varying HSC NB filters to obs_subaru","""We recently received spatially varying filter scans for the HSC NB filters.  These will be necessary to run {{fgcmcal}} on HSC NB filters.  The raw files will be formatted to put into {{obs_subaru}} {{filterTraces.py}}"""
"DM-23025","Story","lsst-texmf",1,"Clarify prompt processing-related definitions in the DM glossary","""The DM glossary has (what I think is) a slightly confusing discussion of the relationship between Prompt Processing, Alert Production and Solar System Processing. Please clarify it."""
"DM-23023","Improvement","ip_isr",8,"Simplify linearity corrections","""The default linearityType is PROPORTIONAL, which is not implemented anywhere.  This should be fixed, so that detectors that do not require linearity correction have a clear NOOP.    A related issue is to allow the linearity defined by the detector to be overridden.  This would make testing new corrections easier."""
"DM-23009","Story","HeaderService",2,"Update ATHeaderService for changes on ts_xml 4.6.0","""The new ts_xml 4.6.0 changed the {{ATSpectrograph_logevent_settingsApplied}} to {{ATSpectrograph_logevent_settingsAppliedValues}} and therefore the ATHeaderService configuration and simulator need to be updated."""
"DM-23008","Story","pipe_tasks",5,"Add DCR model subfilters to Gen3 registry","""Follow the procedure that was done for registering the SkyMap, and do the same thing for subfilters. Need to figure out exactly that procedure is!"""
"DM-23044","Story","cp_pipe|obs_base",2,"PTC task should persist usable linearity models","""Store the output of DM-21221 in some meaningful form using the Butler, and demonstrate that it can be used in downstream processing."""
"DM-23036","Story","fgcmcal",2,"Add ability for fgcmcal to do calibrations on local background-corrected fluxes","""Investigation of calibration errors has shown that improvements can be made by performing local background subtraction on the aperture fluxes.  These will bring the faint stars more in line with the bright stars, and should only improve calibrations (decreasing bias and scatter for bright stars), and this ticket does not imply that these corrections should necessarily be made outside of calibration, or to fluxes other than aperture fluxes used for calibration."""
"DM-23034","Improvement","cbp",2,"Update cbp for changes in how Cameras and Detectors are built","""Please update the cbp package for change in how Detectors and Cameras are built.    I suggest you use the tickets/DM-20488 branch or base your branch off of that one. Or, if you prefer, cherry-pick those changes.    I think the main class that needs updating is SampleCoordinateConverter in testUtils.py.  I had a try at this myself (see attached file), and was able to make a list of Detectors and get rid of the no-longer-needed AmpInfoTable (the test code doesn't care about amplifiers), but could not figure out how to create a Camera (nor verify that the Detectors I made were correct)."""
"DM-23069","Story","ap_pipe",8,"Monthly January ap_pipe rerun","""This is the ~monthly ap_pipe rerun of the HiTS 2015 dataset (all 3 fields). This time we should see if setting {{nImagesMax}} in the best seeing selector will work with the new slurm template generation. To be clear, this rerun should include generating new templates as well as running ap_pipe.    Optional bonus level and/or spinoff ticket: adopt the templates generated as part of this rerun as the new default in the ap_verify datasets."""
"DM-23058","Story","ts_environment",2,"HVAC XML to MQTT","""Create XML SAL bindings for the MQTT telemetry subset."""
"DM-23057","Story","ts_main_telescope",3,"Fix the M2 Cell System in Phase 1","""Fix the bugs found in the M2 cell system. This task is the phase 1.    Founded bugs:   # The log file can not be generated after rebooting the cRIO. (Done)   # The state can not transit after rebooting the cRIO.   # TCP/IP connection is easy to break. (Partially done.)"""
"DM-23056","Story","afw",2,"Suppress FutureWarnings from LSST code","""Since DM-17566 landed, we're generating a bunch of FutureWarnings from inside DM code. Please suppress them."""
"DM-23085","Story","meas_algorithms",1,"Deprecate SourceDetectionTask.makeSourceCatalog","""Per [discussion at the DM-CCB|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=125240021], {{SourceDetectionTask.makeSourceCatalog}} is to be removed in Pipelines release 21.0.0. Please add the appropriate deprecation notices to release 20.0.0."""
"DM-23084","Bug","Qserv",0.5,"Fix Qserv container builds","""Qerve container build scripts are busted downstream of pytest no-longer being published via eups distrib.  Remove explicit eups distrib install from scripts, since pytest is now made available in the build environment via conda."""
"DM-23082","Story","efd",1,"Document EfdClient classes and methods","""Implement the docstrings for the {{lsst-efd-client}} classes and functions."""
"DM-23080","Story","daf_butler",2,"Move dimension Registry code into helper classes","""This implements the DimensionTableRecords and DimensionTableManager classes described in the [prototype document|https://confluence.lsstcorp.org/display/DM/Architectural+Prototype+for+the+New+Gen3+Registry]."""
"DM-23079","Story","daf_butler",1,"Move opaque table Registry code into helper classes","""This implements the OpaqueTableRecords and OpaqueTableManager classes described in the [prototype document|https://confluence.lsstcorp.org/display/DM/Architectural+Prototype+for+the+New+Gen3+Registry]."""
"DM-23077","Story","meas_algorithms",2,"Update default interpolation for Curve classes","""Currently, the behavior is to throw an exception if interpolation outside the curve boundaries is attempted.  It seems like a better default, would be to clamp to zero outside the boundary.  I can imagine this would not be the case for all possible curves, so I will try to make this configurable."""
"DM-23095","Story","documenteer",0.5,"Remove pytest-runner from Documenteer 0.5.x","""Create a patch release in the Documenteer 0.5 line that eliminates any use of pytest-runner. This is intended to avoid difficulties getting Documenteer built on Conda.    pytest-runner is already being removed from the Documenteer 0.6 release via DM-22957."""
"DM-23092","Story","ts_main_telescope",1,"Check position limits for Hexapod move and offset commands","""The main telescope Hexapod should check limits for position and offset commands and reject the command if out of bounds."""
"DM-23090","Story","obs_lsst",1,"Update LATISS filters in obs_lsst to match commissioning filters","""The filter list from DM-23075 must be added to obs_lsst to allow ingest of LATISS data by butler."""
"DM-23087","Improvement","Qserv",8,"Batch mode for allocating chunks during catalog ingests in Qserv","""The current implementation of the Ingest system's {{REST}} service only allows single chunk allocations. This mode of operation has a noticeable overhead which translates into significant delays when ingesting large numbers (up to a few hours for catalogs comprising 150,000) of chunks . Each such chunk allocation requires executing a number of the relatively expensive queries against the persistent state of the Replication system.     Hence, a goal of this effort is to introduce the _batch_ mode for allocating chunks, which would significantly reduce the above mentioned overhead. A new REST service will be added to the Web server of the *Master Replication Controller*:  || method || url || input || output ||  | POST | /ingest/v1/chunk | {chunk,transaction_id} | {worker,port} |  | POST | /ingest/v1/chunks | a list of {chunk ,transaction_id} | a list of {chunk,worker,port} |"""
"DM-23115","Epic","ts_main_telescope",40,"TMA Work Phase 3","""TMA Training & Review of Labview-based vendor software in Tucson & Spain.    TMA CSC design, creation & implementation.    Also any on-going work & support regarding the TMA.    This is a continuation of -DM-19848,- DM-21537"""
"DM-23108","Story","ts_qa",3,"Create a CI build for a CSC","""See DM-18175 for the original intent of that task."""
"DM-23107","Story","ts_qa",3,"Create an IDL conda package job","""Similar to the salobj conda package job, the next step is to create a job to create a conda package of the IDL files and the ts_idl repo.  See DM-18175 for details on the salobj conda package job for guidance on creating this job.     """
"DM-23106","Story","ts_qa",2,"Use Jenkins parallel stage functionality to thread the salgenerator jobs","""In looking for ways to speed up the generation of the RPMs, I found that Jenkins pipelines can run stages in parallel.  See if this functionality can work.    https://jenkins.io/blog/2017/09/25/declarative-1/"""
"DM-23117","Story","ts_main_telescope",2,"Fix the M2 TCP/IP Connectioin","""TCP/IP connection between M2 control and cell systems is easy to break."""
"DM-23132","Story","ts_auxiliary_telescope|ts_main_telescope",0,"Update ts_xml schema to permit 0 occurrences of Author in topics","""Implement RFC-657 by updating the schema in ts_xml to allow the Author tag to be omitted from topics."""
"DM-23131","Story","afw",1,"Fix ""unordered"" map documentation in DetectorCollection getters","""from [~sogo.mineo] on Slack  {quote}  The comment just above this method says """"Get an unordered map"""", but it returns a binary-tree map instead:  [https://github.com/lsst/afw/blob/6637c4fb6fa5813268496d76dcd9e97cbd417bcc/include/lsst/afw/cameraGeom/DetectorCollection.h#L62]  {quote}    We should just fix the docs; we probably have code that now depends on these being ordered, and it's not unreasonable for them to be ordered."""
"DM-23130","Story","ts_main_telescope",5,"Testing of Camera Hexapod SAL CSC","""Testing the Camera Hexapod for the week of the 13th to the 17th. Completed on the 17th. Also helped Roberto and Mario finish hardware tests."""
"DM-23129","Story","obs_base",2,"Update obs_base ingest RawFileData for multi-dataId files","""In DM-23024 I changed FileDataset to support a list of DatasetRef and updated obs_base ingest to work with that.  What I did not do is update RawFileData to allow it to be populated with something that can be converted to a FileDataset with multiple DatasetRef.    The plan in this ticket is to create a new class that contains the dataId, obsInfo, and region and change RawFileData to accept a list of those."""
"DM-23158","Improvement","ts_auxiliary_telescope",0,"Update ts_ATDome for changes to vendor code","""The vendor updated the low level ATDome code and the CSC can no longer parse full status. The error is:    [~tribeiro] kindly got me an example of the new full status output:  """
"DM-23155","Story","ts_qa",1,"Add XML tests to verify a topic does not contain special characters","""The XML topic and attribute names should only contain letters, underscores and maybe numbers.  Create a test to validate this is true."""
"DM-23153","Story","DM",2,"Outline Construction paper PSTN-017","""Start the outline of the construction paper DM outline .."""
"DM-23152","Story","ts_main_telescope",3,"Helping debug Camera Hexapod Fault","""On Friday the 17th, The Camera Hexapod faulted into a so-far unrecoverable state. This task outlines the effort in helping to debug this problem."""
"DM-23148","Epic","ts_environment",20,"EAS Work Phase 4","""This epic is used to hold all stories associated with the Environmental Awareness System (EAS).   This is to continue work from:   * DM-17215   * DM-18732   * DM-20197   * DM-21536"""
"DM-23146","Story","ts_documentation",1,"Write section 2: Configure your Repo for Docstrings","""Write section on configuring your docstrings for tstn-005."""
"DM-23141","Story","cbp",0,"Update the cbp README to include a link to the online docs","""Update the README file in the cpb package to link to the online documentation."""
"DM-23139","Story","ip_diffim",1,"Check whether the gen3 butler pre-filter template inputs and defer their loading if not","""As of the currently available limited ci_hsc gen3 repo we have a very limited number of template images, however a production environment gen3 collection may contain many templates, covering large sky areas.         As a follow up of the initial gen3 support DM-22541 in {{ImageDifferenceTask}}, check whether the number of template inputs can potentially be huge in a production environment or not because of gen3 automatic filtering on patch spatial information and science image coordinate matching.         If all available template images are potentially loaded as task input, add support for deferred loading of the template coadd images to avoid unnecessary I/O and save resources. Load only at a later stage, if input belongs to a relevant skymap patch. If the coadd images loaded as inputs are pre-filtered at the middleware level then we perhaps do not need to implement any cautious approach in {{ImageDifferenceTask}}.     """
"DM-23172","Improvement","astshim",0,"Fix flake8 violations in astshim","""Fix comments that are too long and modernize the flake8 configuration in setup.cfg"""
"DM-23171","Story","astro_metadata_translator|obs_lsst",2,"Add exposure group to metadata translator","""To support the GROUPID header for grouping related exposures in LSSTCam data we need to add a new translation to astro_metadata_translator.     The proposal is to call this """"exposure_group"""" and for most instruments to default it to be a string form of the """"exposure_id"""". For LSSTCam and LATISS it will be the value of the GROUPID header."""
"DM-23167","Story","ts_middleware",1,"test_NoDupcliateAttributes.py is misspelled","""Please correct the spelling on the test name."""
"DM-23166","Bug","utils",0.5,"Add __all__ to lsst.utils.deprecated module.","""The {{__all__}} is needed for the documentation build. See failure log: https://ci.lsst.codes/blue/organizations/jenkins/sqre%2Finfra%2Fdocumenteer/detail/documenteer/761/pipeline/"""
"DM-23165","Story","ts_middleware",0,"Hexapod_logevent_commandableByDDS state attribute missing description","""The attribute in the title is missing a description. This can be seen by removing the exemptions on DM-20971 in all the tests and running pytest. Once this issue is fixed, we can remove the exemption."""
"DM-23164","Story","ts_main_telescope",3,"Fix the Error Handling in M2 Control System","""The error code and message are hard-coded in a string in the M2 control system. This part should be moved into the LabVIEW native error file for the extension and maintenance. In addition, there is no scroll bar for the list of error in the M2 control system. This needs to be fixed as well."""
"DM-23163","Story","ts_middleware",1,"Fix Attribute Description test","""When a description tag is empty (no blank spaces): <Description></Description>, the test is not handling the fact the description.text is None in this case. The test throws this exception:            Also, the test does not handle the case where the description might be blank spaces. In this case the test passes, but there's no actual content in the description.    I found this when I was testing to see if we could lift DM-20971 from all the tests. It showed that the Hexapod XML still had one missing description, but the test failed it an unexpected manner."""
"DM-23162","Story","Stack Documentation and UX",1,"Change python style guide to match RFC-650","""Following the adoption of RFC-650, change the developer guide to put binary operators at start of the next line when having to break a line."""
"DM-23188","Story","efd",1,"select_top_n in lsst_efd_client must support indexed components","""The _select_top_n_ function in the EFD client library must support indexed components just as _select_time_series_ does."""
"DM-23186","Improvement","ts_auxiliary_telescope|ts_main_telescope",0,"Format my T&S packages with black as time permits","""This trivial change will save me development time in the future by eliminating the need to manually format code. Changes:  * Change W504 to W503 in setup.cfg  * Fix any line continuation warnings that result  * Add E203 to work around a bug in flake8  * Run black"""
"DM-23182","Story","ts_qa",2,"Add basic IDL Type test","""Currently there is no test to verify that the IDL Type is present, nor if it contains a valid value if it is."""
"DM-23180","Story","daf_butler",2,"Investigate and fix problems with Butler vs. read-only SQLite databases","""Problems were reported on Slack #stack-club, [here|https://lsstc.slack.com/archives/C9YRAS4HM/p1579842619007000] and [here|https://lsstc.slack.com/archives/C9YRAS4HM/p1571424285032300].    While we've got unit tests for Registry helper code operating on a read-only database, we don't have them for Butler, and it's possible we just need to pass a flag down to the helper code telling it to make a read-only connection."""
"DM-23178","Improvement","afw",0,"Convert some of afw to use f strings","""Much of afw's use of % formatting would be clearer using f strings.    I would like to take a pass to change those. I propose to leave omit:  * Tricky formatting  * Code that is clearer with % (that is rare but not unheard of)  * Examples, because they are not unit tested"""
"DM-23208","Story","daf_butler",2,"Add exposure group to gen3 registry","""Now that DM-23171 add exposure_group to the translator, we can add it to the exposure metadata."""
"DM-23207","Story","cat",1,"Clean up the cat package","""The current thinking of the cat package is to house the declarative yaml schemas in the [felis|https://github.com/lsst-dm/felis] format.  Those felis files are (or will be) used to instantiate TAP_SCHEMA tables, Qserv tables, etc.     Currently the cat repo has some old files and sql scripts that are no longer in use. This ticket is to clean them up.  This will remove unnecessary dependencies, and facilitate including the cat package in different builds (Sci Pi or Qserv) for validation. """
"DM-23206","Bug","validate_drp",0.5,"validate_drp crashes when trying to apply external skyWcs","""RC2 processing on DM-23121 crashed when trying to apply jointcal wcs in validate_drp.  https://lsstc.slack.com/archives/C4JQP6FRS/p1580160187055200    Fix was illustrated by [~price]:      """
"DM-23204","Story","ts_main_telescope",5,"Dome software interface description","""Describe the detailed content of the interface between low level and high level dome control software components, as mentioned in DM-23059"""
"DM-23203","Story","astro_metadata_translator",1,"Add tabular output to translate_header","""In order to simplify the listing of headers from multiple files, add a tabular option to translate_header.    I think the default will be that for one file we use the verbose listing and for multiple files we use the tabular form."""
"DM-23195","Story","cp_pipe",2,"DM-21221 broke cp_pipe due to lack of tests","""The changing of {{...Nl}} to {{...nonLinearity}} is an API change which breaks things, including but not limited to {{makeBrighterFatterKernel}} due to a lack of tests (_i.e._ it's not really [~plazas]'s fault.    Also, the API change where that method doesn't {{return dataset}} and now just does {{return}} is breaking too (also due to lack of tests).    It is deliberately ambiguous whether this ticket is for fixing the breakages, or doing that and adding tests."""
"DM-23223","Story","astro_metadata_translator",1,"Allow translate_header to dump the fixed header","""Currently translate_header has a dumphdr option to list the file header. This is the actual header and there is no option to provide a fixed up header after astro_metadata_translator has patched things up.    Add a new option to allow the fixed header to be seen. It's possible that we could do this with the mode switch and make mode=fixed dump the fixed header and dumphdr could alias to mode=header."""
"DM-23222","Story","obs_lsst",1,"Fix OBJECT ENGTEST date and RADEC ","""[~pingraham] tells me that they started using ENGTEST for real yesterday so I should stop converting OBJECT to ENGTEST from that date.    Also consider fixing the RA/DEC scaling before it is fixed tonight."""
"DM-23221","Story","ts_middleware",0,"Change supplemental group separator in nextVisit","""In DM-18126 we added nextVisit to ScriptQueue but [~ktl] pointed out that the {{+}} separator for the supplemental group numbers was the same separator that ISO8601 uses for time zones so this might be confusing.   Please replace with a {{#}} to indicate the supplemental number."""
"DM-23214","Story","dax_ppdb",2,"Migrate Cassandra development branch to APDB ","""Cassandra development branch ({{u/andy-slac/cassandra}}) for dax_ppdb and l1dbproto needs an update after dax_ppdb was renamed to dax_apdb. """
"DM-23212","Bug","ctrl_mpexec|Middleware",0.5,"pipetask run with multiple ""-i"" command line arguments fails","""This ticket follows up the discussion of the gen3 middleware telecon on 2020-01-23.    Specifying multiple {{-i}} command line options for input connection locations or one {{-i}} option with a comma separated list of connection locations should be equivalent. Please find example pipeline on the ci_hsc_gen3 data attached.          """
"DM-23235","Story","HeaderService",1,"Create containers for ts_xml 4.6.0 and HeaderService 1.3.0","""New version of header service needs a container to run on the summit asap."""
"DM-23234","Story","HeaderService",1,"Create containers for ts_xml 4.4.1 and HeaderService 1.2.1","""New version of header service needs a container to run on the summit asap."""
"DM-23231","Story","obs_lsst",2,"Sort out visit vs exposure ID in gen 2 butler","""In DM-23171 I changed how visit is calculated such that it respects the GROUPID header.  This has led to some confusion because we have been using gen2 butlers as if visit_id and exposure ID were the same thing, and to make things worse exposure_id is not available and obsid is not declared to be a unique header so can't be used on its own to retrieve data.    In this ticket I will:    * Add expId as the exposure_id  * Declare that obsid and not visit is the unique constraint.  * change file templates that use visit to instead use obsid.    """
"DM-23255","Improvement","ts_middleware",2,"Report memory leak in OpenSplice","""INRIA reports a slow memory leak in salobj. Using the attached script they record a loss of 50Mb in 12 hours. Running profiling software suggests the leak is in {{ddsutil.py}} (part of ADLink OpenSplice).    I studied the leak and found it appears to be in OpenSplice dds (even the licensed version in lsstts/salobj:b48_lic). I reported it to ADLink as case 00020396 with two simple """"how to reproduce"""" self-contained archives (both also attached here), one using asyncio and one using threads. I see the same leak either way:  * memory_tester_asyncio.zip  * memory_tester_threaded.zip    These write samples in one subprocess and read them in another. The reader simply counts the samples but does nothing else with them. That is as simple a procedure as I could think of.    So far ADLink has not responded to the ticket. Once they do I will file a new ticket for what we have to do (if there is anything we can do until they fix the problem at their end)."""
"DM-23249","Bug","obs_decam",0.5,"New decam ingest tests need skipif for testdata_decam","""The gen3 ingest tests that were added as part of DM-22708 all need to be protected with skipif for installations that don't have testdata_decam."""
"DM-23248","Story","DM Subsystem Science",8,"Draft changes to DPDD to bring in line with current DRP plans","""Create a branch of the DPDD that incorporates DRP leaderships current best guesses at what we will actually do.  This is primarily the removal of multifit and galaxy Monte Carlo sampling, along with what we expect to replace them; it will not attempt to address more fine-grained issues with particular columns, as I believe others have already made progress addressing those elsewhere."""
"DM-23246","Story","ts_environment",3,"Provide basic English Description based on Spanish MQTT Topic names","""The MQTT topic names are all in Spanish which may be confusing for non-Spanish speaking people. It was decided to keep the Spanish topic names since mechanics generally are Chilean so it will be easier for them to identify the hardware components when they are referred to in Spanish. In addition English Descriptions will be added for those who don't understand Spanish well enough. The Descriptions will be direct translations of the Spanish words into English without an attempt to form proper sentences."""
"DM-23242","Story","HeaderService",2,"Add HeaderService dynamical timeout depending of image exposure time","""Update the ATHeaderService to have a dynamically set timeout that is adjusted by the requested exposure time. For example timeout=requested_exptime+N (in seconds)."""
"DM-23237","Bug","obs_lsst",1,"Strange image types ingested for LATISS images","""The LATISS images that have been ingested at NCSA have a wide range of {{imageType}} values.  Many of these appear to be in error, but they are one-offs.    {code:shell}  $ sqlite3 /lsstdata/offline/teststand/auxTel/L1Archiver/gen2repo/registry.sqlite3  SQLite version 3.27.2 2019-02-25 16:06:06  Enter """".help"""" for usage hints.  sqlite> select imageType, count(*) from raw group by imageType;  ARC|18  BIAS|409  BIAS_0001_0010|21  BIAS_0002_0010|19  BIAS_0002_0100|1  BIAS_0003_0010|19  BIAS_0003_0100|1  BIAS_0004_0010|19  BIAS_0005_0010|19  BIAS_0005_0100|1  BIAS_0006_0010|19  BIAS_0006_0100|1  BIAS_0007_0010|19  BIAS_0008_0010|19  BIAS_0008_0100|1  BIAS_0009_0010|19  BIAS_0009_0100|1  BIAS_0010_0010|19  BIAS_0011_0100|1  BIAS_0012_0100|1  BIAS_0014_0100|1  BIAS_0015_0100|1  BIAS_0017_0100|1  BIAS_0018_0100|1  BIAS_0020_0100|1  BIAS_0021_0100|1  BIAS_0023_0100|1  BIAS_0024_0100|1  BIAS_0025_0100|1  BIAS_0027_0100|1  BIAS_0029_0100|1  BIAS_0030_0100|1  BIAS_0032_0100|1  BIAS_0033_0100|1  BIAS_0035_0100|1  BIAS_TEST|2  DARK|96  DARK_0001_0010|9  DARK_0002_0010|8  DARK_0003_0010|8  DARK_0004_0010|8  DARK_0005_0010|7  DARK_0006_0010|8  DARK_0007_0010|8  DARK_0008_0010|8  DARK_0009_0010|7  DARK_0010_0010|7  ENGTEST|300  FLAT|450  FLAT_0001|52  FLAT_0001_0008_0001_0002|2  FLAT_0001_0008_0002_0002|2  FLAT_0002|51  FLAT_0002_0008_0001_0002|2  FLAT_0002_0008_0002_0002|2  FLAT_0003_0008_0001_0002|2  FLAT_0003_0008_0002_0002|2  FLAT_0004_0008_0001_0002|2  FLAT_0004_0008_0002_0002|2  FLAT_0005_0008_0001_0002|2  FLAT_0005_0008_0002_0002|2  FLAT_0006_0008_0001_0002|2  FLAT_0006_0008_0002_0002|2  FLAT_0007_0008_0001_0002|2  FLAT_0007_0008_0002_0002|2  FLAT_0008_0008_0001_0002|2  FLAT_0008_0008_0002_0002|2  FOCUS|22  FOCUS42086.85|1  FOCUS430|1  FOCUS4550.0|14  FOCUS4550.5|1  FOCUS45522.5|2  FOCUS45524.0|1  FOCUS45525.5|1  FOCUS45527.0|1  FOCUS45527.5|1  FOCUS45528.5|1  FOCUS45530.0|1  FOCUS45531.5|1  FOCUS45554.5|1  FOCUS45568.5|1  FOCUS45568.7|1  FOCUS45568.9|1  FOCUS45569.10000000000001|1  FOCUS45569.30000000000001|1  FOCUS45569.50000000000001|1  FOCUS45569.70000000000002|1  FOCUS45569.8|5  FOCUS45569.90000000000002|1  FOCUS45570.10000000000002|1  FOCUS45570.30000000000003|1  FOCUS45575.59|60  FOCUS467|2  FOCUS46786.85|1  FOCUS46786.92|3  FOCUS46786.95|1  FOCUS46787.04|1  FOCUS46787.25|1  FOCUS47868.4|2  FOCUS47868.7|1  FOCUS47868.80000000000001|1  FOCUS47869.0|2  FOCUS47869.1|1  FOCUS47869.19999999999999|1  FOCUS47869.20000000000002|1  FOCUS47869.29999999999998|1  FOCUS47869.3|1  FOCUS47869.39999999999998|1  FOCUS47869.4|1  FOCUS47869.49999999999997|1  FOCUS47869.59999999999997|1  FOCUS47869.6|1  FOCUS47869.60000000000002|1  FOCUS47869.69999999999996|1  FOCUS47869.79999999999995|1  FOCUS47869.8|35  FOCUS47869.80000000000001|1  FOCUS47869.89999999999995|1  FOCUS47869.89999999999999|1  FOCUS47870.00000000000003|1  FOCUS47870.19999999999999|1  FOCUS47870.20000000000002|1  FOCUS47870.49999999999999|1  FOCUS47870.79999999999998|1  FOCUS47871.09999999999998|1  FOCUS47886.85|6  FOCUS480|7  FOCUS540|1  FOCUS60086.7|1  FOCUS60086.76|1  FOCUS60086.81|1  FOCUS60086.84|1  FOCUS60086.92|1  FOCUS60086.96|1  FOCUS60087.25|2  FOCUS63239.4|1  FOCUS63239.699999999999996|1  FOCUS63239.8|1  FOCUS63239.9|1  FOCUS63239.99999999999999|1  FOCUS63240.0|1  FOCUS63240.099999999999994|1  FOCUS63240.1|1  FOCUS63240.199999999999996|1  FOCUS63240.2|2  FOCUS63240.29999999999999|1  FOCUS63240.3|1  FOCUS63240.300000000000004|2  FOCUS63240.39999999999999|1  FOCUS63240.400000000000006|2  FOCUS63240.46|21  FOCUS63240.49999999999999|1  FOCUS63240.5|6  FOCUS63240.50000000000001|2  FOCUS63240.59999999999999|1  FOCUS63240.60000000000001|2  FOCUS63240.69999999999999|1  FOCUS63240.70000000000001|2  FOCUS63240.79999999999999|1  FOCUS63240.80000000000001|1  FOCUS63240.9|2  FOCUS63240.999999999999986|1  FOCUS63241.09999999999999|1  FOCUS63241.3|1  FOCUS63258|1  FOCUS63258.874|9  FOCUS63258.9|1  FOCUS63275.55|1  FOCUS63277.03399999999996|2  FOCUS75086.41|1  FOCUS75086.77|1  FOCUS75086.81|1  FOCUS75086.83|1  FOCUS75086.95|1  FOCUS75087.02|1  FOCUS75087.04|1  FOCUS75087.15|1  FOCUS75087.27|1  FOCUS75087.36|1  FOCUS840|10  FOCUS84087.02|1  FOCUS84087.11|1  FOCUS84087.17|2  FOCUS84087.27|1  FOCUS84087.39|1  FOCUS98086.85|1  FOCUS98086.92|1  FOCUS98087.01|1  FOCUS98087.11|2  FOCUS98087.18|1  FOCUS98087.29|1  FOCUS98087.35|1  FOCUS98087.36|1  FOCUS98087.56|3  FOCUS98087.68|1  FOCUSTEST|2  FOCUS_632NM|26  MONOFLAT|10  OBJECT|51  QUEUE_TEST|11  TEST|402  TEST_QUEUE|9  UNKNOWN|180  WAVE,FOCUS,632,73.5905|1  {code}  """
"DM-23276","Bug","daf_butler",1,"Fix repr for gen3 Registry to output SQLite path","""The str and repr output for the gen3 Registry objects could be cleaned up:        The DimensionUniverse would be useful to see in the `str` output, while the `repr` should show the sqlite path instead of the Object."""
"DM-23275","Bug","daf_butler",2,"Restore outfile option for butler makeRepo","""Butler.makeRepo takes a parameter to specify the output location of the config file but at some point in time that functionality was removed. Restore it and add a test."""
"DM-23267","Story","ts_qa",2,"Jenkins training - video tutorials","""Task to cover time taking the LinkedIn Learning Jenkins course(s)."""
"DM-23266","Improvement","ts_auxiliary_telescope",1,"Please simplify write_command in ts_salobjATHexapod controller.py","""Suggestions for improving the write_command method in controller.py of ts_salobjATHexapod:  * Decode the data before returning it. That way only {{write_command}} has to deal with bytes; everything else can deal with strings.  * Use {[readuntil}} instead of reading character by character. This is far more efficient and simplifies the code. You wait until all the data you asked for arrives.  * Specify the number of lines of reply that you expect as an argument. This simplifies the method because it does not have to be clever. It also simplifies error handling in code that calls the method because the correct # of replies is guaranteed to be returned (else an exception is raised).  * Strip the final \n from the reply. That way callers don't have to do that.  * Return the replies as a list of strings instead of making the caller do that.    I am not sure who to assign this to. I am happy to do the work myself, if desired.    Note: these are changes I requested in DM-22170 but [~ecoughlin] suggested that they be handled in a different ticket."""
"DM-23262","Story","HeaderService",1,"Bug in RA/DEC calculation from ALT/AZ","""the arguments to from_geodetic are reversed:   {{location = EarthLocation.from_geodetic(lat*u.deg, lon*u.deg, height*u.m)}}    and {{RA/DEC/END}} should use {{DATE_END}} and the moment it uses {{DATA_BEG}} instead."""
"DM-23258","Bug","validate_drp",0.5,"matchedVisitMetricsTask will crash if any visits have a missing source catalog","""Currently, {{matchedVisitMetricsTask}} in {{validate_drp}} crashes if any ccd specified on the command line has a raw but no source catalog (if {{processCcd}} failed for any reason).  The fix is trivial to add a {{datasetExists}} to {{matchreduce.py}}."""
"DM-23257","Story","meas_extensions_scarlet",2,"Create presentation for SST on deblending in the stack","""Create a presentation for the LSST System Science Team (SST) on deblending in the stack. It has been requested that this presentation includes a general introduction to blending in the science pipelines as well as an update on the latest developments."""
"DM-23256","Story","Qserv",8,"Migrate Qserv documentation to LSST-the-doc","""Documentation is now available here:    http://qserv.lsst.io    https://qserv-operator.lsst.io"""
"DM-23278","Bug","obs_lsst",1,"Fix RADEC for LATISS data on 27th Jan","""In CAP-422 I noticed that RASTART/DECSTART were completely wrong. These are the headers that are used for the RADEC calculation in the translator. The translator needs to know that those headers on the 2020-01-27  and -28 should not be trusted (before that date we knew not to trust them because the date was completely wrong)."""
"DM-23281","Story","obs_lsst",3,"FILTER and GRATING not concatenated in LATISS data","""When in Tucson, the disperser was written with the FILTER2 key (note the 2), and this was concatenated (using a """"+"""") with FILTER on ingest, so that we had a compound filter.    Now that we're on-sky, we're writing that as GRATING (which is good) but {{exp.getFilter()}} seems to only return the physical filter which is only the first part (though we know the registry is out of date), but moreover, doing         shows that the filter is just {{blank_bk7_wg05}} rather than {{blank_bk7_wg05+ronchi90lpmm}} as I'd have expected.          """
"DM-23290","Story","ts_main_telescope",3,"Check the SAL Event and Telemetry in M2 Control System Phase 1","""This task will check the SAL published event and telemetry in M2 control system. From the previous tests, I only know the telemetry data is not zero. However, I am not sure the values are reasonable or not. I also noticed the published data of summary state event is always 0. Therefore, this task will try to make sure the published data is reasonable."""
"DM-23289","Story","ts_main_telescope",3,"Check the Script by Harris","""Harris provided the function of script used in M2 control system to assign the actuator steps or forces. This task will evaluate the use of script and test it on the M2 simulator."""
"DM-23329","Bug","obs_lsst",0.5,"Fix controller code in phosim and imsim data","""When I added controller to obs_lsst translator in DM-21204 I didn't realize that S is meant to be used for simulated data and so I used O. Fix that."""
"DM-23324","Improvement","ts_auxiliary_telescope",1,"Update AT ops procedure (tstn-004)","""Update TSTN-004 to the latest operations procedure. """
"DM-23313","Story","meas_extensions_scarlet",1,"Fix dominant failure mode in deblending sources with 2-components","""The dominant failure mode in `meas_extensions_scarlet` is a parentheses that is outside, rather than inside a set of parentheses. Correcting this should fix the large number of errors that we are seeing when using 2-component models and bring the failure rate down to the same rate as the other deblending methods at a small fraction of a percent."""
"DM-23310","Bug","obs_lsst",1,"Some ComCam images do not have LSST_NUM header","""Some of the ComCam images present at NCSA at {{/lsstdata/offline/teststand/comcam/CCS/storage}} appear to be lacking the {{LSST_NUM}} header that identifies the detector serial number.  As a result, they fail to ingest properly, as that header is used to compute the {{detector_serial}} metadata item that becomes the {{lsstSerial}} column in the registry database.    Please update the {{comCam.py}} translators to fix this header.    The canonical mapping from sensor position to serial number is:  """
"DM-23353","Story","ts_qa",1,"Jenkins training - video tutorials - part 2","""Task to cover time taking the LinkedIn Learning Jenkins Essentials course.    https://www.linkedin.com/learning/jenkins-essential-training/next-steps?u=37426900"""
"DM-23351","Bug","ts_auxiliary_telescope|ts_main_telescope",0,"BaseCscTestCase.check_bin_script checks for the wrong initial summary state","""BaseCscTestCase.check_bin_script checks for an initial summary state of OFFLINE instead of STANDBY. Fix this. (Better yet, make it an argument that defaults to STANDBY)."""
"DM-23349","Story","Developer Infrastructure",1,"Build new shared stack with updated conda env","""Once the conda env is updated in DM-22817, a new shared stack needs to be created."""
"DM-23343","Story","synpipe",1,"Mark Synpipe as deprecated","""Following RFC-661, ensure that Synpipe is marked as deprecated before the next major release (20.0.0)."""
"DM-23331","Story","fgcmcal|obs_subaru",2,"Add default fgcmcal configuration files for HSC processing","""Now that {{fgcmcal}} is ready for full production, a set of recommended default config files can be added to {{obs_subaru}}, including look-up-table building, chromatic correction information, mirror coating dates, etc."""
"DM-23371","Story","obs_base",1,"Remove lsst.obs.base.CameraMapper._extractAmpId","""This method has been marked as deprecated since release 11, and its deprecation was announced with release 19.0.0. Remove it."""
"DM-23369","Story","ip_isr",1,"Remove lsst.ip.isr.addDistortionModel","""{{lsst.ip.isr.addDistortionModel}} was announced as deprecated in release 19.0.0 on DM-20154. Remove it before release 20.0.0."""
"DM-23368","Improvement","ts_auxiliary_telescope|ts_main_telescope",1,"Use masterPriority=0 for scripts to speed up script launch","""As explained in DM-22382 it would speed up script launching significantly if we launch scripts with a lower masterPriority than some other existing SAL component. The obvious choice is to use a value lower than the masterPriority of the ScriptQueue itself.    Unfortunately, it appears that master priority cannot be set programmatically. However, it suffices to set the value when the Domain Participant is created. So I propose the following:  * When the ScriptQueue starts up it reads the OpenSplice configuration file pointed to by OSPL_URI.  * If it finds """"masterPriority=<number>"""" then it writes a copy of the file to a temporary directory with masterPriority=0 and changes OSPL_URI to point to the copy.  * Thus we only have to maintain a single copy of the configuration file and any scripts that are launched will use masterPriority=0.      Note: it turns out that the following bit of configuration is not relevant or useful for speeding up script startup (ADLINK reported this on a recent ticket and I have confirmed it with the speed test I sent to ADLink). Apparently it only affects a more persistent form of durability than we use:  """
"DM-23362","Story","obs_lsst",1,"Old LATISS data has missing OBSID/DAYOBS","""[~ktl] reports that old LATISS data has no OBSID or DAYOBS headers so ingest fails.    The fix is to add them from the IMGNAME header during header fixup phase.    see eg /lsstdata/offline/teststand/auxTel/L1Archiver/storage/2019-03-06/AT_O_20190306_000014-ats-wfs_ccd.fits"""
"DM-23359","Story","pex_config",0.5,"Allow pex_config configs to use __file__","""[~erykoff] notes that {{\_\_file\_\_}} is not supported by config files in pex_config. Looking at the code it seems trivial to add support for this."""
"DM-23414","Story","lsst_ci",1,"lsst_ci fails with astropy 4 and numpy >=1.17","""In testing DM-22817 I discovered that lsst_ci doesn't like Astropy 4 because it seems that Astropy with numpy >=1.17 now preserves units inside numpy functions: (resulting in us applying the unit twice):      (from https://ci.lsst.codes/blue/organizations/jenkins/stack-os-matrix/detail/stack-os-matrix/31182/tests/ )    This fails for testObsCfhtQuick  and testObsDecamQuick"""
"DM-23408","Story","ts_main_telescope",1,"Attempt to compile Moog Hexapod Simulator","""Following recent events, there has been a desire to have a simulator for the Hexapod's built by Moog. However, the simulators have not been tested nor documented by us or Moog. I attempted to build the simulator and after many hours was able to successfully build it. """
"DM-23425","Story","ap_pipe",8,"Monthly February ap_pipe rerun","""Reprocess the three HiTS 2015 fields using ap_pipe with the same good-seeing CompareWarp coadd templates as used for January (DM-23069). Make a summary notebook and verify that nothing significant has changed."""
"DM-23424","Story","ts_auxiliary_telescope|ts_main_telescope",0,"Remove ddsutil from ts_salobj","""We worked around a bug in OpenSplice 6.9 by importing including a patched ddsutils.py in ts_salobj. That is no longer necessary with OpenSplice 6.10 and it is time to use the standard module."""
"DM-23422","Story","ts_middleware",2,"Try to speed up ts_salobj","""At one time I believe ts_salobj tests/test_speed.py reported transmitting and receiving several thousand messages per second. With the current version of ts_sal tests/test_speed.py is reporting 600-700 messages/second on my Mac. Try to figure out what changed and improve the speed.    Note that v5.0.0 also runs at the same speed and running older versions requires an older Test IDL file because the ackcmd topic has changed."""
"DM-23420","Story","ap_association",1,"ap_association does not work with numpy 1.18 and pandas 1.0","""I'm testing the new conda environment (DM-22817) and ap_association is failing one test:    It's the {{np.argwhere}} that is falling over.  This is numpy 1.18.2 and pandas 1.0.0.    The nan_mask has a value of:  """
"DM-23445","Story","ci_hsc_gen3|daf_butler|ip_isr|obs_base|obs_decam|obs_lsst|obs_subaru|pipe_base|pipe_tasks",0,"Move visit definition out of raw ingest for Gen3","""At present, RawIngestTask is responsible for adding three different types of dimension records:   - exposure   - visit   - visit_detector_region    We should move the latter two to a separate script that is run after RawIngestTask and (at least at present) only after all associated raws for a visit have been ingested.  That will open the door to (later) being able to define different visit definitions for the same exposure (DM-15536).    This will not on its own allow individual raws to be ingested incrementally - RawIngestTask still needs all raws for an exposure to be present in a single invocation so we can add the exposure dimension record once without needing to see if it already exists in the Registry.  That could be fixed by using Database.sync in a new high-level counterpart to {{Registry.insertDimensionData}} that does perform such a check, but we'll first need to figure out how to handle transactions in ingest - Database.sync is not and probably cannot be part of a larger transaction.    But even that is an easier problem to solve than the corresponding one for visits, because (in addition to the synchronization problem) the visit dimension record needs to contain a region that is currently computed from the regions of all of the detectors that went into it (but could be computed from cameraGeom in the future)."""
"DM-23435","Story","Qserv",8,"Implement redis installation using kubedb inside Qserv operator","""Qserv operator will install redis using KubeDB CRD. This might be a first track for prototyping redis DB.    A redis section will be added to Qserv CRD, with the number of redis masters."""
"DM-23477","Story","pipe_base",1,"pipe_base ScalarError can't be pickled","""Testing the new conda env I had a failure in ci_hsc_gen3 and the failure triggered a failure in the multiprocessing module reporting the failure.  The {{ScalarError}} exception is a subclass of TypeError that takes two parameters. Unfortunately when a {{ScalarError}} is pickled only a single parameter (the message string) is stored and passed to the constructor so reporting the error state fails.    The fix is to make the second parameter optional and to assume that the first parameter is the error message if that's all that is given."""
"DM-23470","Story","ts_qa",1,"Correct the usage of GIT_TAG_NAME in pipeline","""We want several jobs to use the Git Tag name in the job, since the tag contains the application version information.  Currently, the GIT_TAG_NAME variable, provided by the [git-tag-message|https://plugins.jenkins.io/git-tag-message/] plugin, does not work in pipelines.  Therefore, a different implementation is needed until the plugin is updated."""
"DM-23462","Story","ts_middleware",1,"Please use an env variable to specify the masterPriority level in the OSPL configuration","""We want to run Scripts with masterPriority=0 in order to make sure that they never become """"master"""", which would trigger an expensive system-wide DDS realignment.    ADLink knows of no programmatic way to do this, but we can easily use env variable substitution in the {{ospl.xml}} configuration file and that variable can be optional. I suggest the following, where {{masterPriority=""""$\{OSPL_MASTER_PRIORITY:\-1\}""""}} sets the master priority to the env variable OSPL_MASTER_PRIORITY, if defined, else 1. Yes the minus sign is needed (I checked that): the default delimiter really is """":-"""".        This will make it trivial for scripts to assign themselves a masterPriority of 0 and we can also easily assign an early CSC, such as a SAL/Kafka producer, a higher masterPriority."""
"DM-23450","Story","HeaderService",1,"Add a FACILITY header to LATISS data","""We need to add a FACILITY header to LATISS data with a fixed value of """"Vera C. Rubin Observatory"""". """
"DM-23504","Story","HeaderService",1,"Create containers for ts_xml 4.6.0 and HeaderService 1.4.0","""New version of header service needs a container to run on the summit asap.    """
"DM-23503","Story","daf_butler",1,"Butler gen3 datastore templates should handle slashes in data Ids","""It was noted today that files in the ci_hsc_gen3 datastore are not unique and instead look like {{DATA/raw/hsc/raw/i/HSC-I/903986/raw_i_HSC-I_903986_903986_22_HSC_raw/hsc.fits}} -- this is because """"run"""" has a value of {{raw/hsc}} and """"run"""" is at the end of the template.    The templating system should replace / with _. Optionally we could also introduce a """"/"""" format modifier to allow """"/"""" to be retained."""
"DM-23495","Story","ts_auxiliary_telescope|ts_main_telescope",0,"Make QueueModel.next_group_id a static method","""Make QueueModel.next_group_id a static method"""
"DM-23494","Story","ts_main_telescope",1,"Update the ts_hexapod internal simulator with the correct geometry for the hexapod","""Update the simulator in ts_hexapod with the correct geometry for the hexapod. That way when the CSC is run in simulation mode the commanded actuator lengths will be at at least approximately correct.    One known reason that the simulator may still differ from the Moog code is that the simulator assumes that pivot rotations are applied in order: x, y, z. For small rotations it doesn't matter much, but for larger motions the order is important.    Also change the simulator so length = 0 at nominal position (with the position set to 0,0,0 0,0,0)."""
"DM-23491","Story","ts_qa",2,"Parameterize XML version in IDL conda job","""Currently in the IDL Conda packaging process the XML version is hardcoded into the Jenkinsfile.conda recipe.  This is bad, as each XML release requires a ts_idl release.  Figure out the best way to parameterize this value.  Build parameter?  Docker image Env Var (prompting a new image with each XML release)?  Other?"""
"DM-23489","Story","ci_hsc_gen3|daf_butler",0.5,"ci_hsc_gen3 fails with new conda env (sqlite v3.31.1)","""With the new conda env from DM-22817 ci_hsc_gen3 fails because multiple flats match when only one should match.        The two dataIds are:        This is with sqlalchemy 1.3.13 but also fails in the same way with 1.3.1 (current conda env) and 1.3.8 (current eups package).  """
"DM-23529","Story","cat",2,"Add cat to lsst_distrib (as sdm_schemas) ","""Add cat to lsst_distrib so it gets weekly version tags"""
"DM-23527","Story","cat",1,"change fits:tunit: nmgy to nanojanskys","""In cat yml/hsc.yaml   we need to change all those {{fits:tunit: nmgy}} to nanojanskys"""
"DM-23526","Story","fgcmcal",2,"Fix fgcmcal issues exposed during PDR2 run","""During RC2 and PDR2 processing a few issues with {{fgcmcal}} were exposed, and this ticket has consolidated these fixes into one.    First, visit level tests by [~lauren] show that the errors reported in {{fgcmcal}} {{photoCalib}} objects are much larger than for {{jointcal}}.  This is because the errors are taking into account the full calibration error, including uniformity, but this is not what the stack expects.  I do not believe these errors affect coaddition.  Instead, {{fgcmcal}} should be reporting just the """"gray"""" error estimated locally on each ccd.  Second, there are some visits in PDR2 that have an airmass as large as 2.95 (zenith angle >70deg), which was beyond the range of the {{fgcmcal}} look-up table.  A new atmosphere table and LUT will be generated which goes to zenith angle of 75 deg which is the limit of the Subaru telescope.  Third, a couple of default {{fgcmcal}} config changes for {{obs_subaru}} including increasing the number of iterations in each fit cycle for better convergence, and fix an index error on the default {{fgcmcal}} aperture correction parameters.  Related, a bug in {{fgcm}} was fixed that did not properly persist internal aperture corrections for bands that did not have a lot of data (namely, N387)."""
"DM-23524","Story","ts_main_telescope",2,"Support M2 Test","""Support M2 test."""
"DM-23523","Story","ts_main_telescope",1,"Check the SAL Event and Telemetry in M2 Control System in Phase 2","""This task will check the SAL published event and telemetry in M2 control system as the phase 2 . This is a following task of DM-23290."""
"DM-23509","Story","obs_lsst",0.5,"obs_lsst failing LATISS plate scale test","""In DM-23490 the plate scale of LATISS was changed but the tests were not run before merging. This is breaking master:        I will fix the plate scale in the tests."""
"DM-23554","Story","lsst-texmf",0.5,"Add document obsolescence facility to lsst-texmf","""RFC-660 requires that LDM-472 be deprecated. Add an """"obsolete"""" flag to the lsstdoc latex class to add deprecation warnings on each page.  This allows us to declare a document to be obsolete whilst also leaving the text available."""
"DM-23549","Epic","ts_main_telescope",40,"Dome Work Phase 3","""This epic is to contain all the work for the Dome.  It is a continuation of epics:   * DM-18309   * DM-20198"""
"DM-23537","Story","ts_main_telescope",2,"Draft the M2 Test Plan","""Review the M2 requirement document and draft the test plan."""
"DM-23535","Story","ts_dome",2,"Implement replies to command details in mock controller","""After having created the mock controller framework, the commanding details need to be implemented which this story is for."""
"DM-23534","Story","ts_dome",2,"Create mock controler framework for communications between upper and lower level DCS","""For the communications between the upper level DCS and lower level a mock lower level controller will be created based on the ts_ATDome code."""
"DM-23533","Story","ts_dome",1,"Create XML files with proposed command protocol","""For the commanding from the upper level DCS to the lower level components a proposal needs to be made for both the communications and the command protocols. The basis for the commands will be XML files that will be used by both the Rubin Observastory and EIE. This story is for collecting the necessary commands and creating an XML file to share between both parties."""
"DM-23558","Bug","ip_diffim|pipe_tasks",2,"DCR coadds are missing PhotoCalib","""{{ap_pipe}} fails for DCR coadds with the following error. This failure started in {{w_2020_07}} but was fine in {{w_2020_06}}. The error below was from a run with a coadd made using {{w.2020.06-6-g81841ad}} or pipe_tasks, while the failed {{ap_pipe}} run used {{w.2020.07}}       """
"DM-23594","Improvement","Qserv",2,"Improved performance monitoring tools for the Replication system","""Minor improvements of the existing performance monitoring tools:   * verbosity control for reporting results/errors   * added a multi-threaded testing option   * added a simple flow-control testing option"""
"DM-23589","Story","obs_lsst",0.5,"Update LATISS filters in obs_lsst ","""Tonight the LATISS filters were changed. A corresponding change has to be made to lsst.obs.lsst.filters.  The updated list can be found at https://confluence.lsstcorp.org/display/LTS/AuxTel+Filters"""
"DM-23616","Story","ap_verify|obs_decam",2,"Run converted ap_verify testdata through gen3 pipeline","""To more fully test DM-22655, we should run as much of the gen3 pipeline as we can on a converted ap_verify test dataset. As a first test, lets run on ap_verify_ci_hits, instead of the much larger non-ci dataset.    I'll provide the command to run in a comment. You'll need to get three packages on branch {{tickets/DM-22655}} and scons'd: daf_butler, obs_base, and obs_decam. -If you setup ap_verify_ci_hits2015 before sconsing obs_decam, it will run a few extra tests.-"""
"DM-23607","Story","meas_extensions_scarlet",5,"Model deconvolution kernel using scarlet","""Before DFTs were integrated into scarlet, the earliest version of the code calculated the difference kernel needed to do partial convolutions from the narrow model PSF into the wider observed PSFs in each band using scarlet itself.     The basic algorithm is as follows:  * In scarlet we typically define a model PSF {{M}} that is a nyquist sampled gaussian with {{sigma=1/sqrt(2)}}. Fitting sources in the model to the observed images in each band requires convolving the PSF in each band ({{P_b}} with a difference kernel, the kernel needed to match the PSF in the model seeing to the PSF in the observed seeing. So the difference kernel {{D}} is given by {{P=M*D}}.  * The current version of scarlet uses the same technique as the one described in the galsim paper ([Rowe 2014|https://arxiv.org/abs/1407.7676] to calculate the difference kernel in k-space, however the first version of scarlet made this calculation in real space.  * In real space we defined the observed image as the observed PSF and the """"difference kernel"""" used to convolve the model was the model PSF. This works because convolution commutes, so {{P=M*D=D*M}}. In other words, if we define our _model_ to be the difference kernel and convolve it with the model PSF, we can fit the result to the observed PSF and use the same algorithm used in scarlet to fit the model to find the best fit observed PSF without ever going into k-space.  * This worked quite well but was not as fast as matching the kernel in k-space, since the real space calculation required an iterative solution with the k-space version took only one pass. However, the problem with the k-space solution is that performing deconvolution, going from a wider PSF to a narrower PSF is ill-defined in k-space and leads to divergences in the difference kernel, making it numerically unstable.  * Earlier work in DM-20127 attempted to see if we could live with the numerical artifacts produced by the k-space deconvolution but the results were dependent on how different the model PSF and observed PSF were, with limitations on the upper-bound of the observed PSF before numerical artifacts dominated and the initialization was made worse.  * This ticket is to explore using the same real space PSF matching used in the previous version of scarlet, using the improved optimization algorithms of scarlet 1.0, to calculate the deconvolution kernel (the kernel to go from model PSF to observed PSF) to see if it can produce a more numerically stable result. """
"DM-23631","Story","ap_pipe|ap_verify",8,"Create simple python script to create and insert fakes for the HiTS2015 AP processing.","""Create a simple script to insert fakes for AP using the HiTS2015 dataset. Likely this will be on an un-merged ticket of ap_verify.    This script will be fairly hacky as it will copy data around in the ap_verify_hists2015 dataset and edit the DecamMapper on the fly."""
"DM-23630","Story","fgcmcal",1,"fgcmcal failure Ubuntu","""fgcmcal fails on master with the latest conda environment on Ubuntu 18.04.4. The failure is in one of the new tests comparing the `photoCalib.getCalibrationErr()` with the `fgcmZptGrayErr`:        We are not seeing this on other machines (CentOS, macOS), so there's probably a """"fun"""" interaction with system libraries going on here. Adding {{rtol=2e-7, atol=None}} to the above test prevents the error, but may not be the actual solution we want. This suggests to me that there's a float32 calculation going on under the hood somewhere.    I can provide an Ubuntu account to test on."""
"DM-23627","Bug","obs_base",1,"Missing psfMatched_nImage definition","""{{assembleCoadd}} currently fails if {{warpType=psfMatched}} and {{doNImage=True}} using the Gen 2 butler. We just need to add the missing dataset definition to exposures.yaml, and add one for DCR coadds as well."""
"DM-23623","Story","cp_pipe|ip_isr|obs_lsst",8,"Measure crosstalk coefficients for AuxTel chip and add for use.","""Dual purpose: test out the crosstalk measurement code and ensure it works well for this kind of data, and add a crosstalk matrix so that the AuxTel can use it.    If it doesn't work well for some reason, either fix it, or work out what kind of input data would make it happy, and if that's on-sky, add it to the observing plan for the next run.    Also, compare to nominal ITL values as provided by camera team, and see which works better for correction."""
"DM-23651","Story","ap_pipe|ip_diffim|obs_decam",2,"ap_pipe calls some deprecated things","""I noticed when reviewing recent ap_pipe logs that there are some deprecation warnings we should probably deal with.  """
"DM-23649","Story","dm_dev_guide",1,"Relax dev guide wording on post-review squashing","""Add the text agreed in RFC-670 to the developer guide, to allow for post-review commits when squashing them is impractical and when the commits meet our existing quality standards."""
"DM-23643","Story","HeaderService",2,"Create containers for ts_xml 4.7.0 and HeaderService 1.4.0","""New version of header service needs a container to run on the summit asap.    """
"DM-23685","Story","ts_middleware",1,"Test ADLink's fix for the OpenSplice memory leak","""ADLink claims to have fixed the memory leak discussed in DM-23255. Test their fix and make sure neither the reader nor writer are leaking."""
"DM-23679","Story","Middleware",5,"Update M1M3 cRIO with SAL4 compatible code","""Travel to Chile and update and test the M1M3 Controller code and Monitor process to   use SAL 4 and DDS 6.9"""
"DM-23678","Story","daf_butler",0.5,"Bug in s3Datastore when using temporary file","""On macOS high sierra builds daf_butler is falling over in S3 tests with the following error:        We are seeing these now because the new conda env includes moto/boto3.    The relevant code in s3Datastore.py is:    {code:python}  with tempfile.NamedTemporaryFile(suffix=formatter.extension) as tmpFile:      tmpFile.file.write(serializedDataset)      formatter._fileDescriptor.location = Location(*os.path.split(tmpFile.name))      result = formatter.read(component=getInfo.component)  {code}    The problem is that between the write and the read the file is not closed. Closing the file would delete the temporary file so the minimalist fix is to add a {{flush()}} between the write and the read.    It seems like linux and macOS mojave have different buffering allowing the same process to read from something that is still open for write without flushing."""
"DM-23672","Story","ts_dome",2,"Prepare ts_dcs for SALObj","""Add SALObj dependency to the project and implement a skeleton dcs CSC."""
"DM-23670","Story","ts_auxiliary_telescope|ts_main_telescope",2,"Update ConfigurableCsc to output the settingsApplied and softwareVersions events","""Update {{ConfigurableCsc}} to output the {{settingsApplied}} event. The logical place to do this is in {{begin_start}}, which calls {{configure}}. Also update {{BaseCsc}} to output the {{softwareVersions}} event    See https://confluence.lsstcorp.org/pages/viewpage.action?pageId=120786640 for details.  I believe the format of the {{settingsApplied}} field should be {{config_file}}:{{version}}, though that is a bit unclear from the Description field of the XML. The current default version is available as {{self.evt_settingVersions.data.settingsVersion}}.    Note that CSCs which want to set the {{otherSettingsEvents}} field should do that in the constructor, by setting {{self.evt_settingsApplied.data.otherSettingsEvent}}. Document that in """"How to write a CSC"""".    Finally try to figure out how to output {{settingsVersions}} and {{settingsApplied}} in {{BaseCsc}}. These will be nearly empty. The trick is doing this in a way that does not interfere with {{ConfigurableCsc}}."""
"DM-23707","Story","Science Platform",2,"Add JS9 to the stable LDF deployment","""In order to do our visualization bake-off, I'll need access to a cluster local JS9 server.  I'm still unclear whether it would be better to have a singleton, or to spawn a server in everyone's namespaces, but I guess we'll go with the former first.    Eric Mandel has supplied an image that can be used to spin up a server using docker.    {{docker run -dit -p 8080:80 -p 2718:2718 ericmandel/js9server}}"""
"DM-23703","Bug","ap_association",1,"ap_association fails if a new visit has 0 new diaObjects","""When {{association.py}} is called on a new visit, {{new_dia_objects}} is initialized as an empty list. That list only receives properly formatted entries if there are in fact any new DIA objects, but it is used to create the {{new_dia_objects}} pandas dataframe regardless. This results in an error on the next line when diaObjectId is set as the index: [https://github.com/lsst/ap_association/blob/744ec977e52da689ac3639ffcbb519abeedabcd2/python/lsst/ap/association/association.py#L416]         Example error message:  {code:python}  Traceback (most recent call last):    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/pipe_base/19.0.0-9-g0ae078d+4/python/lsst/pipe/base/cmdLineTask.py"""", line 388, in __call__      result = self.runTask(task, dataRef, kwargs)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/pipe_base/19.0.0-9-g0ae078d+4/python/lsst/pipe/base/cmdLineTask.py"""", line 447, in runTask      return task.runDataRef(dataRef, **kwargs)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/pipe_base/19.0.0-9-g0ae078d+4/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/ap_pipe/19.0.0-6-g8dfed85+6/python/lsst/ap/pipe/ap_pipe.py"""", line 180, in runDataRef      diaPipeResults = self.runAssociation(calexpRef)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/pipe_base/19.0.0-9-g0ae078d+4/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/ap_pipe/19.0.0-6-g8dfed85+6/python/lsst/ap/pipe/ap_pipe.py"""", line 267, in runAssociation      ccdExposureIdBits=sensorRef.get(""""ccdExposureId_bits""""))    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/pipe_base/19.0.0-9-g0ae078d+4/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/ap_association/19.0.0-13-g744ec97+5/python/lsst/ap/association/diaPipe.py"""", line 212, in run      loaderResult.diaSources)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/pipe_base/19.0.0-9-g0ae078d+4/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/ap_association/19.0.0-13-g744ec97+5/python/lsst/ap/association/association.py"""", line 128, in run      matchResult = self.associate_sources(diaObjects, diaSources)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/pipe_base/19.0.0-9-g0ae078d+4/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/ap_association/19.0.0-13-g744ec97+5/python/lsst/ap/association/association.py"""", line 222, in associate_sources      match_result = self.match(dia_objects, dia_sources, scores)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/pipe_base/19.0.0-9-g0ae078d+4/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20200220/stack/miniconda3-4.7.12-984c9f7/Linux64/ap_association/19.0.0-13-g744ec97+5/python/lsst/ap/association/association.py"""", line 416, in match      new_dia_objects.set_index(""""diaObjectId"""", inplace=True, drop=False)    File """"/software/lsstsw/stack_20200220/python/miniconda3-4.7.12/envs/lsst-scipipe/lib/python3.7/site-packages/pandas/core/frame.py"""", line 4303, in set_index      raise KeyError(f""""None of {missing} are in the columns"""")  KeyError: """"None of ['diaObjectId'] are in the columns""""    {code}"""
"DM-23702","Bug","ip_isr",1,"IsrTask shoud use regular Input for raw data","""Currently IsrTask connection are defined with all inputs being of PrerequisiteInput type. It should instead be using regular Input type for at least a """"raw"""" type top constrain its inputs to only existing inputs, otherwise it will result in all possible combinations of visits/detectors being used.    Slack link: https://lsstc.slack.com/archives/C2JPT1KB7/p1582938474109700"""
"DM-23701","Improvement","ctrl_mpexec",1,"pipetask-produced DOT for pipelines should show prerequisite inputs","""the DOT graph produced now for pipelines does not include prerequisite inputs, would be nice to add them to the graph but also make them distinguishable from regular inputs."""
"DM-23700","Story","ts_qa",2,"Update and improve various testing documentation.","""Basically, some of the testing documentation is out of date (bad links, old data) and is missing some recent developments, like the CI/CD process.    Attached in an email from Andy with his thoughts.  I will break out the points in that email into bulleted items in this ticket or make new tickets, depending on required effort."""
"DM-23699","Story","fgcmcal",2,"Update fgcmcal default config format to remove possibility of index errors","""The configuration format for {{FgcmFitCycleTask}} has some elements that must be specified in band order.  While this was fine (such as it was) with 5 bands (g,r,i,z,y), with the addition of several narrow-bands this has become more obviously unwieldy.  It would be easy to change these configs to use dictionary mappings instead of ordered lists which would remove ambiguity and make mis-configurations much less likely."""
"DM-23698","Story","fgcmcal",1,"Investigate N387 fgcmcal failures in PDR2 rerun","""In DM-23394, [~hchiang2] reports that there are a number of PDR2 visits that did not produce {{photoCalib}} outputs from {{fgcmcal}}.  This will happen when a visit is deemed to be unsolvable (but this should be logged clearly).  However, there are a number of deep-field N387 visits in the deep fields that were deemed to be unsolvable but from cursory inspection should have been usable."""
"DM-23735","Bug","templates",0.5,"Fix ""name"" variable in roundtable_aiohttp_bot template","""The lsst-templatebot-aide service expects projects to have a variable called """"name"""" that it turns into the name of the repository. Unfortunately in roundtable_aiohttp_bot, the {{name}} variable is instead {{repo_name}}. This ticket will fix that."""
"DM-23728","Story","ci_hsc",2,"Cleanup ci_hsc_gen2 to use new convert script instead of custom one","""In order to help get DM-22655 merged sooner, I'm going to move the work of converting ci_hsc to use the new script onto this ticket, instead of doing it there. I'd already started on that process, and will move that work onto this ticket."""
"DM-23722","Story","daf_butler|pipe_base",1,"Validate dataset type definitions in pipeline task connections","""In debugging DM-22655 we realized again that the dataset type definitions for input datasets in pipeline task connectors are not validated against dataset type definitions already understood by the registry. This led to a strange bug where cpBias had a ExposureF when the file was ingested but the isrTask definition said it was an ImageF.  This led to the pipeline creating a DatasetType object that was at odds with the registry definition and caused an error on get.    At the very least we should warn if there is an inconsistency between the two when the pipeline runs."""
"DM-23719","Story","ts_main_telescope",3,"Write camera cable wrap CSC","""Write the portion of the MTMount CSC that controls the camera cable wrap.    I will probably do this work before finishing the PXI simulator DM-23118 because we should have an existing hardware simulator to talk to, as well as the real hardware, and I consider it higher priority."""
"DM-23718","Story","daf_butler",0.5," Replace dots in gen3 file names","""-In DM-23717 we were reminded that filters can have spaces in them and these end up in file names.-    Dots in the file part of templates cause confusion when extension manipulation occurs in the {{Location}} class. To be safe replace dots in the file name with underscores. Do not change dots in directory parts of path though.    This fix is essentially the same fix as was done in DM-23503 for """"/""""."""
"DM-23717","Story","jenkins",0.5,"FitsError building obs_decam on Jenkins mojave-1","""[Build #31303|https://ci.lsst.codes/blue/organizations/jenkins/stack-os-matrix/detail/stack-os-matrix/31303/pipeline] failed on node mojave-1 in obs_decam {{test_ingest.py}}. Four test cases failed; example error is:        """
"DM-23713","Story","ts_qa",2,"Create CSC deploy-env Jenkins build","""To continue with the CSC build process, we need to start with the deploy-env image.  This needs a Jenkins build to ensure consistency."""
"DM-23711","Story","daf_butler",0.5,"Allow butler configs to use environment variables to find other configs","""We have been discussing on Slack how to allow gen3 configs to be combined from multiple sources.  One option is for the EUPS table file to add a search directory to DAF_BUTLER_CONFIG_PATH.  This works fine but can be unpredictable since the contents of the configuration can depend on precisely which packages have been set up.    On this ticket we will extend {{includeConfigs}} support to allow an environment variable to be specified in addition to a full path or relative path."""
"DM-23769","Story","HeaderService",2,"Add dome information to LATISS headers","""Information values in:  https://confluence.lsstcorp.org/display/SYSENG/Auxiliary+Telescope+Header+Information+Topic+Mapping            """
"DM-23759","Story","Science Platform",2,"Add JS9 JupyterLab extension to nublado","""I have tested out the process for building the extension and it seems to work using {{jupyter-lab}} version 1.2.6 on my laptop.    I followed the instructions [here|https://github.com/mgckind/jjs9] with the exception that I also needed to install {{pandas}}."""
"DM-23753","Story","ts_main_telescope",1,"Train Andrew the Use of Hexapod","""Train Andrew the use of hexapod."""
"DM-23751","Story","System Integration and Test",3,"Create feature releases in GitHub repos for new MTM1M3 and MTVMS","""Create feature branches and then release for the new SAL4 compatible   versions of the M1M3MT and MTVMS packages as tested in Chile"""
"DM-23750","Story","System Integration and Test",2,"Update VMS software and install on summit machines","""Update the VMS software for SAL 4 and OpenSplice 6.9 compatabilty.  Install on summit cRIO and PC and test (no real telemetry yet though)  basic function and logging of telemetry to summit EFD"""
"DM-23780","Story","Science Platform",1,"Refresh jupyterlabutils cluster classes","""The {{LSSTClusterClient}} doesn't work with the version of {{dask.distributed}} that ships with the most recent weekly.  Specifically the way timeouts work has changed in {{dask.distributed}}, so the exponential back off loop in {{LSSTClusterClient}} does not work as expected.    Anecdotally, the problem with {{dask.distributed}} that we were working around with that backoff loop seems to not be a problem anymore, so we can probably take that out.    It may now be that {{LSSTClusterClient}} can be slimmed down to be just a subclass of {{Client}} that overrides the {{__repr__}}.    The {{ClusterProxy}} seems to have bit rotted.  The link to the scheduler status page works, but the links to the status page for the individual workers end up in 500s."""
"DM-23778","Story","obs_lsst",2,"Write config and tests for obs_lsst gen2-gen3 convert","""[~tjenness] pointed out during the review of DM-22655 that we have gen2 repos to test obs_lsst gen2-3 conversion. We will also need to specify some configs specific to this package. Implementing `test_convert2to3.py` would be an easy start, once the right test data is identified.    [~tjenness]: In your comment you said """"This repo even comes with a bunch of gen2 repos..."""": where are they, and what to they contain? We do have `testdata_lsst`, but that's not in lsst_distrib (how big is it? The readme isn't helpful.) and it doesn't contain premade gen2 repos."""
"DM-23773","Story","ts_calibration",2,"Refactor TunableLaser CSC and upgrade to latest salobj(5.x)","""Fix outstanding issues with TunableLaser CSC and perform upgrade to TunableLaser CSC"""
"DM-23772","Story","ts_calibration",1,"Fix detailed states for TunableLaser CSC","""Currently the TunableLaser CSC's detailed states duplicate the summary states and only include a propagating detailed state. The duplicated summary states should be removed and a nonpropagating state should be added."""
"DM-23771","Story","ts_middleware",2,"Add a CscCommander class to salobj","""Add a CscCommander class to salobj, much like the one in ts_hexrotcomm. This should allow making trivial scripts to exercise a CSC. It should handle simple commands automatically and allow overrides for more complex commands."""
"DM-23809","Story","HeaderService",2,"Add weather station headers to header service","""We do not currently write any weather station values to the header. LSE-400 lists:    AIRTEMP  PRESSURE  HUMIDITY  WINDSPD  WINDDIR  SEEING - DIMM seeing value  Please add them in their own section of the header.    Updated information values in     https://confluence.lsstcorp.org/display/SYSENG/Auxiliary+Telescope+Header+Information+Topic+Mapping"""
"DM-23808","Story","ts_auxiliary_telescope",0,"Make azimuth encoder counts long long in ATDome position telemetry","""Change the type of the azimuthEncoderPosition field of the position telemetry topic for ATDome from {{unsigned long}} to {{long long}}. The current field is too short."""
"DM-23802","Story","ts_middleware",1,"Improve DDS queue warnings in salobj","""ts_salobj warns if the DDS queue starts to fill up, but the warning is too crude. At present it warns if it reads >= 10 messages and never again, until it resets the warning when it reads only 1 message.    What we want to know is something on the order of:  - reached 10%  - reached 50%  - reached 90%  - reached 100% (error: data likely lost)    Also the warning should be reset in some fine-grained fashion, e.g. if we reach 10% then report that we have improved, and warn at 50% again.    Use the {{QueueLengthChecker}} for this (it is already used for messages about the Python queue).    Also there are two warnings about queues: one for the DDS queue and one for the Python queue. Improve the text for each so it is completely clear which warning applies to which cache."""
"DM-23801","Story","ts_auxiliary_telescope|ts_main_telescope",0,"Fix ""Contributing"" entry for ts_ATDome and my other T&S packages","""The """"Contributing"""" entry in index.rst is wrong for ts_ATDomeTrajectory and possibly others of my packages as well. T&S Jira tickets should be specified by label, not component (unlike DM)."""
"DM-23800","Epic","ts_main_telescope",40,"Develop and Test the Hexapod and Rotator Software Phase 2","""This epic will maintain, develop, and test the software of Hexapod and Rotator contains the middleware, GUI, and wrapper code in cRIO.    This will include testing of the CCW and Camera Hex/Rot on the Camera Cart at the Summit.  This testing is currently slated for the first two weeks of December.    This is a continuation of epic: DM-21931"""
"DM-23799","Story","ts_main_telescope",3,"Review the Rotator PXI Code","""Review the rotator PXI code to have some understanding of it. This task will try to compile the code by the autotool as well."""
"DM-23812","Story","ts_auxiliary_telescope|ts_main_telescope",0,"Add log name to the logMessage topic","""Add log name to the logMessage topic. I originally thought that since logMessage is associated with a particular CSC the information was redundant, but I am wrong because components of the CSC may use child logs with component-specific names and presently that information is lost.    Update ts_salobj to set this field -- probably conditionally on it existing, so that salobj is compatible with older XML."""
"DM-23830","Story","cbp|lsst_distrib",1,"Add cbp package to lsst_distrib","""Implement RFC-658."""
"DM-23828","Story","obs_decam",2,"Create small test decam gen2 repo with calibs for test_convert2to3.py","""The decam convert tests in DM-22655 rely on a gen2 repo that does not exist in our CI system. To make those tests able to be run as part of CI, we need to shrink the calibration data that lives in ap_verify_ci_hits2015, and make a gen2 repo with it. If the data is small enough, that data could even live in obs_decam.    [~tjenness]'s suggestion is to not zero all the data, but to set each data array to the HDU number, so that we can still test that gen3 and gen2 read the same pixel data."""
"DM-23827","Bug","qa_explorer",1,"wrong python type for matchVisits_config","""I encountered the following error:       Somehow somewhere it thought {{matchVisits}} is from {{lsst.pipe.tasks}}; it should be from {{lsst.qa.explorer}}.   I found an entry in obs_base that has it wrong.     I don't understand why this bug wasn't causing problems before.  """
"DM-23826","Story","ts_middleware",0,"The test of getCurrentTime ts_sal is failing","""[~athornton] reports that the test of getCurrentTime is failing on two different systems. Adam helped me get credentials on a system that showed the problem and it turns out that it is due to a recent change to astropy: astropy now downloads a leap second table at need, and this was occurring in the middle of the test, making measured time differences much larger than expected.    I looked at both the 4.0 and 4.1 branches of ts_sal and concluded that only the 4.0 branch needs a fix, which is to get astropy time once before running the time-critical portion of the test.    The test is radically different in SAL 4.1 (it uses the new getLeapSeconds function) and is immune to this problem."""
"DM-23822","Story","HeaderService",1,"Create containers for ts_xml 4.7.0 and HeaderService 1.4.1","""New version of header service needs a container to run on the summit asap.    """
"DM-23820","Story","ts_documentation",0,"Clean up the Subsystem.xml file ","""The Subsystem.xml file is woefully out of date and/or just wrong.  Hoping to fix it a bit."""
"DM-23815","Story","ts_main_telescope",3,"Update the M2 xml","""Update the M2 xml based on the M2 test result at Mar., 2020. The ICD is LTS-162. After the [M2 test|https://confluence.lsstcorp.org/display/LTS/M2+Testing+on+Summit+at+March+2nd+-+6th%2C+2020], we realized that we may need to update the xml to fulfill the condition now and extend the original xml for the need."""
"DM-23839","Bug","Middleware",1,"Fix MTM1M3 Telemetry name","""Fix MTM1M3 telemetry topic powerData to along with code  ie powerSupplyData  """
"DM-23836","Bug","ip_diffim",1,"DCR templates have incorrect variance","""The DCR templates for image differencing incorrectly set the variance using only the variance plane of the first subfilter that is loaded. The final variance plane is too low by a factor equal to the actual number of subfilters, resulting in an incorrect threshold for detecting sources in image differencing."""
"DM-23848","Story","ts_main_telescope",3,"Put the Rotator into Standby State after the clearError Command","""Put the rotator PXI into the standby state after clearing the error. This task will need to update the Simulink model for the state machine transition. This task also needs to write the related test in Simulink to testify this change. After this, I will need to generate the C/C++ code and put back to ts_rotator_controller and test the new built. I need to think I can test this in C/C++ level in additional to the Simulink level or not."""
"DM-23846","Bug","obs_lsst",0.5,"YAML files with python/object/apply fail in pyyaml>5.2.1","""python/object/apply is considered unsafe. PyYAML 5.2.1+ (at least in 5.3 for sure) seems like they will not load YAML files with python/object/apply using the FullLoader. This seems to make, at a minimum, astro_metadata_translator unhappy in some inute tests for obs_lsst test data.    Here is a test failure    """
"DM-23844","Story","ts_dome",1,"Make sure that the reply to the STATUS command is in line with the proposed communications protocol","""The current implementation of the mock controller doesn't exactly follow the proposed communications protocol. Fix please."""
"DM-23842","Story","ts_dome",2,"Add additional SALOBJ functions to the Dome CSC","""Now that SALOBJ has been added to the project, it is time to implement the azimuth motion control commands."""
"DM-23875","Story","ts_auxiliary_telescope|ts_main_telescope",0,"Update logEvent message for Script and LOVE","""The logMessage topic is defined in several places: generics, Script and LOVE, at least.    I recently updated the generic version but forgot to update the other versions.    Note: we can get rid of the copies once SAL 4.1 is released. It will require an update to SALSubsystems.xml to list which generic topics Script and LOVE use."""
"DM-23874","Story","ts_main_telescope",0,"Add clearError command to NewMTMount","""Add a clearError command to NewMTMount that includes a field for a bitmask of which errors to clear.    Also fix moveToTarget command to eliminate the unwanted azimuth direction flag and clean up the axis state enums a bit."""
"DM-23873","Bug","cp_pipe",1,"Typo in cp_pipe makeBrighterFatterKernel.py","""Two issues:    (1) Function name in line 585 is mis-spelled.  Is spelled fitPtcAndNonlinearity and should be fitPtcAndNonLinearity.    (2) Same function in line 585 is missing  the lookupTableArray input variable.    I have verified that with these two fixes, it all runs OK.    As an aside, I'm surprised there are not automated checks to check for function calls to functions that do not exist!"""
"DM-23865","Story","Documentation",1,"Create an LCR proposing that the LSP be renamed VERA","""This ticket simply captures the outcome of RFC-673; no further action is expected."""
"DM-23898","Story","ts_main_telescope",3,"Test MTMount CSC with the real camera cable wrap and/or the PXI simulator","""Test the new MTMount CSC with the real camera cable wrap and/or the PXI simulator (preferably both) and fix any problems that show up."""
"DM-23894","Story","pipe_analysis",3,"coaddAnalysis: RuntimeError: No good data points to plot for sample labelled: star","""In one edge tract/patch of the HSC-PDR2 DEEP+UDEEP,  coaddAnalysis gave this error:                 Could this edge case be handled more gracefully, such as a softer warning and skipping plotting the patch rather than an error, or other approaches?     The {{pipe__analysis}} version is at commit {{c11be5b}} with stack w_2020_08. """
"DM-23885","Story","ts_main_telescope",2,"cRIO FPGA operation","""Learn how are command passed from ts_m1m3support C/C++ controller to FPGA, and replies passed back."""
"DM-23904","Story","Middleware",3,"SAL release 4,1 candidate","""Test and create SAL 4.1.1 release candidate branch in github. Test with python 3.7.6 and bug fixed version of OpenSplice 6.9 , and XML 4.8"""
"DM-23903","Story","Middleware",2,"Update OpenSpliceDDS repo and rpms with bug fix","""Update the community editioh of OpenSplice  V6.9 with the pydds memory leak fix provided by ADlink. Build and distrubute RPM and update Nexus and github repos"""
"DM-23925","Story","ts_qa",2,"Implement Jenkins parallel stage functionality to the SAL Release job","""As demonstrated in the work on DM-23106, the parallel stage functionality is a real time saver.  Implement this same strategy in the SAL release job, also parallelizing the messaging tests."""
"DM-23922","Story","ts_dome|ts_main_telescope",1,"Add Dome _labels.yaml","""In order for the unit tests of ts_Dome to pass, an empty _labels.yaml is needed."""
"DM-23920","Epic","ts_main_telescope",20,"M1M3 On-going Learning and Updates","""This epic is to capture the on-going learning effort of Petr for the M1M3 and capture any work he does on the M1M3 Support system."""
"DM-23940","Story","ts_middleware",1,"Add CLOCK_TAI support to time in Python","""I filed https://github.com/astropy/astropy/issues/10052 to request CLOCK_TAI support in the time module in Python and was told they would likely accept a patch. Provide one."""
"DM-23933","Story","ts_dome",3,"Produce and consume communication strings with YAML","""We are still reviewing the use of YAML in stead of using plain semi-colon separated strings for the communication between the upper and lower level components but I am going ahead and will start implementing YAML already since this is the way we will go.    EDIT: YAML has been accepted as the preferred communications protocol."""
"DM-23931","Story","daf_butler",1,"Allow butler.makeRepo to complain if a config already exists","""There are many times where we can call makeRepo in cases where a butler repository already exists (or at least the config file exists). It would be useful for makeRepo to be able to complain if that is the case."""
"DM-23960","Story","System Integration and Test",2,"Investigate options for TMA use of EOL'd NI software","""Review the use of EOL'd software components by the TMA control software.  In particular NI SoftMotion module."""
"DM-23959","Story","obs_base",1,"CameraMapper._standardizeExposure should patch header","""When reading a {{""""raw""""}} dataset from the butler, we get an {{Exposure}} back. However, the metadata contained within that {{Exposure}} has not been patched. I believe {{CameraMapper._standardizeExposure}} should call {{fix_header}}."""
"DM-23958","Story","System Integration and Test",1,"Install OpenSplice Enterprise at NCSA","""Obtain license for the install OpenSliceDDS Enterprise and tools on a dedicated node   in the NCSA test stand cluster."""
"DM-23956","Story","alert_packet|alert_stream|sample-avro-alert",2,"Audit sample-avro-alert & alert_stream repositories","""Take a look through the lsst-dm/sample-avro-alert & lsst-dm/alert_stream repos. Understand what's there, and think about whether you understand it and would be able to maintain it. File tickets for any changes that you'd like to make in the short term (and think about longer term evolution, which we should probably discuss in person). Take a look at the ticket backlog on those repos, and see if those tickets seem relevant/obsolete/unclear/etc."""
"DM-23953","Story","ts_main_telescope",2,"Allow logging into file(s)","""Change M1M3 support logging to allow for logging into a file - the current logging assumes it's logging to stdout, and prints out escapes for color logging."""
"DM-23952","Story","meas_deblender",1,"Remove scarlet and proxmin from meas_deblender","""When we  upgraded to scarlet 0.5 in early 2019 we decided that rather than try to place more bandaids on {{meas_deblender}} we would create the new {{meas_extensions_scarlet}} package. In doing so {{meas_deblender}} was left alone, which still included dependencies on {{scarlet}} and {{proxmin}} with code that likely has bit rotted. So this ticket is just to remove all references to {{scarlet}} and {{proxmin}} from {{meas_deblender}} and delete the dependencies, as they be related to an obscure failure in the build system."""
"DM-23950","Story","ts_main_telescope",2,"Change configurations path","""Change M1M3 support to use configured path instead of hardcoded."""
"DM-23949","Story","ts_main_telescope",2,"Changes FPGA to singleton","""FPGA object is passed as parameter to multiple classes constructors. Its much better to implement FPGA as Singleton (as it's completely unexpected we will ever run M1M3 support on cRIOs with multiple FPGAs) and use it this way, removing multiple passing of pointer. This will also facilitate transaction from FPGA class to IFPGA, its abstract parent, which can be either real FPGA or simulated FPGA."""
"DM-23946","Story","meas_base|pipe_tasks",8,"Change localWcs plugins to use a localGnomonicWcs transform.","""[~jbosch] found that the current functor for localWcs would not return a valid transform when far from the Wcs center as it uses getCdMatrix/getTANWcs which behave poorly when far from the Wcs origin/do not utilize larger distortions. This ticket will change the plugins and functors to use linearizePixelToSky instead."""
"DM-23983","Bug","ip_isr",20,"Cannot apply crosstalk in Gen 3 DECam processing","""{{IsrTask}} delegates complex crosstalk corrections to {{CrosstalkTask}}. However, the Gen 3 call to {{CrosstalkTask}} is [disabled|https://github.com/lsst/ip_isr/blob/5673ca6e3699f4db46772b3e01c59e44131b93bf/python/lsst/ip/isr/isrTask.py#L870-L874], citing DM-17169. Because {{CrosstalkTask}} does not run, Gen 3 calls to {{IsrTask}} will fail unless the configuration includes {{doCrosstalk=False}}.    Please make it possible to run {{CrosstalkTask}} in Gen 3 and re-enable it."""
"DM-23980","Story","obs_decam|obs_lsst|obs_subaru",1,"Standardize Gen3 instrument class names and location","""Currently the gen3 instrument classes have no consistency in naming or module path. This adds to the confusion. Currently we have:    * lsst.obs.subaru.gen3.hsc.instrument.HyperSuprimeCam  * lsst.obs.decam.instrument.DarkEnergyCamera  * lsst.obs.lsst.gen3.instrument.LatissInstrument  * lsst.obs.lsst.gen3.instrument.Ts8Instrument  * lsst.obs.lsst.gen3.instrument.Ts3Instrument  * lsst.obs.lsst.gen3.instrument.UcdCamInstrument  * lsst.obs.lsst.gen3.instrument.PhosimInstrument  * lsst.obs.lsst.gen3.instrument.ImsimInstrument  * lsst.obs.lsst.gen3.instrument.LsstComCamInstrument  * lsst.obs.lsst.gen3.instrument.LsstCamInstrument    corresponding to instrument names of HSC, DECam, LATISS, LSST-TS8, LSST-TS3, LSST-UCDCam, PhoSim, LSST-ImSim, LSST-ComCam, lsstCam.    Instrument names have to be unique in Gen3 since telescope is not part of the data model. This is why TS8 is not TS8. lsstCam should probably be LSSTCam.    This ticket will try to clean things up a bit.    obs_cfht has no gen3 support at this time."""
"DM-23977","Story","ts_main_telescope",1,"Move Python code from ts_m1m3supporteui into own repository","""Move Python code from labview ts_m1m3supporteui feature/Python branch into develop branch of ts_m1m3supportgui."""
"DM-23976","Story","obs_base|obs_decam|obs_lsst|obs_subaru",2,"Move gen3 generic curated calibrations ingest code to obs_base","""In DM-23778 I updated writeCuratedCalibrations to support QE curves as well as defects. This is generic code that uses the pipe_tasks read_all function to read standardized calibration data from {{obs_x_data}} packages.  Since by definition these calibrations are standardized we should move this code to obs_base and ensure that all gen3 instruments call it if they have defined an _data package.  The relevant dataset types and curated calibrations would only be created/ingested if they exist in the _data package (which by definition means they are standardized).  The instrument subclasses should only be required to define their non-standard curated calibrations."""
"DM-24003","Story","ts_main_telescope",2,"Refactor the Autotool Files in ts_rotator_controller","""This task will reorganize the files in ts_rotator_controller and update the related configuration.ac and Makefile.ac. This is to improve the readability and maintainability of repository."""
"DM-23998","Story","ts_main_telescope",3,"Update ts_MTMount based on new information from Tekniker","""Update the ts_MTMount code based on my conversation with Alberto 2020-03-23. Changes include:  * Enforce only one command at a time.  * The source field of errors and warnings is a string of the form {{f""""\{subsystem_id\}. \{text\}""""}}, rather than a simple integer.  * The CSC should not command the azimuth cable wrap; let the azimuth axis take care of it. Remove the azimuth cable wrap from the simulator.  * Use the suggested startup sequence.  * Add the suggested shutdown sequence.  * Corrected the source-ish field for the error and warning replies. I had assumed it was an integer, but it turns out to be a string (that starts with an integer; it's ugly)."""
"DM-23997","Story","ts_dome",1,"Consolidate assertComponent and assertOK functions into one assertReply function","""Since the structure of each reply received from the mock controller is similar, it is possible to have one assert method for each kind of reply instead of dedicated ones."""
"DM-23993","Story","ts_dome",1,"Correct sending of OK reply in mock_controller","""The OK reply sent from the mock_controller lacks a space right before the Timeout keyword."""
"DM-23992","Bug","obs_base|obs_decam",2," Cannot load refcats in Gen 3 DECam processing","""Attempting to run the Gen 3 single-frame pipeline as described in [DM-23616|https://jira.lsstcorp.org/browse/DM-23616?focusedCommentId=240326#comment-240326] leads to {{AstrometryTask}} crashing with the error """"No reference tables could be found for input region"""". Running with {{--show graph}} reports that no photometric or astrometric reference catalog shards are included in the quanta for {{CalibrateTask}}. However, they can be retrieved from the Butler using {{Registry.queryDatasets}} (only tested with no data ID constraints).    The working hypothesis from [#dm-middleware|https://lsstc.slack.com/archives/C2JPT1KB7/p1585010272157800] is that this is a problem in ingestion (i.e., in {{convert_gen2_repo_to_gen3.py}}), so I'm filing this as a bug in {{obs_base}}.    Please fix the conversion\(?) so that a repository created as described in DM-23616 can correctly match catalogs to image data IDs."""
"DM-23991","Story","Science Platform",5,"JUPYTERHUB_SERVICE_PREFIX environment variable not passed to workflow environment","""Trying to run the all sky gaia dask notebook fails in the workflow system because the {{JUPYTERHUB_SERVICE_PREFIX}} environment variable is not set in the workflow environment.  This causes dask to throw an exception when it tries to construct the path to the scheduler dashboard interface.    I have confirmed that variable is set in an interactive JupyterLab running {{w_2020_12}} on stable."""
"DM-24015","Story","ts_main_telescope",2,"Review the Rotator Simulink Model","""Review the rotator Simulink model by MOOG. This is to have an initial understanding how the code works and have the idea how to modify it. This task will remove the hard-coded paths in the model for the evaluation as well."""
"DM-24013","Story","ctrl_mpexec",0.5,"Fix bug in --output-run handling introduced in DM-21849","""See [https://lsstc.slack.com/archives/C2JPT1KB7/p1585160382064500]     """
"DM-24012","Story","ts_qa",3,"Prepare for SAL v4.1.x release - Part 1","""Catch-all task to cover various activities needed to prepare for the SAL v4.1.x release.   * V4.1.1 requires Python 3.7.6, so update the Docker image accordingly.   * Cut release candidate branches and run tests.   * Implement Jenkins parallel stages in the SAL Release job   * Update SAL tests with SAL v4.1.0 changes"""
"DM-24034","Story","ts_qa",3,"Prepare for SAL v4.1.x release - Part 2","""Catch-all task to cover various activities needed to prepare for the SAL v4.1.x release.  This is a continuation of DM-24012 into the next sprint   * V4.1.1 requires Python 3.7.6, so update the Docker image accordingly.   * Cut release candidate branches and run tests.   * Implement Jenkins parallel stages in the SAL Release job   * Update SAL tests with SAL v4.1.0 changes"""
"DM-24027","Story","pipe_tasks",1,"CalibDate misinterpreted in curated calibration ingest","""The metadata checking code that runs during read of curated calibrations from obs_x_data packages incorrectly assumes that CALIBDATE should match the validity start.  It turns out that CALIBDATE is meant to be a label for the calibration and is distinct from validity. Please remove the check that requires them to match."""
"DM-24026","Story","ts_main_telescope",2,"Update M1M3 simulator dockerfile to run current simulator in Docker","""Dockerize ts_m1m3simulator."""
"DM-24021","Story","HeaderService",2,"Update docker containers for headerservice with ComCam","""Now that we also have HeaderService for ComCam which uses the same code base as LATISS, we need to have a generic naming for the headerservice."""
"DM-24018","Story","daf_butler",0.5,"Failure to flatten or filter chained collections in queries","""https://lsstc.slack.com/archives/C2JPT1KB7/p1585184879129400"""
"DM-24051","Story","ts_auxiliary_telescope|ts_main_telescope",0,"Remove workarounds for an older version of the ATMCS trackTarget command","""We had to put some ugly code in ts_standardscripts in order for it to work with the version of ATMCS trackTarget command in ts_xml 4.8 and the next version. Remove that when we no longer need ts_xml 4.8."""
"DM-24047","Story","ts_main_telescope",2,"Implement S3 LFA image upload for the Fiber Spectrograph","""The Fiber Spectrograph does not yet try to upload the images it takes to the LFA. Update the code to make that happen."""
"DM-24046","Story","ts_main_telescope",1,"Try to use NCSA's LFA S3 service","""[~felipe] gave me credentials for NCSA's S3 LFA service. Try to use these credentials from home to figure out what will be needed for our CSCs."""
"DM-24045","Story","ts_main_telescope",2,"Add unit tests for mock devices and the mock controller to MTMount","""Add unit tests for the mock devices and the mock controller to ts_MTMount."""
"DM-24043","Story","ts_main_telescope",0,"Build the Lastest MTAOS Docker Image","""Build the latest docker image of MTAOS. The environment of `b41` and ts_xml v4.7.0 is used."""
"DM-24060","Story","meas_algorithms",1,"Improve table creation efficiency in Defects","""DM-24055 made a significant improvement in defect reading speed. Now the profiler is showing that there are some reasonable gains that can be made by adjusting table creation to use columns rather than per row assignment."""
"DM-24055","Story","meas_algorithms",1,"Speed up table parsing in Defects","""Reading defects is taking a very long time. Some of the larger defects files from DECam take over 2 seconds to read in. The bulk of this is in afw Table processing. It seems I was doing it wrong and it can be significantly optimized by preselecting keys."""
"DM-24247","Story","daf_butler",0.5,"butler validation error in ci_hsc_gen3","""[~npease] ran the butler config validation on the ci_hsc_gen3 output repo and got the following report:      Fix the template."""
"DM-24244","Bug","daf_butler",1,"w_2020_13 makeButlerRepo.py missing left parens error with Oracle","""Doing weekly run of ci_hsc_gen3 using weekly stack and Oracle for w_2020_13.   makeButlerRepo.py dies with:    """
"DM-24239","Epic","ts_main_telescope",40,"M1M3 Support System Improvements","""On-going list of improvements to the M1M3 support system."""
"DM-24238","Story","ts_main_telescope",3,"Check M1M3 command input parameters","""M1M3 controller lack (almost any?) parameter checking. At least running M1M3 start_commander without proper Default (configuration name) will throw an error on m1m3 support. That needs to be rectified, verified and sensible messages returned."""
"DM-24237","Story","System Integration and Test",3,"Review proposed replacement for NI softmotion module in TMA software","""Review the porposed solution (Tekniker) to replace the use of NI Softmotion Axis  calls with substitute/direct calls to OpenPLC equivalents. Assist engineers in  establishing a local TMA controller simulation environment with PXI capable PCs'"""
"DM-24236","Story","System Integration and Test",1,"Assist EAS software contractor and update XML","""Assist the EAS contractor with building and testing the software against latest  SAL and DDS versions, rpi firmware upgrades, XML definition"""
"DM-24235","Story","Middleware",3,"Assist CI test and release SAL 4.1 RC2","""Assist SAL 4.1 release CI process with any required tweaks anf fixes revealed during CI  testing """
"DM-24234","Story","ts_main_telescope",0,"Review the Draft of LTS-162 v5","""Review the draft of LTS-162 v5:    [https://www.dropbox.com/s/zgoq9zmcqtogyyz/LTS-162_v5.docx?dl=0]"""
"DM-24262","Story","ap_verify|jenkins",8,"Run HSC AP processing in CI using Gen 3","""Add an HSC Gen 3 dataset to the {{scipipe/ap_verify}} Jenkins job. The job should already be designed to let us plug in more datasets, so the main work would be specifying a Gen 3 run (requires adding an internal flag to the Jenkins job?) and working with Groovy."""
"DM-24250","Story","fgcmcal",2,"Improve startup speed of fgcmcal and add checkpointing for restarts","""The recent large runs of {{fgcmcal}} on HSC data have shown that (a) in certain use cases the startup time is a factor of a few slower than it could/should be, and (b) certain files can be checkpointed to allow faster restart in case of transient file system failures, out of memory issues, etc.  I have a branch {{/u/erykoff/fasterstart}} that implements these changes and will be cleaned up."""
"DM-24285","Bug","daf_butler",1,"fitsExposureFormatter fails to read ""Exposure"" entries correctly","""Copying from slack so I don't get confused in the future:    {quote}  Oh, wait, that's just invoking storageClass.pytype(...) (which will never work with just Exposure sans suffix) instead of using ExposureFitsReader.  15:30  This is a bug in the formatter, I think.  {quote}"""
"DM-24277","Story","jointcal",8,"Apply proper motion and parallax while loading refcats in Jointcal","""There's existing code in the stack to apply proper motions and parallaxes from the reference catalog. Find it, dust it off, and get it going in Jointcal. It may require some modification. If it requires substantial overhauls (e.g. rewriting completely because it's too slow), let's make a new ticket to capture that.    For now, we will correct the reference catalog to the mean epoch of the loaded data."""
"DM-24276","Story","DM",1,"update LPM-251 ","""Perhaps include the usage table from [PSTN-003.lsst.io|http://pstn-003.lsst.io/]  perhaps one of the sizing cost tables - With a ref to DMTN-135 ..     We could also add the Check LIst for iDacs .. discussed in CEC meeting.."""
"DM-24292","Story","ts_main_telescope",2,"Review the Configuration Manager by MOOG","""Review the configuration manager by MOOG. This is a LabVIEW project."""
"DM-24350","Story","efd",2,"Add EFD notebooks to CI","""We currently have a few example efd notebooks.  These should be converted to use the modern utility classes and added to the list of CI'd notebooks.  Now that there is EFD data available from the EFD on int and visible from stable, this is now something we can do.    I would also like to promote the notebooks to the prod branch so that they show up automatically.  That may be thwarted by the fact that the correct data may not be available everywhere.    Note: We did not promote to prod on this ticket.  That will be handled in DM-24410."""
"DM-24347","Story","daf_butler",1,"Allow component gets in gen3 butler to be None","""When a component is being requested from a dataset type, it is entirely possible for that particular dataset that the component will be None. At the moment we do not allow that and it is an error to return None because the python types do not match.    Change datastore such that if a component is being requested then None is an acceptable value.  Once this is supported fix the ingest test in obs_base that skips Wcs component test."""
"DM-24337","Story","obs_base",1,"Fix raw formatter gen3 breakage","""In DM-24285 we made reading components from exposures very efficient but inadvertently broke reading of components from raw files because the API was changed. Nothing in lsst_distrib or lsst_ci noticed and it wasn't until ci_hsc_gen2 that the breakage was discovered.    In that test we showed that reading raw.wcs does not give you the same thing as reading the raw and then calling {{getWcs}}.  This is because the previous implementation did a full read and component extraction but now components are all handled by ExposureFitsReader."""
"DM-24333","Story","ts_main_telescope",1,"Update MTMount to not send TCS_sequence_id","""It turns out that the TCS sequence ID field is only used by the Operation Manager communicating with the PXI. It is not used by the CSC, HHD and EUI connecting to the Operation Manager. It also strips that field from replies before sending them to the CSC, HHD or EUI.    Update ts_MTMount accordingly.    Also update the mirror cover open/close commands to the sequence provided by Alberto:    To deploy the mirror covers (protect the mirror):  * Deploy mirror cover locking pins (1506 = MCL_MOVE_ALL, drive=-1, on=1)  * Deploy mirror covers (905 = MC_OPEN, drive=-1)  To retract the mirror covers (for observing):  * Retract mirror covers (906 = MC_CLOSE, drive=-1)  * Retract mirror cover locking pins (1506 = MCL_MOVE_ALL, drive=-1, on=0  """
"DM-24330","Story","daf_butler|obs_base",8,"add ability to run an obs_base command via the butler command","""Make the butler command in daf_butler able to call the register command in obs_base (at python/lsst/obs/base/instrument.py).    To do this, when obs_base is setup, it should add a colon separated list of CLI python code modules or functions. For example set it to {{lsst.obs.base.cli}}.    Then in butler command itself do something like:    and maybe have the imported class import the subcommands to click somehow   ...it may help to be explicit and have the env var contain the actual command function (so lsst.obs.base.cli.register or somesuch). """
"DM-24319","Story","fgcmcal",8,"Add support for new parquet source tables in fgcmcal","""With new parquet source tables soon to be added to production, these should be supported in {{fgcmcal}} which should greatly speed up the i/o part of the operations.  The plan is that new methods will be written in {{fgcmBuildStarsTask}} that will make use of the source tables, meaning there will be some slight code duplication.  However, since the old method of reading source catalog fits files will be deprecated by this ticket, when the deprecation period is complete the old code can be removed much more cleanly."""
"DM-24352","Story","daf_butler",2,"Add auto transfer mode to gen3 ingest","""When converting gen2 repositories to gen3 we currently default to using symlink mode. This means that in-place conversions can't work and also means that a user can't convert to an S3 bucket.    I think we need a couple of changes that would help a lot with the right decision being made:    # Add a new """"link"""" option that tries a hardlink and falls back to symlink  # Add an auto mode to posix datastore that will check to see if the file is within the repository and use None if it is, else it will use """"link"""".  # Make """"auto"""" an alias for """"copy"""" in S3 datastore.    With these changes the 2to3 conversion can use """"auto"""" mode and that should do the right thing most of the time."""
"DM-24370","Story","ctrl_mpexec",2,"Support extensible scheduling in pipetask","""AP pipeline want to have order of visit processing processing to be stable, in particular association steps for one visit needs to wait until the same step for previous visit is finished. Adding this sort of dependency for quantum graph would be difficult. It may be easier to implement special scheduling logic while executing the graph instead. I want to explore how this can be done in current pipetask and try to make it scheduling more configurable/extensible. Some refactoring (that we always wanted to do) of the internals will probably be needed."""
"DM-24365","Improvement","daf_butler",1,"Add relative symbolic link transfer mode to Gen 3 ingest","""When converting gen 2 to gen 3 repositories, the current options are in-place conversion, hard links, or absolute symbolic links. There are cases (e.g., Git repositories) where links are desirable but neither hard links nor absolute paths are portable enough. A """"relsymlink"""" mode would be useful for these cases.    Because it's intended only for when very specific behavior is desired, """"relsymlink"""" probably does not make sense as an option in either the """"auto"""" or """"link"""" transfer modes."""
"DM-24364","Story","ts_middleware",1,"Please simplify the way ts_sal finds PYTHON includes","""Presently ts_sal salgenerator appears to find Python.h by using {{/include/python$PYTHON_BUILD_VERSION}}. This is a bit of a problem for several reasons:  * It assumes that /include exists  * It is a bit confusing as it's not clear what PYTHON_BUILD_VERSION is being used for.    I suggest offering a new env variable PYTHON_INCLUDE (or similar) that is the full path to the directory containing Python.h. I think it would be much clearer what the env variable was used for.    You could fall back to PYTHON_BUILD_VERSION if PYTHON_INCLUDE was not defined, for backwards compatibility.    Two more small requests to consider (in an attempt to rationalize the env vars):  * Rename LSST_SDK_INSTALL to something a bit clearer. It appears to be the root directory of ts_sal, so perhaps TS_SAL_ROOT? If you do that then do you need SAL_HOME? It is a known subdirectory of ts_sal.  * Move your bin scripts (such as salgenerator) to the bin/ directory. That's what it's there for. Then we just have to get ts_sal/bin on our PATH and they can be found. The current location is surprising and deeply buried. At that point you can probably lose SAL_DIR."""
"DM-24361","Story","ts_main_telescope",0,"Allow the Connection Message in the MT Hexapod PXI Controller","""Allow the connection message (GUI or DDS) in hexapod PXI code."""
"DM-24378","Story","daf_butler|obs_base",1,"Store instrument class with gen3 instrument registration and add API","""When designing the butler command line tools it is clear that life would be much simpler if an instrument could be referred to by name rather than by instrument class. It should only be instrument registration that requires the full class name. All other operations should work by specifying the name, looking up the name in registry and retrieving the class name, using doImport on that class, and instantiating the class for downstream usage.    For this to work we need two changes:    # Add the instrument class full name text string to registry.  # Have an API ({{butler.registry.getInstrument}}?) that will return an instantiated gen3 Instrument (they don't need parameters) given the name of the instrument.    """
"DM-24375","Story","daf_butler",2,"Check time round trip issues with new time format","""Jim reported issues with round-tripping and comparison of timestamps in slack: https://lsstc.slack.com/archives/C2JPT1KB7/p1586273799139100  Need to understand what's causing this and to fix it."""
"DM-24371","Story","ip_diffim|pipe_tasks",20,"Implement fixed correction fixed PSF support decorrelation afterburner","""This is the first code piece in the decorrelation afterburner rewrite.    For helping the review, the whitening concept and the whitening kernel are demonstrated in DM-24316.     """
"DM-24397","Story","DM",1,"fix db2authors for SPIE","""Thought I had this but it needs a bit more work .."""
"DM-24394","Story","ts_qa",2,"Write test for salgenerator GENERATE step","""The salgenerator now has the GENERATE option, that runs validate, html, cpp and idl processes in one command line option.  Write a test to validate this step."""
"DM-24393","Story","ts_qa",2,"Write test for salgenerator IDL step","""The salgenerator has an IDL step that needs to be tested.  Add this in the [https://github.com/lsst-ts/robotframework_salgenerator] repo and get it running on Jenkins."""
"DM-24392","Story","testdata_jointcal",2,"Update testdata_jointcal to include Gaia+PS1 refcats","""Preparatory to DM-17597, we need Gaia+PS1 refcats (sub-selected from the current refcats) for each of the datasets in testdata_jointcal. This ticket is to extract the necessary shards from the refcats in {{lsst-dev:/datasets}} and put them into the relevant subdirectories in testdata_jointcal.    This ticket does not involve any reprocessing of the test data, nor does it involve changing jointcal or fgcmcal to use the new refcats (since that would change the measured metrics)."""
"DM-24387","Story","ts_dome",1,"Refactor duplicate code and add a task scheduler","""There is some duplicate code in particularly the test code. Review and refactor. Also a task scheduler is needed to poll the status command on a regular basis. Add it."""
"DM-24385","Story","daf_persistence",0.5,"Optimize posixStorage.search with relative path","""It turns out that a lot of the overhead in running {{dataRef.datasetExists()}} is extraneous path checking when the template is a relative path.  A quick change to the logic in {{posixStorage.search}} can speed up this operation by ~60% in tests, which is useful when finding large numbers of files (especially, but not limited to, global calibration in {{fgcmcal}})."""
"DM-24383","Story","Firefly-proxy",1,"Update Firefly proxy container image to ACMEv2 compliance","""The Apache proxy for Firefly provided by IPAC to LSST has fallen out of date with the ACME protocol used for certificate transactions.    It must be upgraded to ACMEv2 in order to continue to function.    Please generate an updated container image on DockerHub at {{ipac/proxy}}.  To support future configuration control activities, please apply the tags """"latest"""" and """"1.1.0"""" to this image, and, if possible, apply the """"1.0.0"""" tag to the previously available image."""
"DM-24423","Story","ts_main_telescope",3,"Use the Latest Bending Mode And Sensitivity Matrix for ts_ofc","""Bo updated the bending modes and sensitivity matrix for the phosim:    [https://github.com/lsst-ts/phosim_syseng4/pull/1]    He tried to update the related part in ts_ofc:    [https://github.com/lsst-ts/ts_ofc/pull/19]    This task will take over this PR and finish it. This task will fix some minor bugs as well. It is noted that some test cases in ts_MTAOS will need to update as well."""
"DM-24422","Story","ts_main_telescope",3,"Support the DOF Correction from Multiple Visits Instead of Single One","""Support the DOF (degree of freedom) correction from multiple visits instead of single one. The initial idea now is to use the queue in Model class in ts_MTAOS."""
"DM-24421","Story","ts_main_telescope",2,"Adapt the Change of ts_xml and ts_salobj","""Adapt the change of ts_xml 5.0, especially for the MTM2. This task will need to prepare the appropriate software environment for the test. This task will also use the test framework by ts_salobj."""
"DM-24414","Story","ctrl_mpexec",2,"Implement --prune-replaced option in ctrl_mpexec","""This option was added to the argument parser on DM-21849 but not implemented due to problems with dataset deletion."""
"DM-24410","Story","efd",1,"Promote EFD notebooks to prod","""In DM-24350 we sanitized some EFD notebooks to run on nublado hosted at the LDF.  We intended to promote those notebooks to the standard env that all users see, but I hadn't thought through how authentication would be handled in that context.  In order to do that, we need to make a read only user and inject those credentials into user pods at spawn time.  This ticket is to figure that workflow out."""
"DM-24406","Story","ts_main_telescope",3,"M1M3 hardware simulator","""Run M1M3 cRIO with ICL hardware simulator."""
"DM-24404","Story","meas_algorithms",1,"Squash astropy ecsv read warnings","""I'd certainly believe that these warnings mask a real problem, but it's already been reported upstream (https://github.com/astropy/astropy/issues/8673), and they make it extremely difficult to develop against tests in obs_packages - {{test_convert2to3.py}} in obs_subaru emits 1700 lines of these, for example.    {{warnings.catch_warnings}} + {{simplefilter}} seems to take care of the problem.     """
"DM-24435","Bug","pex_config",8,"Freezing a config locks the registry(ies) of other instances of that config","""Config field instances that correspond to a {{RegistryField}} have an internal member, {{_field}}, pointing back to the original field. {{_field}} points to the same object for all config instances corresponding to the same config. This causes a rare bug where calling {{ConfigChoiceField.freeze}} locks the registry for all config instances using that {{RegistryField}}, including instances that did not exist at the time of the call. See my [post on #dm|https://lsstc.slack.com/archives/C2JPL2DGD/p1586539537027000] for a specific example.    Please change the code so that independently created config instances no longer affect each other. This issue appears to be a side effect of the fix for DM-17757, and may be difficult to fix without introducing still other side effects."""
"DM-24434","Story","daf_butler",1,"symlink bug in posixDatastore.py on Ubuntu","""I received an error when rebuilding the stack, related to the new """"smart"""" symlink mode:        This was apparently due to attempting to hard link a symlink in the `transfer=='link'` mode in posixDatastore. [~tjenness] suggested a fix by using `os.path.realpath(fullPath)` at all calls to `link`."""
"DM-24429","Story","ap_verify|obs_decam",1,"Investigate change in fracDiaSourcesToSciSources in ap_verify CI","""Between 26 & 27 March, the {{fracDiaSourcesToSciSources}} (“Ratio of DIASources to Direct Image Sources per CCD”) being tracked by Chronograf very ap_verify_ci_hits2015 changed for unknown reasons. What happened?"""
"DM-24428","Story","fgcmcal",2,"Update fgcmcal tests to use new PS1 refcats","""When DM-17597 is complete, a new PS1 reference catalog will be available in {{testdata_jointcal}}.  The {{fgcmcal}} tests will be updated to make use of the improved reference catalog (and updated catalog format)."""
"DM-24461","Story","ts_middleware",2,"Segfault in salobj unit test using SALPY_Test","""The following segfaults in ts_salobj v5.8 using SALPY_Test generated by ts_sal v4.0:    I suspect an issue in ts_sal, but I am not positive.    Here is a log:  """
"DM-24459","Story","ts_middleware",0,"Remove ignored fields from my CSCs","""SAL 4.2 will allow topics to have no user-added fields. Update the XML for my CSCs accordingly, especially Test, because that will exercise this capability.    This will have to wait until we have switched our test stands and site to SAL 4.2    Consider ditching the Alias tags at the same time."""
"DM-24450","Story","obs_lsst",2,"Fix parsing of wavefront sensors","""The wavefront sensors need to be defined as a separate kind of raft since the corner rafts contain multiple kinds of sensors, and currently yaml camera assumes all rafts are homogenous in their detector types.  To do this the yaml files append a 'W' to mark wavefront sensor rafts, but since the in memory camera doesn't care about this distinction, we can strip it out when building the full camera yaml.    [This|https://github.com/lsst/obs_lsst/blob/master/python/lsst/obs/lsst/script/generateCamera.py#L236] is where the stripping happens.  Instead of assuming a delimiter, I think I'd like to go to an explicit name translation mapping: e.g. {{output_name = nameTranslator.get(input_name, input_name)}}."""
"DM-24446","Story","ts_qa",3,"Complete the Java versioning implementation","""Most of the work is done to get the versioning for Java correct.  But now those files need to be pushed to Nexus.  The jobs will need to be update accordingly.  This task covers that work."""
"DM-24476","Improvement","ts_middleware",0,"Add a timeout parameter to BaseCscTestCase.check_standard_state_transitions","""Add a timeout parameter to {{BaseCscTestCase.check_standard_state_transitions}} so it can be used with CSCs that require a long time to change to certain states.    It is probably getting too fancy support timeouts that are specific to a given state or a given state transition command. That would really complicate the API."""
"DM-24472","Story","meas_algorithms",5,"Regenerate Gaia DR2 catalogs to correct coordinate error fields","""While checking out the new Gaia DR2 refcats in testdata_jointcal with jointcal, the astrometry tests were failing to converge. After some exploration, I discovered that the coordinate error fields were incorrect: the ingest code was assuming they were radian, when they were actually milliarcsecond.    I've already written most of the code to test this as part of verifying that it exists. Once I'm satisfied, I will re-run the Gaia DR2 ingest, and then replace the testdata_jointcal refcats (which is now trivial, with the new scripts from DM-24392)."""
"DM-24469","Story","ts_dome",1,"Review Dome Software Timeline","""Review the Dome Software Timeline and bring it in line with the current status and the expected the development progress."""
"DM-24468","Story","ts_dome",3,"Poll lower level status and send telemetry","""Introduce a polling mechanism for the lower level statuses and emit telemetry."""
"DM-24467","Story","ts_main_telescope",0,"Review the M2 Wish List","""Review the M2 wish list by Bo:  [https://docs.google.com/document/d/1z_UoaHy32q6yP8ebxfQwK8SL3ThtH0KS8Se--eNcX5A/edit]"""
"DM-24493","Bug","ts_middleware",1,"salgenerator operation order can delete required assets","""The salgenerator can delete necessary assets if done in the wrong order.   * *salgenerator <CSC> sal idl* will delete or overwrite certain C++ artifacts.  This results in *sal <CSC> python* build failures   * if two CSCs have similar roots (e.g. ATDome and ATDomeTrajectory), the second CSC build can completely wipe out the first.    Also, *salgenerator <CSC> idl* is not the correct format, but is still allowed.  It should cause an error instead of executing a build."""
"DM-24489","Story","ts_middleware",2,"Unit tests involving SALPY are much less reliable with ts_sal 4.1","""ts_sal has a few test for communication between salobj and SALPY. At least one of these has become much less reliable.    The possibilities I have thought of are:  * The memory leak fix to OpenSplice. I can test this by running an older Docker image.  * Changes in ts_sal 4.1.  * Whatever is causing the new segfaults that I reported in DM-24461, which is most likely one of the items above.  * Change in salobj. This seems unlikely, because none of the changes seems even remotely relevant.    I have no idea how long this will take to resolve, so I have arbitrarily assigned 2 story points. Given the possible association with DM-24461 I am making this a priority and adding it to the current sprint. I hope to resolve it before releasing salobj v5.9"""
"DM-24483","Story","ts_aos|ts_main_telescope",0,"Prepare the MTAOS Docker Image","""Prepare the MTAOS docker image that adapt the ts_xml v5.0."""
"DM-24479","Story","Verification",5,"Make a matched catalog pipeline task","""In order to use the Gen3 {{MetricTask}} pipeline task, we need to make tasks that can produce the data products used by the metric measurements.    This is to produce the product most commonly used by currently implemented {{validate_drp}} measurements, the per band matched catalog.    Results will be check into [this repository|https://github.com/lsst-dmsst/metric-pipeline-tasks]."""
"DM-24495","Story","obs_decam|obs_lsst|obs_subaru",2,"Convert config overrides to use file in several obs packages","""As per https://community.lsst.org/t/pex-config-configs-now-know-where-they-are/4023,  use {{os.path.dirname(\_\_file\_\_)}} instead of {{getPackageDir}} in obs-package config files.    I'm doing just obs_lsst, obs_decam, and obs_subaru on this ticket because I already did the work before deciding it didn't belong as a side-commit on the ticket I was working on.  Others are welcome to take care of other packages on other tickets.    """
"DM-24508","Story","daf_butler",1,"Add lsst log message init to Click CLI tools","""the lsst log tool needs to be initialized by the Click command line interface scripts, similar to     [https://github.com/lsst/pipe_base/blob/master/python/lsst/pipe/base/argumentParser.py#L497-L508]          """
"DM-24507","Story","cbp",0,"Syntax error in ts_CBP","""In ts_CBP/lsst/ts/cbp/statemachine.py there a syntax error at line 262 (a missing {{_}} in the f-string):      Please fix it"""
"DM-24515","Story","daf_butler",2,"Refactor gen3 butler.prune","""In DM-23671 we refactored datastore deletion into a two pass trash and empty. This allows us to simplify the logic in prune."""
"DM-24513","Bug","Qserv",2,"Fix a bug in the REST server of the Qserv Replication/Ingest system and refactor its implementation","""A refactoring of the REST service made in the previous ticket https://jira.lsstcorp.org/browse/DM-24053 introduced a bug in the implementation of the service. The bug was observed at https://jira.lsstcorp.org/browse/DM-24396. Further analysis of the problem suggested that a code which is routing REST requests to the corresponding processing modules needs to be revisited.    The new implementation of the {{HttpPocessor}} (where the request routing to the corresponding modules and submodules is happening) will no longer instantiate the modules directly. This task will be delegated to the static method of the modules, for example:  {code:c++}  HttpIngestModule::process(...)  {code}  This adds extra flexibility to modules on how they would be instantiated and implemented."""
"DM-24523","Bug","ap_verify",2,"ap.verify.ingestion._findMatchingFiles excludes directories","""As reported on [Community|https://community.lsst.org/t/4107/], the unit tests for {{ap_verify}} include a test where the {{_findMatchingFiles}} function searches for files that don't contain the string """"fr"""". This test causes a false positive when run in a directory containing """"fr"""". Fix {{_findMatchingFiles}} so that exclude patterns are matched only against the filename, as implied by the documentation."""
"DM-24521","Bug","ts_main_telescope",0,"Fix test failures in ts_MTMount test_mock_devices.py with salobj v5.10","""Some ts_MTMount unit tests in test_mock_devices.py are failing with salobj v5.10 that were not failing with 5.8 and 5.9. There are 3 errors, all like this:    Perhaps a tolerance simply needs to be larger, but first understand how the breakage occurs. I hope it's not a bug in salobj 5.10!"""
"DM-24534","Story","cat|ci_hsc",5,"Add source table pipelines to ci_hsc_gen2 & add its cat schema","""DM-24062 added the pipelines of generating the source tables in parquet.   Add the pipelines to {{ci_hsc_gen2}}.  """
"DM-24560","Story","daf_butler|obs_base",3,"make 'repo' an argument, by convention always the first.","""change repo from a required """"option"""" to a required """"argument"""" (former has flags e.g. {{--repo foo}}, the latter is positional)."""
"DM-24558","Story","ts_middleware",3,"Record salobj topic read/write speed in SQuaSH","""Record a measurement in SQuaSH of how quickly salobj can read and write writing DDS samples. Ideally we would record separate values for writing and reading. Note that the existing speed test testss/test_speed.py only measures the combined speed of reading and writing.    See https://github.com/lsst-sqre/notebook-demo/blob/master/lsst-verify-squash/LSSTVerificationSQuaSHDemo.ipynb for instructions."""
"DM-24557","Story","pipe_tasks",2,"Trim matched catalog to output patch coordinates","""Currently the task just matches any source that is close to the output patch.  We need to trim to the patch so we aren't lying to downstream tasks."""
"DM-24556","Story","meas_algorithms",2,"Add normalize method to Defects","""There have recently been discussions regarding {{Defects}} where new defects are appended to the existing list of defects. This works fine but can result in a situation where lots of tiny bounding boxes could be represented by a few large bounding boxes. Many things become more efficient if the minimal set of bounding boxes is used by downstream processing.    This ticket will add a normalize method to {{Defects}} that will recalculate the defect bounding boxes. One implementation could be to generate a mask from the defects and then recalculate the defects from the mask. This would have the side effect of allowing direct comparison of two different Defects instances."""
"DM-24555","Story","daf_butler",2,"Add ability to retrieve various Exposure components in gen3 butler.","""There are some components that were left out of the {{FitsExposureFormatter}}.  These are defined [here|https://github.com/lsst/daf_butler/blob/master/python/lsst/daf/butler/formatters/fitsExposureFormatter.py#L100].  Basically any function defined on the {{ExposreFitsReader}} can be defined there.  See the [header|https://github.com/lsst/afw/blob/f570990def94c74c425d919df9f56a40e06715f2/include/lsst/afw/image/ExposureFitsReader.h#L120] for the method to read the {{photoCalib}} object for example."""
"DM-24546","Improvement","pipe_tasks",0.5,"Improve explanation of calibration and fluxCalibRadius in insertFakes.py code.","""Improve the documentation in the code comments in {{pipe_tasks}} {{insertFakes.py}}.  Explain the use of {{fluxCalibRadius}} and the need for it to be synchronized with the radius used to define {{photoCalib.magnitudeToInstFlux}}.    See discussion at    https://community.lsst.org/t/why-are-fake-sources-corrected-to-mean-the-integrated-flux-within-calibfluxradius/4110/12"""
"DM-24576","Story","ts_auxiliary_telescope|ts_main_telescope",0,"Update ts_FiberSpectrograph S3 writing for changes in salobj v5.9","""Update ts_FiberSpectrograph code that writes images to S3 for changes in ts_salobj v5.9.0. This should be a trivial change.    Add a revision history."""
"DM-24564","Story","Verification",1,"Produce a runnable pipeline description for the metrics tasks","""Now that we have two tasks we can make a pipeline that is not completely trivial.  Write runnable pipeline description that links catalog construction with metric measurement."""
"DM-24593","Story","ts_documentation",3,"Fill out general CSC overview","""Fill out general_csv_overview with more detailed information."""
"DM-24592","Story","obs_lsst",40,"Get astrometry working for the AuxTel","""Get astrometry working for the AuxTel now that we're on sky."""
"DM-24591","Story","ts_main_telescope",2,"Organize the hexapod code by MOOG","""This task will put the haxapod code by MOOG to a new repo and reorganize the code structure. The autotool related code will be rewritten to fit the new structure as well."""
"DM-24590","Story","ts_main_telescope",2,"Abstract the interface of deblending code in ts_wep","""This task will use the factory pattern for the deblending algorithm to let UW team experiment multiple deblending algorithm without the affection of code body."""
"DM-24587","Story","Qserv",20,"Load DC2 data inside CC-IN2P3 cluster","""Load a small set of chunk inside CC-IN2P3 Qserv cluster using replication system.    The procedure is based on: [https://confluence.lsstcorp.org/display/DM/Live+demo%3A+test+ingest+of+a+subset+of+one+track+of+the+HSC+Object+catalog]"""
"DM-24601","Bug","Qserv",0.5,"Qserv master replication controller crashes on the misformed requests to its REST services","""The {{REST}} server of the {{Master Replication Controller}} throws an unhandled exception when parsing the improperly formed {{body}} of the HTTP requests where a JOSN-fied string is expected.    A solution is to catch the exception and to report its reason back to a user."""
"DM-24619","Bug","ts_middleware",1,"salgenerator operation for similarly named CSCs will delete build products","""The salgenerator will delete necessary assets if done in the wrong order.  If two CSCs have similar roots (e.g. ATDome and ATDomeTrajectory), the second CSC build can completely wipe out the first.  In this case, if ATDome is run after ATDomeTrajectory, then the C++ and Java directories inside ts_sal/test/ATDomeTrajectory/ will be deleted.  I'm concerned this could be an issue in the future, if not resolved."""
"DM-24616","Story","obs_base",1,"Stop writing to gen2 butler directory during 2to3 conversion","""We recently started to see some registry files turn up in obs_lsst after running the tests:    Making the {{data}} directory read only tells me that it's the 2to3 tests that are causing the problem.        I'm not sure if this is a bug in running the converter or if the routine should return without error if the sqlite3 file is not present (I guess sqlite3 creates the file if it does not exist).      """
"DM-24612","Story","daf_butler",1,"Add indexes to dataset_collection tables","""Adding the right indexes - once we determine what they are - should be easy after DM-21764.  Stay tuned for a follow-up post on that here."""
"DM-24611","Story","Science Platform",0.5,"Update nublado docs to clarify NCSA VPN profile to uees","""Neither our docs nor the NCSA VPN docs say specifically which profile to use when logging in to the VPN for use with the Science Platform.  I'll add a note that {{ncsa-vpn-default}} is the one to use unless you know better."""
"DM-24610","Story","ts_main_telescope",3,"Assign the OFC state0 in ts_MTAOS by Configuration File ","""Assign the OFC (Optical Feedback Control) state0 in ts_MTAOS by configuration file. The *ConfigurableCsc* class in ts_salobj is the basic CSC (Commendable SAL Component) class for the subsystem such as *MtaosCsc* in ts_MTAOS to use. The configuration file is located at MTAOS directory of ts_config_mttcs. The following document explains the details of this: [TSTN-017|https://tstn-017.lsst.io/]. When writing the configuration file, a schema is needed to verify the configuration file based on: [Write a CSC|https://ts-salobj.lsst.io/salobj_cscs.html#writing-a-csc].    OFC is the component that calculates the correction of mirror bending mode and hexapod position. The control algorithm in use can follow [Real time wavefront control system for the Large Synoptic Survey Telescope (LSST)|https://drive.google.com/file/d/1RyMQWeXWRZLtxM8KkSwtB3STzMM9fCvX/view?usp=sharing] and [Control Algorithm in Optical Feedback Control|https://confluence.lsstcorp.org/display/LTS/Control+Algorithm+in+Optical+Feedback+Control]. The state0 (*s*~*0*~ in the [Control Algorithm in Optical Feedback Control|https://confluence.lsstcorp.org/display/LTS/Control+Algorithm+in+Optical+Feedback+Control]) is an intentional parameter used in *x00* reference, which is explained in the above links.    The AOS software contains the simulation code and control code. For the simulation, the user needs to use the repos: ts_wep, ts_ofc, and ts_phosim. For the control code, the user needs to use the repos: ts_wep, ts_ofc, and ts_MTAOS. The ts_phosim is not needed in the control and the ts_MTAOS is not needed in the simulation. In this task, we focus on the control code.    The followings are the steps in this task:   # Update the [default.yaml|https://github.com/lsst-ts/ts_config_mttcs/blob/develop/MTAOS/v1/default.yaml] in ts_config_mttcs to contain the state0 information as the following: [state0inDof.yaml|https://github.com/lsst-ts/ts_ofc/blob/master/policy/comcam/state0inDof.yaml]. I prefer to have two yaml files (default.yaml + state0inDof.yaml) instead of one (default.yaml) in ts_config_mttcs. However, we need to check ts_salobj can support this or not.   # Provide the related schema: [MTAOS.yaml|https://github.com/lsst-ts/ts_MTAOS/blob/master/schema/MTAOS.yaml] in ts_MTAOS/schema directory. Prefer to have two files instead of one. But this depends on the implementation of ts_salobj.   # Update *MtaosCsc* class in ts_MTAOS to read the configuration of state0. *MtaosCsc.configure()* will read the configuration file from SAL. *ConfigByObj* and *ConfigByFile* classes inherit from *ConfigDefault* to read the data. We need to update the related test cases to make sure the *MtaosCsc* can change the state0 by SAL or file.   # Override the default state0 when *OFCCalculation* is instantiated by *OFCCalculationFactory.getCalculator()* in *Model.ofc*. The state0 is stored in the internal data of *Model.ofc.ztaac.optCtrl*. The developer can do *OFCCalculation.getZtaac()* to get the *ztaac* attribute. After this, the developer can use *ZTAAC.setState0()* to set the state0 values. The related *get()* functions are provided for the test. By default, the state0 is set by *OFCCalculation()* --> *OFCCalculation._configZTAAC()* --> *ZTAAC.setState0FromFile()*. It is noted that we will keep the default state0 file in ts_ofc for the simulation (the AOS simulation does not know the ts_MTAOS. The UW team is using the AOS simulation to help the algorithm development)   # Update the test cases and [versionHistory.rst|https://github.com/lsst-ts/ts_MTAOS/blob/master/doc/versionHistory.rst] to reflect the change."""
"DM-24605","Bug","Qserv",1,"Qserv Replication and Ingest services crash due to an unhandled exception","""Both services crash when attempting to parse improperly formed messages into a Google Protobuf object. This is reported in the log stream of the Replication/Ingest system workers as:  """
"DM-24658","Improvement","daf_butler",1,"Improve error reporting in connection string","""Connection string *sometimes* uses DbAuth to insert username and passwords read from .lsst/dbAuth.yaml into the connection string and ignores it most of the time, trusting that db connection string provided in config is what the user really wants to use.    Error capturing in DbAuth raises DbAuthError from ... to make this happen. It was noticed today, by [~mgower], that leads to confusing error much later on in the code if the YAML is badly formatted. The following is enough to cause the error:         correct:    incorrect:         I would like to add an DbAuthNotFound error to separate the allowed DbAuth failure case from the ones we want to raise early."""
"DM-24653","Story","alert_stream",1,"Make a pip-installable script to send data to the alert stream simulator broker","""Make a script which is pip-installable which can send data to the alert stream simulator broker. The script should just take a file and write it into the broker."""
"DM-24650","Story","alert_stream",8,"Write docker infrastructure to create an alert broker locally","""Write docker scripts to be able to create the basic infrastructure laid out in DMTN-149."""
"DM-24649","Story","alert_stream",1,"Add integration tests to alert stream simulator","""Add an integration test, triggered with Github Actions, which tests that the alert stream simulator is installable and works with the basic tools we are providing."""
"DM-24646","Story","alert_stream",2,"Document alert stream simulator usage and setup","""Write enough docs that a software engineer could install, use, and make sense of the alert stream in a box."""
"DM-24645","Story","alert_stream",1,"Provide a sample consumer application for the alert stream simulator","""Provide a consumer application which simply counts the number of alerts it has received and prints the count to stdout every second. This is intended to be scaffolding code for users to work with."""
"DM-24644","Story","alert_stream",3,"Provide a distributable package for the alert stream simulator","""Package up the alert stream simulator to make it straightforward to install on a Linux host. Some code duplication with (for example) sample-avro-alert is acceptable."""
"DM-24643","Story","alert_stream",5,"Implement infinite-mode data pacer for alert stream simulator","""As laid out in DMTN-149, implement a looping infinite-mode pacer for injecting alerts from disk into a Kafka broker which attempts to simulate a """"realtistic rate."""" Make it configurable as described in DMTN-149, too."""
"DM-24642","Story","alert_stream",2,"Implement simple single-pass data pacer for alert stream simulator","""As laid out in [DMTN-149|https://dmtn-149.lsst.io/#injector-and-data-rates], implement a single-pass pacer for injecting alerts from disk into a Kafka broker using the timestamps in the files themselves."""
"DM-24641","Story","Middleware",1,"Update Opensplice RPM","""Update Opensplice 6.9 RPM to include master priority change to ospl.xml"""
"DM-24637","Story","ts_middleware",0,"Run CscCommander commands asynchronously","""CscCommander presently waits for each command to finish before allowing another command. That is unnecessarily restrictive and really annoying if a task hangs. Modify the commander to run commands asynchronously."""
"DM-24675","Story","ts_deployment|ts_qa",1,"Determine a way to have the SalObj conda job trigger a build off new tags","""The [SalObj Conda Jenkins job|https://tssw-ci.lsst.org/job/SalObj%20Conda%20package/] will create an item when new tags appear, but no jobs runs automatically.  The job can obviously be started manually, but it would be nice to have it trigger automatically.  Determine a way to do this."""
"DM-24674","Story","ts_auxiliary_telescope|ts_deployment",1,"Create Jenkins build for the ATSpectrograph Conda package","""The ATSpectrograph Conda package job should use the DeployEnv docker image and the necessary RPMs/IDLs, all from Nexus3.  It should create a conda package and then run the unit tests.  Must-have unit tests include instantiating the topics and running through the state-machine workflow.  The goal here is to catch unsupported interface changes before a release occurs."""
"DM-24672","Story","ts_auxiliary_telescope|ts_deployment",3,"Create Jenkins build for the ATDome Conda package","""The ATDome Conda package job should use the DeployEnv docker image and the necessary RPMs/IDLs, all from Nexus3.  It should create a conda package and then run the unit tests.  Must-have unit tests include instantiating the topics and running through the state-machine workflow.  The goal here is to catch unsupported interface changes before a release occurs."""
"DM-24671","Story","ts_auxiliary_telescope|ts_deployment",3,"Create Jenkins build for the ATHexapod Conda package","""The ATHexapod Conda package job should use the DeployEnv docker image and the necessary RPMs/IDLs, all from Nexus3.  It should create a conda package and then run the unit tests.  Must-have unit tests include instantiating the topics and running through the state-machine workflow.  The goal here is to catch unsupported interface changes before a release occurs."""
"DM-24667","Story","ts_main_telescope",2,"Determine if the Python MTMount CSC can keep up with telemetry from the low level controller","""Figure out if the new Python MTMount CSC could keep up with telemetry from the low level controller: read the data, parse it and output it as SAL while tracking.    Test at the current rate of 20Hz tracking updates and 20Hz telemetry output per topic.  If that works, try speeding things up the telemetry and tracking rates until the system fails, to get a sense of how close to the edge we will be.."""
"DM-24694","Story","ts_main_telescope",0,"Update the mock hexapod and rotator to transition from fault to standby","""Update the mock controller code in ts_hexrotcomm to transition from FAULT to STANDBY instead of OFFLINE, in order to match improvements that [~ttsai] has made to the rotator low level controller, and will make to the hexapod."""
"DM-24684","Improvement","Qserv",8,"Extend the Replication/Ingest framework and REST API with algorithms and tools for indexing catalogs","""The current implementation of the Replication/Ingest doesn't provide any mechanism for managing (inspecting, creating or dropping) indexes on the data tables within Qserv. Only a few essential (for Qserv to function) indexes get automatically created. A lack of indexes may affect a performance of many user queries. Hence a goal of this development is to add the following capabilities to the system:  * extending the Replication Framework with a set of _request_ and _job_ classes for managing indexes at workers.  * adding a command-line version of the Replication _controller_ tool for managing the indexes  * extending the REST services of the *Master Replication Controller* with the index management services    Other notes:  * the REST services need to be protected with the _auth_key_ mechanism as explained in: https://jira.lsstcorp.org/browse/DM-22745  * it may be necessary to consider putting a cap on the number of indexes which were created by the system due to disk space constraints at a particular Qserv deployment. For example, the system may need to evaluate the amount of the available disk space on the coresponding file system (at Qserv workers) before attempting to create a new index.  """
"DM-24683","Bug","obs_base",1,"Use PRODUCT_DIR instead of OBS_BASE_DIR in obs_base eups table file","""obs_base table file was updated to setup DAF_BUTLER_PLUGINS envvar, but it uses $OBS_BASE_DIR instead of $\{PRODUCT_DIR} in the value and this causes issues when package is setup twice. It looks like to """"unsetup"""" this envvar, the variable needs to be defined with $\{PRODUCT_DIR}.    See also Slack discussion: [https://lsstc.slack.com/archives/C2JPT1KB7/p1588203833017400]    I do not know if there are other packages defining DAF_BUTLER_PLUGINS, if there is they need this fix too."""
"DM-24681","Story","alert_stream",0.5,"Format alerts published into the alert stream according to Confluent Wire Format","""Prefixing alert messages with a magic byte and schema ID will let us interoperate with the Confluent Schema Registry in the future, if we should choose to use it. I've heard good things about the CSR from teams using Kafka in similar ways; it would help manage schema updates much more easily.    """
"DM-24706","Story","ts_main_telescope",3,"M1M3cli","""Develop M1M3 command line tool, so testing of communication to a single actuators can be reasonably commanded. This is just engineering tool, with purpose similar to unit tests (which are missing in M1M3 support as well)."""
"DM-24705","Story","pipe_analysis",1,"Remove afwGeom aliases for geom from pipe_analysis","""Many of the {{afwGeom}} aliases (e.g. [Sphere]Point, Extent, angular units) are now deprecated in favor of those defined in {{geom}}.  Please replace all instances in the \{\{pipe_analysis}} scripts."""
"DM-24703","Improvement","cp_pipe|ip_isr",8,"Make linearity a subclass of lsst.ip.isr.IsrCalib","""With DM-24537 done, ISR """"user curated calibrations"""" can be made into subclasses of the new IsrCalib, ensuring we treat all of these products in a uniform manner.  This will help the transition to Gen3, as we will be able to use fewer mapper tricks.    This ticket covers the linearity correction."""
"DM-24700","Story","Middleware",3,"Assist with streamlining SAL CI testing","""Assist Jenkins CI testers in speeding up  / parallelizing / streamlining the test runs"""
"DM-24698","Story","daf_butler",1,"Clean up (at least) doc bug introduced in DM-21764","""See https://lsstc.slack.com/archives/C2JPT1KB7/p1588310584058000"""
"DM-24697","Story","ts_main_telescope",0,"Update ts_hexrotcomm for ts_xml 5.2","""Update ts_hexrotcomm to be forward-compatible with the pending ts_xml 5.2 release and to make it compatible with explicitly listing the generic topics used.    The issue is that BaseCsc implements several generic commands that it does not actually support (by raising an exception if they are called). The fix is to remove that code. Then those commands can be removed from the XML without affecting ts_hexrotcomm, ts_hexapod or ts_rotator."""
"DM-24721","Bug","daf_butler",1,"w_2020_18 butler create does not work with Oracle","""Trying to run latest weekly (w_2020_18) with Oracle:    Got the create table and index SQL by setting SQLAlchemy's echo=True.   Can repeat the error message."""
"DM-24718","Story","alert_stream",1,"Fix license header to refer to project correctly","""As pointed out in https://github.com/lsst-dm/alert-stream-simulator/pull/3#issuecomment-623492975, alert-stream-simulator's license headers call the project """"rubin-alert-stream."""" This should be corrected."""
"DM-24713","Story","meas_extensions_scarlet",3,"Investigate poor scarlet performance on crowded fields","""The Rubin Observatory LSST-VTS Blending Task Force has attempted to run scarlet on the globular cluster NGC 6569 to test it's effectiveness on crowded fields. The attached image shows that things did not go so well at all, but possibly because of very poor object detection and/or a poorly modeled PSF. This ticket is to investigate the source of the error and at least ensure that scarlet works as well on this field as can be expected on a first pass without detections on the residuals, which is left for a future scarlet ticket."""
"DM-24741","Story","verify",1,"Make output of verify.Job.write() more readable","""Currently, the {{Job}} object writes using `json.dump` with no keyword arguments.  This means there are no carriage returns and that the file is hard to read without reformatting.  Adding a little formatting makes it much more readable at relatively small cost to overall file size."""
"DM-24734","Story","pipe_base|pipe_tasks",2,"Revive and profile RC2 QuantumGraph generation","""DM-24664 should have provided everything we need in terms of a starting data repository, but since we last ran on RC2 we've switched to YAML pipeline definitions, and neither the generic DRP one in pipe_tasks nor the custom one in ci_hsc_gen3 seem quite right.  Ideally we'll be able either make the pipe_tasks one viable with just instrument overrides or define a generic HSC+DRP pipeline in RC2, but if necessary we can put one in the Gen3+RC2 script repo.  After that, time and profile QG generation on RC2 and create tickets to optimize as needed."""
"DM-24766","Improvement","ts_auxiliary_telescope",1,"Update ts_ATDome to use port=0 instead of a port generator when talking to the mock controller","""At present ts_ATDome uses a generator to pick a likely-free port when running unit tests. This is not really safe. It is much better to specify port=0 and let the operating system pick a free port (as ts_hexrotcomm does in OneClientServer). Update ts_ATDome accordingly."""
"DM-24761","Story","Science Platform",2,"Fix Firefly notebook","""When the {{obs_lsstSim}} repository was removed from the distributed stack, it broke the repository being used by the demo Firefly notebook.  This is probably a good thing since that repository was several years old and should probably be deprecated.    This meant moving to an HSC rerun in {{/datasets}} instead.  We will need to move again when we go to gen3, but this seems like a reasonable thing for the time being."""
"DM-24760","Improvement","cp_pipe|ip_isr",20,"Migrate measureCrosstalk.py to cp_pipe","""measureCrosstalk has historically been in ip_isr, but more logically belongs in cp_pipe.  This ticket will move it, and ensure it is fully updated to use the new CrosstalkCalib."""
"DM-24790","Story","ts_dome",2,"Add documentation for DCS","""Update index.rst with a description of DCS."""
"DM-24789","Story","ts_dome",1,"Make sure that the DCS mock controller uses radians instead of degrees","""The EIE lower level components express angles in radians while SAL uses degrees. Make sure that the mock controller for the lower level components use radians as well."""
"DM-24788","Improvement","Qserv",3,"Improved error reporting in the REST services of the Replication System's Master Controller","""There are a few problems with the current design of the HTTP modules (subclasses of {{lsst::qserv::replica::HttpModule}}):  * it's impossible to return an extended description of errors in addition to a simple string sent back to the services' requestors. It would be useful for many operations to let a client have more insight into origins of problems reported by some services.  * the general design for reporting both results and errors is unsafe, and it leaves a room for mistakes.    In the current model a module's implementation has to use the following mechanism for reporting results/errors:  {code:c++}  class HttpSomeModule: public HttpModule {  ...  protected:      virtual void executeImpl() override {          ...          if (error condition) {              sendError(""""error string"""");              return;          }          ....          json result = ... ;          sendData(result);          return;      }      ....  };  """
"DM-24786","Story","daf_butler",2,"New component column in datastore is too small","""In DM-24288 the component name was added to the internal posix datastore record. Unfortunately it was length 16 and sqlite did not complain -- this breaks databases that do check the length of strings. In particular """"TransmissionCurve"""" exceeds the limit. Change the limit to 32 to fix this.    Additionally we might want to add constraints back. Constraints were added previously in DM-18438 but subsequently removed when DatabaseDict was replaced with OpaqueData."""
"DM-24780","Story","daf_butler",1,"Initial mypy configuration for daf_butler","""This ticket adds:   # configuration that tells mypy to run on just lsst.daf.butler.registry.interfaces   # fixes for the type annotations in just that package   # a non-default scons target to run mypy   # travis configuration to run mypy    As mypy isn't part of the stack's usual conda environment, users will have to take care of installing it (I used {{conda install --no-update-deps mypy}}) before trying {{scons mypy}}.    I figure we'll expand the configuration to other daf.butler subpackages as we get them to run clean under mypy.    Work for this ticket is almost entirely done in prep for a Science Pipelines team meeting on type annotations; all that remains is review."""
"DM-24777","Story","efd",1,"Confirm EFD client is not broken by InfluxDB 1.8.0","""Confirm in CI that the efd helper classes work with the new version of InfluxDB (1.8.0)."""
"DM-24769","Improvement","daf_butler|Middleware",1,"Improve connection string matching.","""Michelle Gower noticed that when dialect and driver are specified in the config but not so in the db-auth.yaml the match will not succeed.    Example, the db key in registry config:         db: """"oracle+cx_oracle://host""""     will not match db-auth.yaml entry         - url: oracle://host...     and vice-versa. Specifying the driver has an impact on functionality of the registry since it changes the functionality of the underlying database, but the driver has no direct impact on DB authentication. The same user should be able to connect with any appropriate driver they have available regardless of whether db-auth entry matches the full dialect+driver string or not.         I think it's most natural to allow, and preserve, specified driver in the butler.yaml, but ignore it in db-auth.yaml. I am wary of making it raise an error when it does, but that can be changed."""
"DM-24768","Bug","daf_persistence",2,"build race condition in daf_persistence","""I received a build failure in daf_persistence when rebuilding lsstsw, due to the `testLib.so` file not being produced before pytest started, resulting in this error:        It appears this was due to the SConscript having the `pybind11` and `tests` entries out of order. I'm fixing it in daf_persistence, and I will check whether this is an issue in any other packages. I will also update the dev guide to mention the correct ordering of these statements.    I don't know why I hadn't encountered this before, but I could consistently trigger it on my 2013 Macbook Pro, so my guess is a change in build time with the new conda environment."""
"DM-24805","Story","ts_aos|ts_main_telescope",1,"Build the Latest MTAOS Docker Image to Deploy on NCSA","""Build the latest MTAOS docker image to contain the update of DM-24422, DM-24423, and DM-24610 to deploy on NCSA. AOS needs the upstream packages of *lsst-distrib* and *lsst-sims*. The available version (tag) can follow [tags|https://eups.lsst.codes/stack/src/tags/]. The T&S team uses the weekly built in the most case. For the *lsst-distrib*, the latest available tag is *w_2020_18*. For the *lsst-sims*, the latest available tag is *sims_w_2020_16*. To install these two packages together, we need to make sure to use the same weekly built tag.    The T&S team releases the available development image ([develop-env|https://hub.docker.com/repository/docker/lsstts/develop-env]) regularly. The latest formal tag is *b68*, which has the *lsst-dev* *w_2020_16* installed already. It is noted that we do not use the *latest* tag usually. In this task, we will begin from this docker image to build the image of MTAOS (the latest one now is using *w_2020_15*). The followings are the steps:   # Update the [aos_sal|https://github.com/lsst-ts/ts_Dockerfiles/tree/develop/aos_sal] image to use the *lsstts/develop-env:b68* and publish as [aos_sal|https://hub.docker.com/repository/docker/lsstts/aos_sal] on Docker hub. This image installs the *lsst-sims* and other needed packages for AOS to use.   # Update the [aos_aoclc|https://github.com/lsst-ts/ts_Dockerfiles/tree/develop/aos_aoclc] image to use the latest AOS packages and publish as [aos_aoclc|https://hub.docker.com/repository/docker/lsstts/aos_aoclc] on Docker hub.   # Update the [mtaos_sim|https://github.com/lsst-ts/ts_Dockerfiles/tree/develop/mtaos_sim] image to use the latest ts_MTAOS package and publish as [mtaos_sim|https://hub.docker.com/r/lsstts/mtaos_sim] on Docker hub.   # Deliver to Tiago to deploy the image on NCSA for the test."""
"DM-24804","Story","obs_base",8,"create a 'convert' butler command","""make a {{convert}} command that implements the {{the obs_base convert_gen2_to_gen3}} command.    existing tests are in {{lsst.obs.base.gen2to3.convertTests}}, and {{ci_hsc_gen2}} has a test script {{tests/test_gen2to3.py}}"""
"DM-24802","Story","Middleware",1,"Adjust SAL to accomodate changes to the XML recommendations","""The https://confluence.lsstcorp.org/pages/viewpage.action?pageId=120786640&src=contextnavpagetreemode  proposes some changes which   will require small mods to the SAL parser"""
"DM-24800","Story","Middleware",0.5,"Add #define to provide CLOCK_TAI if not present (temporary)","""For the latest LSST stack the CLOCK_TAI symbol is not defined due touse of an older glibc  version. Implement a temporary worlaround to provide the #define in this situation."""
"DM-24799","Story","ts_main_telescope",3,"Review the Control Algorithm of Rotator in Phase 1","""This task will review the control algorithm of rotator in Simulink model and try to translate to the math equations. This is try to understand the behavior of stop command in the tracking. In the previous test on summit, we learned that the path generator has the weird behavior if stop command was issued in the tracking. We suspect the stop command results in the wrong behavior of path generator."""
"DM-24798","Story","ts_main_telescope",3,"Put the Hexapod into Standby State after the clearError Command","""Put the hexapod PXI into the standby state after clearing the error. This task will need to update the Simulink model for the state machine transition. After this, I will need to generate the C/C++ code and put back to ts_hexapod_controller and test the new built. This task will need to learn and test and hexapod simulink model. This task will also try to understand the logic of look-up table (LUT) in code."""
"DM-24797","Story","ctrl_mpexec",2,"Store per-run information (configs, software versions) in butler repo","""As part of gen2 deprecation we are required to store run details into the butler repository. These are expected to be per-run and so have blank dataIds.    * The config used by the pipeline.  * The pipeline definition.  * The software versions.    """
"DM-24796","Story","ctrl_mpexec",0.5,"pipetask's graphviz dot files need to quote component dataset type names","""Strings with periods apparently aren't allowed as the names of vertices or edges in graphviz unless they're quoted.  At least the pipeline-level dot files (and I assume the QG-level ones) run afoul of this when a dataset type name refers to a component, as in """"{{calexp.wcs}}""""."""
"DM-24813","Improvement","ts_main_telescope",1,"Finish specifying changes to Tekniker's TMA code","""This ticket is to capture the time I will spend on final (I hope) changes to LTS-103 and the change request for Tekniker's TMA code.    Others have also put a lot of time into this, but if I understand the time accounting system we each need our own ticket."""
"DM-24811","Bug","ts_main_telescope",1,"Fix the track target command in MTMount","""Tekniker's """"crude simulator"""" is rejecting the track target command from MTMountCsc. I have asked Tekniker to explain what is wrong. Once I find out update ts_MTMount (assuming the fault is there, which seems likely)."""
"DM-24851","Story","ctrl_mpexec|daf_butler",2,"Change Datastore.getUri to Datastore.getURIs","""When we started to allow datasets to be disassembled this resulted in a single dataset_id corresdponding to multiple disassembled files. This breaks the paradigm for getUri which assumes a single file.    On this ticket we propose to replace getUri with getURIs that will return a tuple of the URI of the primary dataset and a dict mapping component name to component URIs.    For normal disassembly the primary dataset would be None. In the future for virtual datasets this may no longer be true and the primary dataset could be defined with URIs to override components also being returned.    Predicted file will still assume no disassembly."""
"DM-24843","Improvement","ts_middleware",2,"Make <IndexEnumeration> values available in SAL-generated IDL files and libraries","""Please make the SAL index enumeration values available in the IDL files and libraries generated by ts_sal. These are the values for the field called <Enumeration> in SALSubsystems.xml (and which is likely to be renamed to <IndexEnumeration>).    Not a high priority, but it would be nice to have."""
"DM-24842","Story","Middleware",0.5,"Generate Opensplice RPM/DEB for raspberry pi","""Build runitme support archives (DEB/RPM) for the raspberry pi version  of OpenSplice"""
"DM-24841","Story","ts_middleware",0.5,"Please support non-empty specification of a non-indexed component","""For the <Enumeration> field, non-indexed components should be identified by the content """"no"""" instead of an empty tag. This removes the ambiguity between it is not indexed or it was not noted down properly."""
"DM-24840","Improvement","ts_middleware",0.5,"Please allow enumerations with specified values in the Enumeration field of SALSubsystems.xml","""I think it would make SALSubsystems.xml a bit clearer if the <Enumeration> fields could have values specified, e.g.:    For example I would argue that this:    is a bit clearer than this:      It also supports an unusual existing use case: ts_FiberSpectrograph uses special index -1 to mean """"UNKNOWN: use the only connected spectrograph"""" (though that could easily be changed to another value).    If you decide to make this change, please also:  * Reject the XML if a value is 0, since for topic readers 0 means """"read from all indices"""" (a great feature!).  * Please consider allowing optional whitespace around the = and after the comma.    This is a minor suggestion and I do not consider it important enough to justify a lot of work. Once we have good central documentation for SALSubsystems.xml the current system should be clear enough."""
"DM-24838","Story","ts_main_telescope",3,"Replace boot and shutdown commands with enter/exitControl","""M1M3 SS uses boot and shutdown commands for what nowadays shall be done with enterControl and exitControl generic SAL commands. Replace boot and shutdown commands with generic enter/exitControl. Enforce their functionality (if possible) by actually stopping and restarting HW threads on exit/enter."""
"DM-24835","Story","ts_main_telescope",3,"Generate document on dome coditioning contract","""As a component of the Environment Awareness System EAS ([https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73574873),|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73574873)] it's necessary to develop a dome environment conditioning system, to control te temperature during daytime. For that purpose, a document will be generated to lead to a contract for the implementation of this system."""
"DM-24834","Story","ts_main_telescope",1,"Create the M2 GUI/DDS Startup Procedure in Jira Test Manager","""Create the M2 GUI/DDS startup procedure in Jira test manager. This is for the system engineer team to start up the system. The focus is the use of M2 control system (GUI) and SAL. For example, how to check the DDS communication, open the GUI, run the software, commend the system by SAL, etc.. The link of """"LSST Verification and Validation"""" is [here|https://jira.lsstcorp.org/secure/Tests.jspa#/design?projectId=12800]."""
"DM-24833","Story","ts_main_telescope",5,"Dome software meetings","""Prepare and coordinate weekly meetings on dome control software with EIE contractor."""
"DM-24824","Story","HeaderService",2,"Modify event used to populate AT focus header value.","""With CAP-468 completed, the ATAOS now tracks the different focus offsets applied to the lookup tables.     What should be in the header is the user-defined offset from the LUT.    This ticket is to update the FOCUSZ header to point to:    ATAOS_logevent_focusOffsetSummary.userApplied"""
"DM-24892","Story","obs_base",1,"Fix bug in gen2to3 when only special dataset types are being converted","""RepoWalker raises when initialized when there is nothing for it to look for.  This is useful information that should be propagated up to avoid unnecessary filesystem scanning, but it shouldn't be allowed to propagate _all_ the way up and kill conversion, as this isn't all of the work that might need to be done."""
"DM-24862","Story","meas_extensions_scarlet",5,"Update with latest scarlet and proxmin and test for performance","""The API for scarlet changed slightly, with some improvements in performance and in memory usage. So this ticket is to update {{meas_extensions_scarlet}} to properly wrap and propagate those changes and run on the fake patches to measure the gains in performance from the previously tested version."""
"DM-24855","Bug","ip_diffim",2,"Exclude sky sources from Ratio of DIASources to Direct Image Sources metric","""DM-23078 added [Sky Sources|https://community.lsst.org/t/sky-sources-added-to-single-frame-processing/4137] to Single-Frame Processing.  This created an unwanted adjustment in the """"Ratio of DIASources to Direct Image Sources"""" metric.      This ticket is to exclude sky sources from the metric calculation (we should continue to compute and store them because we are likely to use them in the future.)"""
"DM-24925","Story","ts_qa",3,"Merge SAL/XML Jenkinsfiles","""There are two Jenkinsfiles for SAL/XML builds; one for releases and one for daily builds.  They are heavily duplicated, but build different branches and set variables differently.  In theory, with some smart conditionals, these two files can be merged into one.  This task covers the time needed to attempt this consolidation."""
"DM-24924","Story","obs_lsst",1,"Add new telescope name for ComCam and LSSTCam to obs_lsst","""obs_lsst should be able to allow the Simonyi Survey Telescope as a valid telescope name in order to read files for ComCam and LSSTCam."""
"DM-24915","Story","meas_extensions_scarlet",3,"Fix broken Travis CI","""Testing in scarlet started failing on Travis CI yesterday, meaning that the docs are no longer being built. Tests pass locally, and the first test to fail is the current master: https://travis-ci.org/github/pmelchior/scarlet/builds/686233127 . Executing the previous master commit, which was previously passing, is now failing as well: https://travis-ci.org/github/pmelchior/scarlet/builds/686224195 .    This indicates thats something on Travis changed, but it is not clear what this could have been. I checked all of the dependencies and they use the same versions now as they did before:    numpy 1.18.1  scipy 1.4.1  astropy 4.0.1  nbsphinx 0.7.0  matplotlib 3.2.1  numpydoc 0.9.2  jupyter 1.0.0  pybind11 2.4.3  proxmin 0.6.10 (loaded from github, has not been updated)  peigen 0.0.9  prompt_toolkit 3.0.4  sep (loaded from github but has not had a new commit since November)  autograd 1.3"""
"DM-24912","Improvement","ts_auxiliary_telescope|ts_main_telescope",2,"Fix packages broken by ts_salobj 5.12","""DM-21196 introduces a change to ts_salobj that is not completely backwards compatible. Fix code that is broken by this change.    The new version of ts_salobj will probably be called v5.12.0.    So far the main issue I have seen is one or two unit tests in a few packages. I am not expecting anything worse, but I want to verify that before releasing the new salobj."""
"DM-24942","Bug","ts_environment",1,"HVAC defines a command and telemetry topic with the same name","""The HVAC interface defines a command and a telemetry topic with, effectively, the same name:    lsstBarraoblPiso04BarraoblManejadoraBarraoblSblanca    This string appears in both HVAC_Commands.xml and HVAC_Telemetry.xml.  The SAL is having an issue building the HVAC libraries, as a result.  There's no error in the salgenerator output, as far as I can see, but there's an error during the build looking for an output file:    [https://tssw-ci.lsst.org/job/test_linking/158/robot/report/rpm_report.html#suites?s1-s3-s6]         All the libraries seem to generate just fine; there are no other reported errors.  But this may indicate a bigger issue with the libraries."""
"DM-24941","Story","alert_stream",1,"Compile a good sample dataset for alert stream simulator","""Take a bunch of the data from ap_verify_hits2015 and compile it into a single .avro data file which covers multiple CCD visits. Publish it through lsst-dev web directory, and add a Make directive for downloading it."""
"DM-24940","Story","daf_butler",1,"Move NamedKeyDict and NamedValueSet out of utils and clean up typing","""An early attempt to do some of DM-24938 on DM-24734 ran afoul of messiness involving regular dictionaries with dimension element names vs. NamedKeyDict objects holding real DimensionElement instances.  This is exactly the sort of stuff mypy is designed to fix, but the type annotations for NamedKeyDict and NamedValueSet are tricky and in some cases incorrect, and need to be fixed first.    We're also regularly using these containers in downstream packages because they're the natural way to pass around and group by DatasetTypes, and that means we should be exporting them at """"lsst.daf.butler"""" level, instead of requiring imports from """"lsst.daf.butler.core.utils"""", because the last two entries in that path should be considered internal daf_butler details."""
"DM-24937","Story","daf_butler",1,"move implementation of remaining butler commands to script folder","""the butler command functions config_dump and config_validate need to be refactored so that their implementations are in the scripts folder, similar to the other command functions."""
"DM-24935","Story","meas_algorithms",2,"Add support for DataFrame and Table in ScienceSourceSelectorTask and ReferenceSourceSelectorTask","""As of DM-24062, HSC calexp sources (at least) can be consolidated into visit level {{sourceTable_visit}} parquet tables.  While reading this in is extremely fast relative to reading in the individual source catalogs (especially when not reading the full width) [about 95-98% faster in some testing], these full catalogs are {{DataFrame}} objects and cannot be used with our source selectors.    It should be relatively easy to add {{DataFrame}} support to {{ScienceSourceSelectorTask}} and {{ReferenceSourceSelectorTask}} which I believe are the most common down-stream source selectors used for science analysis (and, for example, in {{fgcmcal}} which will be one of the first consumers of {{sourceTable_visit}}, DM-24319."""
"DM-24934","Story","ts_dome",1,"Clarify the meaning of CW/CCW/UP/DOWN and whether a velocity may be negative","""Make sure that it is clear what CW/CCW/UP/DOWN in the Dome commands XML in SAL mean and make sure that it is stated in the description of the crawl commands. Also make sure that negative velocities are rejected?"""
"DM-24932","Improvement","ts_middleware",0,"Improve output from SALPY tests in salobj","""Print how long it takes to get historical data in the salpy<->salobj tests in ts_salobj.    This may help diagnose DM-24931"""
"DM-24970","Improvement","ts_middleware",1,"XML_VERSION=1.0.0 in IDL files","""The reported XML version is 1.0.0 in generated IDL files, instead of the git-tagged version of ts_xml. Here is the first line from an IDL file generated by ts_sal 4.1.1:  """
"DM-24995","Story","efd",1,"Create chronograf organizations for people to use at the base.","""The commissioning and T&S people would like to use organizations to handle their dashboards.  It makes sense to provide that by making organizations with an admin per organization.  I will also hook up github orgs with each organization so people can self serve membership."""
"DM-24985","Story","obs_decam|obs_subaru",1,"'file' needs to be an @property when it uses a testdata pacakge","""in DM-24923 `IngestTestBase.file` was changed from a member variable to a class property. Some subclasses use their `testdata` package to define the value of `file`. These tests are skipped when the testdata package is not set up, but class properties are loaded import time and this fails when performing e.g. `os.path.join`. These class properties must be property functions with the @property decorator to prevent this error.     """
"DM-24982","Story","ts_eas",1,"Install raspis and sensors at home and flash HD card","""Two raspberry pi's are installed at the Recinto with temperature and cloud sensors attached to them. Pick them up, set them up at home and flash the SD card of the raspberry pi 4 with the latest image provided by Garry."""
"DM-24979","Story","daf_butler",1,"config_file_option does not save the 'help' input argument","""in [https://github.com/lsst/daf_butler/blob/master/python/lsst/daf/butler/cli/opt/config_file.py#L27]         the 'help' input argument should be stored as a member var and passed to click.option in __call__"""
"DM-24978","Bug","ci_hsc_gen3",0.5,"Update butler create config option in ci_hsc_gen3","""DM-24584 changed the butler command line argument. In particular for passing in a config file to {{butler create}} in {{w_2020_19}}:           In w_2020_20      ci_hsc_gen3 uses the {{-c}} option but wasn't updated. """
"DM-24976","Improvement","jointcal|testdata_jointcal",1,"Rework testdata_jointcal dependencies","""The new data in DM-17597 will grow the size of a testdata_jointcal checkout significantly. Because testdata_jointcal has dependencies on each of the obs packages that it contains data for, it is re-installed during every build, resulting in potentially significant disk usage.    This ticket is to split out the obs dependencies so that testdata_jointcal has no dependencies itself. jointcal and fgcmcal would then gain optional dependencies on the obs packages whose repos they use, in addition to testdata_jointcal. Those unittests would also need to trip for whether the appropriate obs packages was `setup` and skip the tests if not.    As part of this, we should add a note to `fgcmcal.table` to explain why it has a dependency on jointcal (it needs the gen2 tract-grouping code, which will be unnecessary in gen3)."""
"DM-25014","Bug","obs_base",3,"Coadds converted to Gen 3 without abstract_filter",""" I have a Gen 3 repository that I created from https://github.com/lsst/ap_verify_ci_hits2015/tree/master/templates by running    using the {{w_2020_20}} stack. Trying to run image differencing using {{w_2020_20}} and these coadds gives    Since coadds should be parametrized by some kind of filter, this is presumably an error in the conversion."""
"DM-25010","Story","ap_association",1,"Make Alert serialization optional in diaPipe.","""Create a configurable setting in diaPipe to optionally enable or disable seralizing alert packets."""
"DM-25007","Story","Verification",2,"convert metrics pipeline tasks to use MetricTask","""In putting together a prototype metric pipeline, we re-implemented some of the same things implemented in {{MetricTask}}.  We will just switch over to subclassing that."""
"DM-25006","Story","efd",2,"Update the efd client to use segwarides as the first source of credentials","""Currently the efd client looks for a special file, but now we need to query the segwarides service first."""
"DM-25003","Improvement","ts_middleware",1,"RemoteCommand.set_start should not use data from the previous command","""In ts_salobj {{RemoteCommand.set_start}} presently uses data from the previous command as default values for fields. This is dangerous. [~pingraham] reports he has been bitten by this a few times.    I propose to fix it by modifying {{RemoteCommand.set}} to create a new sample before setting the specified fields. That will also fix {{RemoteCommand.set_start}} and makes the two methods self-consistent.    I have tried that and found:  * ts_salobj unit tests all pass. Thus the old behavior was not tested, which is unfortunate but it was never intended to be a useful feature. The new behavior definitely deserves to be tested.  * ts_scriptqueue unit tests all pass. I was expecting some failure there, but apparently I wrote the tests to not rely on the old behavior. Good!  * ts_standard_scripts unit tests: one test fails so that script may need an update  * ts_observatory_control unit tests all pass"""
"DM-25000","Story","daf_butler",2,"Using components in PipelineTaskConnections no longer seems to work.","""I have a [pipeline task|https://github.com/lsst-dmsst/metric-pipeline-tasks/blob/master/tasks/MatchedCatalogs.py] that worked with w_2020_17 with {{ci_hsc_gen3}}.    With w_2020_19, it now returns {{UserWarning: QuantumGraph is empty}} whether I ask for `calexp.photoCalib` or `calexp.wcs`.  If I switch to using a stand alone dataset, `jointcal_photoCalib` the quantum graph looks as I expect and it allows my pipeline to run to completion."""
"DM-25030","Story","daf_butler",8,"make an import butler subcommand","""replaces ingestExternalData from ci_hsc_gen3 with a butler subcommand; it should be a straightforward wrapper around {{Butler.import_}}    define the command in daf_butler    it should be able to read whatever the butler export generates  and we will consider (later) whether butler export | butler import works (with associated parameters)"""
"DM-25029","Story","obs_base",8,"make define-visits butler command","""replace defineVisits from ci_hsc_gen3 with a butler subcommand."""
"DM-25028","Story","daf_butler|obs_base",2,"change butler create --config-file to --seed-config","""change the {{butler create}} option {{--config-file}} to {{--seed-config}}. Keep the existing help text """"Path to an existing YAML config file to apply (on top of defaults).""""    Change the shared {{--config-file}} option's default help text to be more specific: """"Path to a pex config override to be included after the Instrument config overrides are applied.""""    TODO verify the new config-file help text."""
"DM-25020","Story","obs_subaru",0.5,"Update Sources.yaml with correct local background","""In the current {{Sources.yaml}} which defines the conversion of {{src}} catalogs to {{sourceTable_visit}} parquet tables, the {{base_LocalBackground_instFlux}} is converted to {{sky}}.  However, as pointed out in DM-25019, the {{sky}} value should be the overall background value, and not the residual.  Therefore, {{base_LocalBackground_instFlux}} should be recorded non-transformed, while {{sky}} should have a temporary placeholder that is flagged with a DM-25019 TODO."""
"DM-25016","Bug","ctrl_mpexec",2,"DM-21724 unpickling error appears again ","""Saving a QuantumGraph and run it with pipetask doesn't work. This is the same problem as DM-21724 but the fix got unfixed.     When trying to run a stored  QuantumGraph pickle with   {{pipetask run --qgraph name.pickle  -b  butler.yaml}}  the error is         Slack: https://lsstc.slack.com/archives/C2JPT1KB7/p1590018536265400 """
"DM-25043","Story","Verification",3,"Add AMX and TEX measurements to the new metrics pipeline","""We have a proof of concept for a verification pipeline in the works on DM-25007.  It looks very promising.  Adding AMX and TEX will get it almost to the place where validate_drp is."""
"DM-25040","Bug","ap_association",2,"ap_association uses physical filter in Gen 3","""{{ap_association}} uses the Alert Production database, which has columns named by abstract filter (e.g., {{gPSFluxLinearSlope}}). We have tested this system extensively in Gen 2 with DECam and, to a lesser extent, HSC.    However, attempting to run {{ap_association}} on HSC in Gen 3 gives database errors such as      I believe this bug can be fixed by consistently calling {{Filter.getCanonicalName}} instead of {{Filter.getName}} throughout the {{ap_association}} package. Unfortunately, it may be difficult to test the in Gen 3, since we don't yet have all the infrastructure in place (DM-21939)."""
"DM-25039","Improvement","jenkins",1,"Please allow Jenkins authentication when visiting any URL","""The T&S Jenkins system https://tssw-ci.lsst.org/ gives a 404 error if one tries to go to a link and one's login has expired. This is a headache when trying to see the status of a job started on github, or even just visit a frequently-wanted page such as https://tssw-ci.lsst.org/job/LSST_Telescope-and-Site. I have to open a new browser to https://tssw-ci.lsst.org, log in there, wait for that to complete, and only then can I go to the other page and try the link again.    Please if at all possible enable login when visiting any page. Also please consider a longer time limit on login or some way to """"remember this browser"""" (for those of us on secure computers, e.g. desktops)."""
"DM-25037","Story","DM Subsystem Science",1,"Present DM Status at  LSSTC Board meeting ",""" LSSTC Board requested an update on DM status at their 4 June board meeting"""
"DM-25032","Story","HeaderService",1,"Fix comments in ComCam/MainCam header keywords that currently reference AuxTel","""The following keyword comments need to be fixed to refer to MainTel systems in the ComCam/MainCam headers:     This should reference MTCS  TRACKSYS=                      / Tracking coordinate system from ATMCS       For MainTel, this is from the Camera Hexapod  FOCUSZ  =                   0. / Focus Z position from ATAOS/ATHexapod (mm)"""
"DM-25031","Story","HeaderService",1,"Remove AuxTel specific keywords from ComCam/MainCam headers","""The following keywords are specific to AuxTel and should be removed for ComCam/MainCam   *   INSTPORT   *   ATM3PORT   *   GRATING   *   GRATPOS"""
"DM-25049","Improvement","Qserv",2,"Streamlined naming convention for the REST API resources in the Qserv Replication/Ingest System","""The current implementation of the REST API provided by the Qserv Replication/Ingest system for exploring and managing Qserv may need to be improved. Presently, the API provides two groups of resources:  {code:}  /replication/v1/<service>  /ingest/v1/<service>    /meta/version    In this case availability of services and their behavior will be completely driven by the current version of the services. Another benefit of this schema is that it would with documenting the REST API since each version of the documentation could refer to specific numbers returned by the proposed metadata service."""
"DM-25047","Story","ts_aos|ts_main_telescope",1,"Reformat AOS Modules by Black","""Reformat the AOS packages to black with the same coding style. There are four packages: ts_wep, ts_ofc, ts_phosim, and ts_MTAOS. The task is a place holder for DM-25062, DM-25063, DM-25065, and DM-25066 to calculate the story point."""
"DM-25046","Story","ts_aos|ts_main_telescope",3,"Replace Cython by Pybind11 in WEP","""Replace the cython by pybind11 in cwfs module of ts_wep to follow the DM convention."""
"DM-25045","Story","ts_main_telescope",3,"Review the Control Algorithm of Rotator in Phase 2","""This task will review the rotator Simulink model and try to reproduce the error we had on the summit test that the demand rotator position can be -2000 peak. Another error we have is the peak between tracking targets. We will also investigate the stop profile in model. This is the phase 2 of DM-24799."""
"DM-25057","Story","ts_middleware",1,"SAL's topic hash code generator not consistent","""The code in ts_sal v4.1.2 that generates the has code for DDS topics seems to have a flaw. When I switched the Script SAL component to explicitly list the generic topics it uses (ts_xml tickets/DM-22109), the hash code for {{logevent_checkpoints}} changed (compared to ts_xml develop 133d378) even though {{logevent_checkpoints}} is not a generic topic and did not change at all. I see the same issue in ts_sal v4.1.1    This is quite worrisome for using the new ability to list generic topics as it means the new IDL will not be compatible with the old IDL even though the schemas have not changed.    I have attached the two IDL files.  """
"DM-25080","Story","daf_butler",1,"Finish static typing in daf.butler.registry","""This was mostly done over the weekend, originally intended to be a side-commit on DM-24613.  Might as well get it out for review on its own branch earlier."""
"DM-25074","Story","ts_dome",2,"Add more useful info to the documentation","""The current Dome documentation is pretty thin. Add more useful info, add version info and create a release.    Also, make sure that the flake8 line length is set to 79 characters."""
"DM-25073","Improvement","ts_middleware",1,"Make AsyncS3Bucket capable of constructing the bucket","""There are situations where S3 upload may not have the bucket we are trying to write to. Enhance AsyncS3Bucket to add the ability to create the bucket if it does not exist.    That might also be useful for the mock mode -- try it."""
"DM-25068","Story","ts_main_telescope",3,"Generate document on dome coditioning contract","""As a component of the Environment Awareness System EAS ([https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73574873),|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73574873)] it's necessary to develop a dome environment conditioning system, to control the temperature during daytime. This is a continuation of DM-24835 to compose the technical support documents for the implementation contract."""
"DM-25067","Story","ts_main_telescope",5,"Dome software meetings","""Prepare and coordinate weekly meetings on dome control software with EIE contractor."""
"DM-25066","Story","ts_aos|ts_main_telescope",0,"Reformat ts_MTAOS Python Repository by Black","""Reformat ts_MTAOS Python repository by black."""
"DM-25065","Story","ts_aos|ts_main_telescope",0,"Reformat ts_phosim Python Repository by Black","""Reformat ts_phosim Python repository by black."""
"DM-25064","Story","ts_main_telescope",3,"Tests for PID in M1M3","""Tests for PID code inside M1M3 SS. C++ code to verify PID functionality, look for possible runaways scenarios."""
"DM-25063","Story","ts_aos|ts_main_telescope",0,"Reformat ts_ofc Python Repository by Black","""Reformat ts_ofc Python repository by black."""
"DM-25062","Story","ts_aos|ts_main_telescope",0,"Reformat ts_wep Python Repository by Black","""Reformat ts_wep Python repository by black."""
"DM-25112","Story","ci_lsst",3,"Update ci_lsst for bitrot","""In trying to validate some changes (on DM-24858) in {{obs_lsst}} involving all detector """"flavors"""" associated with that obs-package and requiring adaptations to tests, it was suggested that I try running {{ci_lsst}} (currently on lsst-dm github). It ran without failures for all the default cameras except {{latiss}}, which has suffered some bitrot of a sort. While we await the fully fleshed out ci integrations currently being worked on in cpp-land (e.g. DM-23302 & DM-23622), this ticket is to fix the bitrot so that at least some testing of {{obs_lsst}} changes not possible via unittests can be done.    Of note, the {{ci_lsst}} scripts are being tested and adapted here based on the data that currently resides on {{lsst-dev}} at {{/project/shared/data/test_data/testdata_lsst/raws}}."""
"DM-25110","Epic","ts_environment",40,"EAS Work Phase 5","""This epic is used to hold all stories associated with the Environmental Awareness System.  Previous epics are:   * DM-17215   * DM-18732   * DM-20197   * DM-21536   * DM-23148"""
"DM-25109","Story","Middleware",2,"Wrap up SAL changes for SALSubsystems.xml for a 4.1 hotfix","""Make a hotfix patch to implement the recommended changes to SALSubsystems.xml in SAL"""
"DM-25102","Story","alert_stream",2,"Distribute lsst/alert_stream on PyPI","""Write a setup.py script which describes lsst/alert_stream, and put it in the root of that repository.  Write a Makefile with directives for building and uploading to PyPI.  Upload an initial release. Use version v0.1.0, handled in the same manner as {{astro_metadata_translator}} in https://github.com/lsst/astro_metadata_translator/blob/master/setup.py."""
"DM-25095","Story","ts_aos|ts_main_telescope",0,"Fix Jenkinsfile","""Jenkinsfile introduced in DM-24610 breaks build on branch. Partly expected, the fix (due to unclear nature of env.CHANGE_TARGET) would be to use BRANCH_NAME if CHANGE_TARGET is null"""
"DM-25137","Improvement","ts_middleware",0,"current_tai may return a numpy.float64 instead of a float","""The functions {{tai_from_utc}} and {{tai_from_utc_unix}} return a {{numpy.float64}} instead of a float, and {{current_tai}} will also do so if not using {{CLOCK_TAI}}. This is a nuisance for encoding the data with yaml (and, probably, json). Fix these to always return float. This can be done by casting the value returned by {{tai_from_utc_unix}}. Test the result.    """
"DM-25134","Improvement","ts_middleware",2,"Test ADLink's fix for segfaults with the community edition of OpenSplice","""ADLink provided a fix for the segfaults we see in CAP-529. This fix is for the licensed version. Apply the same change to the community edition of OpenSplice and see if it works there. If it does then submit a pull request for the community edition.    Also document the build and install procedure."""
"DM-25133","Story","ts_qa",2,"Fix the race condition between the RPM daily job and the IDL Conda job","""There is only about a minute between the end of the RPM Daily Build and the start of the IDL_Conda job.  This isn't quite enough time for the yum repo to finish indexing all the new RPMs, so the IDL job often fails as a result.  Figure out a way to have the IDL job wait until the desired RPM is available before trying to install it."""
"DM-25130","Story","ts_dome",2,"Replace YAML with JSON when sending commands from and receiving replies in the Dome CSC.","""In the weekly Dome Software Meeting of 2020-05-28 it was decided to replace YAML with JSON when sending commands from and receiving replies in the Dome CSC. This ticket will take care of that and will also make sure that there will be a central function to construct the commands (in the Dome CSC) and replies (in the mock_controller simulator) that does this so a possible future technology switch could be done more easily."""
"DM-25121","Story","Middleware",2,"Modify SAL rpm naming convention ","""Change the SAL generated rpm naming convention to support the scheme outlined in https://confluence.lsstcorp.org/display/LTS/Proposal%3A+RPM+naming+convention+change"""
"DM-25117","Story","ts_eas",2,"Install ESS software in RPi4 and make sure it runs at system start up","""Take the ESS sources from GitHub and install them in a RPi4 that is prepared with the SAL software stack. Also make sure that the software gets started at system start up."""
"DM-25170","Bug","daf_butler",0.5,"Fix to get predicted butler URIs","""Getting predicted butler URIs crashed with           I think [this line|https://github.com/lsst/daf_butler/blob/master/python/lsst/daf/butler/_butler.py#L826]  means to use {{run}}, not {{self.run}}, in the arguments. """
"DM-25156","Bug","obs_base|obs_decam|obs_lsst",2,"Gen 2->3 conversion of DECam repositories can give duplicate defects","""If I convert a DECam Gen 2 repository containing defects, the conversion succeeds, but running {{ProcessCcd}} on the result gives an error:    The immediate cause is that one copy of the defects is from the Gen 2 repository, the other copy was ingested during the conversion.    Discussion on [#dm-middleware|https://lsstc.slack.com/archives/C2JPT1KB7/p1590719387081900] suggests that this is due to conflicting responsibilities:  * {{obs.base.Instrument}} has some [hard-coded definitions|https://github.com/lsst/obs_base/blob/a51665517dd0ecacd8d72fbcead186475fcf66d3/python/lsst/obs/base/instrument.py#L38-L45] of curated files, which are processed any time {{ConvertRepoConfig.doWriteCuratedCalibrations}} is set. Defects are included.  * {{ConvertRepoConfig}} also has a [{{curatedCalibrations}} field|https://github.com/lsst/obs_base/blob/7c071951e367c4bef83840b75921f3a2f3af29cb/python/lsst/obs/base/gen2to3/convertRepo.py#L252-L263], which presumably allows other datasets to be handled using {{writeCuratedCalibrations}}. This list does not include defects by default.  * HSC [adds defects to {{ConvertRepoConfig.curatedCalibrations}}|https://github.com/lsst/obs_subaru/blob/c641360ad764cf8db63ecf1d14af6c93660160ff/config/hsc/convertRepo.py#L35-L36]. The bug described above *does not* occur.  * DECam makes no changes to {{curatedCalibrations}}, and its [config override file|https://github.com/lsst/obs_decam/blob/8567ae41add358da7b9af65fc81c39e39078b975/config/convertRepo.py] makes no mention of defects. The bug *does* occur.    The above behavior implies that DECam repositories with defects cannot be converted using the default configs, which goes against our general aim to provide working defaults for all Tasks.    Possible solutions:  * Do away with {{ConvertRepoConfig.curatedCalibrations}}, as proposed by [~tjenness]. However, this does raise the question of how to handle observatory-specific curated calibrations.  * Have DECam explicitly register defects in {{curatedCalibrations}}, as HSC does. May be hard to scale to other instruments.  * Duplicate the dataset types hardcoded into {{Instrument}} in the default {{ConvertRepoConfig.curatedCalibrations}}. Won't benefit configs that overwrite this field instead of appending to it."""
"DM-25153","Story","obs_decam|obs_lsst|obs_subaru",0.5,"Make it clear that gen3 instrument class paths don't need .instrument","""In DM-23980 I standardized the instrument class names for Gen3. Doing so means that both {{lsst.obs.lsst.LsstCam}} and {{lsst.obs.lsst.instrument.LsstCam}} work. Since we don't want multiple ways of specifying the same instrument and we already know of cases where people think they need to include the {{.instrument}}, rename the internal {{instrument.py}} to {{_instrument.py}} to make it clearer that this name should not be used.    One caveat is that when we register the instrument we call getFullTypeName so if you specify the short name the registry still sees the full name and we therefore have to promise not to move that class later inside the package. One solution to that is for the instrument class to not use getFullTypeName but to """"know"""" the public name of itself."""
"DM-25152","Story","obs_base",2,"butler ingest raws does not register translators","""[~spietrowicz] has discovered that butler ingest-raws does not work with LSST data because the metadata translators have not been registered. It seems the tests are passing because other tests import the translators.    I think a generic fix is to preimport all registered instrument classes before running the ingest itself.  This would cause all metadata translators to be imported. All these classes should exist."""
"DM-25171","Story","obs_lsst",1,"Update translator for phosim to use nominal weather defaults","""When ingesting/processing {{phosim}} data, one encounters the following messages:  {code:python}astro_metadata_translator.observationInfo WARN: Ignoring Error calculating property 'temperature' using translator <class 'lsst.obs.lsst.translators.phosim.LsstPhoSimTranslator'>: """"Could not find ['TEMPERA'] in header""""  astro_metadata_translator.observationInfo WARN: Ignoring Error calculating property 'pressure' using translator <class 'lsst.obs.lsst.translators.phosim.LsstPhoSimTranslator'>: """"Could not find ['PRESS'] in header""""  astro_metadata_translator.observationInfo WARN: Ignoring Error calculating property 'boresight_airmass' using translator <class 'lsst.obs.lsst.translators.phosim.LsstPhoSimTranslator'>: """"Could not find ['AIRMASS'] in header""""  LsstCamAssembler WARN: argDict[boresightAirmass] is None; stripping  {code}  If {{phosim}} is never going to give us weather it would be good make the translator use nominal defaults to and not complain about it."""
"DM-25182","Story","efd",1,"Write procedure for adding credentials to segwarides","""Documentation is needed to describe adding credentials to segwarides.  It is essentially just executing {{vault kv patch}} with the correct paths and data, but still needs to be written down concretely."""
"DM-25179","Improvement","ts_auxiliary_telescope|ts_main_telescope",3,"Add circular mock actuators to ts_simactuators","""Add circular versions of PointToPoint and TrackingActuator to to ts_simactautors. By """"circular"""" I mean an a rotation with no limits and the ability to take the shortest path to a given target or go in the positive or negative direction.    It will always report position in the range [0, 360) degrees but accept any angle for the commanded angle.    Note on implementation: the most naive implementation is to increment or decrement the internal angle as required. By my calculations it would take a millions of wraps before we lose 0.1"""" accuracy due to roundoff errors. One could get fancier and check if the absolute value of position is > 720 and reduce all elements of the path if so."""
"DM-25178","Story","daf_butler",3,"Add parameter support to formatter configuration","""In order to implement DM-13353 we need to be able to specify parameters in datastore configs associated with the write formatters.    We must assume that parameters are never required for reading with a formatter since that would break our contract with the user that any change to configuration of a datastore should not break the ability to read a file."""
"DM-25177","Story","daf_butler",1,"pipelines.lsst.io broken by missing safeFileIo in daf_butler","""e.g. https://ci.lsst.codes/job/sqre/job/infra/job/documenteer/883/console:    """
"DM-25207","Story","ts_qa",2,"Update SAL/XML test suite generators to use the Generics field","""The Generics field of ts_xml/sal_interfaces/SALSubsystems.xml, will define which Generic topics the CSC is using.  It will either be """"yes"""" if it uses them all, or a comma-delimited list of specific topics.  This requires adding some infrastructure to the suite generators.    Also, there should be an XML unit test to verify this field is either yes, or contains valid topic values."""
"DM-25204","Story","ts_auxiliary_telescope|ts_main_telescope",2,"Update code for changes to simactautors","""DM-25179 introduces some breaking changes to ts_simactuators. Update other code accordingly."""
"DM-25203","Story","ts_qa",3,"Process various releases and make build harness changes as necessary","""This sprint includes 3+ releases, SAL v4.1.3, SAL v4.1.4 and XML v6.0.  This task covers the time necessary to process the releases and deal with any fallout or issues that result.     Also, the XML 6.0 release will be built against SAL v4.1.1.  The current build harness isn't quite ready to build against an older version, so this task will also cover the work to update the build accordingly."""
"DM-25192","Story","daf_butler",1,"Switch from Travis to GitHub Actions in daf_butler","""We have recently been noticing delays in Travis communiction. We have been given permission to switch daf_butler to GitHub actions as a test bed.    To simplify dev guide documentation later we have been advised to do flake8 in one workflow and mypy in a second."""
"DM-25188","Story","ts_main_telescope",1,"Sends modbus commands from M1M3cli","""Add the ability to M1M3cli app to send Modbus commands to ILC. That will enable execution and debugging of connections with ILCs."""
"DM-25187","Bug","daf_butler",1,"daf_butler registry EllipsisType breaks pipelines.lsst.io doc build","""The pipelines.lsst.io build failed this morning with      This is presumably due to the lack of documentation for this type despite its presence in {{\_\_all\_\_}}."""
"DM-25184","Story","jointcal|obs_subaru",1,"Make obs_subaru config overrides play nice with new jointcal filterMap config","""Monika Adamow  3:37 PM:  When I try to run       with w_2020_22 I get      Lauren MacArthur  3:45 PM  I *think* that’s the gaia flux column, but is HSC still using ps1 for jointcal (astrom)?    Lauren MacArthur  3:57 PM  The filterMap is now getting loaded with the gaia entries:  in /datasets/hsc/repo/rerun/RC/w_2020_22/DM-25176/config/jointcal.py  # Mapping of camera filter name: reference catalog filter name; each reference filter must exist  config.astrometryRefObjLoader.filterMap={'u': 'phot_g_mean', 'g': 'phot_g_mean', 'r': 'phot_g_mean', 'i': 'phot  _g_mean', 'z': 'phot_g_mean', 'y': 'phot_g_mean', 'B': 'g', 'V': 'r', 'R': 'r', 'I': 'i', 'r2': 'r', 'i2': 'i',   'N387': 'g', 'N468': 'g', 'N515': 'g', 'N527': 'g', 'N656': 'r', 'N718': 'i', 'N816': 'i', 'N921': 'z', 'N926'  : 'z', 'N973': 'y', 'N1010': 'y', 'I945': 'z', 'HSC-G': 'g', 'HSC-R': 'r', 'HSC-R2': 'r', 'HSC-I': 'i', 'HSC-I2  ': 'i', 'HSC-Z': 'z', 'HSC-Y': 'y', 'NB0387': 'g', 'NB0468': 'g', 'NB0515': 'g', 'NB0527': 'g', 'NB0656': 'r',   'NB0718': 'i', 'NB0816': 'i', 'NB0921': 'z', 'NB0926': 'z', 'NB0973': 'y', 'NB1010': 'y', 'IB0945': 'z'}  # Name of the ingested reference dataset  config.astrometryRefObjLoader.ref_dataset_name='ps1_pv3_3pi_20170110'  vs. /datasets/hsc/repo/rerun/RC/w_2020_19/DM-24822/config/jointcal.py  # Mapping of camera filter name: reference catalog filter name; each reference filter must exist  config.photometryRefObjLoader.filterMap={'B': 'g', 'V': 'r', 'R': 'r', 'I': 'i', 'r2': 'r', 'i2': 'i', 'N387':   'g', 'N468': 'g', 'N515': 'g', 'N527': 'g', 'N656': 'r', 'N718': 'i', 'N816': 'i', 'N921': 'z', 'N926': 'z', 'N  973': 'y', 'N1010': 'y', 'I945': 'z', 'HSC-G': 'g', 'HSC-R': 'r', 'HSC-R2': 'r', 'HSC-I': 'i', 'HSC-I2': 'i', '  HSC-Z': 'z', 'HSC-Y': 'y', 'NB0387': 'g', 'NB0468': 'g', 'NB0515': 'g', 'NB0527': 'g', 'NB0656': 'r', 'NB0718':   'i', 'NB0816': 'i', 'NB0921': 'z', 'NB0926': 'z', 'NB0973': 'y', 'NB1010': 'y', 'IB0945': 'z'}  # Name of the ingested reference dataset  config.photometryRefObjLoader.ref_dataset_name='ps1_pv3_3pi_20170110'    3:57  Ah, I think it’s appending to this (now added by default) list:  https://github.com/lsst/jointcal/commit/41e890198605efd737f5d0b3035ce6271dad9c1c    Lauren MacArthur  4:02 PM  ^^ @parejkoj: it looks like that default is not safe if astrometryRefObjLoader.ref_dataset_name gets overridden (or perhaps obs_* packages have to be careful about appending vs. setting?    John Parejko  1 hour ago  [~madamow]: I haven’t tested it yet, but I think you can add this at obs_subaru/config/jointcal.py:10:  config.astrometryRefObjLoader.filterMap = {}  (edited)"""
"DM-25222","Bug","ctrl_mpexec|daf_butler",1,"Error with --init-only --skip-existing","""What lead up to this problem is that I am back to trying to make ctrl_bps work with current version of the stack with as minimal effort as possible (i.e., it works then start making bigger changes).  I am testing with a sqlite3 ci_hsc_gen3 repo created with this week's stack (w_2020_22).   With [~jbosch]'s help I had made enough changes (e.g. --output-run --extend-run) that it ran through all of isr, but failed when it tried to run the --init-only quanta for the next step, charImage with the following constraint error message:     Then I remembered the discussion about needing to do something extra with the --init-only calls.  Per the discussion in DM-24797, I added --skip-existing to my pipetask calls with --init-only.   Now it fails on the isr --init-only (i.e., the first quanta executed).    command line:    output:    I have not changed ctrl_bps to do all init's in a single pipetask call, but from the ticket it didn't sound like that was a requirement."""
"DM-25217","Story","ts_eas",2,"Reinstall CentOS and document all steps","""Now that CentOS is running on the RPi4, reinstall it and document all steps. The document can be found at    [https://confluence.lsstcorp.org/display/LTS/Installation+instructions+CentOS+7+on+Raspberry+Pi+4]"""
"DM-25216","Story","ap_association",1,"ap_verify failure: ap_verify.py: error: no config field: diaPipe.doSerializeAlerts","""In Jenkins overnight: https://ci.lsst.codes/blue/organizations/jenkins/scipipe%2Fap_verify/detail/ap_verify/596/pipeline"""
"DM-25208","Story","Alert Production",2,"Fix broken test in lsst/alert_packet master","""{{python -m pytest .}}  does not succeed on the master branch of github.com/lsst/alert_packet, at least for me working locally. We should fix this.    The error I get is this:         """
"DM-25250","Story","ts_dome",2,"Adjust DCS and the mock controller to the new JSON protocols and LLC states and statuses","""In the Dome Software Meeting of 2020-06-04 new JSON-based command and configuration protocols were agreed upon, as well as new LLC states and statuses. This ticket is to make the necessary changes to the Dome CSC and mock controller to adopt those changes.    Protocol details, with mention to the response codes, can be found here    https://confluence.lsstcorp.org/display/LTS/Command+and+Configuration+Protocols"""
"DM-25249","Story","ts_main_telescope",2,"Track the Multiple Targets","""The rotator Simulink model should be able to track multiple targets. The system will fail/ crash if there are targets that have different directions. In addition, sometimes, the simulation will fail even though all targets are in the same direction. This task will dig into the Simulink model to see how is fitting of multiple targets.    The following figure demonstrates the failure. The x-axis is the time in second and the y-axis is the value such as the rotation position in degree. There are two targets with positions of +1.5 and -1.5 degree. The simulation time is 30.1 seconds and the simulation crashes in the middle with zero-crossing error.      !trackErrorForTargetsWithDifferentDirections.png|thumbnail!"""
"DM-25246","Story","daf_butler",2,"Make version of RC2 bootstrap script that can convert reruns as well","""Modify [a copy of] the gen3-hsc-rc2 bootstrap.py script that can convert the outputs of one or more standard RC2 processing runs.    This should just be a matter of updating the configured dataset types and passing Rerun arguments to ConvertRepoTask.run, and then inventing an interface that allows the user to specify which processing runs to convert.  """
"DM-25245","Story","ts_main_telescope",2,"Put the Rotator into Fault State if no Track Command for a Long Time","""If the rotator does not receive the track command for a long time, the rotator should be put into the Fault state. This could be 0.5 second (by Tiago) or 1 second (by Russell). At this moment, we do see this in the Simulink model by the simulation experiment, but we do not know how that is decided. In addition, we did not see this when we did the test on summit. This task needs to figure out what is the existed logic in model and how to update it.    The following is the figure to show the simulation result (detail is at DM-25243):    !track_v0_1_long_enterFault.png|thumbnail!    The system is at the Fault state around time equals 20.2 seconds (no new track command after time=6 seconds)."""
"DM-25243","Story","ts_main_telescope",3,"Fix the Bugs of Trajectory If No Track Command Received In the Tracking","""The path generator will continuously update the demand position even if there is no new track command received in the SlewAndTrack sub-state. The initial suspect is that this comes from the non-zero target velocity in the final received track command. This will continue to update the position command. The initial idea to fix this is to reset the velocity command to be zero if no new track command received.    The following figure (x-axis: time in seconds, y-axis: value such as position in degree) shows this problem. There are two targets (positions = 1.2 degree and 3 degree. velocity = 0.01 deg/sec and -0.01 deg/sec). The track command does not continue after the time equals 6 seconds. We could see the rotator position is at 3 degree when time is at 8 seconds but the demand position is decreasing after time=8 seconds (rotator's position keeps the same) because of the second target has the velocity of -0.01 deg/sec.    !track_v0_1_long_enterFault.png|thumbnail!     """
"DM-25236","Story","daf_butler",1,"Temporarily remove quantum tables from Registry","""Getting the quantum database representation stable and future-proof requires more thought than we want to put into it before gen2 deprecation, so this ticket is a near-term replacement for DM-24613, which we'll pick up again later.  See also https://lsstc.slack.com/archives/C2JPT1KB7/p1591284060371700    Preliminary plan is to remove the quantum and dataset_consumer tables, along with the dataset.quantum_id column.  It'll be easier to add those back in than alter them to match what we do in the future."""
"DM-25232","Improvement","Qserv",0.5,"Minor refactoring in Qserv due to migration to Protobuf version 3 API","""After migrating the Qserv dependencies to Protobuf version 3 the following warnings showed during compilation stage (this is just one example):    There are three sources of the warnings in Qserv modules:  {code:bash}  % fgrep 'ByteSize()' core/modules/*/*  core/modules/proto/FrameBuffer.h:        uint32_t const messageLength = message.ByteSize();  core/modules/replica/ProtocolBuffer.h:        uint32_t const bytes = message.ByteSize();  core/modules/wdb/QueryRunner.cc:        tSize += rawRow->ByteSize();  {code}  Hence, a goal of the development is to migrate to the newer API."""
"DM-25295","Story","ts_eas",3,"Introduce a more intelligent HVAC naming scheme to avoid overly long topic names","""The HVAC SAL topic names are deduced from the Spanish MQTT topic names where special characters have been replaced with Spanish descriptions of those special characters. This leads to overly long topic names like    HVAC_lsstBarraoblPiso01BarraoblTccGuionP1GuionSalaGuionMaquinas    Come up with a naming convention such that those long topic names can be made much shorter and still can uniquely be converted from the SAL topic names to the MQTT topic names and back. Then implement that in both ts_xml and ts_hvac."""
"DM-25292","Story","obs_lsst",0.5,"ComCam Instrument.name and translator instrument name differ","""[~spietrowicz] has discovered that I messed up the comCam instrument name when I normalized them in DM-23980. I ended up with LSSTComCam in the gen3 instrument and LSST-ComCam in the metadata translator.    Standardize on LSSTComCam to match LSSTCam."""
"DM-25288","Story","HeaderService",1,"Update setup.py to include Header Templates","""The naming of the folder with the templates for the HeaderService changed when adding ComCam support, but the {{setup.py}} failed to capture this and therefore the conda packages are now faulty."""
"DM-25286","Story","Middleware",2,"Update OpenSplice builds with latest community edition","""Update the builds of OpenSplice (rpm's and ts_opensplice) to the   latest version from the community edition github repo"""
"DM-25280","Story","alert_packet|ap_association",1,"ap_association broken by changes to alert_packet","""https://ci.lsst.codes/blue/organizations/jenkins/scipipe%2Flsst_distrib/detail/lsst_distrib/1021/pipeline        This will break tonight's nightly build unless we get a quick fix in soon."""
"DM-25263","Story","Qserv",1,"Document non-partitioned table ingest ","""Include description of non-partitioned table support in documentation for the new Qserv ingest system"""
"DM-25327","Story","daf_butler|obs_base",3,"Change gen3 to write Packages in YAML format","""In DM-25325 I updated base.Packages to allow YAML format to be written. Now I need to change daf_butler to write them out in YAML and obs_base to check that butler can read them properly.    I've added YAML representers so that a simple change to the formatters config yaml to use YamlFormatter should do it. We could also use a specialist formatter that knows how to do read/write with writeParameters controlling the file format..."""
"DM-25325","Story","base",1,"Write Packages object as YAML","""We currently write Packages out as Pickle but we would prefer to write them out as YAML."""
"DM-25323","Story","daf_butler|obs_base",1,"Switch PropertySet in gen3 to YAML formatter","""We seem to have defaulted to writing PropertySet/List in pickle format in gen3 even though it's using YAML in gen2. Switch to YAML and add a quick test in obs_base."""
"DM-25313","Story","ts_main_telescope",3,"Generate document on dome coditioning contract","""As a component of the Environment Awareness System EAS ([https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73574873),|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73574873)] it's necessary to develop a dome environment conditioning system, to control the temperature during daytime."""
"DM-25312","Story","ts_main_telescope",5,"Dome software meetings","""Prepare and coordinate weekly meetings on dome control software with EIE contractor."""
"DM-25311","Story","ts_main_telescope",2,"Document the Track Simulation in Rotator Simulink Model","""Document the track simulation in rotator Simulink model. This is a follow-up task of DM-25045 to summarize and analyze the test results."""
"DM-25308","Story","ts_main_telescope",2,"Change Health & Status data to direct FIFO","""Health & Status data are routed in FPGA through the Request queue. The 64bit data are then squeezed into 4 16bit Response FIFO values. This design is suboptimal for two reasons:   * response queue is also used to send Modbus responses from ILCs, the mix effectively prevents multi-threading on CPU (Host) side to query H&S data and responses at the same time   * as H&S data are mixed with responses, it's hard to tell which data on reposne queue are from H&S and which are from ModBus - that is probably reason why vital H&S collection was implemented in FPGA, but not in C/C++ controller (where it most likely never worked)"""
"DM-25307","Story","HeaderService",2,"Create docker images HeaderService for salobj 5.14.0 and v2.2.1","""New docker images are needed for the HS using   HeaderService: 2.2.1  salobj: v5.14.0  idl:v1.2.0  xml:v5.1.0   sal: 4.1.1"""
"DM-25347","Story","daf_butler",1,"Integer out of range when trying to convert RC2 rerun using postgresql","""While running gen3-hsc-rc2/bootstrap.py on recent RC2 rerun (w_2020_22) using PG, it failed with the following.  """
"DM-25346","Story","ts_auxiliary_telescope",1,"Modernize ts_ATDomeTrajectory","""Update the code in ts_ATDomeTrajectory based on lessons learned from ts_MTDomeTrajectory.    The main change is to support more sophisticated algorithms by sending the next target event to the algorithm.    Additional changes wanted:  * Eliminate use of astropy angles; we aren't gaining any benefit and they add clutter.  * Use {{handle_summary_state}} instead of {{report_summary_state}}."""
"DM-25345","Story","base",0.5,"base fails to build standalone","""After YAML support was added to base Packages in DM-25325 we started to get failures in standalone builds of {{base}} the first time scons was typed. It seems that the YAML constructor assumes that {{Packages}} full name is {{base.packages.Packages}} rather than {{lsst.base.packages.Packages}}.  This causes the {{isinstance}} test to fail. Running the tests a second time fixes the problem for reasons we aren't entirely sure about.    The fundamental problem seems to be that we are using namespace packages in {{base}} and do not have a {{\_\_init\_\_.py}}. Adding one fixes the problem."""
"DM-25339","Story","ts_dome",1,"Please clean up the Dome events.","""The existing Dome {{inPosition}} event has several serious problems:  * It has no boolean flag indicating whether or not the specified device is in position. We need to know """"is in position"""" and """"is not in position"""".  * It has a {{deviceId}} attribute, which badly breaks salobj's ability to automatically output new events only when data has changed. The most recent output is likely to be for a different device! Thus we will get far too many of these events, even when nothing has changed.  * The {{devicePosition}} field is not not useful (especially if you implement DM-25333) and is inadequate for the azimuth (without an associated velocity and time).    I suggest:  * A different inPosition event for each device/axis, e.g.:  * azimuthInPosition(inPosition=True/False)  * elevationInPosition(inPosition=True/False)  * etc.    An alternative is to have one or several events with multiple fields, e.g.:  * inPosition(azimuth=True/False, elevation=True/False, ...)  but it only makes sense to combine data that you get in a single status call. Otherwise you imply information that you don't have!    The same basic problem applies to most other events, including {{motionEnabled}} and {{driveFault}}, {{overTemp}}, {{speedLimitReached}}, {{accelerationLimitReached}} (why do those last two even exist?).  * It would be much better to have a separate event for each device  * We need a flag or other simple way to tell """"this condition is present"""" and """"this condition is absent"""".    Other changes to consider:  * Remove the word {{Change}} from all events that have that suffix. """"Change"""" is redundant. The event is being output *because* the state changed.  * Combine {{lockingPinEngaged}} and {{lockingPinDisengaged}} as {{lockingPin}} with a boolean {{engaged}} flag.  * Combine {{brakeEngaged}} and {{brakeDisengaged}} as {{brake}} with a boolean {{engaged}} flag.  * Combine {{motionEnabled}} and {{driveFault}} into {{driveState}}, with an enum field for enabled/not enabled/fault and another field for the fault code (which is null if enabled/disabled).  * Rename {{interlockAlarm}} field {{interlockAlarmCode}} to {{code}} and look for similar redundancies in other topics. There are a lot of fields that seem needlessly verbose (why """"devicePosition"""" instead of """"position"""", etc.)  """
"DM-25333","Story","ts_dome|ts_main_telescope",0,"Please add target events to Dome","""Whenever the Dome CSC is commanded to a new azimuth or elevation, if the command is accepted then it should output a """"target"""" event that gives the details. That way other code, such as the MTDomeTrajectory CSC, can see what's going on.    I suggest these two events (rename as you see fit):      If we cannot get EIE to give us """"move position velocity time"""" then you may have to ditch the """"tai"""" fields. But I am guessing we can either get that, or something close enough that you can fill out the tai field with at least a reasonable guess.    Once you know what the louver commands will be, I suggest the same sort of event for that data -- and similarly for other systems the Dome controls."""
"DM-25357","Story","ts_eas",1,"Create CentOS SD image with SAL for Raspberry Pi 4","""Create CentOS SD image with SAL for Raspberry Pi 4 for future use."""
"DM-25356","Improvement","ts_middleware",0,"Update ts_salobj unit tests to accept a private_identity field","""ts_sal 4.2 will add a {{private_identity}} field to DDS topics, while maintaining and using the {{private_host}} and {{private_origin}} fields.    This breaks a few unit tests in salobj. Update the tests to optionally allow {{private_identity}}."""
"DM-25354","Story","daf_butler",2,"Extend registry schema to support metadata/configuration","""For schema stability we need a place where we can store identifying information for schema itself and various configuration-related info as well. That will server as a sort of metadata for the rest of the schema and data in registry. To be usable from many releases it itself needs to be super-stable but we also should be be able to store all sorts of metadata in it, exact structure of that is not possible predict today. I think the most generic solution for that is a simple key-value store with arbitrary keys and values encoded as strings. All other structures can be mapped to key/value using reasonable rules, though some care is certainly needed to avoid name collision."""
"DM-25353","Story","ts_qa",2,"Update build scripts for the new RPM naming format","""This task covers the work to update the build scripts after the SAL is updated with the new RPM naming format.         The Java/Maven name format was also updated.  The build scripts will also need to be updated."""
"DM-25352","Story","ts_main_telescope",1,"Update the M2 xml Based on the Latest LTS-162","""Update the M2 xml based on the latest LTS-162. This will also add some interfaces needed to support the level-3 integration test (integration test in software/ simulator level to check the communication of components)."""
"DM-25379","Story","ctrl_mpexec",1,"psycopg2.OperationalError: SSL when running ci_hsc_gen3","""While running ci_hsc_gen3 against the PostgreSQL server, I've been seeing the following error message (Usually > 100 times per ci_hsc_gen3 run when it happens):    I've only seen the following once:      This doesn't seem to actually affect the run.  This doesn't happen 100% of the runs.  It only seems to happen when ci_hsc_gen3 runs pipetask (i.e., never butler commands).  Here are counts from a few runs (from grep of stdout/stderr):      Google searches of the error messages makes it sound like a multiprocessing code issue (e.g., https://virtualandy.wordpress.com/2019/09/04/a-fix-for-operationalerror-psycopg2-operationalerror-ssl-error-decryption-failed-or-bad-record-mac/).   I had found result that talked about TCP keepalive so I tried  pool_pre_ping=True in the create_engine call, but that didn't seem to make any difference."""
"DM-25377","Story","base",1,"Update base.Packages serialization to support bytes","""In DM-25325 support was added for YAML serialization but the serialization still requires a file name to be given.    It would be helpful for butler gen3 s3 datastore to support a serialization to from bytes by updating the PackagesFormatter (created in DM-25327)."""
"DM-25376","Improvement","ts_middleware",1,"Please retain the current behavior of private_origin and private_host in ts_sal 4.2","""ts_sal 4.2 pre-release (develop commit 62503396) appears to change how private_origin is set. Please restore the existing behavior (in 4.1) until version 5.0, when we will switch to using private_identity for some of that.    Also for SAL 5.0 we will need some way of differentiating the same user running multiple processes (e.g. multiple Jupyter notebooks or logins) so command acknowledgements can be reliably disambiguated.    The question is whether the distinction between a user on one notebook or another is of interest to the authorization system. My guess is """"no"""" -- all logins are treated the same. In that case the additional information belongs in a separate field -- and I suggest using private_origin the way it is used now, since we already have it. But if the answer is """"yes"""" -- different logins are authorized independently -- then any additional identifying information clearly belongs in the {{private_identity}} field."""
"DM-25411","Bug","daf_butler",1,"Fix broken postgres test due to attribute manager","""My DM-25354 merge have broken unit test for Postgres (and I think for Oracle too):      The issue is with the handling handling of the empty strings, our sqlite backend adds constraint to the schema which disables empty strings, that was done to work around Oracle issue that treats empty strings as NULLS. as a result the code now raises integrity exception when saving empty string to database in sqlite case but there is no similar check for oracle/sqlite so that works OK.    Simplest fix for my case would be either to suppress this check in the test completely or to add a new check in attribute manager that raises exception independently of a backend."""
"DM-25408","Improvement","Qserv",1,"A more efficient implementation of the empty chunks list generator","""This development effort was triggered by https://jira.lsstcorp.org/browse/DM-24307. In the original version of the _empty chunk list_ generator a hard-wired fixed number {{1000000}} is used as an upper limit for chunk numbers to be evaluated by the algorithm. It turns out there is a better (and also - more efficient) way to limit a set of chunks to be evaluated. A complete list of such chunks could be obtained by calling this method:    Also, the new implementation of the generator will reduce the total number of entries to be stored in either form of the list (a file or a database table)."""
"DM-25407","Bug","ap_verify",1,"ap_verify cannot handle curated crosstalk data in Gen 2","""Following the merge of DM-23983, {{ap_verify}} crashes because it only ingests defects, and not other types of curated calibrations (in particular, crosstalk coefficients). Modify {{ap.verify.ingestion.DatasetIngestTask}} to process 0 or more curated calibrations in the format expected by {{IngestCuratedCalibsTask}}.    In addition to updating the (obs_lsst, obs_decam, obs_subaru) package override files for {{DatasetIngestConfig}}, double-check that this field is not overridden in the four existing datasets.    Since this will break all configs for {{DatasetIngestTask}} anyway, also rename {{textDefectPath}} and {{defectIngester}} to {{curatedCalibPaths}} and {{curatedCalibIngester}}, respectively."""
"DM-25403","Story","daf_butler|obs_base",0.5,"Clean up naming of gen3 formatters","""Currently obs_base formatters are all in the top level python/lsst/obs/base directory with long names. As we get more of them it makes sense to move them into a formatters directory as is done in daf_butler.  Similarly in daf_butler we use names like {{lsst.daf.butler.formatters.yamlFormatter.YamlFormatter}} and this has a lot of repetition. Following a discussion on Slack [~ktl] agreed that the formatter in the file name could be removed without resulting in confusion since we always use the full names in configs.    Therefore in this ticket I will:    # Move obs_base formatters to a formatters directory and use the new name scheme.  # Shorten the names of the formatter python files to drop Formatter in daf_butler.    Note this will break existing repositories but the fix is simple and other backwards compatibility breakage this week means that we can make this change without any additional impact."""
"DM-25391","Story","verify",2,"Refactor metric measurement code to reduce duplication","""There is some duplication that I think we can reduce by factoring things out into base classes that can be inherited in multiple place.  I also thing we may find we can push things up into {{MetricTask}}."""
"DM-25416","Story","daf_butler",0.5,"Fix sphinx build for daf_butler","""In DM-25327 I forgot to check the sphinx build in daf_butler before merging. This broke the weekly."""
"DM-25431","Story","base",2,"Add conda env to base.Packages","""Examining the package versions we store in butler repository when running pipelines, it is clear that we are not including the details of our conda environment.  We need to add code that will read the conda env and include all the versions (possibly overwriting version information determined from the current technique). This will have the advantage of giving us details of {{boost}} and related packages that are not visible to python.    One wrinkle is that I do not yet see an obvious way to get this information without having {{base}} run {{conda list -e}}."""
"DM-25429","Story","verify",1,"Implement an example measurement","""Implement a simple example visit level measurement."""
"DM-25420","Story","ts_main_telescope",0,"Update XML for MTDomeTrajectory","""Update the XML for MTDomeTrajectory in ts_xml.    This was implemented, reviewed and merged as part of DM-24058.  However, I wanted a separate ticket for CAP-563 that could be closed before ts_MTDomeTrajectory was merged."""
"DM-25419","Story","ts_dome",2,"Adopt DCS and mock controller to ts_xml changes","""Due to work on MTDomeTrajectory the command, telemetry and event XML files for the Dome have been updated. Adopt the DCS and mock controller to these changes."""
"DM-25437","Story","verify",2,"Convert metrics pipeline repository to use eups","""We currently set up a few environment variables up by hand when running the pipelines.  This is somewhat error prone, so I'd like to convert to using eups to handle that more automatically.  This could also include adding proper Python modules."""
"DM-25473","Improvement","ts_middleware",1,"Please echo private_identity from commands as identity in ackcmd messages.","""I am implementing the authList support in salobj and realized that ackcmd replies from SALPY_Test do not have the {{identity}} field correctly set to the {{private_identity}} field from the command being acknowledged.    If practical it would be a help to have this fixed in SAL 4.2, because it will allow ts_salobj 6 to fully handle authorization and operate with SAL 4.2 (as well as SAL 5). It is likely to also benefit running a combination of SAL 5 and SAL 4.2 (which I strongly suspect will work), though without authorization in the SAL 4.2 CSCs.    All that said, a simple workaround will allow ts_salobj 6 to work without this, so it's not critical. DM-25474."""
"DM-25471","Improvement","ts_middleware",1,"Please move salgenerator and other crucial bin scripts to the bin/ directory","""If you are willing, please consider moving {{salgenerator}} and any other important executable scripts from {{lsstsal/scripts}} to {{bin/}}.    Also please make sure {{lsstsal/bin}} is *not* added to $PATH. I find it on my $PATH when I run [~tribeiro]'s dev Docker image and there is no such directory.    I think this would be an improvement because:  * """"bin/"""" is where all other T&S and DM packages put executable scripts.  * {{lsstsal/scripts}} has 170 or so scripts, most of which are executable. It seems unfortunate to have all of those on the $PATH unless we really need them to be there.    Note that the current eups table file adds {{bin/}} to the PATH but not {{lsstsal/scripts}}. If you prefer to leave {{lsstsal/scripts}} on the PATH then I would like to change that so both are added to PATH."""
"DM-25468","Improvement","daf_butler",2,"Add protection for repeated schema initialization","""In our code we support repeated schema initialization (in PPDatabase.declareStaticTables}} method) but it is not very safe and can potentially cause loss of data if it happens on a populated database. We want a reasonable protection to avoid disaster, schema should only be initialized once and all later attempts should raise an exception.  """
"DM-25465","Story","ts_eas",1,"Thoroughly inspect ESS code and form API proposal","""In order to be able to use the ESS CSC as a generic CSC for all kinds of sensors, the existing ESS code needs to be inspected so an API can be extracted. This issue is for doing the inspection and for forming an API proposal."""
"DM-25456","Improvement","ts_middleware",0,"Add authList support to Script","""The Script component needs authorization list support: the generic setAuthList command and authList event.    I will implement this as part of DM-25126 but merge it sooner."""
"DM-25503","Story","DM Subsystem Science|validate_drp|Validation|Verification",1,"Port metric AD2 to metric task framework","""Metric AD1 implemented in the validate_drp framework should be ported to the new framework.    """
"DM-25492","Story","ts_eas",2,"Integrate ESS code in ESS CSC","""Take the ESS code that reads the sensors and integrate it into the ESS CSC code."""
"DM-25491","Story","ts_eas",2,"Command all sky camera using GPhoto","""Use the Python bindings for libgphoto2 and the GenericCamera CSC to command the all sky camera."""
"DM-25482","Bug","Qserv",3,"Investigate and fix a possible bug in the chunk allocator","""The current implementation of the Ingest system may have a bug in the single chunk allocator. The problem was reported at:  https://jira.lsstcorp.org/browse/DM-24587?focusedCommentId=248700&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-248700    Extend the error reporting of the allocator to return a collection of replicas which may be causing this problem. Fix a bug if any exists."""
"DM-25481","Story","Qserv",1,"Repair busted Qserv container builds","""Use of Qserv dependency tarballs in Qserv container builds results in broken paths being baked into the containers (we end up with tarball build-time paths instead of Qserv container build-time paths for components such as mariadb).    Short-term fix is to disable use of tarballs in the Qserv container builds (these builds are already scheduled for demolition, and finding and implementing all the necessary path fixups is deemed not worth the effort at this time.)"""
"DM-25480","Story","HeaderService",1,"Remove SEQNAME from PRIMARY common template for ComCam","""The {{SEQNAME}} is defined in both the:  * primary_hdu.header  * primary_sensor_hdu.header    However it should only be present on the {{primary_sensor_hdu.header}}    Also add FILTER=r to the ComCam template."""
"DM-25476","Story","ImgServ",2,"Remove misleading dax_imgserv ups directory","""I believe the {{ups}} directory in {{dax_imgserv}} is actually unused, as the package is installed using {{pip}} and {{setup.py}} rather than {{eups}}.  The real dependencies appear to be in {{requirements.txt}} and the {{Dockerfile}}.    The presence of this misleading information is confusing automatic dependency tooling for the product tree.  Accordingly, it would help if it were removed.  Other unused files (like {{SConstruct}}?) could be removed at the same time."""
"DM-25515","Story","ip_isr|pipe_tasks",1,"Fix references to https://lsst-web.ncsa.illinois.edu/~buildbot/doxygen","""The doxygen output has not lived at this location for a long time.  The proper URL should be {{https://doxygen.lsst.codes/doxygen/}}"""
"DM-25514","Improvement","Qserv",8,"REST API for building the secondary index in Qserv","""In the current implementation of the new Ingest system the _secondary index_ of a database is normally populated in the end of the _super-transactions_. The algorithm harvests contributions from the corresponding MySQL _partitions_ of the director table's chunks and loads them into the index table at Qserv """"czar""""'s database . Depending on the amount of data ingested into that table during a transaction the index building operation may noticeably slow down the commit phase of the transaction. After gaining the first experience with using the new Ingest system it has become apparent that some workflows may benefit from having the _secondary index_ construction as an explicit stage deferred till a moment when all director table's contributions were loaded into Qserv.    Hence, a goal of the current development is to refine and extend the REST API of the Master Replication Controller to allow more options in building the index. Specifically, the following changes are proposed:  * add an optional parameter *build_secondary_index=<val>* to existing database creation service to indicate an intent to defer the index creation till the very last stage. The default value of the parameter will be 0 which would preserve the current behavior.  * extend the database information structure DatabaseInfo with the corresponding flag.  * modify the transaction commit service not to make contributions into the index if the deferred index construction for the database was requested.  * add a new POST service for constructing indexes as a separate operation to be performed before (or with extra controls) after publishing a database. The service should also allow an optional parameter to allow rebuilding the index from scratch.  * update the documentation on the Ingest System accordingly.  * evaluate if the version of the Ingest API needs to be incremented as well."""
"DM-25516","Story","obs_base",1,"numpydoc warnings in obs_base test utilities","""The following problems are causing warnings in doc builds.  (There are more in the geom and afw test utilities, but those appear to still be in doxygen form.)   * [https://github.com/lsst/obs_base/blob/master/python/lsst/obs/base/butler_tests.py#L82] needs quoting around the code (or {{**}} is misinterpreted)   * [https://github.com/lsst/obs_base/blob/master/python/lsst/obs/base/camera_tests.py#L52-L57] indented an extra space   * [https://github.com/lsst/obs_base/blob/master/python/lsst/obs/base/tests.py#L80] indented an extra space"""
"DM-25636","Story","ts_middleware",2,"Write a simple authentication controller","""Write a simple authentication controller that accepts and processes requests for authentication.    This will be the foundation on which the LOVE interface for authentication will be built, so it will use the LOVE component name. The long-term plan is for LOVE to show each such request to the operators, who will accept or reject the request. In the meantime (having no telescope operators and no GUI for authentication) the simple authentication controller will simply accept each request.    For now I will put the code into a new package ts_authenticate. We may well move it when INRIA starts implementing the operator interface for approving authentication requests."""
"DM-25635","Story","ts_main_telescope",3,"Generate document on dome coditioning contract","""As a component of the Environment Awareness System EAS ([https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73574873),|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73574873)] it's necessary to develop a dome environment conditioning system, to control the temperature during daytime."""
"DM-25634","Story","ts_main_telescope",5,"Dome software meetings","""Prepare and coordinate weekly meetings on dome control software with EIE contractor."""
"DM-25633","Improvement","ts_auxiliary_telescope|ts_main_telescope",0,"Fix warnings in test_queue_model","""Two tests in test_queue_model are giving warnings because they don't wait until some scripts have finished."""
"DM-25627","Story","ctrl_mpexec",8,"make qgraph and run subcommands for pipetask","""Implement {{qgraph}} and {{run}} using click (in the {{pipetask2}} command, which will eventually replace {{pipetask)}}    Add the """"chained"""" subcommands feature, write a Community post about it describing the differences from the existing {{pipetask}} command, request feedback."""
"DM-25621","Story","ts_deployment",2,"Jenkins maintenance - install plugins, apply updates and bug fixes","""Please, add {{docker-compose}} to the Jenkins nodes so we can experiment using it to manage the build of deployment containers. """
"DM-25526","Bug","ts_management",1,"Fix array handling in ADLink's community edition of OpenSplice","""Examine the differences between our OpenSplice code and ADLink's community edition and try to determine what fixes the array handling. Then submit a pull request."""
"DM-25519","Improvement","ts_main_telescope",1,"clang-format M1M3 support code","""M1M3 C++ code is written in Eclipse, using Eclipse tab-based formatting. That contradicts to DM recommended clang-format. I am reformatting single files if I do significant changes, but time has come to reformat the whole.    Lets couple that with Github action to check for clang-format."""
"DM-25518","Improvement","ts_auxiliary_telescope|ts_main_telescope",1,"Update my packages for ts_xml 6, SAL 4.2, and salobj 6","""Update my packages for SAL 4.2 (the new private_identity field), ts_xml 6 (the new setAuthList command) and salobj 6 (stop using deprecated code -- primarily {{BaseCsc.main}}).    Packages that need work include:  * ts_ATMCSSimulator: bin script calls BaseCsc.main  * ts_hexrotcomm: setAuthList needs to be added to good commands for checking state transitions  * ts_salfafka: schema tests do not expect private_identity and should be modified to allow private_host to be missing  * ts_watcher: bin script calls BaseCsc.main    Also investigate warnings in ts_scriptqueue unit tests.  """
"DM-25640","Story","ctrl_mpexec|pipelines_lsst_io",1,"Add documentation for ctrl_mpexec to pipelines.lsst.io","""ctrl_mpexec has a perfectly serviceable {{doc/}} directory, which builds without errors or warnings. It doesn't provide much useful information beyond automatically generated API docs yet, but it at least provides something convenient to link to. We should include it on pipelines.lsst.io."""
"DM-25638","Story","ts_main_telescope",0,"Update MTMount simulator to use motion parameters from specification","""Michael just noticed that the MTMount simulator is using values for Elevation and Azimuth motion that are not the same as the specification. We agreed that the best would be to use the same parameters we use for survey simulations, which are actually based on the minimum requirements.         For the camera cable wrap the (minimum) requirements are:         Note that there's a +/- 4 degrees of hard-limit on the CCW, probably not on the simulator though.     """
"DM-25658","Story","ts_main_telescope",3,"Fix the Following Error in the Rotator Simulink Model","""Fix the following error in the rotator Simulink model. There is the problem of physical model in plant that the rotator's position will differ from the related position command gradually until the trigger of *followingError* (the difference >= threshold) and this stops the motion of rotator. According to the observation, this happens if the rotator moves in the negative direction.    In the following figure, there are two targets: (1) position=1.2 deg and velocity=0.01 deg/sec and (2) position=1.5 deg and velocity=-0.01 deg/sec. The total simulation time is 20.1 sec. There is no big difference between the position command and position. The error of *noNewTrackCmdError* after the slew of the second target is triggered as expected.   !trackAdapNoNewTrackCmd.png|thumbnail!    However, if the second target has position=-1.5 deg and velocity=-0.01 deg/sec, the following error is triggered while the rotator turns the direction to slew to the second target:   !trackSolverAdap.png|thumbnail!"""
"DM-25654","Story","nublado",5,"Audit notebook aspect requirements","""Have a look through the requirements on the notebook aspect of the science platform presented in the [DMSR|https://docushare.lsst.org/docushare/dsweb/Get/LSE-61] and the [LSP requirements|https://docushare.lsst.org/docushare/dsweb/Get/LDM-554].  The intent is to perform an audit to check for self consistence and completeness.    A special effort should be made to identify missing or incomplete requirements in order to improve our ability to verify the system."""
"DM-25685","Bug","ts_middleware",1,"Investigate the memory leak in lsstts/deploy-env:salobj_5.15.0","""[~mareuter] reports that the SAL/kafka producers are leaking memory. Investigate the problem. Determine if it's DM-23255, which we have a fix for, or something else. See that ticket for simple dds scripts to measure memory leakage. For this ticket I will use https://jira.lsstcorp.org/secure/attachment/42424/memory_test_asyncio.zip"""
"DM-25675","Story","HeaderService",1,"Implement OBSANNOT keyword in HeaderService","""Add OBSANNOT keyword needs to be implemented in the headers.    {{CCCamera_logevent_imageReadoutParameters.daqAnnotation}}    {{ATCamera_logevent_imageReadoutParameters.daqAnnotation}}      This applies to all camera flavors."""
"DM-25707","Story","ts_middleware",0,"ts_salkafka seems to be ignoring ackcmd topic messages","""The salkafka producers seem to not be sending out ackcmd Kafka messages when the SAL topic messages are received."""
"DM-25705","Story","obs_subaru",1,"Add tests for stray light in gen3","""In DM-25689 we found some problems with stray light files.  We need to add a test to obs_subaru to ingest an example file and then be able to retrieve it."""
"DM-25698","Bug","obs_decam",1,"Fix missing obs_decam dependencies","""The obs_decam tests do not depend on the decam/crosstalk and decam/defects being built, and almost certainly should"""
"DM-25692","Story","obs_base",1,"Write gen3 formatter for Exposure Filter","""In DM-25447 I discovered that a read-only Filter component for Exposure can't work because the information is derived from metadata that is stripped and a Filter can not be persisted since Filter.writeFits is broken.    I propose that we write a very simple formatter that bypasses the FITS persistence system and simply writes a yaml file that includes the filter information. On read it will translate the filter name to a Filter object by looking it up in the filters singleton. This can then be set in the exposure using {{setFilter}}.    This will turn filter into a normal component and should be quick to implement."""
"DM-25689","Story","obs_subaru",1,"Problems converting RC2 with w_2020_25",""""""
"DM-25719","Improvement","ts_middleware",0,"Cherry-pick the change to salobj 5 needed by salkakfa for DM-25707","""Cherry-pick the salobj 6 change that allows disabling filtering when reading ackcmd topics to salobj 5, so we can release a new ts_salkafka DM-25707.    Also update the requirements in ts_salkafka accordingly."""
"DM-25713","Story","HeaderService",2,"Update docker images and  conda for Headerservice 2.3.1","""HS need to be deployed at the base using version 2.3.0  """
"DM-25712","Improvement","ts_auxiliary_telescope|ts_main_telescope",1,"Write stop scripts for the main and aux telescope","""Write simple scripts to stop the aux tel and main telescope. These will call the stop_all functions in ts_observatory_control."""
"DM-25710","Story","dm_dev_guide",1,"Update dev guide to clarify rule on .py extensions for scripts","""See RFC-698."""
"DM-25756","Story","Firefly|SUIT",1,"Refresh lsst-demo certificate - June 2020","""Refresh the certificate for the HTTPS service on the {{lsst-demo.ncsa.illinois.edu/firefly}} server."""
"DM-25755","Story","SUIT",2,"Define minimal set of image-query features to replace legacy PDAC Portal","""Document in one place the specific minimal set of work that would be required to fully replace the PDAC Portal's image-search features with an IVOA-services-oriented equivalent.  This was in-progress work at the time of the DM-10 freeze, and is the minimal piece of new development that would facilitate the use of the Portal during DP0 and commissioning activities.    This amounts to writing a specification for DM-18692, and involves collecting various sketches together for concreteness."""
"DM-25754","Bug","pipe_base",0.5,"UnboundLocalError: local variable 'n' referenced before assignment","""Came across this with some pipetask run commands, and it looks like a bug at https://github.com/lsst/pipe_base/blob/master/python/lsst/pipe/base/graphBuilder.py#L556    """
"DM-25750","Story","daf_butler",0.5,"gen3 queryCollections does not work with regexes","""[~krzys] noted that {{registry.queryCollections}} does not work with regexes despite being documented to do so.    This patch helps a little:  {code:diff}  diff --git a/python/lsst/daf/butler/registry/wildcards.py b/python/lsst/daf/butler/registry/wildcards.py  index c416105f..52efe8f2 100644  --- a/python/lsst/daf/butler/registry/wildcards.py  +++ b/python/lsst/daf/butler/registry/wildcards.py  @@ -739,7 +739,7 @@ class CollectionQuery:           if wildcard is Ellipsis:               return cls.any           assert not wildcard.strings  -        return cls(search=CollectionSearch.fromExpression(wildcard),  +        return cls(search=CollectionSearch.fromExpression(wildcard.items),                      patterns=tuple(wildcard.patterns))          def iterPairs(  {code}    We did not notice this previously because there are no tests using regexes."""
"DM-25746","Bug","ap_association",1,"filterName in APDB needs to be one of g, r, i, z, or y","""Before DM-21333 (filter overhaul) happens, we need an interim quick fix for making it possible to run ap_pipe on HSC data in the R2 and I2 filters. Presently, `getCanonicalFilter` retrieves `afw_name` if available and `abstract_filter` otherwise (e.g., https://github.com/lsst/obs_subaru/blob/master/python/lsst/obs/hsc/hscFilters.py#L81). The problem is that `afw_name` only exists for R2 and I2 (as `r2` and `i2`), but the APDB schema uses the filter name to construct a myriad of columns that assume all filters are correctly represented as one of g, r, i, z, or y. Presumably `getCanonicalFilter` is used in other places where `afw_name` is the desired thing to return, and I shouldn't mess with it at this time."""
"DM-25745","Improvement","ts_main_telescope",0,"Update the Simulator entry for MTMount in SALSubsystems","""Update the Simulator entry in SALSubsystems.xml for MTMount with one or more links to the vendor's simulator code."""
"DM-25744","Story","meas_extensions_scarlet",3,"Test scarlet on a single full patch of HSC data","""Previous versions of scarlet have suffered from memory issues that prevented them from running on a full HSC patch, causing us to create small 1k x 1k patches to test the stack implementation of scarlet. This ticket is just to run scarlet on a full HSC patch to verify that all of those issues have been taken care of or generate new tickets to fix any issues that come up."""
"DM-25743","Story","ts_main_telescope",2,"Document the Algorithm of Interpolation for Rotator","""Document the algorithm of interpolation for rotator. At this moment, the rotator Simulink model uses the extrapolation for *track* command. This task tries to define the question clearly and provides the analytical solution of interpolation. The update of Simulink model will be a separate ticket."""
"DM-25742","Improvement","Qserv",2,"Add a REST service to report chunk-to-worker allocation maps during catalog ingest","""Some large scale catalog ingest workflows may benefit from seeing  a status of the {{chunk->worker}} allocation map. Specifically, this could be used for the monitoring purposes. Hence, a goal of the proposed development is to add the following service to the REST service of the *Master Replication Controller*:  || method || service || request query || result ||  | GET | /ingest/chunks |?database=<name> | JSON |    Where:  * the name of a database is passed in the query string of a request  * the service returns a JSON object (see details in the documentation linked below)    Notes:  * the service should *not* be used as a reliable source of information to decide on the chunk allocation/placements during catalog ingest. Use the corresponding *POST* method instead.  * the service can be used for databases in any state (_published_ or not).    Other action items:  * update the documentation on the *Ingest System* at: https://confluence.lsstcorp.org/pages/viewpage.action?pageId=133333850"""
"DM-25739","Improvement","ts_auxiliary_telescope|ts_main_telescope",0,"Update SALSubsystems for SAL components rowen has some responsibility for","""Update SALSubsystems for the following SAL components:  * ATDome  * ATDomeTrajectory  * ATMCS  * ATPneumatics  * FiberSpectrograph  * Hexapod  * LOVE  * MTDomeTrajectory  * MTMount  * NewMTMount  * Rotator  * Script  * ScriptQueue  * Test  * Watcher"""
"DM-25738","Story","ts_aos|ts_main_telescope",1,"Update MTAOS to Adapt the Latest xml Version","""Update *MTAOS* to adapt the latest xml version, especially for the *M2* xml update (DM-25475) and *Hexapod* xml update (DM-25856). Maybe need to check there is the update of *M1M3* or not. This task will update the CSC test as well for the [timeout issue|https://github.com/lsst-ts/ts_MTAOS/issues/27] and use the *Controller* by *ts_salobj* to help for the test (receive the subsystem correction). For the use of *Controller*, the CSC test in *ts_m2* is a good example. After this task is done, need to prepare a new docker image of *MTAOS* simulator to deploy in NCSA for the integration test."""
"DM-25767","Story","pipe_base",1,"Add checking for duplicate keys in pipeline definitions","""If a pipeline definition document has the same label for two or more tasks, the last one will clobber the rest silently.  Tasks should not have the same label, but if they mistakenly do, it can lead to confusing behavior.  It would be nice if the quantum graph builder would throw an exception in the case of duplicate labels in the same pipeline definition document.    I believe it already does throw an exception for duplicate keys in separate pipeline definition documents inherited in a single one."""
"DM-25764","Story","ts_eas",1,"Review ESS XML and add timestamps if necessary","""Review the ESS telemetry topics and add a timestamp if there isn't already one."""
"DM-25762","Story","ts_dome",2,"Move Dome CSC documentation on Confluence to .rst files","""There is a lot of documentation related to the Dome CSC and the communication with the Lower Level Components on Confluence. This ticket is to migrate the relevant documents to .rst files."""
"DM-25761","Story","ts_middleware",1,"Compare performance of ts_opensplice with the community edition","""Compare Python performance of ADLink's official community edition of OpenSplice (with my array fix and segfault fix) against what we are using. If the performance is similar and all tests pass, I hope we will consider using it -- though it still has to be checked with the other languages."""
"DM-25758","Story","ts_dome",1,"Adjust DCS and the mock controller to a change in the configuration protocol","""A small change has been introduced in the configuration protocol: all values need to be arrays."""
"DM-25790","Story","ts_main_telescope",3,"Support the Configuration File in Rotator Low-Level Controller Code","""Support the use of configuration file in rotator low-level controller. MOOG provided the middleware wrapper orginally that allows the user to update the configuration file by SAL. T&S team replaced it and used the Python CSC based on *ts_salobj* instead. This new CSC does not allow to do so. Therefore, this task will update the low-level controller code to let the user can configure the rotator by the configuration file."""
"DM-25788","Bug","ts_middleware",0,"BaseCscTestCase.check_bin_script does not set LSST_DDS_DOMAIN","""BaseCscTestCase.check_bin_script should set the LSST_DDS_DOMAIN environment variable to a random value, just like make_csc does.    Thanks to [~tribeiro] for reporting this."""
"DM-25786","Bug","daf_butler|sphgeom",2,"Cannot import sphgeom objects in Gen 3","""I've run into an issue when trying to import the Gen 3 portions of {{ap_verify_ci_hits2015}} and {{ap_verify_ci_cosmos_pdr2}}. Both datasets' export files were created using the call      This creates patch/tract nodes in the {{export.yaml}} that look like:      When I try to import the {{export.yaml}}, I get the following stack trace:      [~tjenness] recommends adding serialization support to {{sphgeom}} that makes these types compatible with {{yaml.safe_load}}. This is related to DM-25448, but distinct in that there's no {{LookupError}} with the registry."""
"DM-25784","Story","ts_auxiliary_telescope",1,"Update documentation for ts_ATDome to match our new template","""Try out the new documentation format on a small package: ts_ATDome."""
"DM-25779","Story","jointcal|log",2,"Investigate jointcal chi2 changes in a large HSC run","""Before trying to implement DM-25159, I need to check that jointcal does not have cases where the chi2 gets dramatically worse in one step but then recovers. It should be relatively simple to write a script that scans a log and generates a plot of the chi2 for that jointcal run.    I'll need access to the logs from jointcal runs on a big HSC run (RC2? Whatever the biggest one is)."""
"DM-25777","Story","ts_auxiliary_telescope",0,"Add ts_simactuators to ts_ATDomeTrajectory dependencies","""List ts_simactuators as a dependency of ts_ATDomeTrajectory"""
"DM-25774","Improvement","ts_main_telescope",3,"M1M3SSPublisher as singleton","""Instead of passing M1M3SSPublisher (OpenSplice class, created once) pointer to zillion of classes, it will be much easier to have M1M3SSPublisher as singleton _(see similar refactoring we finished for FPGA)_.         Various other classes might be singletonized as well, with SafetyController one of the prominent example."""
"DM-25792","Story","verify",1,"Forward units on to JSON serialization of verify.Job even when NaN","""For some reason, when a {{Measurement}} is NaN (specifically {{numpy.nan}} the units are set to the empty string in the serialized JSON document of the {{Job}} to which the {{Measurement}} belongs.  {{astropy.Quantity}} allows a NaN to have a unit, so it does not appear to be dropped at that stage.    This is to figure out which phase is dropping the unit: adding the measurement to the {{Job}} or serialization to JSON.  Then find a way to make sure the unit is forwarded on.  This may require a special JSON serializer for {{Measurement}} objects or {{astropy.Quantity}} objects."""
"DM-25795","Story","ts_main_telescope",3,"Fix the Bugs of Transition of Tracking","""Fix the transition of tracking in deciding the tracking trajectory. In the previous update (DM-25243), I made two mistakes. One is that I do not generate a smooth velocity command in the tracking (I forgot the 4000 Hz internal calculation). The other one is that I do not stop the rotator's velocity smoothly if there is no new tracking command for some time. This ticket is to fix these two bugs."""
"DM-25813","Story","ts_main_telescope",5,"Dome software meetings","""Prepare and coordinate weekly meetings on dome control software with EIE contractor."""
"DM-25812","Story","ts_main_telescope",1,"Enable camera cable wrap tracking rotator by default","""The MTMount CSC should start up with the camera cable wrap tracking the camera rotator."""
"DM-25806","Improvement","ap_verify",2,"Support parallel ap_verify ingestion in Gen 3","""The Gen 3 {{lsst.obs.base.RawIngestTask}} can be passed the number of processes to use for ingesting in parallel. This could potentially greatly speed up the processing of large datasets like HiTS2015. Propagate the existing {{ap_verify.py -j}} flag to Gen 3 ingestion."""
"DM-25825","Story","ts_middleware",0,"Add a function to ts_salobj that returns the OpenSplice version","""Add a function to ts_salobj that returns the OpenSplice version"""
"DM-25867","Story","sphgeom",2,"Make sphgeom pip installable","""It would be helpful for Google POC developers if they could do daf_butler development using pypi dependencies. For this to work sphgeom needs to be buildable using pip."""
"DM-25863","Story","pipe_analysis",2,"Fix and update metric generation in colorAnalysis.py","""As of DM-22255, it appears the metrics defined in {{colorAnalysis.py}} are no longer being added to the verify {{job}}, so the persisted {{json}} file does not included any actual measurements (e.g. they do exist in {{datasets/hsc/repo/rerun/RC/w_2020_19/DM-24822/verify/color/tract-9813/colorAnalysis_verify_job.json}}, but are not present in {{datasets/hsc/repo/rerun/RC/w_2020_22/DM-25176/verify/color/tract-9813/colorAnalysis_verify_job.json}}).  This needs to be fixed.    Additionally, to allow tracking the metrics per-tract when dispatched to the [SQuaSH metrics dashboard|https://sqr-009.lsst.io], a tract tag needs to be added to the metric metadata."""
"DM-25858","Story","HeaderService",1,"Update the file SALSubsystems for HeaderService components","""Update the file SALSubsystems.xml for HeaderService components for AT/CC and MT following the definitions from:  [https://ts-xml.lsst.io/salsubsystems_attributes.html]"""
"DM-25856","Improvement","ts_main_telescope",3,"Add compensation support to the MT Hexapod CSC","""Add LUT correction to the Hexapod CSC."""
"DM-25855","Bug","obs_decam",1,"Fix missing obs_decam dependencies, pt 2","""""""Looks like https://github.com/lsst/obs_decam/blob/master/decam/SConscript#L71 needs to also depend on makeCrosstalk or decam/crosstalk"""""""
"DM-25885","Bug","daf_butler",2,"Export/Import of some datasets prints time warnings","""Exporting, then importing certain dataset types with timestamps results in the warning:    While the warning is harmless, some repositories produce dozens of copies, which is distracting.    Dataset types known to trigger this problem:  * DECam {{defects}}  * DECam {{crosstalk}}  * HSC {{unbounded}}    Discussion on [#dm-middleware|https://lsstc.slack.com/archives/C2JPT1KB7/p1594327976459000] concluded that the problem is likely limited numerical precision in the process of converting TAI to UTC, exporting it, importing it, and converting back to TAI.    While we could work around the warnings by not labeling datasets with such an (arbitrarily) early date, [~salnikov] believes the conversion must be made more precise to support general storage of epochs."""
"DM-25881","Story","daf_butler",0.5,"Add extra logging to S3 datastore","""During some test processing on Google we are running into an odd situation where a file exists in S3 that should not exist and an attempt is made to overwrite it. To help debug this add more debug logging messages into s3datastore."""
"DM-25880","Story","ts_aos|ts_main_telescope",2,"Write the User Document of MTAOS","""Write the user document of MTAOS. The target reader is the operator or scientist. The [ts_athexapod|https://github.com/lsst-ts/ts_athexapod] can be used as an example."""
"DM-25871","Story","ts_dome",0,"Replace list-table with csv-table","""The tables in the Dome CSC documentation are marked up with list-table directives but it is clearer with csv-tables. This ticket is to replace all list-table markup with csv-table."""
"DM-25868","Bug","Qserv",1,"Fix a bug in a script starting XRootD services at Qserv deployments","""There is a bug In the current implementation of the startup script:    The script would incorrectly redirect the log streams of both {{xrootd}} and {{cmsd}} services into the same file:    As a result of this all logging information of the {{cmsd}} service would be completely lost.    The problem affects any multi-node installation of Qserv in both the bare OS or Docker-based installations, including the """"integration test"""". It also affects both the master and worker components of Qserv.    A goal of this development is to ensure the output of each service goes into a separate log file based whose name is based on the name of the corresponding service ( {{xrootd}} and {{cmsd}}). After that there should be 2 separate log files in the corresponding deployments:  """
"DM-25903","Story","cp_pipe",1,"CALIB_ID written by findDefects.py is wrong","""Sort out ambiguity between the """"slot name"""" which is the butler-queired detectorName, _i.e._ just S12, and the fully qualified name reported by {{detector.getName()}}."""
"DM-25902","Bug","ts_environment",0,"Environment CSC defines 'string' attributes with units, should be unitless","""In Environment_Telemetry.xml, the *Environment_windSpeed* and *Environment_airPressure* topics each have a *sensorName* string attribute, but the Units are incorrectly defined.  One is Pa and the other is degree.  They should both be unitless."""
"DM-25899","Improvement","ts_middleware",1,"Move the body of the command-line scripts in doc/ to library modules.","""There are two command-line scripts in the doc/ directory that contain a lot of implementation. Move the implementation to library modules. Also consider adding unit tests.    Also add an auto black formatter and a unit test for black formatted code."""
"DM-25895","Story","ts_documentation",0,"Updates to the developer guide","""Small portions of the developer guide are out of date - updating the guide to match current reality. """
"DM-25892","Story","ts_eas",1,"Modernize GenericCamera code and unit tests","""The unit tests of GenericCamera still make use of the old Harness infrastructure. This is not needed anymore. This ticket aims to replace that with a more modern CSC test approach."""
"DM-25936","Story","meas_extensions_scarlet",1,"Fix pickle bug","""There is currently a bug that prevents some models from saving correctly due to an integer that is wrapped by autograd. This ticket is to fix that bug."""
"DM-25934","Bug","cp_pipe",2,"MeasurePhotonTransferCurveTask appears to ignore the defect mask","""I was testing MeasurePhotonTransferCurveTask with isr.doDefect=True.  The code reads in and applies the defects and correctly applies edge mask pixels when isr.numEdgeSuspect=N.  However, when calculating the mean/variance pairs, it appears that the defect mask is ignored.  I think the andMask need to be set in afwMath.StatisticsControl to correct this."""
"DM-25923","Story","obs_base|obs_lsst",0.5,"Add cache to yamlCamera.makeCamera","""Instantiating a yaml camera takes a long time (10 seconds for imsim on my Mac). This can cause significant slow downs if there are repeat calls to yamlCamera.makeCamera with the same yaml file.  This is particularly noticeable in tests.  Since the camera returned by makeCamera should be immutable, it makes sense to add an lru_cache decorator around that call.   This should also allow the local caching to be removed from obs_lsst."""
"DM-25922","Bug","base",0.5,"Ensure getVersionFromPythonModule() returns a string","""I encountered the below error while building a fresh stack. This is likely due to one of my {{pip}}-installed packages pulling in {{fancycompleter}}, which has a different kind of {{version}} than we are expecting. [~tjenness] suggested forcing a cast to {{str}}, which got {{base}} to build.    """
"DM-25921","Story","cp_pipe|ip_isr",2,"Liaise with camera team about CTI correction","""[~snyder18] has written lots of great CTI correction code, and there was talk with [~roodman] in March about getting some of this DM-ified.    Ticket is to get this conversation restarted, and put somewhere more appropriate than in private messages."""
"DM-25920","Story","ts_main_telescope",3,"Support dome coditioning contract","""Support activities to develop a dome environment conditioning contract, to control the temperature during daytime. The activities include reviewing proposals, provide technical information to potential contractors, meetings with Rubin Observatory reviewers and contractors."""
"DM-25912","Improvement","ts_middleware",0,"Stop automatically sending InProgress ack for commands","""Stop automatically sending an InProgress ack when starting a background do_xxx callback. Instead allow the user to send the ack for slow commands, and include an estimate of duration.    Get this into v6.0.0 since it is a slightly backward incompatible change."""
"DM-25957","Story","daf_butler",0.5,"Remove unnecessary numpy usage from daf_butler","""There are two places in daf_butler where we use numpy without needing to. Both of them involve random numbers that can be replaced with calls to {{Random}} instead. There is one usage in a test which is protected and then one other test that requires a numpy integer.    Remove the unnecessary usage and protect the remaining one.    numpy is going to be pulled in by sphgeom but that's not reason to use numpy in butler when it doesn't give us anything."""
"DM-25955","Story","DM Subsystem Science",2,"Prep for presentation to Strong Lensing SCs","""Presentation will involve a few overview slides and a lot of Q&A.     """
"DM-25954","Story","cp_pipe|ip_isr",3,"Follow-up on Robert's comment on ""Sensor Characterization and ISR"" page following DM-25793","""Robert Lupton provided comments and feedback on the """"Sensor Characterization and ISR"""" confluence page: https://confluence.lsstcorp.org/display/DM/Sensor+Characterization+and+ISR#/    This ticket is to follow-up on those comments, and file new tickets for some of them if needed. """
"DM-25970","Bug","ap_verify",1,"ap_verify CI command line broken","""After merging DM-21915, {{ap_verify}} CI runs fail with the following error:      We believe this is from the addition of an extra argument ({{--gen2}}), with a shell comment that got parsed as an argument instead. Moving the comment to its own line should fix the problem."""
"DM-25966","Story","HeaderService",1,"Update puppet HeaderService at the NTS","""Update HeaderService version to 2.3.1"""
"DM-25984","Bug","cp_pipe",3,"Investigate why the afw means of flat images are NANs for several amps of BOT data after DM-25934","""Craig Lage reports that after implementing masks to calculate clipped statistics DM-25934, the mean values of several amplifiers are now NAN (they had a reasonable value before the DM-25934). Investigate the cause and fix it. """
"DM-25980","Bug","Qserv",2,"Increased connection timeout for the backend service in a configuration of mysql-proxy","""During a stress testing of Qserv it was observed that {{mysql-proxy}} may report failures to connect to its _backend_ MySQL server and report the following to its clients:    Typically, this is seen when the number of clients exceeds a certain limit. Specifically, it has been observed (and reproduced on many occasions) that 2 out of 40 simultaneously launched query processing requests would instantly fail with the above shown error.    Further analysis of the log file (done by [~salnikov]) has revealed the following message in the proxy's log file:      According to the documentation portal for the proxy, there is a command line option which allows increasing the timeout:    See: https://downloads.mysql.com/docs/mysql-proxy-relnotes-en.pdf    Hence, a goal of this development is to investigate if setting the following value of this parameter when starting the proxy would solve the problem:    Deploy the updated version of Qserv at the development cluster at NCSA and test it. Report results and limitations in this ticket."""
"DM-25979","Story","meas_algorithms",1,"IngestIndexReferenceTask throws if coord_err_unit is None","""See [this report on Slack|https://lsstc.slack.com/archives/C2JPMCF5X/p1594855003499800] from [~kadrlica]:  """
"DM-26004","Story","ctrl_mpexec|pipe_base",1,"Clean up qgraph show-workflow implementations ","""Currently {{pipetask qgraph --show workflow}} figures out the dependencies in its own method, but the {{QuantumGraph}} class can provide such information already.  I don't know why I didn't use it but I'll clean it up here.  For this ticket the output format would stay the same, just improving the implementations. """
"DM-26003","Story","www_lsst_io",3,"Post-release cleanup of www.lsst.io codebase","""Some maintenance chores now that we've launched www_lsst_io:   * Upgrade the node version we're using locally and in GitHub Actions, and thus update more packages (locally this means adopting the node version manager).   * Cleaning up the components, namely moving components into the basics/ and algolia/ directories.   * More consistent documentation of components"""
"DM-26001","Story","www_lsst_io",0.5,"Fix buttons in www.lsst.io to use the correct pointer","""{quote}The cursor doesn’t become the pointing-finger over the blue buttons, and the buttons don’t display any transient “I’m being pressed” feedback.  Combined with the other things below it creates some uncertainty about whether the buttons are “live” or not.  {quote}"""
"DM-25994","Story","ts_main_telescope",3,"Publish the Velocity or Needed Telemetry to DDS for Rotator","""Publish the velocity or needed telemetry to DDS for rotator."""
"DM-25986","Bug","Qserv",2,"Master replication controller crashes in the Kubernetes environment","""Repeated crashes of the Master Replication Controller have been reported at IN2P3 in the Kubernetes-based Qserv installation which also includes the Replication/Ingest system. The crashes are seen in two scenarios:  * when starting the Qserv instance the Controller may crash a few times before getting into a stable state  * when ingesting new catalogs (typically when committing {{super-transactions}})    In both cases the following messages were reported by the Controller:    A goal of this effort is to investigate a reason of the crash and fix/reinforce the Controller's implementation."""
"DM-26011","Story","obs_lsst",1,"Intermittent failures in obs_lsst tests","""Since I merged DM-25923 we've been getting some intermittent failures in obs_lsst tests that seem to be related to the camera caching returning the wrong object.  This only seems to happen in some environments with many cores. The TS3 ingest test fails because it ends up registering a camera that looks like LSSTCam and not TS3.  There is also a failure in writeCuratedCalibrations that is related where the detector in the data package does not exist in the camera despite the correct data package being used.  """
"DM-26010","Story","daf_butler",0.5,"Simplify mypy configuration after ending use of namespace packages","""Now that [~tjenness] has removed our usage of namespace packages, we can simplify our mypy configuration by running it in a more standard manner - from the root directory, on a directory, instead of from the python subdirectory, on a package.    At least in my (VSCode) case, this will also make in-editor configuration vastly better."""
"DM-26008","Story","pex_config",1,"Add YAML representers to pex_config","""pex_config serializes to pickle by converting to text. This should be easy to also do as a yaml representer.  Doing this will give us the option of switching quantum graphs over to yaml."""
"DM-26007","Bug","meas_algorithms",2,"defaultFilter is not used if a filterName is given to loadSkyCircle","""If {{defaultFilter}} is supplied without a {{filterMap}}, and the user specifies {{filter=something}} in {{loadSkyCircle()}} (as one normally does, because when you load the refcat you don't know how its filter mappings are configured), {{getRefFluxField()}} will fail:        I believe the solution is to add {{camFlux}} to the {{fluxFieldList}} in {{getRefFluxField()}}, so that if {{defaultFilter}} is specified, you'll still get a fluxField of some kind. The behavior of how {{defaultFilter}} and {{filterMap}} should interact is undefined in the docs that I can see, so although this is a behavior change, I think it is more self-consistent. We also do not use {{defaultFilter}} anywhere in the stack currently that I've found, and this change should make it useable for RFC-697."""
"DM-26027","Story","HeaderService",1,"Update docker images and conda for Headerservice 2.3.2","""HS need to be deployed using version 2.3.2"""
"DM-26020","Story","ts_main_telescope",3,"Rotator Plant Model Analysis","""Tasks capturing Mike's work on the Rotator Plant Model for the last couple of weeks.  Mike has entered 24 hours into his time sheets, so 3 SP will used for this task."""
"DM-26015","Story","pipe_base",1,"Validate PipelineTaskConnections dimensions are iterables other than str","""if a connection's (or task's) dimensions is specified without a comma and there is only one dimension a weird error is generated as the system attempts to iterate over the string. This ticket will add validation to catch this case"""
"DM-26013","Story","ts_dome|ts_eas",1,"Check SALSubsystems.XML file for attributes for several subsystems","""This page    [https://confluence.lsstcorp.org/display/LTS/SALSubsystem+Attributes]    describes the attributes of all subsystems in SAL. Check the attributes for the following projects and correct them if necessary:   * Dome   * EAS   * ESS   * HVAC"""
"DM-26048","Story","ts_main_telescope",5,"Dome software meetings","""Prepare and coordinate weekly meetings on dome control software with EIE contractor."""
"DM-26047","Bug","cp_pipe|obs_lsst|pipe_tasks",0.5,"Defect calibration product filename collision","""I have been creating defect calibration products to use when running measurePhotonTransferCurve.py.  After ingestion, the defect calibration product filenames have the sensor number (Sxx) but not the raft number (Rxx) or detector number, and so are not unique.  An example filename is {{CALIB/defects/2019-10-12T15\:02\:16.071000/defects-2019-10-12T15\:02\:16.071000-S11.fits}}.  When running BOT data, both detector 40 (R11_S11) and detector 85 (R21_S11) ended up with the same filename.      The defect files were created with:    and ingested with:  """
"DM-26040","Improvement","ap_association",2,"Add AP timing metrics for DiaPipelineTask and all subtasks","""Currently, {{ap_verify}} times only {{AssociationTask}} from {{ap_association}}. Add timing measurements for {{DiaPipelineTask}} and its other first-level subtasks to bring the level of SQuaSH instrumentation in line with image differencing and single-CCD processing."""
"DM-26036","Improvement","ts_main_telescope",0,"Add missing unit test","""In DM-25712 I forgot to add one unit test (which doesn't do very much, so not a big loss). Add it."""
"DM-26070","Improvement","ap_verify",3,"Add visit definition to ap_verify","""DM-21915 implemented ingestion of {{ap_verify}} datasets in {{Gen3DatasetIngestTask}}, but neglected to include visit definition. This means that the repository, following ingestion, is not in a state where the AP pipeline can be run on it.    Add visit definition to {{Gen3DatasetIngestTask}}, so that users running {{ingest_dataset.py}} from the command line get a repository that is usable immediately. Because {{ap_verify}} datasets are necessarily complete and self-contained, the usual complications to doing visit definition (e.g., partially ingested visits) do not apply."""
"DM-26069","Story","afw",2,"Create requirements list for new Filter implementation","""After discussion with [~krzys] about approaching implementation of the new Filter design, we wanted to write down a list of requirements for the new system. RFC-541 was more focused on technical requirements, but some of the comments there can be built on to help with use case requirements. RFC-624 provides a design, but discussion since that has led to some questions about how exactly that design maps to how this system would be used.    For this ticket, I will write up (probably not a DMTN?) a list of use cases and requirements for Filters in the stack, based on the above RFCs, my own experiences with the {{Instrument}} {{FilterDefinitions}}, and expectations for how filter names are used for photometry."""
"DM-26066","Story","meas_extensions_scarlet",1,"Use proper versioning in scarlet","""Use setuptools_scm to properly calculate the scarlet version, and create a scarlet 1.0 tag."""
"DM-26064","Story","alert_stream",1,"Change alert-stream-simulator tests to use latest alert packet version","""Tests currently fail because they specifically ask for v2.1 of the alert schema, but that was deleted recently. They should use the latest schema."""
"DM-26061","Story","alert_stream",1,"Fix missing seek_to_beginning method in alert-stream-simulator","""As pointed out by @ebellm, there's a missing method from the internal Kafka client."""
"DM-26055","Story","ts_eas",2,"Install GenericCamera CSC on raspberry pi3 and make the camera work with it","""Now that the raspberry pi 3 with the Canon all-sky camera is up and running at the Recinto, it is time to install the CSC on it and get it working with the camera."""
"DM-26052","Improvement","ts_middleware",1,"Please document private fields and the ackcmd topic in the HTML for ts_xml","""Please add documentation for the private fields present for all topics in the HTML generated from ts_xml. Please also document the ackcmd topic. None of these are defined in the XML, so this documentation will have to be manually created and maintained.    The following descriptions are my own understanding and are how ts_salobj uses them (though users can set the public fields of the ackcmd topic as they like). Anyone should feel free to correct me if I am mistaken. I have added [~dmills], [~tribeiro], and [~rbovill] as watchers for this reason.    I suggest that the private fields be documented in one place (even though they are present for all topics) to avoid needless repetition. But do as you think best. The private fields, which are present on all topics are:    * private_sndStamp: time at which the sample was sent (TAI, unix seconds).  * private_rcvStamp: time at which the sample was received (TAI, unix seconds).  * private_identity: For a CSC this has the form <SAL component name>[:index] e.g. """"Script:5"""" or """"ATDome"""". For a user this has the form username@host. This field is used for authorization. New in ts_sal 4.2.  * private_origin: the process ID of the writer.  * private_host: the host address of the writer. This is deprecated, and due to be removed in ts_sal 5.  * private_seqNum: for commands this uniquely identifies the command (within a reasonable timespan, since the value must eventually wrap around). For other kinds of topics this may be incremented for each sample, though that is optional.  * <SAL component name>ID e.g. ScriptID (only present for indexed SAL components): the SAL index of the writer.    The ackcmd topic is how commands are acknowledged. Note that there is just one ackcmd topic that is used to acknowledge all commands. The public fields and one private field of the ackcmd topic are as follows:    * private_seqNum: the private_seqNum of the command being acknowledged.  * ack: the acknowledgement code, one of the CMD_ constants, such as CMD_COMPLETE = 303 or CMD_FAILED = -302.  * error: the error code. Set to a nonzero value if ack=CMD_FAILED.  * result: salobj sets this to an error message if ack=CMD_FAILED. I am not sure if it is used for anything else.  * identity: the private_identity of the command being acknowledged (see below).  * host: the private_host of the command being acknowledged. private_host is deprecated, so this field is also deprecated, and both should be gone in ts_sal 5.  * origin: the private_origin of the command being acknowledged, which is a process ID.  * cmdtype: command identifier: I believe this is supposed to be the 0-based index of the command in an alphabetical list of all topics for that SAL component. That is surprising to me as the list includes all topics, not just command topics. I hope I am wrong, but if so, I need to fix it in ts_salobj.  * timeout: the approximate expected duration of the command. Only set if ack=CMD_INPROGRESS.    I am not sure if you want to also explain the acknowledgement sequence here. It should certainly be documented somewhere, and this might be a nice place for it. As a quick reminder:    * The initial ack code is CMD_ACK when the command is read.  * If the command will take a long time to run then the CSC should respond with a CMD_INPROGRESS ack that includes an estimate of the command duration. This should only happen after the command has been approved.  * Usually the next ack is the final one for this command and is typically one of:  ** CMD_COMPLETE if the command finishes successfully.  ** CMD_FAILED if the command fails.  ** CMD_NOPERM if the command issuer is not authorized to send the command.  ** CMD_ABORTED if the command is superseded.  * CMD_TIMEOUT is returned if the command _issuer_ times out waiting for command completion. Note that it is the issuer, not the CSC, that returns this. If the command times out inside the CSC then the ack code is CMD_FAILED. In particular note that if the issuer gives up waiting for command completion and then the command finishes, the user will only see the CMD_TIMEOUT ack, but the DDS system will see the final ack from the CSC.  * There are at least two other CMD_ codes as well:  ** CMD_NOACK: ts_salobj sets the ackcmd field of AckTimeoutError to this value if no CMD_ACK was seen for the command before the command timed out. I am not sure how non-salobj systems use this code.  ** CMD_STALLED: I think the intent is to indicate """"this is going more slowly than I expected, but I am still working on it."""" I am not sure which systems use this code.    Here is how the ackcmd topic shows up in an IDL file. This also shows the data types of the private fields:        """
"DM-26084","Improvement","ts_auxiliary_telescope|ts_main_telescope",0,"Add JenkinsTestResults entries for ATMCS, Test, MTDomeTrajectory and Watcher to SALSubsystems.xml","""Add the missing JenkinsTestResults entries to SALSubsystems.xml for Test, MTDomeTrajectory and Watcher."""
"DM-26081","Improvement","ts_main_telescope",3,"Make Hexapod and Rotator configurable CSCs","""At present the Hexapod and Rotator are not configurable. Update the base class to make them configurable. Rotator will offer TCP/IP configuration. Hexapod will also offer compensation configuration once DM-25856 is implemented."""
"DM-26100","Story","Qserv",8,"Review/update orchestration harness for KPM50 tests","""For KPM50 we want to check the state of the existing test harness that was used for previous tests and understand its limitations and bottlenecks."""
"DM-26095","Improvement","ts_middleware",1,"Support LSST_DDS_HISTORYSYNC<0 disables wait_for_historical_data in ts_sal","""Support LSST_DDS_HISTORYSYNC<0 disables wait_for_historical_data in ts_sal.    This is for use on nodes that have no durability service running. Some or all CSCs that do not control other CSCs may be run in this way."""
"DM-26094","Improvement","ts_middleware",0,"Support LSST_DDS_HISTORYSYNC<0 to disable wait_for_historical_data in ts_salobj","""Support LSST_DDS_HISTORYSYNC<0 to disable wait_for_historical_data in ts_salobj.    This is for use on nodes that have no durability service running. Some or all CSCs that do not control other CSCs may be run in this way."""
"DM-26091","Story","ts_main_telescope",1,"Review the Trajectory Document of TMA","""Review the trajectory document of TMA: [^TrajectoryGenerationAlgorithmForLSST.docx]."""
"DM-26089","Story","ts_eas",1,"Install ESS CSC on the raspberry pi 4","""Install the ESS CSC on the raspberry pi 4 running CentOS 7 and make sure that it can be started. Also update the installation guidelines with the necessary steps."""
"DM-26088","Story","ctrl_mpexec",1,"Unmask LSST_LOG_CONFIG for setting log config","""lsst.log allows its config to be set via a configuration file at the LSST_LOG_CONFIG environment variable. However currently this feature cannot be used with the PipelineTask framework, because it resets the logging properties.      It'd be convenient if this reset can be skipped while a configuration file is provided.   """
"DM-26102","Improvement","Qserv",2,"Enable auto-tuning for the XRootD ""spread"" in Qserv","""This ticket is based on [DM-25891].    The new version of XRootD allows to auto-tune the client parameter """"spread"""" by setting its value to 0. Hence, an objective of this effort is to test the effect of auto-tuning when processing multiple shared scan queries at a large-scale Qserv installation. If it works, and if it doesn't have any side effects on the performance of Qserv then make auto-tuning the default parameter of Qserv."""
"DM-26104","Story","ts_main_telescope",1,"Do the Coverage Test for Rotator PXI Code","""Do the coverage test for rotator PXI code by *gcovr*."""
"DM-26113","Story","ts_middleware",0,"Cherry pick setting a random LSST_DDS_DOMAIN in BaseCscTestCase.check_bin_script to salobj 5","""Release a salobj 5 that sets a random LSST_DDS_DOMAIN in {{BaseCscTestCase.check_bin_script}} by cherry-picking the change from salobj 6"""
"DM-26112","Story","ts_environment",2,"Create Jenkins Conda build for the Environment CSC","""Task to track the work to create the Conda recipe and Jenkinsfile.conda for the Environment CSC."""
"DM-26110","Story","ts_middleware",1,"Add conda build to ts_authorize","""Add the conda build files to ts_authorize. This may have to wait until ts_sal 5 is released -- at least to run it."""
"DM-26133","Bug","utils",2,"generateAcronyms not robust for misformated glossary","""A recent addition to glossaries missed one quote - it passes travis anyway of course. Finding the offender required adding a print to the script. There should really be a try catch on the reader to indicate the offending line.    It may also be good to add a check format option which could be invoked by travis for a badly formated glossarydefs ffile. """
"DM-26129","Bug","ts_aos|ts_main_telescope",0,"[XML] Update MTAOS entry in SALSubsystems.xml","""These fields for the MTAOS entry in ts_xml/sal_interfaces/SALSubsystems.xml need to be updated:    <VendorContact> text must not be empty"""
"DM-26128","Bug","ts_main_telescope",0,"[XML] Update MTM2 entry in SALSubsystems.xml","""These fields for the MTM2 entry in ts_xml/sal_interfaces/SALSubsystems.xml need to be updated:    <JenkinsTestResults> text must not be empty    * Note: Work with DM-26120."""
"DM-26122","Bug","ts_main_telescope",0,"[XML] Update MTEEC entry in SALSubsystems.xml","""These fields for the MTEEC entry in ts_xml/sal_interfaces/SALSubsystems.xml need to be updated:    <Github> text must not be empty    <JenkinsTestResults> text must not be empty    <Simulator> have a URL or one of the following: Internal to CSC, Not Required, Not Provided"""
"DM-26120","Bug","ts_aos",0,"[XML] Update IOTA entry in SALSubsystems.xml","""These fields for the IOTA entry in ts_xml/sal_interfaces/SALSubsystems.xml need to be updated:    <ActiveDevelopers> text must not be empty    <Github> text must not be empty    <JenkinsTestResults> text must not be empty    <Simulator> have a URL or one of the following: Internal to CSC, Not Required, Not Provided"""
"DM-26119","Story","daf_butler|obs_base",2,"Test dataset disassembly with ci_hsc_gen3","""Composite disassembly is not properly tested anywhere for afw Exposures. Run ci_hsc_gen3 with disassembly turned on and see what breaks."""
"DM-26144","Story","pipe_base",1,"Allow Pipelines to inherit configs","""Currently if a task is declared in a Pipeline task list, and the task is already declared in an inherited pipeline (with the same label), the task and its configs replace the inherited versions meaning all configs need to be declared in a pipeline, even if only one config is to be added.    This ticket will change this behavior. If a task is declared in a pipeline that inherits the same task with the same label, the new config options will be added to the existing config overrides. If a label is declared with a different task than what exists in the inherited pipeline, it will completely replace the existing definition, as the config options likely no longer apply."""
"DM-26142","Improvement","Qserv",1,"Add the columns separator option to the file ingest tool","""Add the following option to the command line tool:    The default value of the option should be {{COMMA}}.    Update section 11.2.2 of the [User guide for the Qserv Ingest system|https://confluence.lsstcorp.org/pages/viewpage.action?pageId=133333850] as well."""
"DM-26177","Story","ts_main_telescope",3,"Write the Test Framework of SAL LabVIEW API in Phase 1","""Write the test framework of SAL LabVIEW API. This task begins to construct a framework to test the LabVIEW API for each new SAL update. In the past, we used the component CSC in LabVIEW to test this. Now, we need a framework to test this automatically. The SAL LabVIEW APIs rely on the shared memory, which is not needed for the C++ and JAVA APIs. Therefore, this kind of automatic test framework should be helpful for the maintenance of CSC in LabVIEW. This task is in the phase 1."""
"DM-26174","Story","ts_main_telescope",3,"Optimize the Tool that Generates the SAL LabVIEW APIs","""Optimize the tool that generates the SAL LabVIEW APIs. The [ts_SALLabVIEW|https://github.com/lsst-ts/ts_SALLabVIEW] is used now to transform the data type from SAL IDL. The execution speed is slow now. This task will try to optimize the performance.    * I noticed some type definition do not work as expected. This task will try to fix this as well."""
"DM-26171","Story","butler|pipe_tasks",1,"calibrations cannot be retrieved on the last day of a validity range","""The validity ranges in the calibration database are currently set as days with no time included, which means that they implicitly round down.   In consequence, a calibration that should be valid on the last day of a validity range can never be looked up.    The simplest fix is to make validEnd equal to validStart for the next interval.  There is a problem for calibs taken exactly at the roll-over, but this window is only 1ms wide, and providing we don't take calibs at midnight we will be OK.  For gen2, I think this is OK, but we should handle it properly in gen3 (especially as people like to take calibrations on dark and stormy nights)    [~czw] points out that the place to fix the code is in the {{fixSubsetValidity}} method in ingestCalibs.py"""
"DM-26170","Improvement","Continuous Integration",1,"Migrate ci_cpp from lsst-dm to lsst","""Upon acceptance of the associated RFC, ci_cpp, ci_cpp_gen2, ci_cpp_gen3, and testdata_latiss_cpp will be moved from the lsst-dm github organization to lsst."""
"DM-26168","Story","meas_extensions_scarlet",2,"Test wavelet detection in crowded field","""The TVS crowded field working group is working on testing scarlet on DECam images of the globular cluster NGC-6569. One of the issues is detecting all of the sources in the field, since the high stellar density and wide PSF in redder bands makes detection more ambiguous.    This ticket is to test out the wavelet detection algorithm of Remy Joseph. The idea is that because the field is dominated by point sources, we should be able to use wavelets to create a high pass filter for the image and only allow the highest frequency coefficents to pass through, removing the wings of PSFs and lowering the detection threshold."""
"DM-26166","Bug","cp_pipe",1,"Recent tests of ptc.py show strange results","""I've been running ptc.py on the BOT data for some time with good results.  Recently, I've been working with the defect calibration files to mask out the edge pixels.  On 17-Jul, I ran ptc.py on the BOT data for detector 94.  This was with     {{  You can see the python script that ran that at }}    {{and the output repo is at}}    {{Everything looked completely normal, and the gains agreed better with the Eotest Fe55 results.  So I set up to run all of the CCDs that way.  This took a while to get everything running, but it is now finished with all 81 CCDs.  The python script is at }}    {{and the output repo is at }}    {{This ran with}}    The    plot looks OK at first glance, but the values are all messed up.  The gain comes out ~1.8 instead of ~1.0.  The PTC curve, instead of turning over at ~100,000 ADU like it should, turns over at ~60,000 ADU. I'm not sure what went wrong.  I don't know if it is something I did or if the code has changed.  Note that both the good run above and the bad run are after the refactoring of ptc.py"""
"DM-26161","Story","ts_main_telescope",1,"Setup the Software Environment to Update M2 Software","""This task is to setup the needed software environment (by virtual box) on my MacBook Pro to update the M2 software. The original linux laptop and desktop are in Chile and Tucson office individually. Therefore, I need to setup the environment on my personal laptop to do the development of M2 software."""
"DM-26160","Story","daf_butler",1,"Fix test failure where URI special characters are in build directory","""Following DM-24475 the obs_base build failed because there is a """"+"""" in the build path and somewhere a double URI encoding is happening so that the + is encoded and then the resulting % is encoded."""
"DM-26159","Story","Qserv",0.5,"Fix teardown crash in qhttp unit test","""There has been for some time an intermittent crasher that occurs sometimes during teardown of the boost::unit unit test for qhttp (testqhttp).    Andy Salnikov recently obtained a repeatable failure and extracted a core; investigation of this indicated the problem is occurs as a bad object dereference in a race between the asio service teardown in one thread and a socket accept handler executing on the service handler thread."""
"DM-26200","Story","ts_auxiliary_telescope",0,"ATHexapod should set itself to FAULT state if start command fails","""The ATHexapod is not setting its internal state to be FAULT when the start command fails. It does issue the proper summaryState info to SAL, but then its internal state is inconsistent with what is presented by the EFD."""
"DM-26199","Story","ts_main_telescope",3,"Support dome coditioning contract","""Support activities to develop a dome environment conditioning contract, to control the temperature during daytime. The activities include reviewing proposals, provide technical information to potential contractors, meetings with Rubin Observatory reviewers and contractors."""
"DM-26198","Story","daf_butler",1,"Allow butler import to skip some dimensions","""As discussed on DM-26195 it would be useful to skip instrument dimensions on import if the instrument has already been registered.    One quick work around is to allow the user to specify a list of dimensions to skip and use them in the {{Backend.load()}} method.    It looks like this is a trivial fix as such and it does work."""
"DM-26197","Story","ts_main_telescope",1,"Replace hexrotcomm.CscCommander with salobj.CscCommander","""When time permits rewrite the Hexapod and Rotator CSC commanders to use the standard salobjlCscCommander and delete the hexrotcomm.CscCommander.    I wrote the hexrotcomm version first, and the salobj version based on that. The salobj version is now much better."""
"DM-26191","Story","ts_middleware",0,"Improve documentation for CscCommander.amain","""Improve the doc string for CscCommander.amain to document the parameters and clarify that index is a required argument."""
"DM-26189","Story","ts_middleware|ts_qa",2,"Various build script updates","""As SAL and XML are released, the build scripts need to be updated accordingly.  Normally, there are specific events that I use to create these tasks (a release, for example).  However, this sprint had no such event, but there was significant work to be done on the scripts.  Namely, activating the SALSubsystems.xml unit tests and writing the Jira tickets for outstanding work on that file."""
"DM-26188","Story","ts_deployment|ts_qa",3,"Coordinate the Jenkins Conda build hackathon","""This task covers the time necessary to prepare for and then lead the hackathon to create the various CSC Conda Jenkins builds."""
"DM-26187","Story","meas_deblender|meas_extensions_scarlet",1,"Rename deblend.py in meas_deblender and meas_extensions_scarlet","""To {{sourceDeblendTask.py}} and {{scarletDeblendTask.py}} respectively, thereby implementing RFC-717. """
"DM-26185","Epic","ts_management",40,"PCW 2020","""This epic is for tracking the time spent at the PCW 2020"""
"DM-26181","Story","ctrl_mpexec",1,"Ensure that filters are defined in pipetask multiprocessing","""In DM-26119 I learned that when pipetask uses multiprocessing we never instantiate an {{Instrument}} and therefore we never define the filters for that instrument in the global singleton.    In single process mode it's fine because at some point an Instrument is created.    Modify pipetask multiprocessing such that the dataIds are scanned for the """"instrument"""" dimension and we call {{Instrument.fromName(dataId[""""instrument""""], registry)}}.  Currently we only expect one instrument.    When the singleton is removed it's likely that some related initialization will be needed to register the filters but we assume that would allow the same initialization for multiple instruments.    CC/ [~krzys], [~Parejkoj] in case they have come across this problem before."""
"DM-26211","Story","Middleware",1,"Generate list of essential ts_sal files","""Generate a list of essential components of ts_sal that are required  in order for Jenkins to be able to create the CSC runtime assets  and run the tests"""
"DM-26210","Story","ts_management",2,"Attend PCW ","""Attend the virtual PCW meetings"""
"DM-26209","Story","ts_management",2,"Attend 2020 RubenObs PCW","""Attend the 2020 Project & Community Workshop 8/10-8/14"""
"DM-26208","Story","ts_qa",2,"Please update the version of Python in lsstts/robot:latest to 3.7.x and put black on the PATH","""Please update the version of Python in lsstts/robot:latest so we can use features in Python 3.7.    Another option to consider is running ts_xml Jenkins with lsstts/salobj instead, if that would work."""
"DM-26236","Story","ts_main_telescope",3,"Support dome conditioning contract","""Support activities to develop a dome environment conditioning contract, to control the temperature during daytime. The activities include reviewing proposals, provide technical information to potential contractors, meetings with Rubin Observatory reviewers and contractors."""
"DM-26235","Story","ts_main_telescope",5,"Dome software meetings","""Prepare and coordinate weekly meetings on dome control software with EIE contractor."""
"DM-26233","Story","ts_eas",1,"Command all-sky CSC using an external python script","""Now that the basic all-sky CSC and driver are done, they need to be commanded as well. In order to test that functionality, create an additional python script and command the CSC with that."""
"DM-26232","Story","ts_eas",1,"Command ESS CSC using an external python script","""Now that the basic ESS CSC is done, it needs to be commanded as well. In order to test that functionality, create an additional python script and command the CSC with that."""
"DM-26230","Bug","ctrl_mpexec",1,"Improve pipetask dignostics on multiprocessing timeouts.","""When a task timeouts the disgnostics that pipetask produces is only a standard traceback mentioning TimeoutError:      but it does not say which task timed out or for which quanta. Need to add that info.    And a bug that [~ktl] noticed is that there exists timeout command line option which is supposed to change timeout value but it's not used by CmdLineFwk.  """
"DM-26229","Story","daf_butler",1,"Investigate failure in daf_butler test in nightly build","""In the nightly release build https://ci.lsst.codes/blue/organizations/jenkins/release%2Ftarball/detail/tarball/6041/tests one of the ingest symlink tests failed:        Normal Jenkins is passing and the job worked the previous night.    Only two tickets were merged yesterday: DM-26119 and DM-25985; and neither look like they should affect ingest.  """
"DM-26225","Story","ts_eas",1,"Integrate ESS USB code in ESS CSC","""The ESS code has been adjusted to support a single USB device. Integrate that code into the CSC."""
"DM-26260","Story","afw",1,"ExposureFitsReader can't read compressed darks/biases","""Working on the new pipeline_check package I realized that the 33MB dark and bias files can trivially be compressed using fpack to be 5MB each.    Compressing these single data array FITS files (GZIP_1 or GZIP_2) then breaks ExposureFitsReader with a SEGV when trying to read the mask that does not exist:        The compression confuses the reader because compression creates an extra hdu binary table. MaskedImageFitsReader does not look at the EXTTYPE header and so tries to read the next extension as if it's a mask.    I'm not entirely sure why we write FITS files with EXTTYPE headers but then don't use them when we read.    The most important issue here is the SEGV.    To reproduce run {{fpack -g2}} on the {{CALIB/DARK/2013-11-03/NONE/DARK-2013-11-03-010.fits}} from {{testdata_ci_hsc}}.  Then try to read the .fits.fz file with ExposureFitsReader:    {code:python}  from lsst.afw.image import ExposureFitsReader  reader = ExposureFitsReader(""""dark.fits.fz"""")  e = reader.read()  {code}    [~ktl] points out that we probably should be reading these as Image and not Exposure but that might require invasive changes to pipelines.    A more generic solution would be for MaskedImageFitsReader to query for EXTTYPE and if there are no MASK and VARIANCE extensions, skip trying to read them regardless of the number of extensions found.    """
"DM-26258","Story","daf_butler",0.5,"Fix problem with daf_butler tests failing with escaped characters in path","""A test failed in the nightly (again) which is the same problem but in a different test. This time I will run the tests locally in a similar directory."""
"DM-26257","Story","HeaderService",1,"Update docker images and conda for Headerservice 2.3.3 and new ts_xml/ts_salobj/ts_idl","""HS need to be deployed using version 2.3.2"""
"DM-26255","Story","ts_eas|ts_environment",2,"Create conda build recipe for HVAC","""Once the HVAC CSC has been created, the conda recipe can be created as well."""
"DM-26254","Story","ts_eas|ts_environment",3,"Create HVAC CSC","""Create the CSC for HVAC that at least publishes the HVAC telemetry based on what it receives via MQTT."""
"DM-26253","Story","ts_eas",1,"Create conda build recipe for EAS","""Once the EAS GitHub repo, code and unit tests have been modernized, the conda recipe can be created as well."""
"DM-26252","Story","ts_eas|ts_environment",1,"Create conda build recipe for MTEEC","""Once the MTECC GitHub repo, code and unit tests have been modernized, the conda recipe can be created as well."""
"DM-26251","Story","ts_eas|ts_environment",2,"Modernize EAS GitHub repo, code and unit tests","""The EAS GitHub repo is very much outdated and needs to be modernized. This also is true for the code and unit tests. Please fix this all."""
"DM-26250","Story","ts_eas|ts_environment",2,"Modernize MTEEC GitHub repo, code and unit tests","""The MTEEC GitHub repo is very much outdated and needs to be modernized. This also is true for the code and unit tests. Please fix this all."""
"DM-26270","Story","Middleware",2,"Support the New Enum Syntax in IDL File","""Support the new enum syntax in IDL file: (1) shared enum such as the *SummaryState*, and (2) assign the enum value in <Enumeration> of xml. Use the *Test* subsystem as an example, the structure of summary state looks like this:    {color:#4c9aff}struct logevent_summaryState \{{color}  {color:#4c9aff}    long summaryState;{color}  {color:#4c9aff}    long priority;{color}  {color:#4c9aff} };{color}    There is no information to say summaryState is a enum (e.g. *// enum :*).    In addition, the following part in *Test* xml does not reflect to IDL file:  {color:#4c9aff}<Enumeration>Int0ValueEnum_Zero=0, Int0ValueEnum_Two=2, Int0ValueEnum_Four=04, Int0ValueEnum_Five=0x05</Enumeration>{color}"""
"DM-26267","Bug","ts_main_telescope",0,"Disable the fault method in hexrotcomm.BaseCsc","""hexrotcomm.BaseCsc handles state transitions differently than salobj, since the state is maintained in the low-level controller. One problem with this is that it does not make sense for a hexrotcomm CSC to send itself into a FAULT state.    Thus the fault method should be disabled and avoided."""
"DM-26266","Story","ts_management",2,"Attend 2020 RubenObs PCW","""Attend 2020 RubenObs PCW."""
"DM-26265","Bug","ap_verify",1,"ap_verify tests use fixed temp directories","""The two sets of {{TestWorkspace}} tests use a hardcoded temporary directory ({{_temp}}) for some tests that don't use the standard setup, causing a conflict between the tests. Replace {{_temp}} with a normal temporary directory."""
"DM-26264","Story","Qserv",0.5,"Fix qhttp ajax unit test","""qhttp ajax unit test sometimes fails in Jenkins.  Troubleshoot and fix."""
"DM-26263","Story","pipelines_lsst_io",1,"Add “scientist-facing” release notes to pipelines.lsst.io","""[~jbosch] & [~ebellm] have prepared notes on how the changes made in release 20.0.0 impact on the data products which will be consumed by end users. Please ensure these notes are included on the pipelines.lsst.io site."""
"DM-26283","Story","ts_main_telescope",2,"Determine the compensation models for the Hexapod, including coefficients","""Determine a suitable model for Hexapod compensation, with coefficients."""
"DM-26291","Story","www_lsst_io",1,"Fix URL redirects on the document series pages (www.lsst.io)","""The document series pages on [www.lsst.io|http://www.lsst.io/] are creating infinite redirects based on the search state cached in the URL. The advanced search page had a similar issue and we fixed that in  DM-24955."""
"DM-26289","Story","lsst-texmf",5,"Update lsst-texmf build and Docker image for Python 3.7/GitHub Actions","""The lsst-texmf build process hasn't been updated in several years, and it's now worth making several updates to improve the stability and performance of both CI and the Docker image product going forwards:   * Switch to GitHub Actions for better performance   * Target Python 3.7 for both the test environment and the Docker image   * Use a multi-stage docker build and intermediate image caching to create a compact docker image that no longer relies on https://github.com/lsst-sqre/lsst-texlive"""
"DM-26286","Story","ts_main_telescope",3,"Document M1M3 SS Context, Model,..","""Provide more Doxygen docs for Context, Model and related (now singletons). Publish build Doxygen doc on https://ts-m1m3support.lsst.io"""
"DM-26305","Story","ts_middleware",0,"Improve documentation of DataType in salobj topic classes","""Try to clarify the documentation for data types in salobj topic classes, and what the callback function receives."""
"DM-26304","Story","daf_butler|obs_base",1,"Move PexConfigFormatter to obs_base","""PexConfigFormatter is anomalous in that it's defined in daf_butler but can't be used by daf_butler, shouldn't be used by daf_butler and can't be tested in daf_butler.    It should move to obs_base where the other lsst-specific formatters exist. It can then be tested properly in obs_base."""
"DM-26294","Story","Qserv",1,"Merge Gsoc student PR about networkpolicies","""PR is here: https://github.com/lsst/qserv-operator/pull/13"""
"DM-26317","Story","obs_decam|obs_subaru",1,"Add camera caching to obs_decam and obs_subaru Gen3 Instrument","""It takes half a second for getCamera to read the HSC camera in HyperSuprimeCam instrument class every time we call it. This adds up really quickly when we are looping over exposures and calling {{loadCamera}}.    Add a simple lru_cache as was done for YAMLCamera in DM-25923"""
"DM-26316","Improvement","cp_pipe|ip_isr",1,"Allow bias generation to retain overscan signal","""ComCam data has patterns in the biases along the x-axis (perpendicular to parallel transfers).  The fitted overscan is therefore not removing all of the signal it should.  Reversing the application of the overscan and bias correction should allow these patterns to be removed by an initial bias pass, allowing the overscan correction to remove the row-by-row signals."""
"DM-26315","Story","ts_aos|ts_main_telescope",1,"Support the Update of Sensitivity Matrix","""Support the update of sensitivity matrix. Bo updated the sensitivity matrix and bending mode in the following two PRs:   1. [https://github.com/lsst-ts/phosim_syseng4/pull/3]   2. [https://github.com/lsst-ts/ts_ofc/pull/26]    Because this update will break the unit tests in *ts_ofc*, I will support the fix of them. In addition, the scientific pipeline uses the *gcc/g++ 7.3*. The [phosim_syseng4|https://github.com/lsst-ts/phosim_syseng4] has the problem of compilation. This task will try to upgrade it and do the related test.    The update of M2 force file in *ts_phosim* should break the unit tests as well. Need to fix them."""
"DM-26327","Story","obs_base|obs_decam|obs_lsst",1,"Add support for x-flipped WCS in gen3 formatters","""I might be missing something but it looks like the DECam WCS uses the flipX parameter in gen2 for raw data but it doesn't in gen3. I'm not entirely sure how that can be true.    Regardless LATISS will need flipping (DM-24592) so I need to add a class property to raw formatter base to indicate whether flipX should be applied. Should be quick."""
"DM-26320","Story","ts_main_telescope",3,"Please clarify some parts of the TMA simulator docs","""I found some parts of https://ts-tma.lsst.io/v/feature-tickets-DM-25520/virtual_machines.html confusing and would appreciate some clarifications.    The title """"Virtual Machines"""" does not make it clear that these are for running simulation code. Perhaps """"Simulators"""" or """"Simulators and Virtual Machines"""" or...?    The instructions for dealing with IP addresses could be clearer. I did not realize I was supposed to pick a different address than the one my machine already had. Consider something like this for macOS (though you'll have to replace my IP numbers with yours for consistency):        I had no idea how to set the IP address of the mtmount_default_... Windows virtual machine. Please consider something like the following (unless you can recommend a better way to get to the properties editor; this seems quite roundabout). Also this could be on a separate page if you expect mostly people familiar with Windows to be reading the document:  .    The section about setting up a Host Network Manager for VirtualBox seemed pretty clear, but I'm a bit surprised it didn't appear at the beginning, before importing the Windows VM. I thought it perhaps had to be done for each of the PXI virtual machines individually, but it clearly is a global settings. You might consider clarifying that (or moving it to before importing any of the VMs, which would make it self-evident). Here are the notes I wrote to myself:      I also found that I wasn't sure about importing any of the virtual machines. It turned out I could just use the defaults, but I was not at all clear on that. It would help to make it clear whether or not the user is expected to change anything during the import (and under what circumstances). In my case I found that all the instructions were for changing things after import.    I realize all this detail just adds to an already long document. I'm not sure what to say except for one not familiar with either Windows or VirtualBox it can be pretty painful trying to figure out what's going on. And if VirtualBox evolves I suppose too much detail may end up being a problem."""
"DM-26318","Story","daf_butler",1,"Fix WebDAV failures on Jenkins","""DM-26310 is breaking Jenkins because www.lsst.org is not visible from Jenkins servers. We are using responses package so this shouldn't be an issue but it seems that we are failing to mock the {{requests.options}} call.  """
"DM-26363","Story","ts_main_telescope",3,"Test the Jenkins with LabVIEW","""Test the Jenkins with LabVIEW on my desktop to see it can do the unit test, generate the Junit xml reports, and publish or not. I think it might be easier to use the virtual box to do this test (install the Jenkins in the virtual box)."""
"DM-26343","Story","daf_butler",1,"Fix extension usage in ButlerURI and Butler Ingest","""In DM-26138 we ended up with a filter name that includes {{1.4}}.  This breaks butler ingest because gen2 puts the 1.4 in the file names and ButlerURI assumes that 4 is part of a file extension.  Fix ButlerURI.getExtension so that it only returns a single extension unless there is a special case of .gz, .bz2, .xz, and .fz (in which case it returns two).  This should fix ingest for filters with a dot in them and allow us to use the filter name we want for imsim."""
"DM-26335","Story","System Integration and Test",2,"Test RPI Centos7 container with hardware","""Build a 64bit CentOS 7 (aarch) container and test it with hardware setup  (temp sensors and POE hat)"""
"DM-26365","Story","mops",1,"Linkage analysis tool abstract for 2020 DPS meeting","""Submit an abstract for a poster covering the linkage analysis tool as a possible QA tool for small body linking algorithms. """
"DM-26391","Story","ts_deployment|ts_qa",2,"Assess status of Conda job completion","""Determine which CSCs need Conda Jenkins jobs, which currently have them and how many are left to work on.  Then coordinate finishing any remaining work."""
"DM-26379","Bug","Middleware",1,"Missing Control in SAL LabVIEW VI and IDL Information","""The SAL LabVIEW VI failed because the topic is allowed to have no attributes. Take the [^sal_Test.idl] as an example. The fault command is:    -----------------------------------------------------------------------    struct command_fault \{   };   #pragma keylist command_fault TestID    -----------------------------------------------------------------------    This will fail the *ts_SALLabVIEW* for the empty string. If the *ts_salobj* does not need this, it is better to remove this from the IDL file. In addition, this will break the SAL LabVIEW API like the following:    !failedAPI.png|width=400,height=274!    The API itself is broken already for the empty structure:   !failedAPI_mag.png|width=346,height=136!"""
"DM-26400","Story","ts_main_telescope",5,"Dome Control Software Development Support","""Support activities for the development of low level dome control software development by EIE contractor. The activities include  organization and attendance to technical meetings, review of documentacion, enforce compliance to requirements of software implementations, plan timeline of deliverables, provide technical support and guidance during development."""
"DM-26399","Story","ts_main_telescope",3,"Support dome coditioning contract","""Support activities to develop a dome environment conditioning contract, to control the temperature during daytime. The activities include reviewing proposals, provide technical information to potential contractors, meetings with Rubin Observatory reviewers and contractors."""
"DM-26398","Bug","Alert Production",2,"SourceDetectionTask alters input exposure image values in place","""In connection to the test run of DM-26182, the output exposure written to storage does not match with the result of {{ZogyTask}}. It was narrowed down to {{lsst.meas.algorithms.SourceDetectionTask}} that alters the input exposure in place.                   In this case, {{doSmooth = False}}  i.e. the input exposure is a likelihood image. The variance plane seems to be unaffected at least the constant value block that is the result of ZogyTask is preserved."""
"DM-26429","Story","daf_base",0.5,"Improve DateSystem enum docs to clarify EPOCH","""I was not able to find documentation about the EPOCH value of {{daf.base.DateTime.DateSystem}}. From the C++ code, it looks like it means """"Julian Epoch Year"""", like the [astropy time format|https://docs.astropy.org/en/stable/api/astropy.time.TimeJulianEpoch.html#astropy.time.TimeJulianEpoch], but """"epoch"""" is also used elsewhere in the same code to refer to """"nanoseconds since the unix epoch"""", which is quite a different thing.    We need a short docstring on that enum (or elsewhere, if enum docstrings don't work) to make the values explicitly clear.    Also, the private `_getEpoch` could be similarly updated to specify that it is the Julian Epoch Year."""
"DM-26426","Story","Qserv",2,"Upgrade Qserv image inside Qserv-operator","""use image `deps_20200729_0234` whose git SHA is `3130bd0`"""
"DM-26423","Story","ts_middleware",1,"Make SAL/kafka producers shut down gracefully for SIGTERM","""Make the SAL/Kafka producers shut down gracefully for SIGTERM (and SIGINT)."""
"DM-26421","Story","nublado",3,"Add instructions for using an access token outside of nublado","""Logging in to nublado provides an access token to the user that can be used to access services in the API aspect.  This is to provide an extension to nb.lsst.io to provide instructions on how to do that in a specific example case.  I'd like to use access of the TAP service via the TOPCAT tool as my exemplar."""
"DM-26419","Bug","ap_verify",1,"Update CI repositories for latest Butler","""DM-26331 added a change to the Gen 3 registry schema that is likely to break {{ap_verify}} datasets despite our use of repository cloning. Update {{ap_verify_ci_hits2015}} and {{ap_verify_ci_cosmos_pdr2}} to conform to the new schema."""
"DM-26414","Story","ip_isr",1,"Handle masked pixels in ip_isr's MEDIAN_PER_ROW","""If there are masked pixels in the overscan, the \{\{MEDIAN_PER_ROW}} overscan correction code generates a warning:        Please remove this.  I think the simplest fix is \{\{row = row[~row.mask].data[0]}} in collapseArrayMedian, but there may be other occurrences.  A better solution might be to stop using {{np.ma}} in favour of using stack-native code everywhere, which understands {{Mask}} planes.     """
"DM-26452","Improvement","ip_isr",1,"Fix fringe filter inconsistency","""The tests here:  [https://github.com/lsst/ip_isr/blob/master/python/lsst/ip/isr/isrTask.py#L1300]  and here:  [https://github.com/lsst/ip_isr/blob/master/python/lsst/ip/isr/fringe.py#L251]  should match."""
"DM-26447","Story","ts_auxiliary_telescope|ts_main_telescope",1,"ScriptQueueCommander: support setting logLevel, etc. in the add command","""Enhance the ScriptQueue commander to allow the user to specify logLevel and other options for the add command. Preferably make these optional arguments that use keywords, e.g. logLevel=40."""
"DM-26445","Story","daf_butler",1,"w34 ingest_raws fails with ci_hsc_gen3 and PostgreSQL with Timespan error","""scons --butler-config=/scratch/mgower/weekly_ci_hsc_gen3/postgres/output/1598279875/butler-seed.yaml -j 8 --enable-profile    With butler-seed.yaml looking like       Leads to:  """
"DM-26480","Story","ts_middleware",0,"Fix ts_sal unit tests for volatile telemetry","""A few ts_sal unit tests are now failing, as expected, because telemetry topics are now volatile and so have no historical (late joiner) data. Update the tests on the version 5 ticket branch."""
"DM-26475","Story","SUIT",3,"Update 'suit' package build procedure to new online help system","""From [~gpdf] - [~loi] discussion this morning: update the {{suit}} package's build scripts to     # use the new Firefly online help system, building the help from the suit-specific fork [lsst/suit-help|https://github.com/lsst/suit-help] of the core online help text at [Caltech-IPAC/firefly-help|https://github.com/Caltech-IPAC/firefly-help], and   # place the generated pages into the .war file output of the build, and therefore into the resulting Docker image, for service from Tomcat under a sub-endpoint of the {{suit}} / Portal Aspect application.    This feature should be backported to the rc-2.0 branch of {{suit}}."""
"DM-26499","Story","ts_main_telescope",0,"Get conda job running for ts_MTDomeTrajectory","""The conda job for ts_MTDomeTrajectory is failing. Looks like missing dependencies. https://tssw-ci.lsst.org/job/MTDomeTrajectory%20Conda%20package/"""
"DM-26493","Story","ts_main_telescope",3,"Support the Shared Enum in LabVIEW","""Support the shared enum in LabVIEW. Based on Dave, the bug described in DM-26270 can not be fixed in his side. Therefore, the ts_SALLabVIEW may need to be updated to support this.    To do this, maybe I will need to pass """"const"""" and """"enum : xxxx"""" in the IDL file.    This ticket will try to fix the *space/tab* and *private* in the IDL file."""
"DM-26489","Story","ts_main_telescope",0,"Fix references to atdometrajectory in ts_mtdometrajectory","""There are a few references to atdometrajectory in the ts_mtdometrajectory package (presumably holdovers from starting the package by copying ts_atdometrajectory). Fix them."""
"DM-26488","Story","ts_qa",3,"Get the CSC Conda jobs running regularly and as part of the daily workflow","""Now that DM-26391 is complete, we have a fairly accurate picture of the state of the CSC Conda jobs.  The next step is to get those jobs running regularly so we get the feedback on the status of the jobs.    We also want the wrap the Conda jobs into the daily workflow.  This will require a lot of coordination and logic."""
"DM-26486","Bug","Qserv",1,"Qserv Replication worker service crashes after receiving spurious packets","""The server crashes if a clients sends an incorrect or a random) request. Here is what's reported in the Replication/Ingest/Export worker's log file:    The problem could be triggered by any random request like:  {code:bash}  curl http://qserv-db34:25001/meta/version -X GET  {code}  Note that the service has a proprietary (non-HTTP) binary protocol based on Protobuf.    A proposed solution is to reinforce the code to catch exception {{std::overflow_error}} and close a connection with the offending client."""
"DM-26485","Story","afw",1,"Add vectorized pure-python interface to convert ra/dec to and from x/y for SkyWcs","""Currently, there is no direct way to convert numpy arrays of ra/dec to and from x/y with a {{SkyWcs}}, which leads to inefficiencies when computing {{SpherePoint}} for large numbers of positions.  Some of this would be fixed with DM-19235 which I believe is tricky because of the memory ordering.    As it turns out, AST supports using numpy arrays without any memory finagling, for example in {{suprême}}: https://github.com/LSSTDESC/supreme/blob/75a2008d203e28b3d42738374823f1f5e42d9db1/supreme/utils.py#L157    This ticket will add {{wcs.xyToRaDec}} and {{wcs.raDecToXY}} (or some suitable name) to {{wcsContinued.py}} to allow general access to these very fast ways of interfacing with the AST code.  I don't believe the names {{skyToPixel}} and {{pixelToSky}} can be used because pure-python methods can't do the overloading (plus these don't return or take quite the same type of data structures)."""
"DM-26521","Bug","Qserv",0.5,"Requests processor in the Qserv Replication worker crashes after receiving spurious packets","""Fix a problem in the replication worker processing requests from the master controller. It was overlooked at [DM-26486].    *TODO*: As a side note, plan (in a separate ticket) for refactoring the worker services to have a common base class which would provide communication services. """
"DM-26517","Story","ts_middleware",1,"Simplify simulation mode support in BaseCsc","""At present supporting simulation modes in CSCs requires overriding 3 methods: BaseCsc.implement_simulation_mode, BaseCsc.add_arguments, and BaseCsc.add_kwargs_from_args. Simplify this as follows:    Add a valid_simulation_modes argument to BaseCsc. Default it to None for backwards compatibility. If not None then do the following:  * Test the {{simulation_mode}} argument in the {{BaseCsc}} constructor.  * Make {{BaseCsc.handle_simulation_mode}} a no-op.  * Add a {{--simulate}} argument to {{BaseCsc.amain}}'s argument parser, if there is more than one valid simulation mode.    This will greatly reduce the amount of extra work needed by CSC authors to add a simulation mode.    Also convert at least one other package to use this new technique, to check the design."""
"DM-26502","Story","ts_aos|ts_main_telescope",3,"Support the LSST FAM in AOS Modules in Phase 1","""Support the LSST full-array mode (FAM) in AOS modules in phase 1. The SE team will provide the needed parameters such as the off-axis correction, sensitivity matrix, etc. This task is to update the *ts_wep*, *ts_ofc*, and *ts_phosim* to support the following evaluation of convergence. In the mean time, the SE team will check the calculated wavefront error by *cwfs* with the *ZEMAX* test data. The field points on 21 rafts will be checked and evaluated. After this cwfs test is done, the related test data will be added into *ts_wep*.    Bo verified the cwfs with ZEMAX in the following: [fam.ipynb|https://github.com/bxin/cwfs/blob/master/examples/fam.ipynb].    The sensitivity matrix file is [^senM_189_19_50.yaml]. The field numbers start from lower left, then go up: [^senM_189_200812.pdf].       This task is the phase 1."""
"DM-26530","Improvement","Qserv",3,"Improved batch mode of ingesting table contributions into Qserv","""The current implementation of the Ingest system has a binary tool *{{qserv-replica-file-ingest}}* providing the _batch_ mode for loading a list of contributions (read from input files) into various tables:    Where, the mandatory parameter *{{<contributions>}}* requires a *{{JSON}}*-formatted text file with an array of file contributions into potentially any tables using multiple transactions. Here is an example of such file:  {code:yaml}  [{""""worker-host"""":""""qserv-db01"""",""""worker-port"""":25002,""""transaction-id"""":123,""""table"""":""""Object"""",""""type"""":""""P"""",""""path"""":""""input/chunk_187107_overlap.txt""""},   {""""worker-host"""":""""qserv-db01"""",""""worker-port"""":25002,""""transaction-id"""":123,""""table"""":""""Object"""",""""type"""":""""P"""",""""path"""":""""input/chunk_187107.txt""""},   {""""worker-host"""":""""qserv-db02"""",""""worker-port"""":25002,""""transaction-id"""":123,""""table"""":""""Object"""",""""type"""":""""P"""",""""path"""":""""input/chunk_187108_overlap.txt""""},   {""""worker-host"""":""""qserv-db02"""",""""worker-port"""":25002,""""transaction-id"""":123,""""table"""":""""Object"""",""""type"""":""""P"""",""""path"""":""""input/chunk_187108.txt""""},   {""""worker-host"""":""""qserv-db01"""",""""worker-port"""":25002,""""transaction-id"""":123,""""table"""":""""Object"""",""""type"""":""""P"""",""""path"""":""""input/chunk_187109_overlap.txt""""},   {""""worker-host"""":""""qserv-db01"""",""""worker-port"""":25002,""""transaction-id"""":123,""""table"""":""""Object"""",""""type"""":""""P"""",""""path"""":""""input/chunk_187109.txt""""},   {""""worker-host"""":""""qserv-db02"""",""""worker-port"""":25002,""""transaction-id"""":123,""""table"""":""""Object"""",""""type"""":""""P"""",""""path"""":""""input/chunk_187110_overlap.txt""""},   {""""worker-host"""":""""qserv-db02"""",""""worker-port"""":25002,""""transaction-id"""":123,""""table"""":""""Object"""",""""type"""":""""P"""",""""path"""":""""input/chunk_187110.txt""""}  ]    qserv-replica-file-ingest FILE-LIST-TRANS <transaction-id> <table> <type> <contributions> [--auth-key=<key>] ...    This file would produce the same yield as the existing one if used like illustrated below:  {code:bash}  qserv-replica-file-ingest FILE-LIST-TRANS 123 Object P <contributions>  {code}    Advantages of the new batch mode:  * the file of contributions is reusable across transactions  * a scope of failures during ingest is limited to a single transactions    (!) Destinations where the tables contributions are meant to be ingested do not change after aborting and restarting transactions.  """
"DM-26550","Story","astro_metadata_translator|obs_lsst",2,"Add observation_reason to ObservationInfo","""In DM-26476 we discuss a need for an observation reason to be added to gen3 registry. This requires that we add the concept to ObservationInfo. This will be a string that can have any value.    Provide a default implementation that returns a reason of """"science"""" for observation_type of science, and """"calibration"""" for all other cases. Then provide obs_lsst implementation that looks for TESTTYPE header and overrides it with that value. We do not yet know the name of the header that will be used for LSSTCam and ComCam.    Adding reason suggests that using """"science"""" for observation_type might be too generic since that was previously trying to serve both roles. Code already relies on """"science"""" for observation type though so it will be difficult to switch those to using reason instead."""
"DM-26546","Story","ts_middleware",0,"Change --simulate to true/false if there are only two valid states","""Change the --simulate argument in BaseCsc.amain to be true/false if there are only two valid simulation modes."""
"DM-26540","Story","Middleware",5,"NCSA Test stand DDS debug 2","""Continue testing DDS deployments with the NCSA test stand.   Explore the impact of seperating subsystems into dds """"partitions"""""""
"DM-26539","Story","ctrl_mpexec",1,"w_35 ci_hsc_gen pipeline.sh dying due to SSL Error","""w_35 of the software stack + ci_hsc_gen3 dies in pipeline.sh with      [~madamow] first generated the error and I was able to duplicate it.  While a full run has not yet completed using -j 1, it was run far enough to get through the first few PipelineTasks without having this error.  No error messages from previous steps in scons.  Full output of pipeline.sh:    The error seems to repeat multiple times and then we get lines like:     """
