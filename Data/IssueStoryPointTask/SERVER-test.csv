"issuekey","type","components","storypoint","title","description_text"
"SERVER-44991","Bug","WiredTiger",1,"Performance regression in indexes with keys with common prefixes","""Test creates 5 collections with 10 indexes each. Indexes are designed to have keys with substantial common prefixes; this seemed to be important to generate the issue. Collections are populated, then are sparsely updated in parallel, aiming for roughly 1 update per page, in order to generate dirty pages at a high rate with little application work.    !compare.png|width=100%!    Left is 4.0.13, right is 4.2.1. A-B and C-D are the update portions of the test. The performance regression is seen in the timespan for the update portion, and in the average latency.    The rate of pages written to disk and pages evicted is substantially lower in 4.2.1. In this test dirty fill ratio is pegged at 20%, so the rate at which pages can be written to disk is the bottleneck.    The test is run on a 24-CPU machine, so the CPU utilization during both tests is roughly what would be expected with ~5 constantly active application threads, plus 3-4 constantly active eviction threads. But in spite of the same CPU activity for eviction, we are evicting pages at a much lower rate, so we must be using more CPU per page evicted in 4.2.1. Perf shows that this additional CPU activity is accounted for by __wt_row_leaf_key_work."""
"SERVER-45074","Improvement","Build",2,"Commit queue commit message validation should double check the ticket ID (ticket key)","""It is a real pain if you make a commit that has the wrong ticket number prefix - you end up needing to do a bunch of manual work to reconcile the various places things got logged incorrectly to paper over the mistake.    Since we are adding validation for commit messages in other ways (formatting, etc.) we should see if it would be possible to also validate against JIRA that the ticket you are nominally committing to makes sense: is open, is assigned to you, etc.  """
"SERVER-45113","New Feature","Testing Infrastructure",2,"Dump core on test failure","""When a test fails, resmoke should call hang_analyzer.py to create core dumps for currently-running mongod processes. Modify hang_analyzer.py to have an option to only dump, without the rest of the analysis."""
"SERVER-45544","Bug","Testing Infrastructure",3,"burn_in_tests for certain tests can time out regardless of what changed","""I recently worked on a ticket that modified the create_index_background_unique_collmod.js workload. I noticed that, even doing a patch build with a variable name change on the test would cause burn_in_tests to time out, possibly due to this test not interfacing well with the way burn_in_tests is run.    """
"SERVER-45128","Task","Sharding",1,"Reset batchtime for ""~ Linux DEBUG WiredTiger develop"" build variant to default","""The batchtime was increased to 7 days under SERVER-45127 to temporarily disable the build variant until the storage engines team has time to investigate the recent redness."""
"SERVER-45313","Bug","Testing Infrastructure",1,"validate commit message doesn't escape commit messages properly","""There was an issue with validate_commit when a commit message had both double quotes ("""") and parens in it. It caused a bash error when we tried to process [it|https://evergreen.mongodb.com/task/mongodb_mongo_master_commit_queue_validate_commit_message_patch_185facf0acf9c22e09893051a28040e8ee39292b_5e0641fbe3c33123080b2a3c_19_12_27_17_41_04##%257B%2522compare%2522%253A%255B%257B%2522hash%2522%253A%2522185facf0acf9c22e09893051a28040e8ee39292b%2522%257D%255D%257D]. We should ensure that commit messages are properly escaped when passed to the script.  ----  As a Server engineer,  I want validate_commit to properly handle characters that need to be escaped,  so that my commit message can properly be validated.  ----  AC:  * validate commit is able to properly handle commit message with characters like: """", (, ), ', etc."""
"SERVER-45320","Improvement","Testing Infrastructure",1,"Remove evergreen client from buildscripts","""All uses of the [local evergreen client|https://github.com/mongodb/mongo/blob/master/buildscripts/client/evergreen.py] in buildscripts have been removed from the mongo repository (except a metrics script that is not currently being used) in favor of [evergreen.py|https://github.com/evergreen-ci/evergreen.py]. We should remove the metrics script and client so that we no longer have to maintain them and no one accidentally starts using them.  ----  As a server engineer,  I want the local evergreen client code removed,  so that I no longer have to maintain it.  ----  AC:  * `buildscripts/client/evergreen.py` is removed.  * all tests and dependencies on `buildscripts/client/evergreen.py` are removed."""
"SERVER-45355","New Feature","Testing Infrastructure",2,"Send SIGABRT for failed tests that use Jasper","""SERVER-45342 modifies process.py in resmoke to allow SIGABRT to be sent to fixtures when a test fails. We also need to allow jasper processes to do the same thing so core dumps are generated    The main change is to allow stop() in jasper_process.py to stop the process with sigabrt, similar to how process.py does it [here|https://github.com/mongodb/mongo/blob/5a14578a131325525fc92cbb1ee315ebb35add8d/buildscripts/resmokelib/core/process.py#L196]"""
"SERVER-45377","Improvement","Replication|Testing Infrastructure",1,"Add methods to globally disable and re-enable hang analyzer in tests","""While the passing the '{{runHangAnalyzer=false}}' argument to {{assert.soon}} works well in mosts tests, there are a few replica set tests that expect throws of {{assert.soon}} calls located several functions deep into the ReplSetTest fixture.    In such cases, it would be cleaner if we had global enable/disable methods for the hang analyzer and let tests wrap an enable/disable pair around the places where they expect {{assert.soon}} to fail, to be used as such:  """
"SERVER-45766","Task","Testing Infrastructure",1,"Remove ""requires"" from the server yaml","""As a EVG engineer,  I want the server evergreen.yml to remove uses of 'requires'  So that I no longer have to support 'requires' functionality.    ----    AC:  * All uses of requires in the server evergreen.yml have been removed.     ----    While discussing a request around creating dependencies dynamically, it became apparent that requires is poorly understood and rarely used. From grepping all static configs, it looks like only the server uses it.    From discussing this with [~david.bradford], it sounds like as a result of moving towards more task generation and uses, the current uses of requires are no longer important. The original implementation was motivated (EVG-720 by a cleanup requirement that no longer exists and is better solved in other ways in modern Evergreen. We should therefore remove it from the server config so that Evergreen can remove it from its code base."""
"SERVER-45491","New Feature","Testing Infrastructure",2,"Add resmoke.py option to save mongod.log and mongos.log files",""" [^SERVER-45491.patch] Copied from TIG-2235 to be a SERVER ticket.    When resmoke.py runs replica set tests, the mongod servers log to stdout by default. This can be overridden only by modifying the Javascript test code to pass useLogFiles to ReplSetTest.    It would be useful to me have a way, without modifying the Javascript test code, to make the servers log to files for post-test analysis. I propose a resmoke.py command-line option that enables logging to disk and prevents post-test cleanup of the logfiles."""
"SERVER-45644","Improvement","Testing Infrastructure",3,"Reevaluate timeouts used by burn_in_test","""In burn_in_tests, we will [dynamically set timeouts|https://github.com/mongodb/mongo/blob/b758eb90dd982460af62fbb61737f935dae9b828/buildscripts/burn_in_tests.py#L462-L519] based on the expected runtime  of the test being run. There have, however, been [some issues|https://evergreen.mongodb.com/task/mongodb_mongo_master_enterprise_rhel_62_64_bit_display_burn_in_tests_patch_e3dd9e80e38f3528bc50c3e1115c46a0687885fa_5e1602857742ae2ce7683e71_20_01_08_16_26_12##%257B%2522compare%2522%253A%255B%257B%2522hash%2522%253A%2522e3dd9e80e38f3528bc50c3e1115c46a0687885fa%2522%257D%255D%257D] with the timeouts being used. We should investigate if we can improve the timeout calculations.    ----    As a Server engineer,  I don't want my burn_in_tests runs to timeout if there are not issues,  So that I do not have to spend time investigating non-issues.    ----    AC:  * burn_in_timeouts are adjusted to generate less false-timeouts."""
"SERVER-45680","Improvement","Testing Infrastructure",2,"Burn_in_tests should pick up changed files in mongo-enterprise-modules files","""Currently, burn_in_tests picks up changed files in the mongodb/mongo repo. It should do the same for the 10gen/mongo-enterprise-modules repo.    User story:  As a MongoDB engineer, I should be able to run burn_in_tests patch builds that run the jstests I've changed in the 10gen/mongo-enterprise-modules repo, ensuring that my jstests changes do not cause them to fail.    AC:  * Burn_in_tests picks up changes to jstests in 10gen/mongo-enterprise-modules repo"""
"SERVER-45715","Bug","Storage",1,"Fix spelling mistake in warning around failure to get storage stats","""https://github.com/mongodb/mongo/commit/3f469e451c7ff6a46d908197da87d018dce27bdf    Introduced a warning message with a spelling mistake: """"aquire"""" -> """"acquire"""".    This ticket should fix that.  """
"SERVER-45713","Improvement","Build",2,"Run rhel7 push and publish tasks on large rhel70 distro","""RHEL7 repos are too big for rhel70-small distro.  Push and publish_reo tasks need more than 80G of free space now."""
"SERVER-45730","Improvement","Build",2,"update commit queue message validation","""We should change the commit message validation to:   * raise an error when a ticket reference is omitted. Currently this is a warning.   * handle revert messages where the author can be different to the Jira assignee. Currently this only generates a warning but it should be changed to be handled the similar as a backport."""
"SERVER-45764","Bug","Testing Infrastructure",1,"Generate resmoke tasks need to take setup time into account when setting timeouts","""When we generate timeouts in generate_resmoke_suites, we calculate the timeout to use based on the historic runtime of that tests being run. However, we fail to include any of the time spent running setup, including the time required to download the artifacts. We do include a buffer in the calculated timeouts, so we don't hit this too frequently. But that buffer is a lot smaller than we thought and any extra time spent setting up could cause the tests to hit timeouts even if the tests run at normal times."""
"SERVER-45748","Bug","Testing Infrastructure",1,"burn_in_tags_bypass_compile is not looking at the correct task","""The burn_in_tags_bypass_compile scripts is not looking at the correct task to download the compiled artifacts from. As a result, all compile tasks generated from burn_in_tags are recompiling the server instead of just downloading already compiled files. It looks like this has been happening since August."""
"SERVER-45832","New Feature","Testing Infrastructure",2,"Generate selected tasks in a patch using task mappings","""As a mongoDB engineer,  I should be able to run the selected_tests_gen task,  and know that it will run all tasks for a given set of related task mappings returned by selected-tests service,  So that I know all tasks that are affected by my code changes will be run    ------------------------------    AC:    * When I run the selected_tests_gen task in my patch build, it runs all tasks related to my file changes (using the task mappings model)  * When I run buildscripts/selected_tests.py locally, it logs which tasks and steps are executed so that other engineers can debug any issues encountered.  * When an execution task(s) and its parent display task are returned by the task mappings endpoint for a given source file, the selected_tests_gen task should know to run only the _gen task associated with that parent display task, not the execution task(s)"""
"SERVER-45958","Improvement","Testing Infrastructure",2,"End to end tests for selected_tests","""User story:  As a server engineer,  I want to know that any changes made to code related to buildscripts/selected_tests_py will be tested via and end to end test of buildscripts/selected_tests_py, so that I can be sure that the script and its dependencies are functioning correctly.    AC:  * At least 1 end to end tests for buildscripts/selected_tests_py exists and is run as part of """"buildscripts_test""""."""
"SERVER-45949","Improvement","Testing Infrastructure",2,"Update validate commit message client to work with new patch description standard","""The current patch description format is the commit message.    The new patch description will be the following format:       Commit Queue Merge: '<commit message>' into '<owner>/<repo>:<branch>'    Multiple modules are supported as follows:       Commit Queue Merge: '<commit message 1> <- <commit message 2>' into 'owner/main_repo:master'    This description comes from the evergreen client executable and since we can't force a client upgrade, the validate client must support both formats.     """
"SERVER-46029","Task","Testing Infrastructure",0,"do not write core files in the hang analyzer when running locally (sans Evergreen)","""Currently, the hang analyzer can run for local testing if an assert.soon times out.  This can write large core files into the current directory, silently, which can consume a lot of disk space.  I think we should disable the writing of core files unless running under Evergreen."""
"SERVER-46146","Bug","Testing Infrastructure",1,"Reduce the number of BVs running the hang analyzer unittests","""There's no need to run the shell hang analyzer unittest on more than a handful of build variants as we don't expect the behavior of Python to differ."""
"SERVER-46141","Improvement","Testing Infrastructure",3,"Testing burn_in_tests requires multiversion installation","""When I run the tests for burn_in_tests (`python -m unittest buildscripts\/tests\/test_burn_in_tests.py`), I get the following error that mongo-4.2 is not installed:      My understanding is that this test requires a developer to run `buildscripts\/evergreen_gen_multiversion_tests.py` locally in order to create the necessary multiversion mocks that the test needs to run. We should separate these tests into a separate file so that testing burn_in_tests does not also test multiversion setup, since they are different things.    As a MongoDB engineer, I should be able to run burn_in_tests tests without needing any multiversion-related dependencies to be installed.    AC:  * The above error does not occur when running test_burn_in_tests.py  """
"SERVER-46125","Task","Performance",5,"system_perf.yml and perf.yml cleanups","""Following from SERVER-46082 etc/perf.yml and etc/system_perf.yml can now be cleaned up a bit.   * source dsienv.sh can be removed   * setup-dsi-env.sh can be removed   * some of the shell.exec blocks can be merged, at least for perf.yml   * perf.yml has diverged between master and 4.2, for example mongod.log ends up in different directory. This should be reconciled to stable branches.   * In Microbenchmarks there are two mongod.log checks that are always green because they check files from dsi unittest-files. Pending future work on dsi libanalysis code, suggested solution is to just `rm -r dsi/bin/tests`   * Ryan: Prefer that also perf.yml uses run-dsi.   * I added a couple `set -o verbose` when troubleshooting bin/analysis.py. This could be removed I think.   * I think it's possibly related to perf.yml that analysis.py / mongod.log check isn't picking up the test start and end times from perf.json. As a workaround, I disabled the election related checks in analysis.common.yml.   * I bet boostrap.production isn't actually needed in perf.yml?   * Addition from team discussion:   ** Consolidate setupcluster into one DSI command    ** Read from expansions.yml instead of what sysperf currently does to write runtimesecret.yml, etc.    For system_perf.yml, consider also renaming the yaml file expansions to match what is used in dsi:   * cluster -> infrastructure_provisioning   * setup -> mongodb_setup   * test -> test_control"""
"SERVER-46167","Task","Upgrade/Downgrade",5,"Enumerate and remove Storage-related FCV 4.2-dependent code and tests","""The following tasks need to be completed once we branch for 4.6:    1. Create a list of tickets with code and tests to remove, add them to the 4.6 Upgrade/Downgrade Epic, and mark them as """"is depended on by"""" this ticket. This will assist the Upgrade/Downgrade team in tracking progress. If there is an insufficient amount of work to warrant multiple tickets, then the work can be done under this ticket directly.    2. Complete all necessary tickets promptly.    3. Create a ticket identifying Storage-related generic upgrade/downgrade references that the Upgrade/Downgrade team should update now that the 4.2-dependent references have been removed."""
"SERVER-46236","Bug","Testing Infrastructure",2,"Selected_tests_gen task should run tasks on all required variants, not just enterprise-rhel-62-64-bit ","""Currently, the selected_tests_gen task [only runs tasks on the enterprise-rhel-62-64-bit variant|[https://github.com/mongodb/mongo/blob/74306a6fd07a7194567f77c930e0dc4e18098df3/etc/evergreen.yml#L1552|https://github.com/mongodb/mongo/blob/74306a6fd07a7194567f77c930e0dc4e18098df3/etc/evergreen.yml#L1552.]][.|https://github.com/mongodb/mongo/blob/74306a6fd07a7194567f77c930e0dc4e18098df3/etc/evergreen.yml#L1552.] As specified in the [Design doc|[https://docs.google.com/document/d/1azKrJr3babowhr6M8vs9cCTQOmLdUeyqmyVKp_ENSOw/edit#]], the selected_tests_gen task should run tasks from all required builders.      As a MongoDB engineer,  I should be confident that the selected_tests_gen task is running any affected tasks on all required builders,  so that no required tasks are missed.         AC:    * selected_tests_gen task can result in tasks being run on enterprise-rhel-62-64-bit, enterprise-windows-required, linux-64-debug, enterprise-ubuntu-dynamic-1604-clang, and ubuntu1804-debug-aubsan-lite."""
"SERVER-46267","Bug","Testing Infrastructure",3,"bypass compile on burn_in_tags is broken","""The bypass compile for burn_in_tags is not working. You can see in the [this patch build|https://evergreen.mongodb.com/version/5e3d7a85c9ec4401bd159b1b]. There are a few things wrong.    * The rhel-62 compile was also bypassed, so the burn_in_tags needs to use the mainline compile artifacts, but it is trying the use the rhel-62 artifacts, which do not exist.  * The compile task no longer generates a """"shell"""" file and bypass compile is attempting to copy that file.  * The compile_TG now includes the package task by default, which add a 25 minute task to the burn_in build variants.    We should fix all of these things.    ----    As a Server engineer,  I want bypass compile to work with burn_in_tags,  So that I don't have to wait to recompile artifacts that have already been compiled.    ----    AC:  * burn_in_tags reused compiled artifacts even if the rhel 62 compile used bypass compile.  * burn_in_tags does not run package in the generated build variants."""
"SERVER-46374","Bug","Testing Infrastructure",1,"Move noPassthrough test to run on large distro on rhel6.2 build variants","""We have been seeing several cases where the noPassthrough suites are running out of memory on rhel 6.2. We can move them to large distros to avoid this."""
"SERVER-46439","Improvement","Testing Infrastructure",2,"Add acceptance tests for burn_in_tags","""Add end to end tests for buildscripts/burn_in_tags.py.    As a server engineer,  I want end to end tests for burn_in_tags  so that I can makes changes to the scripts without worrying about breaking things.    AC    At least 1 test executes the main body of burn_in_tags."""
"SERVER-46437","Improvement","Testing Infrastructure",2,"Create a baseline build variant to understand task splitting overhead","""It would be nice to have a way to understand the overhead associated with splitting up tasks into subtasks. This would allow us to watch any runtime issues that might be hidden by splitting up a task (e.g. large test runtime increases being masking by more aggressive splits of the tests). It would also help us understand if and where there are opportunities for improvements in task splitting.    One way to accomplish this would be to have a build variant that mimics a standard build variant, but without splitting the tasks. We wouldn't need to run the task frequently, once a week would likely be enough.     ----    As a Dev Prod engineer,  I want a build variant without task split to run,  So that I can measure the overhead task splitting causes.    ----    AC:  * A way of measuring the overhead of task splitting exists."""
"SERVER-46643","Improvement","Testing Infrastructure",2,"eslint running for 30+ minutes in Commit Queue for enterprise only changes","""We are frequently seeing eslint take over 30 minutes in the commit queue. Looking at recent occurrences of this, it appears to happen for enterprise only changes. My guess is that since there are no changes to the mongo repository, it is linting the entire repository.    ----    As a server engineer,  I want enterprise only changes to the commit queue to not take over 30 minutes to lint,  So that I don't have a long-running task blocking the commit queue.    ----    AC:  * Enterprise-only commit queue entries do not take over 30 minutes to process."""
"SERVER-46691","Improvement","Testing Infrastructure",3,"Rework the timeout task in evergreen.yml and ensure analysis & archival works","""Once SERVER-46687 is completed, the timeout task in evergreen.yml needs to be modified to:  - If running powercycle or jepsen, run the hang-analyzer as before (call {{resmoke hang-analyzer args directly}} - this just means keep [this section|https://github.com/mongodb/mongo/blob/c553f6acd0ce7768d25a2dcdfa9358aa22b5ee55/etc/evergreen.yml#L3526-L3577].  (Resmoke does not execute powercycle, so the mechanism outlined in this project will not work for it.)    otherwise:  call new script that will:  - Send sigusr1/windows event to resmoke processes explictly - the code for this exists in hang_analyzer.py, it needs to be moved into it's own file that still lives in mongo/buildscripts.  - Wait for the resmoke processes to exit. Since we already know the pids this should be easy."""
"SERVER-46688","Improvement","Testing Infrastructure",1,"Use TestData.inEvergreen to determine if data files should be archived","""The [--archiveFile|https://github.com/mongodb/mongo/blob/c553f6acd0ce7768d25a2dcdfa9358aa22b5ee55/buildscripts/resmokelib/parser.py#L55-L60] flag needs to be specified for archival to be done. The intention was for local invocations of resmoke to not archive data files in s3.     The same functionality can be achieved by checking {{TestData.inEvergreen}} without needing to set a command line argument."""
"SERVER-46684","Improvement","Testing Infrastructure",2,"Repackage the hang-analyzer as a resmoke subcommand","""- Move hang_analyzer.py to the resmoke directory  - Rewire all usages of the hang-analyzer to be run through new command syntax (assert.soon, evergreen.yml 'run hang analyzer'  - Ensure running the hang-analyzer locally works as it does now  - Update documentation and do engineer outreach to ensure users are aware of the change  - buildscripts/hang_analyzer.py will print the new command syntax  - backport to 4.2    The exact syntax will need to be fleshed out, but the new command should at least be able to accept {{pids}} and {{process_types}} for backwards compatibility."""
"SERVER-46682","Improvement","Testing Infrastructure",3,"Reuse debugger process for processes of same type in hang_analyzer.py","""Reloading the symbols for every process is another bottleneck. To alleviate this, hang_analyzer.py will be modified to reuse the same debugger process and analyze all processes of the same type (ex. All mongod processes will be analyzed in the same debugger process).   - Processes will be grouped by process type (Ex. all mongod processes)  - A single process will be created that will:        The debugger scripts are all hardcoded strings, the [script for GDB|https://github.com/mongodb/mongo/blob/c553f6acd0ce7768d25a2dcdfa9358aa22b5ee55/buildscripts/hang_analyzer.py#L363-L385] is especially ugly. GDB has an [API for python|https://sourceware.org/gdb/onlinedocs/gdb/Python-API.html], so if this change turns out to be non-trivial to hardcode as plaintext, we can consider rewriting it to use the python API.    As part of this ticket, ensure the performance improves.      """
"SERVER-46732","Improvement","Testing Infrastructure",1,"Cap number of tasks generated on non-required build variants","""We recently hit an issue where the amount of evergreen project config generated by generate.tasks exceeded the maximum document size and started causing issues. It looks like this was caused by the number of tasks being generated as each task adds to the project config. It also looks like this would only happen if all the build variants in the version were run.     We could reduce the chance of this happening by capping the number of sub-tasks we will generate for a task in non-required build variants.    ----    As a server engineer,  I want to limit the number of tasks dynamically generated in non-required builders,  So that versions do not hit the maximum document size.    ----    AC:  * non-required builders set a cap on number of tasks to generate."""
"SERVER-46769","Improvement","Testing Infrastructure",3,"Migrate from optparse to argparse","""Python's optparse does not support subcommands, but argparse/click does. To enable doing that, we need to migrate.    * Look into click and whether that would be a better option.  * Define new resmoke syntax with argparse. There are differences between how optparse/argparse work, so the syntax will have to change.   * Add infrastructure for resmoke to run subcommands, with emphasis on extensibility for the future  * Attempt to keep old resmoke syntax (and eventually deprecate). This might not be possible. If not, look into having a legacy flag, or at least print nice error messages to make it easy to figure out the new syntax.   * Update usages of resmoke in the system.  * Update documentation and do engineer outreach to ensure users are aware of the change  """
"SERVER-46813","Bug","Testing Infrastructure",1,"Revert ""Temporarily reduce frequency of randomized testing""","""We implemented a change to reduce frequency of randomized testing, to reduce the number of BFGs being created, so this is to revert that change."""
"SERVER-46827","Task","Testing Infrastructure",3,"E2E tests","""Before working on actual features, add the E2E tests outlined in the test plan and ensure they fail:    Create resmoke unit tests that will test these scenarios:  - Run a single test using a resmoke fixture (simulating a test timeout)  - Run multiple tests using a resmoke fixture (simulating a task timeout)  - Run a test using mongorunner to spin up mongods (simulating a non-fixture test)    For each test, the script that sends a signal to resmoke will be called. The same script waits for those processes to have exited. Once they have, we will inspect that the analysis and archival has been done for all cases above. This should test everything except for evergreen calling it’s timeout task.     When beginning to add project features, ensure they pass these tests."""
"SERVER-46820","Task","Testing Infrastructure",2,"Kill hung processes as the last step in resmoke's signal handler","""After the signal handler has finished running the hang-analyzer, it will kill the hung processes, similarly to what archival does now. This is necessary to ensure resmoke can make forward progress and shut itself down so that the evergreen agent does not timeout while waiting for resmoke processes to exit.    Note that archival will still need to be able to shut down hung processes in the case that the test fails normally without timing out."""
"SERVER-46867","Bug","Testing Infrastructure",2,"Ensure that a db directory is created even when alwaysUseLogFiles is enabled","""When alwaysUseLogFiles is enabled, the noCleanData option is set to make sure that previously-logged data is not deleted. This will prevent resetDbpath() from being called. However, resetDbpath() is what is used to create the db path in the first place.    We need to create the directory if it doesn't exist, while allowing existing paths to not be cleaned."""
"SERVER-46851","Improvement","Testing Infrastructure",1,"Decrease the number of jobs in logical session cache tests","""The logical session cache tests are frequently running out of memory due to the host size they are running. Reducing the number of jobs should help them use less memory."""
"SERVER-46842","Improvement","Testing Infrastructure",1,"resmoke.py shouldn't run data consistency checks in stepdown suites if a process has crashed","""resmoke.py ordinarily checks that a test didn't cause the server to crash [by calling {{self.fixture.is\_running()}}|https://github.com/mongodb/mongo/blob/d09c84a0856060c38e58d971599966af8719a454/buildscripts/resmokelib/testing/job.py#L180] after the test finishes. However, due to the stepdown thread and the job thread only being synchronized by calling {{ContinuousStepdown.after_test()}}, [it isn't safe to check whether the fixture is still running|https://github.com/mongodb/mongo/blob/d09c84a0856060c38e58d971599966af8719a454/buildscripts/resmokelib/testing/job.py#L32-L37] immediately after the test finishes.    {code:python}  # Don't check fixture.is_running() when using the ContinuousStepdown hook, which kills  # and restarts the primary. Even if the fixture is still running as expected, there is a  # race where fixture.is_running() could fail if called after the primary was killed but  # before it was restarted.  self._check_if_fixture_running = not any(      isinstance(hook, stepdown.ContinuousStepdown) for hook in self.hooks)  {code}    Skipping this check causes resmoke.py to continue to run the other data consistency checks, even when a process in the MongoDB cluster has crashed. While misleading for Server engineers in terms of causing them to click on the """"wrong"""" link in Evergreen for the task failure, it also have a severe negative impact on our automated log extraction tool by preventing it from finding relevant information. We should ensure process crashes in test suites using the {{ContinuousStepdown}} hook prevent other tests and hooks from running. I suspect having [{{_StepdownThread.pause()}}|https://github.com/mongodb/mongo/blob/d09c84a0856060c38e58d971599966af8719a454/buildscripts/resmokelib/testing/hooks/stepdown.py#L427-L436] check that fixture is still running as the last thing it does would accomplish this."""
"SERVER-46891","Bug","Testing Infrastructure",2,"Selected_tests_gen is creating tasks that should be excluded","""Selected_tests_gen should not generate non-jstest tasks. Currently, the logic it uses to exclude non-jstest tasks is only run on tasks generated by task_mappings (see [here|[https://github.com/mongodb/mongo/blob/36ae8a4824a88bd49ab5fa62740419c10c6bc39d/buildscripts/selected_tests.py#L192-L196]).] We should also run this logic on tasks generated by test_mappings. Currently, some tasks generated by test mappings are resulting in non-jstest tasks being generated (see example [here|[https://evergreen.mongodb.com/version/5e6d148f2fbabe4bcd3215b5]] which shows _concurrency* tasks being generated).         As a server engineer, I should know that selected_tests_gen only generates jstest tasks, to be in line with the scope of the Selected Tests project.         AC:  * Changing the files that are changed in the version above should not result in concurrency_* tasks being generated"""
"SERVER-46887","Improvement","Testing Infrastructure",0,"Use threshold of 0 in selected_tests_gen","""As part of https://jira.mongodb.org/browse/TIG-2412, we determined that the best threshold to use is 0.     As a server engineer, I should know that the threshold used to determine which tasks to run for selected-tests is 0, since that is the threshold that most accurately captures which tasks should be run based on my code changes.    AC:  * Threshold is set to 0 in selected_tests_gen here: [https://github.com/mongodb/mongo/blob/36ae8a4824a88bd49ab5fa62740419c10c6bc39d/buildscripts/selected_tests.py#L56.]     """
"SERVER-46914","Bug","Testing Infrastructure",1,"burn_in_tests is looking at multiversion in non-multiversion case","""The burn_in_test script is failing to generate task in the normal case (non-multiversion) because it is attempting to look up multiversion information even though multiversion has not been setup.    See [here|https://evergreen.mongodb.com/task/mongodb_mongo_master_enterprise_rhel_62_64_bit_burn_in_tests_gen_patch_8c1515929f34d41dbefbb9476e1dd893d523ad01_5e70dbc89ccd4e532fc74873_20_03_17_14_16_56##%257B%2522compare%2522%253A%255B%257B%2522hash%2522%253A%25228c1515929f34d41dbefbb9476e1dd893d523ad01%2522%257D%255D%257D] for an example.     If burn_in_tests is not running in multiversion mode, it should not look at multiversion configuration."""
"SERVER-47004","Bug","Testing Infrastructure",2,"eslint is not properly linting enterprise modules","""eslint is not be run properly in the commit-queue and allowing lint failures to be introduced. See [here|https://evergreen.mongodb.com/task/mongodb_mongo_master_enterprise_rhel_62_64_bit_lint_eslint_fadc3d1cd88084567e24559f75b216158186bde8_20_03_17_17_17_42] for an example."""
"SERVER-46996","Task","Packaging",1,"all push/publish_packages tasks should run on small hosts","""With the migration to the new architecture for publishing linux packages, it's safe to move all package publication tasks (push/etc.) to using the smallest possible evergreen hosts (i.e. -smalls.)     Additionally if any of these tasks aren't running on linux x86_64, they probably ought to be. """
"SERVER-46983","Task","Packaging",0,"Upload repobuilding packages to correct URL","""Barque service needs the packages uploaded to S3 so it can run the repobuilding job."""
"SERVER-47054","Improvement","Testing Infrastructure",1,"Don't fail due to long timeouts on non-patch builds","""When generating sub-tasks, if we appear to be setting timeouts greater than a certain threshold, we will fail the task generation. This is to inform the patch builder that they are trying to run a patch build that will take a really long time. We require them to manually disable the check if that is something they are sure they want to do.     On mainline builds, however, we should skip this check since there is no one to go manually override it and some of the repeated-execution tests are bumping up against it."""
"SERVER-47165","Bug","Testing Infrastructure",2,"Missing the mongohouse binary for a server patch with no code changes","""{color:#1d1c1d}Missing the mongohouse binary for a server patch with no code changes{color}         {color:#1d1c1d}https://evergreen.mongodb.com/task/mongodb_mongo_master_enterprise_rhel_62_64_bit_mqlrun_patch_c5eea7753b2fe3082d853ff9400117c85ac42dab_5e7e553f7742ae355b925437_20_03_27_19_34_40{color}"""
"SERVER-47312","Improvement","Testing Infrastructure",3,"Run hang_analyzer.py via assert.soon() without calling gcore on ASan builders","""The changes from [e89c041|https://github.com/mongodb/mongo/commit/e89c041616cbaea0648bb60ce32ddab1f33d3e97] as part of SERVER-45884 disabled running the hang analyzer on ASan build variant (i.e. builders using {{--sanitize=address}}) via {{assert.soon()}} due to {{gcore}} not respecting the {{madvise()}} settings on the 20TB of shadow memory. This had come up previously in SERVER-29886 for the """"timeout"""" phase in the {{etc/evergreen.yml}} project configuration and was resolved by running hang_analyzer.py without the {{-c}} option in order to avoid producing core dumps.    We could similarly have the mongo shell omit the {{-c}} option when running hang_analyzer.py. On a related note - the mongo shell offers an {{_isAddressSanitizerActive()}} function which returns true if it was compiled with {{--sanitize=address}} (we generally assume the server binaries have the same build flags), so we should consider removing {{TestData.isAsanBuild}} to avoid there being two ways of expressing the same thing.    Add a test to check that the hang_analyzer still runs on ASan without dumping core."""
"SERVER-47409","Bug","Querying|Shell",3,"writeconcern>1 gives no error on standalone server","""When i query """"db.collection.insertOne(\{name:""""xyz""""},\{w:2})"""" gives error on standalone server which is correct but """"db.collection.insert(\{name:""""xyz""""},\{w:2})"""" does not.         I got it on mongo enterprise 4.2."""
"SERVER-47592","Bug","Testing Infrastructure",1,"Tasks missing buildvariants in version","""This screen shot is from the """"patches"""" page. I should only see results for five variants, but it looks like there are two additional variants shown with no titles. """
"SERVER-47537","Task","Testing Infrastructure",1,"Adjust frequency of less common build variants on 4.4","""The following build variants are run on most commits on the 4.4 branch, but don't really need to be run that frequently. For comparison, they are being run once a day or less on master.  * ~ Enterprise RHEL 7.0 (no-libunwind)  * ~ Enterprise RHEL 7.0 (Dagger)  * hot_backups RHEL 7.0"""
"SERVER-47547","Bug","Testing Infrastructure",3,"benchmarks*.yml test suites need to be updated after switch to hygienic","""The changes from [a83ee33|https://github.com/mongodb/mongo/commit/a83ee33c56dcfc8cdcfa0dd0c458f6fef89a3113] to exclude the {{hash_table_bm}} microbenchmark from Evergreen have effectively been undone by the file now being run as {{build/install/bin/hash_table_bm}}. This has been causing [the {{benchmarks_orphaned}} task to time out in Evergreen since mid-February|https://evergreen.mongodb.com/task/mongodb_mongo_master_enterprise_rhel_62_benchmarks_benchmarks_orphaned_876b3af1091b299884869c34a41f7f37d4dcc0bb_20_02_14_12_24_50/0].    This has also been causing the {{chunk_manager_refresh_bm}} microbenchmark is now being run as part of the {{benchmarks_orphaned}} task rather than the {{benchmarks_sharding}} task."""
"SERVER-47611","Task","Testing Infrastructure",2,"Re-work to_local_args function using argparse","""The current optparse implementation uses a private method {{_get_all_options()}} that is has no argparse equivalent. """
"SERVER-47591","New Feature","Testing Infrastructure",3,"Add build variant that runs some tests with live-record","""Run a smattering of light-weight tests with {{live-record}} in a new BV.    Tests that start up more than 5 processes will be excluded."""
"SERVER-47590","New Feature","Testing Infrastructure",3,"Download and install udb ","""Allow udb to be downloaded and installed before live-record runs.    Need to figure out a way to keep the download URL private."""
"SERVER-47589","New Feature","Testing Infrastructure",2,"Integrate live-record with resmoke.py","""Add an option to resmoke.py to run with live-record"""
"SERVER-47796","Bug","Testing Infrastructure",2,"commit-queue lint-clang-format not run on enterprise changes","""I have the same issue as SERVER-45586 I think.    https://jira.mongodb.org/browse/EVG-7894 It looks to me like maybe the commit-queue CI might not include Enterprise module changes in the lint-clang-format task, the way that the master waterfall CI does. I submitted a change that got through with format errors in enterprise code, only to break the master waterfall and generate a BFG.     https://jira.mongodb.org/browse/BFG-599619    My commit-queue CI run's lint-clang-format task doesn't look like it made a patch from the enterprise module change.    https://evergreen.mongodb.com/task_log_raw/mongodb_mongo_master_enterprise_rhel_62_64_bit_lint_clang_format_patch_085ffeb310e8fed49739cf8443fcb13ea795d867_5ea60ada306615619458e984_20_04_26_22_29_05/0?type=T#L1035    """
"SERVER-47880","Task","Testing Infrastructure",2,"Send SIGSTOP to all processes before attaching to any","""We can prevent processes from getting unstuck when the hang analyzer attaches to them by sending SIGSTOP to all of them first. Commands that run in process threads should still work if we use these commands:  """
"SERVER-47965","Improvement","Testing Infrastructure",3,"Remove multiverison blacklisting from burn_in_tests.py","""See SERVER-47136 for more context.     As part of adding multiversion testing for repl and sharding, there was some blacklisting code that was added to burn_in_tests that was specific for these suites in order to blacklist tests that behaved differently between Mongo version (for example while a bug fix is waiting for a backport).     However, burn_in_tests is probably not the correct place for this blacklisting logic to live. By putting the logic in burn_in_tests, we are effectively saying that the tests are unstable, not that the tests have inconsistencies between versions. It might make more sense to put the logic in resmoke, which burn_in_tests is already using to get the list of tests to run and is already doing some blacklisting."""
"SERVER-47995","Bug","Testing Infrastructure",2,"Extraneous ""Unit Tests"" Link on Failed Tasks","""Failed Evergreen non-unittest tasks have the """"Unit Tests"""" link on them, some of which are tarballs that are in the GBs. E.g. [this one|https://evergreen.mongodb.com/task/mongodb_mongo_master_enterprise_rhel_62_64_bit_replica_sets_multiversion_patch_da4a8e0e85627d6febd8bce3fd87f221e0ff97c6_5eb2be6be3c3310f36bc5cf2_20_05_06_13_42_24##%257B%2522compare%2522%253A%255B%257B%2522hash%2522%253A%2522da4a8e0e85627d6febd8bce3fd87f221e0ff97c6%2522%257D%255D%257D] is 1.8GB.    The unzipped file showed binaries and debug symbols for mongo/d/s that """"gather failed unittests"""" is picking.    We should have the function not run for non-unittest tasks. This requires a change in evergreen.yaml.     """
"SERVER-47989","Bug","Testing Infrastructure",1,"Ensure lint dependencies are specified","""As part of SERVER-47796, we added some extra python dependencies to linting. We should make sure those are included in the lint requirements."""
"SERVER-48017","Improvement","Testing Infrastructure",1,"Don't pass deleted files to lint","""clang_format is hanging in patch builds on he'll 6.2. It looks like it appears to be because it is trying to run against a file that has been removed."""
"SERVER-48112","Improvement","Testing Infrastructure",2,"Use Absolute Imports in Resmoke","""Use absolute imports. E.g., \{{from buildscripts.resmokelib}} instead of \{{from .}}."""
"SERVER-48109","Improvement","Testing Infrastructure",1,"Skip Known-Broken Python Resmoke Tests","""Mark known-broken tests as ignored (in the unittest annotations) rather than via resmoke suite configs. Confirm with original author(s) of the exclude lines."""
"SERVER-48105","Bug","Testing Infrastructure",1,"Selected tests is trying to access data from a NoneType","""I saw this in a patch build using selected tests. It looks like we are trying to use some unavailable data.    """
"SERVER-48090","Task","Testing Infrastructure",1,"Support python 3.6 for evergreen.py and shrub.py","""There was a request via MAKE-1317 to support python 3.6 with our test generation tools. This ticket is to make the updates to server codebase for that support."""
"SERVER-48163","Bug","Testing Infrastructure",1,"Fix jstestfuzz_*_multiversion generation","""A recent refactor to who tasks are generated cause an issue with generating jstestfuzz_*_multiversion tests. It looks like we are trying to generate extra tasks without the needed configuration that causes the generate task to fail."""
"SERVER-48158","Task","Testing Infrastructure",2,"Add Resmoke testing for Jasper's logging endpoint","""As part of a test-driven-development approach we're taking for the Jasper resmoke integration project, we will first add unittests in resmoke for the following scenarios    1. resmoke logging to a """"parent"""" end point directly, with one resmoke and one jasper process logging to a child endpoint  2. Same as above but with two parent endpoints and one child logging endpoint for each parent.    We'd like to assert that the output log exhibits properties of the logging hierarchy. The log itself can go to a file or an in-memory buffer."""
"SERVER-48155","Task","Testing Infrastructure",2,"Remove TestQueueLogger","""The [TestQueueLogger|https://github.com/mongodb/mongo/blob/e2602ad053b2120982fbcac8e33e1ad64e6ec30a/buildscripts/resmokelib/logging/loggers.py#L321] is never logged to directly; it's only used for providing test type information and endpoints to TestLoggers. Now that we're storing logging configuration information globally, we can have each logger determine its own endpoint.    We should remove TestQueueLogger completely and allow TestLogger and HookLogger to be constructed directly and log to the configured endpoints."""
"SERVER-48150","Task","Testing Infrastructure",2,"Streamline resmoke loggers","""We currently [construct|https://github.com/mongodb/mongo/blob/e2602ad053b2120982fbcac8e33e1ad64e6ec30a/buildscripts/resmokelib/logging/loggers.py#L149] JobLoggers from ExecutorRootLogger instances, creating a weird situation where they use some information from ExecutorRootLogger and some information from FixtureRootLogger. After changing how logging configuration is managed, we should be able to construct JobLoggers directly in Job objects."""
"SERVER-48145","Task","Testing Infrastructure",3,"Extract resmoke logging configurations","""ExecutorRootLogger, FixtureRootLogger, and TestsRootLogger mostly exist for configuration purposes, but they create a confusing secondary logger hierarchy. They should be removed in favor of passing configuration information itself to loggers.    This configuration may need to be partially global with its own inheritance relationships to avoid duplicating logic, as long as it's cleanly separated from the loggers themselves."""
"SERVER-48132","Bug","Testing Infrastructure",2,"Selected tests is missing the majority of fuzzer tasks","""The Selected Tests alias is using the regex """".\*\_fuzz.\*"""" to detect fuzzer tasks. However, most of the fuzzer tasks are named something like """"jstestfuzz_*"""", so none of those are being picked up by the fuzzer. We need to update that regex or come up with a better way of selected tasks.    ----    As a server engineer,  I want selected tests to pull in all fuzzer tasks,  So that I don't have to run them manually.    ----    AC:  * All js fuzzer tasks are run in a selected tests patch build."""
"SERVER-50282","Improvement","Testing Infrastructure",0,"Provide a debugging setup script for spawnhosts that load artifacts with coredumps","""Overlong filenames truncating important properties is actually a bug. This ticket has been repurposed to provide a script that unpackages files necessary for inspecting a coredump on a spawnhost. It assumes the bug will be eventually fixed (and the bug only impacts a subset of cases).    *Original Description*  The only time I spawn a host with data files from a test failure is when there's an available core dump that I want to load in GDB. I have a script that programmatically unpackages everything into the appropriate directory. Whether or not server engineers use a script to set up their gdb usage, I believe spawning a host to investigate a core dump is a common use-case.    Unfortunately when filenames are long, important properties [can be trimmed|https://github.com/evergreen-ci/evergreen/blob/86ebeb15ddc211f1390c5cc56af54a3712728e62/operations/fetch.go#L476] such as the keyword {{coredump}}\[1\]. What makes this difficult is that it not only breaks my script (acceptable, this sort of scripting isn't supported or built on some established agreement), but it also breaks my ability to do the corollary work by hand.     Doing a {{tar \-tf <archive>}} AFAIK is a complete filescan. At that point it's faster to just download the coredumps by hand. This arguably defeats the purpose of spawning a host with artifacts loaded.    I don't know what a feasible solution here is. There's probably a reason why filenames are long (for uniqueness? though IMO, unreadable). Some ideas:    * Use shorter strings for {{evergreen fetch}} to generate, which preserve the contents of the archive (at the expense of labeling the variant/task id which AFAIK only becomes a problem if a user fetches artifacts for multiple tasks in the same directory).   ** If this is backwords breaking for established use-cases, consider adding a flag to {{fetch}}, e.g: {{evergreen fetch -t <task> --artifacts --shortnames}}. Let users spawning a host and loading data to opt-in to short filenames  * Add environment variables containing absolute paths to interesting artifacts for users sshing into the instance. Scripts can hook into these without needing to rely on filename patterns. E.g:  ** BIN_ARCHIVE for the archive containing mongod  ** DBG_ARCHIVE for the archive containing mongod.debug  ** COREDUMP_ARCHIVE for the archive containing all coredumps  ** SRC_DIR for the mongodb repository path {{fetch --sources}})    \[1\]  """
"SERVER-48287","New Feature","Testing Infrastructure",1,"Don't run FuzzerRestoreClusterSettings on suites with FCV 4.2","""Same as SERVER-47716, but for jstestfuzz_sharded_multiversion"""
"SERVER-48375","New Feature","Testing Infrastructure",1,"Create jepsen ""smoke-test""","""Add it as a bang (required) builder so we don't accidentally break jepsen in the future."""
"SERVER-48395","Bug","Storage",5,"Extended stalls during heavy insert workload","""While working with the repro for WT-6175 I noticed that there were extended stalls during the insert phase.    !stalls.png|width=100%!    * The stalls seem to end with the start of the next checkpoint  * With checkpoints disabled the stalls lasted as long as 10 minutes  * During the stalls the log reports operations that took the entire duration of the stall to complete  * They appear to have something to do with page splits.    FTDC, logs, and repro script attached. The repro creates two collections of 5 GB each with a 5 GB cache, using 50 client threads on a machine with 24 cpus.  """
"SERVER-48590","Improvement","Testing Infrastructure",1,"QOL improvements for hang-analyzer","""1) Log a raw_stacks file for each process instead of one file for all processes (this was the behavior prior to SERVER-46682). The 'debugger_mongod.XXXXX.log' files that we used to get are now all in the 'debugger_mongod.log' file, but we can't split those out into per process logs because we only call gdb once.    2) Pass '-o=file' into the hang-analyzer usage in assert.soon to get the hang-analyzer output as an artifact in the task.  """
"SERVER-48705","Bug","Testing Infrastructure",2,"resmoke.py sending SIGABRT to take core dumps on fixture teardown may overwrite core files from hang analyzer","""When archival is enabled for a test or test suite, resmoke.py sends a SIGABRT signal to its fixture processes to take a core dump of them (in addition to collecting the mongod data files). If a JavaScript test has already invoked the hang analyzer via an assert.soon(), then the core file generated from the hang analyzer will be overwritten.        Note that the core dump taken by resmoke.py sending a SIGABRT signal is unlikely to match the thread stacks in the hang analyzer output because running the hang analyzer is expected to perturb the state of the MongoDB cluster."""
"SERVER-48703","Improvement","Testing Infrastructure",1,"Dynamically split causally_consistent_hedged_reads_jscore_passthrough","""It looks like the causally_consistent_hedged_reads_jscore_passthrough suites was recently added. It looks like this suite has a runtime of over 1.5 hours. We should convert this suite to a dynamically generated suite so that we can split it into sub-suites that can run in parallel.    ----    As a Server engineer,  I want the causally_consistent_hedged_reads_jscore_passthrough to be split into subsuites,  So that it can be run in parallel and I can have lower makespans in patch builds.    ----    AC:  * causally_consistent_hedged_reads_jscore_passthrough is dynamically split into sub-suites."""
"SERVER-48960","Bug","Testing Infrastructure",5,"Drive powercycle setup commands with expansions.yml","""Create a python wrapper around {{remote_operations.py}} that takes an Evergreen expansions.yml as input and calls {{remote_operations.py}} as we do now throughout evergreen.yml. Since the wrapper script is in Python, we can call [{{RemoteOperations}}|https://github.com/mongodb/mongo/blob/31a64f0cc546f325e1773091562f15264049c2d1/buildscripts/remote_operations.py#L344] directly instead of through a subprocess.    Because {{remote_operations.py}} is invoked at different points in evergreen.yml, we can't combine all 20 invocations into a single call to the wrapper, instead we want to retain the existing logic for now and create a subcommand to the wrapper for each contiguous group of calls. The subcommand names can mirror the function names in evergreen.yml :    - copy_ec2_monitor_files  - setup_ec2_intance  - tar_ec2_artifacts  - copy_ec2_artifacts  - gather_remote_event_logs  - gather_remote_mongo_coredumps  - copy_remote_mongo_coredumps    It's likely some the calls can be further grouped together based on [their usage in evergreen.yml|https://github.com/mongodb/mongo/blob/31a64f0cc546f325e1773091562f15264049c2d1/etc/evergreen.yml#L3184-L3196] but we can overlook that as part of this ticket to ensure we don't accidentally change the behavior of powercycle.    The goal of this ticket is to set {{$ssh_connection_options}}, {{$private_ip_address}} and all the other command line options for every invocation only once in the Python wrapper."""
"SERVER-48953","Improvement","Testing Infrastructure",2,"Add an option for resmoke to accept a replay file that lists tests.","""The patch now allows the following command line invocations:    and      If the contents of {{foo.txt}} are:      the invocation is analogous to:      Thus other command line flags such as {{--suite}} still take effect.    Also noteworthy, resmoke will run the contents of the replay file in the order they are listed. Repeated test files will be run once per repetition; prior behavior was to dedup test files.    Original ticket:  When running a set of tests with resmoke, one has the option of running them in alphabetical order or totally random. It would be nice if the random runs could at least use a deterministic order when provided a seed.     The goal here is to also be compatible with using {{\-\-jobs=N}}. The jobs flag will partition the test suite into different runners. When providing a seed, the each runner should deterministically run the same tests in the same order."""
"SERVER-48951","Improvement","Testing Infrastructure",3,"Create a resmoke option that better manages output for reproducing runs locally","""Resmoke will dump all output into either stdout or a log file. When people are running things locally, they often want:  * To save all the detailed output into a log file for perusal  * A way to know that the run may have hit an error condition  * A way to know that the set of tests is making progress    Many people use a series of mrlog, greps, tee and output redirection to achieve this, e.g:      Additionally, many people that craft those for individual reproduction attempts, haven't yet realized that saving it as a shell alias/function/script would be useful in the future.    The goal of this ticket is to provide a useful starting point for accomplishing the bullet points using the current keywords that MongoDB tests generate."""
"SERVER-49097","Bug","Testing Infrastructure",0.5,"sys-perf builds differ from release builds","""sys-perf artifacts are multiple gigs whereas regular waterfall builds are dozens of megs. Cursory glance shows we may be doing a debug build on sys-perf."""
"SERVER-49096","Improvement","Testing Infrastructure",5,"Have replica set tests log a pid/port topology","""The goal is to make it more convenient to find these mappings without having to look for the invocation of each process.    This should also include ports used by {{mongobridge}}.    Investigate whether this log can be output after resmoke rotates logs after each test."""
"SERVER-49164","Improvement","Testing Infrastructure",0,"Sweep for and fix missing dependencies in evergreen.yml","""We just noticed that some tasks (like """"jscore txns large txns format"""") are dependent on compile when it probably makes more sense to have them depend on jscore?    https://evergreen.mongodb.com/task/mongodb_mongo_master_enterprise_rhel_62_64_bit_dynamic_required_jsCore_txns_large_txns_format_3ea60282c8841c67d4e2f3a365b7f1640c84198c_20_06_29_14_07_33    While at it, it seems like someone should just do a one-time sweep and see if there's any other dependencies it would make sense to add.    I know this doesn't fit perfectly with the STM charter, but TBH it probably doesn't fit well with *anyone's* charter, and this seems like the cleanest fit?    CC [~pasette]"""
"SERVER-49203","Bug","Testing Infrastructure",0,"Jepsen-Smoke Has a 15% System-Failure Rate","""The failures manifest themselves like        A repeated execution of the [latest failure|https://evergreen.mongodb.com/task/mongodb_mongo_master_ubuntu1804_debug_aubsan_lite_jepsen_smoke_e53293b8749c692ae2abe50ff02f4aee6fea8b84_20_06_30_10_26_41] is green indicating that this is a transient error rather than something linked to the server. This represents a bug in the test or infrastructure rather than in the server.    The fixes I see are:    # Disable this task  # Add retry logic to this task  # Dig deeper into the jepsen test itself to figure out why this happens roughly 15% of the time.  """
"SERVER-49402","Improvement","Networking",1,"Misleading error message when connecting to Data Lake","""When users connect to Atlas Data Lake (ADL) with the mongo shell, they may sometimes encounter the error:    This is because ADL URIs have a {{.query.mongodb.net}} suffix - and not a {{mongodb.net}} suffix.    We should update https://github.com/mongodb/mongo/blob/43e2423bae07e13cf624b9d5fb74e62bd1959b19/src/mongo/shell/mongo.js#L360-L370 to provide a correct error message for ADL users."""
"SERVER-49488","Improvement","Networking|Shell",1,"Mongo shell is conflating authentication & network errors","""The mongo shell attempts to authenticate right after it connects to a server and returns [an exception|https://github.com/mongodb/mongo/blob/43e2423bae07e13cf624b9d5fb74e62bd1959b19/src/mongo/shell/mongo.js#L360-L370] if it's unable to. This means that if the client credentials are invalid, it will interpret that as a _connection_ failure and raise an exception.    It is unexpected that the shell would conflate an authentication problem with the general class of network connection failures. Here's what clients see when all that's wrong is invalid credentials:    It's unclear to me if this is expected behavior (it's confusing at best). If so, using a more generic error message instead of specifically offering that clients check their IP allowlist would be less confusing to users. If not, we should fix it."""
"SERVER-49716","Bug","Testing Infrastructure",0,"""gather_failed_unittests"" does not work on ubuntu1804-build","""Observed in https://evergreen.mongodb.com/task/mongodb_mongo_master_enterprise_ubuntu_no_latch_1804_64_bit_unittests_f1c2d6c29d960506c770958ed39ebe0677a3fdda_20_07_15_23_08_41/0."""
"SERVER-49786","Task","Testing Infrastructure",1,"Freeze DSI and Genny for non-master perf projects","""PM-1822 will change the interface between DSI and sys-perf evergreen yamls. To minimize the risk of breaking non-master branches and the overhead of multiple backports during PM-1822, we wish to """"freeze"""" the version of DSI in use on the following projects:    # [sys-perf v4.4|https://github.com/mongodb/mongo/blob/v4.4/etc/system_perf.yml]  # [perf v4.4|https://github.com/mongodb/mongo/blob/v4.4/etc/perf.yml]  # [sys-perf v4.2|https://github.com/mongodb/mongo/blob/v4.2/etc/system_perf.yml]  # [perf v4.2|https://github.com/mongodb/mongo/blob/v4.2/etc/perf.yml]  # [sys-perf v4.0|https://github.com/mongodb/mongo/blob/v4.0/etc/system_perf.yml]  # [perf v4.0|https://github.com/mongodb/mongo/blob/v4.0/etc/perf.yml]  # [sys-perf v3.6|https://github.com/mongodb/mongo/blob/v3.6/etc/system_perf.yml]  # [perf v3.6|https://github.com/mongodb/mongo/blob/v3.6/etc/perf.yml]    To do this we will create a """"legacy"""" branch of DSI and modify non-master evergreen yamls to use this. This means that any changes to DSI will not be usable by old perf projects unless those changes are backported.    At the end of PM-1822 we could selectively bring the required projects back up to DSI master or leave these projects """"forever frozen""""."""
"SERVER-49764","Bug","Performance",1,"Update instructions for running Genny sys-perf patch builds","""The instructions in system_perf.yml for genny patch tasks mentions {{--force-workloads}}, which is no longer an option in Genny, we should update the instructions there to the new approach.    We may also consider updating genny to reject unknown arguments"""
"SERVER-49818","Bug","Testing Infrastructure",1,"Enterprise Windows required builder no longer runs burn_in_tests as non-required builder","""The changes from [9a421e1|https://github.com/mongodb/mongo/commit/9a421e19cef1caa2627d4776db700ae5c8751932] as part of SERVER-46450 reduced the set of Evergreen tasks which run on the """"! Enterprise Windows"""" build variant, but did not restore [the {{burn_in_tests_build_variant: enterprise-windows}} setting|https://github.com/mongodb/mongo/commit/deca8251f356292eb1c813b65c4f6ebd458a1094#diff-71ccc9b828b2d68dab47c8be07ab6f96L9137] for it. This greatly limits the ability of patch builds to detect whether a new or modified test is going to fail post-commit on the """"* Enterprise Windows"""" build variant."""
"SERVER-49945","Improvement","Build",1,"Mark mypip.ini file as hidden","""It is a small thing, but all the other linter configuration files are hidden files starting with a {{.}}, with the exception of {{mypy.ini}}. A brief glance at the docs suggests that it too could be hidden. Doing so would slightly reduce the clutter at the top of the tree."""
"SERVER-50078","Bug","Build",2,"Compile bypass applied when it should not have","""See dev-only comment with patch build links, but as far as I understand it, changes to {{SConstruct}} should disable compile bypass.    See also EVG-12714."""
"SERVER-50133","Bug","Testing Infrastructure",2,"Perf YAML Cleanups","""Depends on SERVER-49786    From sys-perf yaml:    # Remove mark_idle invocations and   # Switch run-dsi invocations to use subprocess.exec and no extensions  ## kill the {{set}} lines; no dsienv.sh or setup-dsi-env.sh--kill in DSI (kill signal_processing_setup.sh from DSI while you're there)  ## never any absolute paths or .py suffixes always just {{run-dsi command}}; kill bin/anaysis.py  # Kill """"write yml config"""" in favor of expansions.yml  # """"deploy cluster"""" calls run-dsi deploy-cluster  # Do json.send as a post task  # Kill useless/constant {{project_dir}}, {{platform}}, {{script_flags}} vars    For perf.yml:    # call analysis through run-dsi  # the killall_mci expansion doesn't exist so kill that from the pre/post steps; make the {{pkill}} scripts not ugly af"""
"SERVER-50277","Task","Testing Infrastructure",5,"Performance Yaml Cleanups pt 1","""A handful of things that will make iteration a bit easier. This is all really hard to do in separate tickets or in a staged way. Smaller PRs first wherever possible, but minimize times we backport. Best to just rip off the bandaid.    Changes to sys-perf yamls (master and 4.4):    # Single f_run_dsi_workload Evergreen function  ## Mostly the same logic that's currently in the handful of existing functions, but in a single function.  ## Update the param names to match the files e.g. {{cluster}} to {{infrastructure_provisioning}}  ## Use conventional module locations where possible  ## Use conventional report output locations where possible  ## Remove cruft like dsienv.sh; run-dsi invocations are single-line scripts  # Change the order of tasks/functions to keep compile and dsi stuff more separated.  # Add a genny task that is *not* a generated task.    Changes to microbenchmarks yamls (master and 4.4):    # Single f_run_microbenchmarks_workload evergreen function for non-genny workloads  # Single f_run_genny_workload evergreen function for genny workloads  # Both functions to use conventional module locations where possible  # Remove extraneous genny invocation--I think just need the call to {{lamp}} without venv nonsense  # Tidy the weird {{pkill}} logic  # Conventional locations for genny, DSI, and signal-processing modules  # Change the order of tasks/functions to keep compile, dsi, and non-dsi-based-workloads more separated.    Changes to DSI:    # Update for conventional paths above  # Make evergreen-dsitest.yml a representative snapshot of what's in system_perf.yml and, if possible, something similar for perf.yml  # Change documentation for how to patch-build without compile    Changes to Genny:    # Kill """"legacy"""" task-gen logic"""
"SERVER-50313","Improvement","Testing Infrastructure",2,"Add standalone tasks to live-record buildvariant","""all test suites that run on a standalone, except for:   * Unittests   *non-mongod/s C++ test suites like libfuzzer, snmp   * all test suites that run on a replica set, except ones explicitly listed below   * all test suites that run on a sharded cluster, except ones explicitly listed below   * has requires_fast_memory tag (–excludeWithAnyTags=requires_fast_memory)         We will make the following effort to run the above tests with undo. If the following approaches combined don't ensure the suite can run undo, we will modify the scope to exclude the failing test suites   * blacklist problematic tests, up to once time per suite (i.e. all failing tests in one patch build)   * Audit tags of failing tests or tags for performance requirements and exclude those tests     * increase the election timeout   * increase the test and task timeout   * reduce the WT cache size   * reduce the size of the cluster   * turn off continueOnFailure   * reduce the number of clients   * adjust the data size   * run on larger instances, including adding new EC2 8x instance"""
"SERVER-50362","Bug","Testing Infrastructure",1,"Add resilience to repeat execution for multiversion tag generation","""If a task like {{sharding_multiversion_gen}} is run more than once, the {{generated_resmoke_config}} directory isn't created, so placing a tag file in it fails.    It should be relatively safe to no-op if the path we're placing the tag file in doesn't exist; if this happens when it shouldn't then in the worst case a test will run which should've been excluded and fail, which would let us know something was wrong."""
"SERVER-50352","Task","Testing Infrastructure",1,"Add understanding of previous syntax for multiversion exclusions","""We'd expected that backporting SERVER-48048 immediately would obviate the need to understand the previous yml syntax, but that doesn't seem to be the case; it looks like we use previous release versions in multiversion tests rather than the tips of other branches.    We should add back in the logic from earlier CRs of SERVER-48048 to handle this. Right now everything in {{etc/backports_required_for_multiversion_tests.yml}} is being unconditionally excluded."""
"SERVER-50379","Task","Testing Infrastructure",1,"Reduce frequency of ! and * builders on 4.4","""Now that 4.4 has been released, we'd like to adjust the frequency of the hourly builders to run with a higher interval."""
"SERVER-50641","Improvement","Testing Infrastructure",1,"Add more aggressive timeouts to commit queue tasks","""There are occasionally issues where the tasks in the commit queue appear to hang. Since the default timeouts are around 2 hours, this can cause large back ups in the queue. We could add more aggressive timeouts to the tasks in the queue so that they timeout much earlier. The lint tasks already do this and timeout around 40 minutes.    We should look at the historic runtimes of the tasks to pick appropriate timeouts.    ----    As a server engineer,  I want hung commit queue tasks to time out earlier,  So that the commit queue does not get blocked for a long period of time waiting for a task that is just going to timeout anyway.    ----    AC:  * All tasks in the commit-queue have a timeout of under 1 hour."""
