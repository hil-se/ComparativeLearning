"issuekey","type","components","storypoint","title","description_text"
"DM-16302","Bug","ap_verify",1,"ap_verify_hits2015 readme has invalid visit ID","""The readme for the {{ap_verify_hits2015}} dataset has an example run of {{ap_verify.py}} that uses {{visit=54123}}. This visit does not exist. Modify the example to use a visit ID that is present in the dataset, and confirm that the example works."""
"DM-16295","Story","cp_pipe|obs_lsst",2,"Get cp_pipe etc working for ts8 for bootcamp","""There will be several changes necessary, don't know what they are till we try and they pop up.    Put them all on this ticket."""
"DM-16294","Story","obs_lsst",1,"Fix coadd dataset templates in obs_lsst and possibly elsewhere","""obs_lsst has some unnecessary overrides of obs_base datasets and some datasets that probably shouldn't exist at all.  For the latter we should try to track down where they were cargo-culted from as well."""
"DM-16319","Bug","ap_verify|verify_metrics",1,"ap_verify source count metrics do not exist","""{{ap.association}} and {{ap.verify.measurements}} record a number of source count metrics using the {{lsst.verify}} framework. However, these metrics are not actually defined in {{verify_metrics}}. Add proper definitions for these metrics so that they appear in SQuaSH."""
"DM-16314","Story","obs_lsst",1,"Look at obs_lsstCam","""I have been asked to take a look at obs_lsstCam to do a mini review."""
"DM-16312","Story","pipe_supertask",1,"Rename Sensor to Detector in pipe_supertask","""DM-15537 renamed couple of things in gen3 registry, those names should also be changed in pipe_supertask."""
"DM-16309","Story","dm_dev_guide",1,"Please clarify documentation on line lengths in docstrings","""Per [discussion on Slack of 2018-10-25|https://lsstc.slack.com/archives/C2B6DQBAL/p1540481139000100], there's a certain amount of ambiguity in our developer documentation about formatting docstrings. Please propose some text to make this clearer."""
"DM-18212","Bug","ts_middleware",1,"The heartbeat event is missing from SALGenerics.xml in ts_xml","""The heartbeat event is missing from SALGenerics.xml in ts_xml    I assume this is an oversight, since it is a standard event. But if not, it should not have been removed from the Test product. I will restore it there for now to work around this bug. But please feel free to remove it from Test again if this issue is fixed."""
"DM-16326","Story","Third Party Software",0.5,"Fix astropy's formatting of FITS times","""In TSEIA-83 we noted that Astropy has been generating time strings in a non-standard format.  Fix Astropy."""
"DM-16338","Story","meas_algorithms",2,"Add fluxErr to LoadReferenceObjectsTask makeMinimalSchema","""Adding fluxErr to {{LoadReferenceObjectsTask.makeMinimalSchema()}} helps with some of the problem posed in RFC-535, while being uncontroversial. This will ensure that future reference catalogs have this field by default."""
"DM-16335","Story","Developer Infrastructure",1,"Refresh shared stack on (Princeton's) tiger2/perseus","""Following DM-16286, the shared stack build on Princeton systems is broken. We'll need to bootstrap a new shared stack to revive it."""
"DM-18242","Story","ts_management",1,"Wrap a SAL method ","""Work on task https://jira.lsstcorp.org/browse/TSS-3196"""
"DM-16347","Story","pipe_tasks",1,"DcrAssembleCoadd array size mismatch","""Bug encountered while trying to test the new astro metadata package that fixes obs_decam observatory longitude:    {code:}  dcrAssembleCoadd FATAL: Failed on dataId=DataId(initialdata={'filter': 'g', 'patch': '0,0', 'tract': 0}, tag=set()): ValueError: operands could not be broadcast together with shapes (2003,2003) (2000,2000) (2003,2003)   Traceback (most recent call last):    File """"/Users/sullivan/LSST/code/eups_distrib/stack/miniconda3-4.5.4-fcd27eb/DarwinX86/pipe_base/16.0-13-gb122224+4/python/lsst/pipe/base/cmdLineTask.py"""", line 388, in __call__      result = self.runTask(task, dataRef, kwargs)    File """"/Users/sullivan/LSST/code/eups_distrib/stack/miniconda3-4.5.4-fcd27eb/DarwinX86/pipe_base/16.0-13-gb122224+4/python/lsst/pipe/base/cmdLineTask.py"""", line 447, in runTask      return task.runDataRef(dataRef, **kwargs)    File """"/Users/sullivan/LSST/code/eups_distrib/stack/miniconda3-4.5.4-fcd27eb/DarwinX86/pipe_base/16.0-13-gb122224+4/python/lsst/pipe/base/timer.py"""", line 149, in wrapper      res = func(self, *args, **keyArgs)    File """"/Users/sullivan/LSST/code/eups_distrib/build/pipe_tasks/python/lsst/pipe/tasks/dcrAssembleCoadd.py"""", line 217, in runDataRef      results = AssembleCoaddTask.runDataRef(self, dataRef, selectDataList=selectDataList)    File """"/Users/sullivan/LSST/code/eups_distrib/stack/miniconda3-4.5.4-fcd27eb/DarwinX86/pipe_base/16.0-13-gb122224+4/python/lsst/pipe/base/timer.py"""", line 149, in wrapper      res = func(self, *args, **keyArgs)    File """"/Users/sullivan/LSST/code/eups_distrib/build/pipe_tasks/python/lsst/pipe/tasks/assembleCoadd.py"""", line 361, in runDataRef      inputData.weightList, supplementaryData=supplementaryData)    File """"/Users/sullivan/LSST/code/eups_distrib/build/pipe_tasks/python/lsst/pipe/tasks/dcrAssembleCoadd.py"""", line 378, in run      modelWeights)    File """"/Users/sullivan/LSST/code/eups_distrib/build/pipe_tasks/python/lsst/pipe/tasks/dcrAssembleCoadd.py"""", line 521, in dcrAssembleSubregion      maskedImage.image.array *= modelWeights  ValueError: operands could not be broadcast together with shapes (2003,2003) (2000,2000) (2003,2003)   {code}"""
"DM-16343","Bug","Third Party Software",0.5,"pytest-flake8 creates many forked processes","""[~jbosch] noticed that when he runs {{scons}} he gets many unexpected python processes created by pytest.  It looks like for every pytest core an additional N processes are created where N seems to be the number of effective cores."""
"DM-16363","Story","pipe_analysis",3,"ValueError in coaddAnalysis with HSC-RC2 tract=9615 filter=HSC-R ","""coaddAnalysis with HSC-RC2 tract=9615 filter=HSC-R data gave the following error:      Other tracts/filters in HSC-RC2 finish without errors. A command to reproduce is       This used to finish fine in early September with {{w_2018_36}} (before the DM-15869 issue). """
"DM-16393","Story","QA",20,"Dask investigations","""Investigate dask as an option for doing distributed analysis.  Ideally this would lead to a proof of concept visualization that is only possible with this kind of system."""
"DM-16392","Bug","meas_base",0.5,"Aperture correction field keys not guaranteed to point the same offsets within a given reprocessing","""In perusing the {{pipe_analysis}} outputs of the RC2 reprocessing runs to check that our results are all looking as they should, I noticed that the aperture corrections were comparing differently between reprocessing runs (e.g. w42 vs. w41). While, in principle, this could happen as a result of code changes, this did not appear to be the case as the flux comparisons were all identical. Digging into it, I discovered that the key offsets point to a different place for different patches/visits for all aperture correction fields *within the same processing run*. I.e. the catalog schemas don't match each other, nor the one defined in the schema files in the repo.    E.g. in {{/datasets/hsc/repo/rerun/RC/w_2018_42/DM-16095/}}, the meas cat schema in {{schema/deepCoadd_meas.fits}} has:    But for two patches, we find:      This is most undesirable as it precludes concatenating all patches in one tract into a single catalog (which requires them all to have identical schemas).  The fix may be as simple as looping over a sorted list (as opposed to one where order is not guaranteed) when adding the apCorr keys to the schema."""
"DM-16405","Story","SUIT",5,"Python client: add support for hue-preserving rgb","""Add support for hue preserving rgb. Might need a variant of set_stretch function."""
"DM-16404","Story","L1 Database",5,"Implement multi-node support in ap_proto","""for more realistic tests I'd like to add support for running ap_proto on many hosts, maybe using MPI or some other sort of IPC (it should be a low-level data exchange so there is no critical point here)."""
"DM-16401","Story","pipe_tasks",2,"Disable writing metadata for MergeDetections and MergeMeasurements Tasks","""When splitting apart these two tasks, the writeMetadata method overload in the old base class was not propagated to each of the merge tasks. Add the no-op method overload to each of the merge tasks."""
"DM-16400","Improvement","ap_verify|verify_metrics",1,"Create a timing metric for ApPipeTask","""Now that {{ap_pipe}} is implemented as a {{CmdLineTask}} with a {{timeMethod}} decorator, and with {{ap_verify}} actually calling {{ApPipeTask.runDataRef}} (as of DM-15901), it would be easy to time the entire task and store it as a SQuaSH metric. Register such a metric in {{verify_metrics}} and start tracking it in {{ap_verify}}."""
"DM-16429","Story","obs_base",1,"Ensure WCS (and other Exposure components) are retrieved properly when loaded individually","""It looks like <exposure>_wcs datasets are coming from the header (which may be an approximation) instead of the true WCS in the FITS binary tables.  Fix this, and add support for more components if it's easy to do so.    Note that using the header was once thought to be necessary to do this efficiently, but in fact there's always been a trick to get anything out of the binary tables efficiently (due originally to [~price], I think): load a 1-pixel subimage of the exposure, and pull the component out of that.    However, since DM-15500 we've had an {{ExposureFitsReader}} class that provides direct and efficient access to all of those components without that trick, and that's what we should use here."""
"DM-16428","Story","ImgServ",40,"Implement and publish SODA 1.0 in ImgServ through VO Service Interface","""The latest SODA 1.0 Recommendation from IVOA focuses on image cutout and stitching operations, in addition to the standard VO service registration.         For reference, see [SODA 1.0|http://www.ivoa.net/documents/SODA/20170604/REC-SODA-1.0.html]"""
"DM-16426","Story","pipe_tasks",1,"Remove errant print statement in multiband.py","""DRP accidentally let a print statement slip through to master. Remove it.    This is a first ticket Andres, and also includes familiarizing himself with our workflow.           """
"DM-16423","Story","HeaderService",2,"Ensure that templates are not updated when no data available from SAL","""Ensure the header templates are unmodified and therefore undefined values are preserved when no data is available from SAL for a given keyword."""
"DM-16421","Story","mops",20,"MOPS Change Request Preparation","""Continue developing the change request to incorporate the updated thinking on Solar System data products and algorithms.    The deliverables of this element include:   * Development timeline for the next 6 months, sufficient to support the next development cycle planning. ✅   * Draft long-term (4-yr) plan in form of a list of milestones and a Gantt chart. ✅   * Updates to DPDD ✅   * Updates to LSE-61   * Updates to LDM-151 ✅   * Updates to LSST Schema Document ✅   * Resolution of LSST-MPC MOU    [~eggl] and [~mjuric] will be collaborating on this story (splitting the story points 50:50)."""
"DM-16418","Story","mops",1,"Monthly LSST-MPC collaboration status review","""Monthly review of LSST-MPC collaboration status, presentation of progress, review of issues."""
"DM-16415","Story","mops",5,"Establish MPC Database Replication Environment","""Create accounts for the Minor Planet Center staff on the epyc machine at UW, and set up a basic PostgreSQL server. The MPC staff will use this to set up a replica of the internal MPC database, running on SSDs. This will later be used to test the existing database throughputs, and whether they can scale to LSST requirements."""
"DM-16414","Story","pipe_analysis",2,"Confirm fix of DM-16392 after next RC2 processing","""The fix on DM-16392 is easiest to confirm on the {{pipe_analysis}} processing outputs of the RC2 bi-weekly reprocessing.  The issue was that the order aperture corrections were being added to the schema was not deterministic (loop was being done on a set).  As a result, when attempting to concatenate all patches of a given tract into a single catalog and using a template schema, the aperture corrections were often pointing to different key offsets, thus getting the wrong column appended into catalog.  This issue was discovered in perusal of the plots output by {{pipe_analysis}}'s *compareCoaddAnalysis.py* and *compareVisitAnalysis.py* when comparing outputs from one reprocessing to the previous one (between which no algorithmic changes had been made that could've caused this discrepancy, backed up by the identical flux measurements for the same points).  This ticket is to capture the effort that went into diagnosing the bug and ensuring the fix was successful after the {{w_2018_44}} -- assuming the fix lands on time -- is completed."""
"DM-16413","Story","obs_base",0.5,"Remove more paf files from obs_base","""These somehow escaped the purge of DM-15767.  They *should* no longer be in use, and hence easy to remove."""
"DM-16409","Story","ip_diffim",8,"Familiarization with the ip_diffim codebase","""[ip_diffim|https://github.com/lsst/ip_diffim] is the home of image differencing algorithms within LSST. Read through the current {{master}} branch, understand what's there and think about the structure.    Understanding the way ip_diffim is structured will (at a minimum) involve developing some familiarity with the pipe_base and meas_base frameworks. The former defines the structure of “tasks”, which form the basis of LSST pipelines; the latter, the “measurement framework” which provides a system of plugins for measuring source properties given a collection of pixels. A good target for this ticket would be to understand:    - What {{Task}}​s exist in the ip_diffim package, and what they do;  - Major {{Task}} configuration options;  - What measurement plugins exist in ip_diffim, and what they do.    Detailed understanding of how the algorithms are implemented isn't important for now, as long as you have a good mental map of what's available and the large scale structure of how the package fits together.    The following documentation may be helpful:    - https://pipelines.lsst.io/v/daily/modules/lsst.pipe.base/task-framework-overview.html  - https://pipelines.lsst.io/v/daily/modules/lsst.meas.base/intro.html    """
"DM-16443","Bug","dm_dev_guide",1,"RST Guide Example Broken","""The RestructuredText style guide includes an [example for linking to images|https://developer.lsst.io/restructuredtext/style.html#plain-images], but this example works only on local builds because it links to the uningested image. The example should say    which will work on both local and web builds."""
"DM-16442","Story","HeaderService",8,"Build and test HeaderService against new version of SAL and xml","""New version of ts_sal and ts_xml have been committed to master by T&S. The new ts_xml needs to be rebuilt and the HeaderService and salpytools need to be tested against this new version."""
"DM-16441","Improvement","display_firefly",2,"Speed up creation of footprints table for Firefly","""DM-15823 implemented a function {{createFootprintsTable}} to convert an {{afwTable.SourceCatalog}} into an {{astropy.io.VOTableFile}}  for Firefly to draw LSST detection footprints. The function includes a slow loop over rows of the table to copy data from the input table to the output table, which can take tens of minutes for a large {{SourceCatalog}}.      A column-wise copy appears to greatly speed up this function."""
"DM-16436","Story","qa_explorer",2,"Fix broken inheritance in WriteObjectTableTask","""Changes in multiband.py removed a base class that was only loosely tied to the derived classes and moved shared functionality out into free functions. At the time of merge, qa_explorer was not changed as it was not part of the main stack and so the dependency change went unnoticed.    This ticket will fix the inheritance breakage in WriteObjectTableTask and clean up some coding standards in the file it is placed in."""
"DM-16451","Bug","display_firefly",0.5,"Fix color parameter names for overlaying footprints","""In {{firefly_client.FireflyClient.overlay_footprints}}, the highlight color parameter is {{highlightColor}} and the selection color parameter is {{selectColor}}. These names need to be used in {{display_firefly}} in the {{overlayFootprints}} method."""
"DM-16447","Story","HeaderService",2,"Ability to add comments to the templates.","""At the moment the HeaderService uses the function  \{\{read_scamp_head()}} to read in the header templates. This function does not have the ability to ignore lines with comments. The simplest and fastest solution would be to clone and modified that function and make it part of the headerservice."""
"DM-18208","Improvement","ts_middleware",2,"Please provide a variant of getSample_x that always returns the last value seen","""It would be very helpful for {{salobj}} and ameliorate the need for TSS-3195 and TSS-3218 to have a function like {{getSample_x}} that always returned the last value seen (instead of returning """"no new data"""" if called multiple times). This could be a new flag argument to {{getSample_x}}.    I have discussed this with [~dmills] before but I don't think I ever filed a ticket, so here it is. I believe [~dmills] prefers to have such a function query the EFD if necessary. I am strongly opposed to this for the following reasons:  - It adds a lot of complexity which will be difficult to test  - It is likely to make the function unpredictably slower    Also I worry that it is likely to delay implementation of this useful feature.    But in any case, I would rather have a different function for EFD lookup, or at least a flag argument that will enable or disable it."""
"DM-17356","Story","ts_middleware",3,"Enhance ts_SALLabVIEW to make it externally scriptable","""The ts_SALLabVIEW VI currently requires user interaction to provide the    location of the .idl and .so files. We need to be able to have this information   be provided externally (eg at command line) so that the entire process can be   run automatically with no user interaction required.   e.g.    updateSALLVcontrols ATMonochromator [optional location]    the default location would be $SAL_WORK_DIR/subsystem-name/labview/lib    Below are notes to myself to finish this task. """
"DM-16468","Story","pipe_tasks",3,"Speed up and stabilize dcrModel convergence","""With larger numbers of DCR subfilters (e.g. 5) the dcrModel solution can sometimes oscillate between iterations of forward modeling. This results in premature termination of the modeling loop, because the convergence may improve by a large amount in one iteration, and by a very small amount in the next, triggering the convergence end condition. One solution is to set a small enough gain on the new model solutions so that modeling converges smoothly, but then more iterations are required to reach the same level of convergence. Instead, the gain should adapt to how well the model is improving compared to predictions."""
"DM-16467","Improvement","ip_isr",8,"isrTask conversion to pipelineTask","""isrTask needs to be updated to work with a Gen3 butler as a valid pipelineTask.  DM-15862 will unify the ISR processing, so this should make all cameras functional with a Gen3 butler."""
"DM-16463","Story","ctrl_iip",8,"Introduce user configurable cfg file options","""Under the config/ dir, will be a 'configurables' directory. A user-defined configuration file can be dropped in this directory, and any time the DM L1 system is moved into standby state, the files in this directory will be read and inserted into a redis database instance. When DM offers a list of possible configs for the operator to choose from, the primary keys  (config file name) that define each separate config file will be presented to the operator as a comma delimited list. When the operator chooses a particular name, the key/value pairs for that configuration is presented.    Note: A formal enumeration of keys in a user configurable file will be provided. It is expected that the list of configurable options will grow as the system approaches completion. Users will be able to select values for the list of some or all of the keys, and name this configuration with a unique name.         A default configuration will be present and used if a unique config is not selected.    If a config file only sets values for two out of say, 50 possible keys in the formal enumeration, the other 48 keys will be set to default values.    One of the many uses these files will be used for is to describe which CCDs in the FPA are to be read. This data will be able to be specified as *_inclusive_* or _*exclusive.*_         The configurables dir will have a README and a couple of example files."""
"DM-16462","Story","ctrl_iip",3,"Separate Forwarder Allocation Assignment to its own config file.","""SSIA"""
"DM-16461","Story","ctrl_iip",2,"Make message broker creds its own config file.","""SSIA"""
"DM-16476","Story","Firefly",8,"Revamp table watching sagas so there is one ""Master Table Watcher"" ","""Revamp table watching sagas or watcher so there is one """"Master Table Watcher"""" which will:   # Analyze the table for type. Right now we have three- catalogs, image meta data, footprints but there will be more.   # Start the appropriate watcher for just that table id.  This watcher will live as long as the table is loaded.   # The """"Master Table Watcher"""" has configuration to determine which watcher are supported. i.e. it would not load a LSST footprint watcher in the IRSA case.   # A watcher would have two functions.  One to determine if it is a supported table and the other that would be the watcher."""
"DM-16473","Story","obs_lsst",1,"Support BNL ts8 data and add raft data","""Support BNL ts8 data and add raft data to the serial number dictionary"""
"DM-16481","Bug","pipe_supertask",0.5,"cmdLineFwk crashes when filling output collection","""stac crashes when it tries to add a DatasetRef to output collection:    Apparently in {{_updateOutputCollection()}} I'm passing dict.values() to an argument that is supposed to be a list."""
"DM-18229","Bug","ts_main_telescope",2,"MTMount OSS telemetry topic causes Java too many parameters error","""This is a ticket to track the Java """"too many parameters"""" error in the MtMount OSS telemetry topic.  This issue will probably go away when the vendor updates the topics.  QA needs the ticket to properly shutdown the tests that are affected."""
"DM-16494","Improvement","Firefly|SUIT",1,"Ensure that Firefly can read VOTable 1.3 and in particular the BINARY2 data format","""VOTable 1.3 is the current standard, and the BINARY2 data format is the one most likely to be used as the LSST default.  BINARY2 adds proper support of NULL values, in particular.    The action is to upgrade the Java support libraries used by Firefly to a version that provides full support for this.  I suggest at least STIL Version 3.2-1 (see http://www.star.bristol.ac.uk/~mbt/stil/sun252/history.html).    This is required for LSST and also has to work in production for IPAC since attempts to access external services via Firefly are increasingly likely to generate data in this format.    Two previous tickets (DM-7225 and DM-7405) have touched on this, with comments stating that the issue was resolved, but tests today showed that Firefly was not able to read a table in BINARY2 format.    This may be related to the """"bit"""" bug fixed in STIL Version 3.0-13 (17 Aug 2015)."""
"DM-16504","Story","HeaderService",8,"Build/Install and test new ts_sal and ts_xml ","""Build/Install and test new ts_sal and ts_xml for the HeaderService in preparation for the Reverification of the Auxtel CSC funcionality.    https://confluence.lsstcorp.org/display/SYSENG/Reverification+of+AuxTel+CSC+Functionality"""
"DM-16502","Bug","SUIT",2,"Restore SUIT functionality","""After the recent DAX changes, SUIT is broken.    Update SUIT to use upper case """"QUERY"""" parameter and new [PDAC service URLs|https://confluence.lsstcorp.org/display/DM/DAX+service+URLs].  Fix the display of the search page (bug exposed by TabPanel changes)."""
"DM-16522","Bug","Firefly|firefly_client",2,"Dev imageviewer Git Commit: c79022a fails on the attached FITS image file","""This problem was found on NED's ivv.ned.ipac.caltech.edu/byname, using NGC 4151.  Click on images the click on the first row 'View Image'.   The image gets fetched by the browser (Chrome and Firefox), but the display gets greyed out, and all subsequent attempts to 'View Images' appear to result in fetches, but the screen remains greyed out.    It also is easily reproduced using an IRSA viewer on a firefly server using v1.0.0 Built On: 2018-10-31, Git commit 79022a. Try [http://ff1.ned.ipac.caltech.edu:8080/firefly/] and upload the attached fits file.    Note: Uploading the attached image to the irsaviewer application hosted on [https://irsa.ipac.caltech.edu|https://irsa.ipac.caltech.edu/] (v3.1.0_Final-3099) works as advertised.         Implementation fixed 2 issues:   * ThumbnailViewer does a undefined check it should have been doing, this protects the {{render()}}   * A plate projection sets up the coordinate system correctly"""
"DM-16521","Story","ctrl_execute|ctrl_platform",2,"Add information for ctrl_platform_lsstvc and add queue option","""Add Additional explanation of how jobs and nodes are labeled."""
"DM-16530","Story","HeaderService",2,"Changes to salpytools to due to updates on ts_sal and ts_xml","""Due to changes to ts_sal and ts_xml and underlaying names and function, the salpytools module  needs to be updated,"""
"DM-16538","Story","Stack Documentation and UX",0.5,"Add PSTN series to www.lsst.io and include refresh date on page","""Add PSTN series to www.lsst.io and include refresh date on page."""
"DM-16544","Bug","ap_pipe",8,"Investigate mask propagation through ip_diffim","""As first identified in DM-13081, the template mask planes seem to propagate into unreasonably large masks in the difference image.  This ticket is to investigate the source of this behavior and fix it, if appropriate.  It may be useful to consult with [~gkovacs]."""
"DM-16542","Bug","Qserv",1,"Qserv data loader fails with wide table","""Sabine sent me a bug report on slack, apparently integration test fails while loading data for one particular table. Here are few pieces of info for that:  {quote}  I currently try to upload a Run1.1 dataset to the Qserv nodes available at CC-IN2P3. One of the data catalogs deepCoadd_meas contains ~840 parameters per entry which lead to a problem with the Qserv http get request that should retrieve the schema of the table.  More precisely, the deepCoadd_meas table is created properly in Qserv, all the columns are well defined and the mysql command """"describe deepCoadd_meas"""" works fine. However the https get request that should retrieve the table schema before the data ingestion fails (internal server error): I tracked the problem down and went to the conclusion that the error is due to the length of the response - everything works fine when I reduce the number of columns in the table.  {quote}    {quote}  I managed to reproduce the problem by using directly the following command :  curl --verbose  --anyauth -u ... --X GET http://127.0.0.1:5012/dbs/qservTest_case149_qserv/tables/deepCoadd_meas/schema  this command works fine when the number of columns in the table is reasonable, but as soon as I reach a given number of columns an """"internal server error"""" is thrown.  During my tests I checked each time that the deepCoadd_meas tables were not corrupted by using the equivalent mysql/qserv command:   mysql -P 30040 -u qsmater -h ccqserv125 qservTest_case149_qserv -e """"describe deepCoadd_meas;"""". This command always worked fine, I therefore concluded that the http request goes wrong when the size of the answer to the request is too big.  {quote}    {quote}  I created a tarball that contains the qserv-check-integration.py input data. It is available for download here : https://mydrive.lapp.in2p3.fr/s/oXUApFgSU2FAy8A  . I use the following command to upload the data python qserv-check-integration.py -l -i 130 --mode qserv -t <data_directory_name>  {quote}  """
"DM-16552","Story","cp_pipe|ip_isr",20,"Produce summary of sensor effects and strategies to mitigate","""Develop a summary on Confluence of the various sensor effects which DM team should be aware of. Collate as much information as possible on:    - A description of the effect;  - What strategies the Camera Team have developed to mitigate it;  - What strategies DM have developed to mitigate it;  - Identify where those strategies diverge;  - What requirements there are for handling this effect.    Note that, in some cases, the strategies developed to date may be “none”!    Record this information on Confluence at: https://confluence.lsstcorp.org/display/DM/Sensor+Characterization+and+ISR    The aim is to use this page as a central “knowledge base” for future work, and to keep it updated as we learn about new effects or refine our approach to addressing them."""
"DM-16550","Story","daf_persistence",0.5,"Races in YAML tests in daf_persistence","""The YAML storage tests in daf_persistence create a temporary directory but do not use it. This leads to test failures when the tests are run in parallel.  Also fix the pickle test so that it no longer uses the root directory."""
"DM-16557","Story","dax_ppdb",2,"Move ap_verify_queries function into Ppdb","""DM-15588 removed the placeholder database APIs from ap_association, pipe, and verify. In doing this, a convenience function was created to compute a summary metric on the PPDB for use in ap_verify. This ticket will move that function and it's unittest into the Ppdb class and modifies ap_verify's usage of the function."""
"DM-16558","Bug","afw",3,"removeMaskPlane function in multiband.py does not work","""In perusing the stack for examples of mask usage and manipulation, I came across this funtction:    [https://github.com/lsst/afw/blob/master/python/lsst/afw/image/image/multiband.py#L481-L490]    It looks like there are two issues with it:    1) {{lsst.afw.image.MaskX}} has no attribute {{removeMaskPlaneDict}}, so any call to the function results in:  {code:python}  AttributeError: type object 'lsst.afw.image.image.image.MaskX' has no attribute 'removeMaskPlaneDict'    The fix here is to pass *name* to the function.    Finally, I also noticed that the *MultibandMask* class is missing the {{removeAndClearMaskPlane()}} function.  I don't think this was intentional, so one should be added."""
"DM-16561","Story","pex_config",2,"Brokenness when comparing configs with inheritance relationship","""...or just similar field names, I suppose. Viz:    {code:python}  In [1]: import lsst.pex.config as pexConfig    In [2]: class SuperConfig(pexConfig.Config):     ...:     foo = pexConfig.Field(doc=""""test"""", dtype=str)     ...:     In [3]: class SubConfig(SuperConfig):     ...:     bar = pexConfig.Field(doc=""""test"""", dtype=str)     ...:     In [4]: super_c, sub_c = SuperConfig(), SubConfig()    In [5]: pexConfig.compareConfigs("""""""", super_c, sub_c)  Out[5]: True    In [6]: pexConfig.compareConfigs("""""""", sub_c, super_c)  ---------------------------------------------------------------------------  AttributeError                            Traceback (most recent call last)  <ipython-input-7-e502e8e334d3> in <module>()  ----> 1 pexConfig.compareConfigs("""""""", sub_c, super_c)    /software/lsstsw/stack_20181012/stack/miniconda3-4.5.4-fcd27eb/Linux64/pex_config/16.0-7-g9645df7+1/python/lsst/pex/config/comparison.py in compareConfigs(name, c1, c2, shortcut, rtol, atol, output)      101     equal = True      102     for field in c1._fields.values():  --> 103         result = field._compare(c1, c2, shortcut=shortcut, rtol=rtol, atol=atol, output=output)      104         if not result and shortcut:      105             return False    /software/lsstsw/stack_20181012/stack/miniconda3-4.5.4-fcd27eb/Linux64/pex_config/16.0-7-g9645df7+1/python/lsst/pex/config/config.py in _compare(self, instance1, instance2, shortcut, rtol, atol, output)      356         """"""""""""      357         v1 = getattr(instance1, self.name)  --> 358         v2 = getattr(instance2, self.name)      359         name = getComparisonName(      360             _joinNamePath(instance1._name, self.name),    AttributeError: 'SuperConfig' object has no attribute 'bar'  {code}    *Both* of these comparisons are mistakes: the configs aren't equal, so shouldn't return as if they are (in the first case), and the comparison should certainly not raise."""
"DM-17277","Story","ts_middleware",2,"Provide support for Kafka writers","""Support the auto generation of Kafka capable data writers for SAL mediated data"""
"DM-16598","Story","afw",2,"Add PhotoCalib.calibrateImage() option to compute variance without calib err term","""Currently {{PhotoCalib.calibrateImage()}} computes the variance plane as:      where {{scale}} and {{scaleVar}} are my own names for the scale factor that the photocalib applies and the measured uncertainty on that photocalib.     This equation assumes that the  scale factor variance and the image variance are independent, and this isn't obviously true.    Whether this is the correct variance equation is irrelevant, however. It is a change to how the variance plane in the zeropoint-normalized warps is currently computed, and I suspect  it is the primary source of the photometry differences we're seeing in coadds produced with jointcal.   While we are testing the effects of using {{jointcal}} vs. {{meas_mosaic}}'s calibration on coadd (DM-16596), it is important that we are able to test these two changes (jointcal's calibrations and the variance plane equation change) separately.     Implementation: This could be done with an extra argument like {{photoCalib.calibrateImage(Image, addCalibVar=False}} or with a state switch like {{Calib}}'s  {{Calib.setThrowOnNegativeFlux(False)}}.    """
"DM-16589","Story","dax",1,"Create REQ for SLAC","""Create the fy19 requisition for SLAC budgets"""
"DM-16563","Story","Stack Documentation and UX",1,"Fix \input detection regex in lsst-projectmeta-kit","""In https://github.com/lsst-dm/dmtn-101, there are commands like {{\inputData{CBP}}}. These are being detected by lsst-projectmeta-kit as {{\input}} commands."""
"DM-16603","Bug","pipe_tasks",1,"Fix dcrAssembleCoadd config issues","""The {{config}} of {{dcrAssembleCoaddTask}} was not properly checked before, and appears to fail validation. This ticket is to make the simple fixes needed for the {{config}} to pass validation."""
"DM-16599","Story","meas_deblender",1,"merge_footprint_XXX flags are not being set/propagated","""There seems to be a problem with propagating {{merge_footprint_XXX}} flags.         E.g. in some DESC processing an object has    note that there is a {{merge_peak_sky}} but no {{merge_footprint_sky}}. When [~jbosch] looked into this, it seemed as if the problem was generic rather than just for sky objects."""
"DM-16632","Improvement","pipe_tasks",0.5,"dcrAssembleCoadd log should refer to patches/quadrants, not coords","""The dcrAssembleCoadd log prints things like """"Computing coadd over (minimum=(39900, 39900), maximum=(41899, 41899))"""". These are apparently x,y coordinates of some sort within a patch, and it works on each patch in quadrants. It would be clearer/friendlier to print something like """"Computing coadd for patch=1,1 quadrant 1/4."""""""
"DM-16612","Story","meas_modelfit",1,"Fix compiler warnings in Meas Modelfit","""Fix compiler warnings in meas model fit related to marking methods as overloads"""
"DM-16642","Improvement","verify",2,"Generalize job metadata code","""The SQuaSH-requested metadata are currently hardcoded into {{MetricsControllerTask}}. Generalize this system by delegating the work to a SQuaSH-specific subtask, as described in [DMTN-098|https://dmtn-098.lsst.io/]."""
"DM-16641","Bug","pipe_tasks",1,"dcrAssembleCoadd makes too many nImages","""The option doNImage is very handy for coadd assembly, as it creates an """"nImage"""" of each patch with pixel values that show how many images (i.e., warps) will be assembled at that location. The nImages are saved as fits files. However, things get a little complicated with dcrAssembleCoadd's nImages.    This ticket is to change the present situation so only one nImage is created one time. The current state of affairs with doNImage (approximately in order):   * dcrAssembleCoadd calls regular assembleCoadd, which creates an nImage for all patches in the deepCoadd directory before beginning assembly   * These nImages are overwritten with nImages that have pixel values 3x larger than before (in this example, 3 is the number of DCR subfilters being used)   * Another set of nImages is created in the dcrCoadd directory alongside the dcr coadds, which are identical to the original nImages    Somewhat related to this, when one uses the butler to load a DCR coadd and does {{dcrCoadd.getInfo().getCoaddInputs().visits}}, it lists each constituent visit 3 times (i.e., nSubfilter times). This is probably also a bug."""
"DM-16656","Bug","Firefly|SUIT",2,"LC Viewer: error loading periodogram and peak tables","""Time Series viewer fails to load periodogram and peak tables.    Line 62 of PeriodogramAPIRequest.java - LC_FILE (""""original_table"""") parameter is always null. It comes from the tableMeta source attribute (line 508 of LcPeriodogram.jsx), which has been removed  as a part of DM-16273.      """
"DM-16654","Story","afw",0.5,"Merge external PR for afw for/from Jim Chiang","""PR from Jim here:    [https://github.com/lsst/afw/pull/415/files]    Ticket, test, merge."""
"DM-16651","Story","Stack Documentation and UX",0.5,"sphinxcontrib-bibtex error for DMTN builds (floating version incompatibility)","""[~krzys]:    {quote}  hi, I'm having trouble building a DMTN. The build (https://travis-ci.org/lsst-dm/dmtn-098/builds/461067187?utm_source=github_status) fails with  {quote}      I think the issue that documenteer has been allowing the sphinxcontrib-bibtex version to flow, but is proactively pinning Sphinx. A new version of sphinxcontrib-bibtex might be assuming Sphinx 1.8 APIs, which we're not using yet. The obvious solution is to pin sphinx-contrib-bibtex."""
"DM-16648","Technical task","daf_butler",3,"New design for DataUnit/Dimension objects","""Prototype a new design to replace the DataUnit, DataUnitJoin, and DataUnitRegistry classes, without integrating them into the rest of the system (yet).     """
"DM-16668","Story","SUIT",2,"Implement the UI for TAP service, Master Ticket","""- UI should be 3-boxes layout. Left: selection of schema and table, bottom: columns with constraints, right: spatial/temporal/wavelength constraints if the columns with the corresponding UCDs are present.   - We need a widget for TableItemListField, (similar to but hopefully more generic than IRSA's CatalogTableListField, which would map table rows into the selectable display items. This widget will be used to display schema and table lists. (Both of them can have long descriptions with links.)   - We need to upgrade CatalogConstraintsPanel to take table model (rather than giving it processor id and parameters), so that we can pre-sort table model by column_index, if it is available, and use columns UCD information to display spatial/temporal/wavelength constraints. Also, as Loi pointed out, CatalogConstraintsPanel is buggy: tab should be moving the focus to the next input box, filters and selections should clear when different table is used. (There are some hard-to-reproduce edge cases, when they don't.)   - Should we allow user to view and modify ADQL query? As shown by the prototype implementation, keeping ADQL and ADQL-building UI on the same page is tricky, because they have to be in sync, and while UI-to-ADQL is not hard, ADQL-to-UI is non-trivial. Should we allow free-form ADQL with tree-like schema browser on the side as an alternative to the table driven UI above?    Each of the items above can be a separate ticket.    Other comments from prototype implementation [https://github.com/Caltech-IPAC/firefly/pull/713:]   - ADQL query is what get submitted, but it's not obvious that you need to click on Set ADQL from Constraints before Search.   - When new schema and table are selected, ADQL query remained the previous value. Very confusing when you've gone through the selection/inputs process then click Search to get the same previous search results.   - Having fixed boxes with spiny during loading may improve look and feel. As is, UI is resizing without feedback.   - At some point, I assume there would not be both Additional constraints and ADQL Query in this dialog.   - The native drop-down list box is not the best widget for displaying schema and table lists. We'll need one with multi-line formatting, similar to CatalogTableListField."""
"DM-16697","Story","DM",1,"Create instrucions for AAS workshop","""Dig out LSST Europe instructions and update for AAS - ask NCSA about account sign up page."""
"DM-16696","Bug","afw",1,"PhotoCalib produces negative flux errors for negative flux measurements.","""The `PhotoCalib`, `instFluxToMaggies` method is missing an absolute value causing calibrated flux errors to be negative when fluxes are negative (as can happen in a difference image)."""
"DM-16693","Bug","pipe_tasks",1,"Long Decam DCR run failures with invalid values","""When [~mrawls] ran {{DcrAssembleCoaddTask}} it failed on patches with large regions of no data. The Task should test whether subregions contain data at an earlier stage, and skip them or fail earlier. See the log below for an example:      """
"DM-16690","Story","ap_association|ip_diffim",2,"Change totFlux column names in imageDifferenceTask","""The direct image, forced flux columns created in imageDifferenceTask are not currently usable with slots and therefore awkward to use with calibration objects. This ticket will change the names to ip_diffim_forced_PsfFlux_[value] and the associated slot_forcedDirectFlux. The ticket will also propagate the PsfFlux plugin flag columns to the DiaSource catalog produced by ip_diffim."""
"DM-19913","Story","ts_qa",1,"XML - Create test to verify Alias matches EFDB_Name","""The topic Alias must match the last part of the EFDB_Name, otherwise the SAL can't properly build the libraries.  Add a test to robotframework_ts_xml to verify this."""
"DM-16707","Story","SUIT",8,"TAP search prototype","""Create a prototype page which would allow to browse TAP schema and submit queries to the selected TAP service."""
"DM-16700","Story","Data Release Production",2,"Add additional filter throughput terms to fgcmcal to fix HSC r/r2 bimodality","""DM-15895 investigated the source of the bimodality in the HSC S18a fgcm run when comparing HSC r-band to Gaia G band.  Most of the relative offset between different regions of the footprint was due to differing throughput of the HSC r and r2 filters.  This ticket will add additional fit terms to fgcm to allow for these sorts of throughput offsets (which also applies to the HSC i/i2 filters)."""
"DM-16699","Story","atmospec",40,"Initial atmospec development work","""Write a hacky, zeroth order version of the pipeline so that we have some skeleton tasks and structures in place to iterate on.    This should probably be done on a user branch, but I wanted to have a ticket number for this work to save git hassles later on as this will touch more than just atmospec.    This will initially be pretty hacky in places and probably not adhere to all standards, but will be tidied up before review.         Checklist/to-do list/steps in Augustin's pipeline:               """
"DM-16729","Story","JupyterLab",2,"Test quotas for DASK workers","""JupyterLab allows creating dask clusters.  Putting users in their own namespace allows for putting limits on the size of those clusters.  Test whether this works from the LSP at LDF."""
"DM-16758","Story","SUIT",3,"Test the lsst-lsp-int(PDAC) in February/March/April","""Monthly test to catch issues early"""
"DM-16757","Story","SUIT",2,"Test the lsst-lsp-int(PDAC) after PDAC hardware merge into the k8s commons","""test to make sure the system still work as it used to after the hardware merged into the k8s commons. """
"DM-16737","Story","Continuous Integration",3,"Test release process","""Test the build and release process.  This includes making all the relevant branches and mocking a feature branch that needs to be included (i.e. more than one release candidate)."""
"DM-16735","Improvement","ap_association|dax_ppdb",2,"Add sqlalchemy engine timeout setting to Ppdb config","""Mutli-processing runs of ap_pipe using the sqlite setting for Ppdb are running into the issue of timeouts when storing, assessing the database. This is a similar issue to what to was discovered in the previous sqlite, db backend. This ticket will add a timeout config to Ppdb that will allow this setting to be increased for both sqlite and other db options.    Additionally, [~salnikov] stated that PpdbProtoVisits was not meant to be used in production, only his testing. As such I will remove this call from being used in ap_association."""
"DM-17310","Story","ts_calibration",5,"Complete implementation of basic functionality of TunableLaser CSC","""Technically the code is there, but has not been functionally tested. In order to be complete, it must be tested and working. This allows the TunableLaser to start emitting the light beam and stop emitting through SAL state transitions. The component API already implements this functionality. Had Russell Owen look over the current implementation and he had some suggestions. I will be making those changes as part of this task.    The CSC now demonstrates basic state transitions including substates for propagating the laser. It demonstrates both local host functionality and network functionality with the chesterfield script machine. It can start propagating when in the enabled state. It can also stop propagating and be in the enabled state or if disabled will also stop propagating. Revamped the hardware wrapper api based on better understanding of hardware itself, updated the firmware to gain access to several error registers. Revamped unit tests to a slight degree. There is also a very simple settings api. Added all temperature sensors to telemetry in preparation for some stability(plus the fact that we don't know which ones are important). Added changedWavelength event to indicate that the wavelength has changed(may be redundant if wavelength is published as telemetry).          [Github Pull Request|https://github.com/lsst-ts/ts_TunableLaser/pull/8]"""
"DM-17333","Story","ts_middleware",1,"Finish acmCmd","""For the most part I have the changes I have made here complete TSS-3276, this task is to go over with Dave on my computer and make sure indeed that this is the behavior that is desired. I also have questions.     Primarily which files are involved with the Python wrapping. I will also include these relevant files with the visuals I am creating to help understand the salgenerator pipeline. """
"DM-17325","Story","ts_middleware",2,"Update EFD writers for multiple inserts per transaction","""Modify the EFD writer generators to produce code that bundles multiple available updates into single transactions to increase efficiency when the message rate it high"""
"DM-17324","Story","ts_middleware",1,"Configure mirror lab efd access via vpn","""Make the mirror lab EFD instance accessible via a VPN connection using the second ethernet port"""
"DM-17269","Story","ts_middleware",2,"Add 10g switch and configure private network","""Continue adding hw test cluster machines to optionally be no a private network,   provide mechanism for outside access (collaborate with IT N+S)"""
"DM-16788","Story","Qserv",20,"Add REST services for monitoring and managing the Replication System","""Deliverables:  * REST services for monitoring and managing the Replication System  * Web UI for displaying the status and managing the Replication system and Qserv"""
"DM-16801","Story","skymap",2,"Add method to turn sequential indexes to pairs in skymap","""Skymap supports turning index pairs into a sequential number. A method is needed to turn these sequential numbers back into pairs."""
"DM-16797","Story","pipe_base",2,"Add template string names and formatters to PipelineTask configs","""There is a common pattern in man of our tasks where dataset types share a common sub string. This ticket will introduce a way to template these names and format them at configuration time."""
"DM-16814","Story","dm_dev_guide|Stack Documentation and UX",1,"Replace Packages section in C++ Documentation Guide","""The C++ documentation guide recommends providing package documentation using Doxygen groups, which are being phased out. The section on package documentation should be rewritten (possibly as a link) pointing developers to the new Sphinx-based system."""
"DM-16813","Story","ip_isr",2,"Crosstalk correction doesn't raise when no xtalk matrix found","""[~lauren] reports that if doCrosstalk is set to True, rather than raising like all other parts of isr (right?!) when failing to find the necessary calibration products, processing continues, and sets all xtalk bits in the mask plane.         Fix should be to raise if parameters aren't found, in keeping with doBias, doFlat, etc."""
"DM-16810","Bug","butler",1,"Butler schema changes to run on Oracle","""We had a few issues importing the Butler schema into Oracle that should be relatively easy correct.    Oracle does not have a boolean data type for table columns. The column actual in table Datasetconsumers is a boolean in SQLite. We suggest changing that to varchar2(1) and adding a """"actual in ('T','F')""""check constraint in Oracle.    """"Size"""" is a reserved word in Oracle. The size column in table posixdatastorerecords will need to be renamed.    """"Group"""" is a reserved word in Oracle. The group column in table detector will need to be renamed.    There is a data type mismatch in constraint Dataset_fk6 between column detector (number) in table detector and column detector (varchar) in table dataset. Data types must match in columns defined in FK/PK constraints."""
"DM-17323","Improvement","ts_middleware",1,"EFD Writers optimization","""*Improvements*:   * Insert more data in 1 query   * Increase loop time on the EFD writers to reduce CPU usage    *Tests*:    (EFD writers used to perform these tests are in: [https://github.com/aanania/sal_initialization_scripts] , they are a copy of the SAL efd writers + small updates)    From some tests with the EFD writers with the M1M3 simulator (50hz data) on the VMs. These tests were done in VMs with limited resources so performance may not be as good as in real servers.    For the case of the MariaDB (same for influxdb) wih the VMs I got the issue that the insertion rate is slower than the data received.    With the EFD writers that comes with SAL I get this plot for (sndTimestamp – rcvdTimestamp). When the time is at ~220 I start losing messages due to overflow. (files attached with some data)     Then I did some udpates to the EFD writers to insert more rows in just 1 query (see files attached, they are not production updates because I removed EFD topic case from the code generation and I’m not very familiar with tcl). With these updates it seems that the performance issue was fixed and I’m not getting an increase in the time difference between (sndTimestamp – rcvdTimestamp) messages. The plot with this update (sndTimestamp – rcvdTimestamp) looks like this for a few hours run.    From mysql page (there’s also a similar page for Influx that says the same):         “To optimize insert speed, combine many small operations into a single large operation. Ideally, you make a single connection, send the data for many new rows at once, and delay all index updates and consistency checking until the very end.”      Ref: [https://dev.mysql.com/doc/refman/8.0/en/insert-optimization.html]     """
"DM-16828","Improvement","verify",1,"Add Job viewer to lsst.verify","""While working on {{ap_verify}} I found it easier to have a standalone program for summarizing a Job's contents than to manually load and inspect the Job object as described in [SQR-019|https://sqr-019.lsst.io/]. I add this script to {{lsst.verify}}, with documentation, in the hope that it will be useful for other developers."""
"DM-16825","Story","obs_lsst",1,"Please add the RTM-006  raft ","""Got the following while butlerizing some Dev runs in the {{LCA-11021_RTM-006-Dev}} folder of the SLAC test stand data:   {{ingest.parse WARN: translate_detector failed to translate detector: 'RTM-006'}}    Is it valid to add to the raft serial dict?     One example file:    {{/project/rgruendl/SLACmirror/SLACgpfs/jh_archive-test/LCA-11021_RTM/LCA-11021_RTM-006-Dev/5884D/xy_stage_acq/v0/38955/S22/E2V-CCD250-217-Dev_10.50_10.60_021_5884D_20180426174356.fits}}"""
"DM-16821","Story","daf_butler",1,"Add better debug output to butler queries","""Format sql queries with query parameters for better debugging"""
"DM-16819","Story","pipe_base",2,"Make minimal Gen3 shim for Gen2 DataRef, ButlerSubset, and Butler","""Write minimal shims that implement *some* Gen2 APIs using Gen3 implementations.  That will start with just get and put on DataRef and Butler, for Tasks that (at most) just pass Data IDs around without looking at what's in them.    Future ticket could add some data ID translation, if we decide that's better than putting conditional logic in the Tasks themselves.    Also add a """"gen"""" attribute to both Butler classes, so conditional code can actually be written."""
"DM-16818","Story","Developer Infrastructure",0.5,"t&s jenkins / docker hub credentials","""[~ttsai] would like to be able to build docker images under jenkins and push them to docker hub.  This requires a docker hub """"role"""" account to be setup and credentials installed into jenkins."""
"DM-16817","Story","pipe_tasks",2,"ingestCalibs resets all validity ranges","""ingestCalibs [modifies the validity ranges of calibs|https://github.com/lsst/pipe_tasks/blob/master/python/lsst/pipe/tasks/ingestCalibs.py#L97-L175], since there may be some overlap in the validity ranges after adding new calibs. However, this applies the new validity range to all calibs, even those that do not have an overlapping validity range. It also operates on all types of calibs, so that when ingesting flats, the validity ranges of biases can be modified.  The end result is that is not currently possible to maintain more than a single validity range within the entire calibs registry."""
"DM-18205","Improvement","ts_middleware",1,"Please enforce string length limits","""SALPY libraries do not enforce any limits for strings when sending topics:  - If a string for a fixed-length string item is longer than specified by the XML, the whole string is sent without warning. This can lead to many bad things, including a segfault when DDS tries to clean up.  - Surely there is an upper limit for a variable-length strings -- the maximum amount of data for a topic, of nothing else. What happens if this limit is exceeded?    One or both of these can lead to a *segfault* when DDS tries to clean up later.    I think both conditions should raise an exception when one tries to send the topic. It is important to catch errors early, and guarantee that data received by all listeners is correct."""
"DM-16837","Story","pipe_supertask",1,"Let PipelineTasks accept config parameters that are lists from the command line","""PipelineTask command line activator should be able to accept config overrides which are lists from the command line."""
"DM-16835","Bug","Continuous Integration",1,"scipipe/ap_verify job timing out","""[ap_verify build #74|https://ci.lsst.codes/blue/organizations/jenkins/scipipe%2Fap_verify/detail/ap_verify/74/] failed with what is believed to be a timeout error triggered by DM-16017 doubling the number of Job files from 6 to 12. Rather than rolling back the merge, the timeout on the {{ap_verify}} job should be increased (see discussion on DM-16519).    Please increase {{run_timelimit}} to accommodate at least 12 Job files. This is the maximum number of {{ap_verify}} jobs expected in the foreseeable future; DM-16536 will decrease the number of files to 7, and any future increases will not happen until we introduce metrics at new levels of granularity (e.g., visit- or tract-level)."""
"DM-16834","Story","daf_butler",0.5,"Fix skymap Dimension setting for converted Gen2 SkyMap Datasets","""Running deepCoadd_skyMap (and similar Datasets) through gen2convert does not result in the set the """"skymap"""" dimension key, which breaks PipelineTasks that use those Datasets as inputs.  This is due to missing translation rules in the gen2convert package.     """
"DM-16832","Story","Requirements Documents",1,"Prepare summary of design & scope options for mini broker / alert filtering service","""Requested by Zeljko. To include an overview of capabilities as well as potential cost savings. Initial text provided by [~ebellm]."""
"DM-16831","Bug","pipe_supertask",2,"Crash when running multi-task pipeline","""We tried to run {{stac}} with two tasks in a pipeline and it crashed:       This looks like it's trying to insert NULL as dataset_id into collection table for the new collection, and it happens when adding inputs to a new output collection. Maybe it also tries to add intermediate non-existing dataset?"""
"DM-16830","Story","afw",2,"Add versioning to PhotoCalib","""While converting PhotoCalib to be defined in nanojansky, I realized it would be good to add versioning to its persisted output. [~jbosch] says that SkyWcs is probably the best example of how to do this (sadly, we have neither a standard nor a common convention for how to version persisted afw objects).    For example, we are going to want to add a wavelength dependency in the future, which will definitely change the persistence."""
"DM-16869","Bug","daf_butler",1,"Inconsistent hash for DimensionSet/DimensionNameSet","""It looks like recent switch from units to dimensions created issuers in GraphBuilder, I'm getting error when trying to run simple pipeline of two tasks :      Looks like the dict indexing on DatasetType is broken, and this seems to be related to hash returning different values when dimension is either DimensionGraph or DimensionNameSet."""
"DM-16864","Story","ip_diffim|pipe_tasks",8,"Investigate relative DcrModel option","""An option that might improve the DcrModel is to make the model relative to a reference image. Each subfilter model plane would act like a """"rubber sheet"""" that can enhance or suppress the flux of the reference image in a pixel, rather than storing the absolute flux for that subfilter. This may make it easier to apply regularization, and ideally will also prevent noise being amplified.    If this feature ends up creating more problems than it solves, or otherwise does not perform as well as the original code, it should be closed as Won't Fix."""
"DM-16862","Improvement","afw",2,"Convert afw.math to numpydoc","""Convert all Doxygen-formatted docstrings in {{afw.math}} to Numpydoc style, and move corresponding topic documentation to {{doc/}}."""
"DM-16858","Improvement","afw",1,"Convert afw.display to numpydoc","""Convert all Doxygen-formatted docstrings in {{afw.display}} to Numpydoc style, and move corresponding topic documentation to {{doc/}}."""
"DM-16856","Improvement","afw",1,"Convert afw.coord to numpydoc","""Convert all Doxygen-formatted docstrings in {{afw.coord}} to Numpydoc style, and move corresponding topic documentation to {{doc/}}."""
"DM-16855","Improvement","afw",1,"Convert afw.cameraGeom to numpydoc","""Convert all Doxygen-formatted docstrings in {{afw.cameraGeom}} to Numpydoc style, and move corresponding topic documentation to {{doc/}}."""
"DM-16849","Story","atmospec",5,"Get Augustin's reduction pipeline running","""\{\{git clone https://github.com/guyonnet/slitless_image_reduction/}}    clone croaks & install it    Install and configure SExtractor    Get the pipeline running.    Then port it to py3 so it can be run from the same env as the stack.     """
"DM-17332","Story","ts_middleware",3,"Standalone OpenSplice","""Create a standalone program that can run on multiple machines. """
"DM-17331","Story","ts_middleware",3,"Pybind11 Leaning","""This task captures the time spent learning pybind 11. I have a standalone program that I have been working on as well which I used as a sandbox. Doing this helped with the learning curve jumping onto the templates used for ts_sal. """
"DM-16901","Story","meas_deblender",1,"Delete DeblendAndMeasureTask. ","""DeblendAndMeasureTask has not been updated since 2014. It has bitrotted.  """
"DM-16873","Story","pipe_tasks",8,"Convert MeasureMergedCoaddSources to Pipeline Task","""Turn MeasureMergedCoaddSources into a PipelineTak"""
"DM-16872","Improvement","afw",1,"Fix numpy warnings in afw","""Building {{afw}} with Numpy 1.15 gives a large number of {{FutureWarning}} and {{PendingDeprecationWarning}}, such as:      Rewrite the code to use non-deprecated APIs, as long as it's possible to do so using the Numpy 1.14 API."""
"DM-17364","Story","ts_auxiliary_telescope",2,"Please provide an event in ATDome that tells us where the dome is headed","""The ATDomeTrajectory CSC needs to know where in azimuth the dome is headed, in order to work properly. It would be really nice to get this as an event instead of having to follow a telemetry stream, because the one value we care about only changes occasionally.    I am requesting a new event that outputs the commanded state. For this to be useful the dome would have to output the event when it starts up, presumably listing the current state of the dome as the commanded state."""
"DM-17330","Story","ts_qa",3,"Review Pointing Component v0.2 Release","""This task covers the time spent to review the test results for the v0.2 Release of the Pointing Component."""
"DM-16931","Story","pipe_supertask",1,"Activator should register dataset types before trying to run pipeline","""Currently you can't change the config options that specify DatasetTypes to something new without explicitly registering them yourself first.  Make this something the command-line activator can (optionally) do for you.     """
"DM-16922","Bug","Firefly",1,"Region description parsing error on region size unit in arcsec and arcmin","""The region description parser at the client side doesn't interpret the region description with size unit in arcsec or arcmin correctly.    ex. the region description is like  image;box(100, 150, 1.0', 1.2', 0) # color=red     """
"DM-16917","Epic","ts_aos|ts_auxiliary_telescope|ts_qa",5,"Test ATHexapod Algorithm","""Test ATHexapod Algorithm"""
"DM-16914","Epic","ts_auxiliary_telescope",5,"AuxTel Pneumatics & Pointing Configuration Integration in Tucson","""Integration to be partitioned as follows:   # ATPointing + ATAOS integration    # ATAOS + ATPneumatics + ATHexapod integration   # ATPointing + ATAOS + ATPneumatics + ATHexapod integration    Required CSCs:   * ATPointing   * ATAOS   * ATHexapod   * ATPneumatics    Resources Required:   * Integration & Test Environment   * SAL   * EFD   * AuxTel Scripts"""
"DM-16908","Epic","ts_auxiliary_telescope|ts_dome",5,"Finishing ATDomeTrajectory Algorithm","""Finishing ATDomeTrajectory Algorithm         Duration: 10 Days"""
"DM-16907","Epic","ts_auxiliary_telescope|ts_qa",5,"Test ATDome Algorithm","""Test ATDome Algorithm"""
"DM-16905","Story","lsst-texmf",0.5,"Install lsst-texmf into the docker image in full","""Install the lsst-texmf repository in full into its Docker distribution. This will fix issues where \{\{generateAcronyms.py}} attempts to find a glossary file in etc/, but it is missing.    Also check that Python is installed in the Docker image (and drop Java since GaiaAcr.jar is replaced by generateAcronyms.py).    See also: https://github.com/lsst/lsst-texmf/issues/147"""
"DM-16904","Story","pipe_base",1,"Pass butler object to adaptArgsAndRun in PipelineTask","""The adaptArgsAndRun api for PipelineTask needs to include a butler object."""
"DM-16957","Bug","pipe_supertask",1,"Multi-process option is broken in pipe_supertask","""Looks like another victim of Unit to Dimension switch - {{-j}} option stopped working in stac:    I think DataId is not trivially pickled and may need special serialization override.  """
"DM-16954","Epic","ts_aos|ts_auxiliary_telescope|ts_qa",5,"Test ATPneumatics Algorithm w/ Hardware","""Test ATPneumatics Algorithm"""
"DM-16946","Epic","ts_auxiliary_telescope|ts_pointing|ts_qa",5,"Test ATAOS Algorithm","""Test ATAOS Algorithm"""
"DM-16945","Epic","ts_auxiliary_telescope|ts_pointing",5,"Finishing ATAOS Algorithm","""Finishing ATAOS Algorithm         Duration: 10 Days"""
"DM-16943","Epic","ts_auxiliary_telescope|ts_pointing",5,"Finishing ATPointing Algorithm","""Finishing ATPointing Algorithm         Duration: 10 Days"""
"DM-16938","Epic","ts_aos|ts_auxiliary_telescope|ts_qa",5,"Test ATPneumatics Algorithm","""Test ATPneumatics Algorithm"""
"DM-17004","Bug","jointcal",3,"JointcalRunner.__call__ not receiving ""butler"" in kwargs","""[~boutigny] reported [on slack|https://lsstc.slack.com/archives/C2K1NGR8E/p1545327822003100] that he was getting failures in jointcal when running multiple tracts, because """"butler"""" was not in the kwargs list. There haven't been any relevant changes to {{pipeBase.ButlerInitializedTaskRunner}}, so I'm not sure what could have happened.    I'll try to come up with a test case for this, but to start with I should try to reproduce it on lsst-dev."""
"DM-17003","Bug","ci_hsc",2,"ci_hsc tests (may) not have correct linker environment on macOS","""This is a probable regression introduced in DM-16819, when I tried to re-enable the test_import.py script in SCons (it looked like it was supposed to be run, but wasn't because the SConstruct wasn't talking to the SConscript because ci_hsc doesn't really use sconsUtils).    The causality was masked by a transient known download bug in Astropy."""
"DM-16998","Improvement","Qserv",8,"Update k8s/qserv/qserv_deploy and run Replication Service at CC-IN2P3","""- k8s 1.10.x upgrade was not working on Centos7  - old qserv version was not working on k8S 1.13 so qserv/qserv_version was updated to lates   - support for local storage was improved (using local-storage abstraction instead of hostpath 'raw' directive)  - replication service support was added (i.e. repl-svc is now able to use local storage trough k8s)  """
"DM-17029","Story","meas_algorithms|meas_astrom",8,"Update LoadReferenceObjectsTask to output fluxes in nanojansky","""PhotoCalib is now defined in terms of nanojansky, but our reference catalogs are saved in Jy, and remain in Jy when the user loads them. We need to get our refcat loaders to produce nJy to keep our calibrations self-consistent.    It may be enough to just multiply fluxes and flux errors by 1e9 after the data is read from disk, but [~krughoff] may have other suggestions.    We will have to add a few work-arounds for this to {{PhotoCal}} and other tasks that use the {{Calib}} object, as it will remained defined in Jy. If only we could do DM-10153 simultaneously (but I think that would be maddening)."""
"DM-17044","Story","ctrl_mpexec|pipe_base",0.5,"Make searching packages for PipelineTasks optional in command-line activator","""The process of importing all modules in lsst.pipe.tasks to search for PipelineTask is slow enough that it's not always a convenience; while it's very nice to have for the list subcommand, it'd be nice to disable it if the user provides fully-qualified names for the Tasks to be run.    Another option might be to cache the results of the search to a temporary file so it's only slow the first time the activator command-line tool is invoked in (e.g.) a terminal session, but it seems to me that it'd be difficult to know when to invalidate that cache."""
"DM-17043","Story","meas_algorithms",8,"Add selection on S/N in objectSizeStarSelector","""Currently, the *objectSizeStarSelector* Task allows for source selection based on flux limits. A selection on signal-to-noise (S/N), i.e. flux/fluxErr, is often preferred, so should be added as an option for this source selector.    Additionally, there is currently no unittest for *objectSizeStarSelector*, so a minimal one should be added (following the *test_astrometrySourceSelector.py* and *test_matcherSourceSelector.py* examples).    For this ticket, the option will simply be added in the same manner as the flux selection is done, but all current defaults will be left as is. Looking towards the future, I anticipate submitting an RFC to make S/N selection the default (instead of a flux-based selection, but, in principle, both could be activated simultaneously) as well as adapting all the *SourceSelectorTask* to make use of the configuration-based selection classes in *BaseSourceSelector*-derived Tasks (e.g. *objectSizeStarSelectorTask*, *AstrometrySourceSelectorTask*, *MatcherSourceSelectorTask*, *FlaggedSourceSelectorConfig*) [https://github.com/lsst/meas_algorithms/blob/master/python/lsst/meas/algorithms/sourceSelector.py#L153])."""
"DM-17042","Story","pipe_base",1,"PipelineTask single-config override does not parse booleans correctly.","""Options like {{-c label.option=True}} don't seem to work.  If needed, I think [~yusra] has a more complete how-to-reproduce."""
"DM-17041","Story","pipe_base",0.5,"Make PipelineTask command-line label default to Task class name","""stac/pipetask currently require the user to create a label explicitly in order to provide config overrides.  We should make the default label to the Task class name (i.e. the same name that was just passed to {{-t}}).  While it's possible to to have multiple instances of the same Task, that's currently quite rare and we should make the common case simpler and more intuitive.    After a bit of discussion, [~nlust], [~yusra], and I agreed it'd be better to use the Task class name rather than {{Task._defaultName}} because the former is what's also typically present on the same command line."""
"DM-17048","Story","daf_butler",0.5,"Fix handling of ref_cat in gen2convert","""We've been accidentally ignoring ref_cat because we didn't have its StorageClass (SimpleCatalog) in Gen3 yet; adding that yields a sequence of (minor) additional problems."""
"DM-17338","Story","ts_auxiliary_telescope",1,"Create SmartDome command analysis summary","""Create a summary analysis of the SmartDome commands, indicating which interrupt which others, etc."""
"DM-17055","Story","dax_ppdb",1,"Change Sigmas to Err in dax_ppdb schemas","""Some of the columns names in dax_ppdb still has several columns that were not converted by myself from Sigma to Err. This ticket will convert the column names to the expected Err name."""
"DM-17049","Story","squash",0.5,"Add verify timestamp as a new field in InfluxDB measurements ","""I was trying to add to the SQuaSH dashboards a single stat showing the time of the last validate_drp measurement - it turns out that stats visualization does not display timestamps, only numbers, and it is not possible to do math on timestamps in InfluxQL to get say """"number of days without measurements""""     https://github.com/influxdata/docs.influxdata.com/blob/master/content/influxdb/v0.13/troubleshooting/frequently_encountered_issues.md#doing-math-on-timestamps     So I think it is a good idea to add the timestamp of the measurement as a new field, as we did for the EFD topics, there that information was useful to report on things like latency for instance. """
"DM-17060","Story","ctrl_mpexec|pipe_base",1,"Fix non-merged ticket","""Some work did not get properly merged in pipe_supertasks on ticket-16797 before much of that content was refactored into different packages. This ticket will add that missing code to the right places."""
"DM-17246","Story","ts_auxiliary_telescope",5,"Write ATMCS simulator","""Write a simulator for the ATMCS CSC in Python. I'm not positive it will have the necessary performance, but it's quick to try."""
"DM-17172","Story","ts_middleware",2,"Update configuration to MySQL Cluster to be able to add more topics ","""The default configuration doesn't give enough memory to MySQL cluster to allocate all the tables for the EFD. Need to be reviewed why and how to solve it."""
"DM-17171","Story","ts_middleware",3,"MySQL TIER tests using separate table spaces","""Try to use table spaces to allocate tables in different disks for TIER purposes. This seems to be a better solution than having multiple instances (one for each TIER).    This test will be performed in a virtualized environment."""
"DM-17170","Story","ts_environment",1,"Meet with people from DatControl","""Meet with Orlando Castro from DatControl to test and review communication protocol between our software and their HVAC system. It seems that is can be done using a SQL data base to send commands to their system.    Also need to check if this also give us the telemetry of the system, so we can publish it through SAL later.    This task is to keep things moving forward while German is on vacation."""
"DM-17160","Story","ts_auxiliary_telescope",2,"Add error check to ATHexapod ","""Add error check to ATHexapod code. This also includes command rejection."""
"DM-17067","Story","ctrl_mpexec",0.5,"Move parsing of dataset-name-substitution option to ctrl_mpexec","""DM-17060 implements parsing of the value of the option {{--dataset-name-substitution}} inside PipelineBuilder class. I think it would be better and more generic for PipelineBuilder to accept a dict and parsing should happen in a cmdLineParser."""
"DM-17066","Improvement","dbserv",5,"update albuquery to work with latest QServ parser on UDFs","""Per incoming request from [~gpdf], we are to deploy legacy DAX services at lsst-lsp-int in PDAC. Upon deployment, it was found that queries with UDFs including the following were failing:                     qserv_areaspec_circle()                     qserv_areaspec_poly()    As it turned off, the issue was caused by the addition of back ticks in albuquery to work around old Qserv parser not being able to handle top-level groupings with UDF.  The latest parser improvements by [~npease] seem to have removed that need to do that.           This ticket is to remove the workaround, retest, and deploy albuquery to lsst-lsp-int.     """
"DM-17089","Story","Qserv",5,"remove antlr2 and related code from qserv","""Remove any use of Antlr 2 and related code (refactor or remove as appropriate) from qserv."""
"DM-17088","Bug","daf_persistence|pex_config",0.5,"Fix collections import deprecation warning in python 3.7","""In python3.7 these warnings turn up:    {quote}  DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working  {quote}    pex_config and daf_persistence are known to have the problem."""
"DM-17073","Story","ip_isr",1,"ISR is too chatty","""Lower some of the new logger INFO messages to DEBUG"""
"DM-17326","Story","ts_middleware",1,"SAL mentoring","""Continue SAL mentoring, advise in building single task command/event test programs for faster Jenkins testing"""
"DM-17279","Story","ts_hardware",3,"Debug network non-connection on mirror lab EFD machine and VPN","""Debug network configuration issues involved in establishing remote access  (via reverse VPN to gateway pc) to EFD in mirror lab for test campaign"""
"DM-17112","Story","obs_lsst",3,"Update corner rafts to have correct detector type","""Since the base detector type is {{SCIENCE}} the Corner rafts are inheriting the same type.  I need to add some detector types that implement the other enumerations."""
"DM-17110","Story","Firefly",8,"Save tables in VO format","""- Save the table in VO format.      Firefly will have more meta data about table supplied by VOTable, and keeping them in the saved file would be desirable.     - fix the following table save' related issues as commented in DM-16048 https://jira.lsstcorp.org/browse/DM-16048     Comment 2:  . In the """"Save table"""" dialog, the second line """"Save as""""  is changed to """"File name"""".    Comment 3.   The default filename for a cone search has a dash, underscore, parenthesis, colon, space, and double quotes.     Fixing methods:        remove all of the special characters except for dashes and underscores.        Replace left parentheses with dashes.        Remove the trailing right parentheses, or replace the right parentheses with dashss.        Replace double-quotes with 'asec'.        Remove spaces.        Replace decimal points with 'p' for 'point'.          ex: for cone search,        WISE-allwise_p3as_psd (Cone:100'').csv => WISE-allwise_p3as_psd-Cone_100asec.csv       for elliptical, box, polygon, multiple-object and all sky search, form the filenames        respectively to be like:       WISE-allwise_p3as_psd-Ellipse60_0_0p26asec.csv        WISE-allwise_p3as_psd-Box_100asec.csv      WISE-allwise_p3as_psd-Polygon.csv      WISE-allwise_p3as_psd-MultiObject.csv      IRAS-irasgal-AllSky.csv    Comment 4,   For elliptical searches, the filename comes out with the string 'Eliptical'.     Fixing method:     Change it to be 'Ellipse', and the filename contains information on position angle and axial ratio as well as the semi-major axis.     Comment 5     When you upload a table for Multi-Object search,  there is no string to indicate what type of search was done.    Fixing method:   'MultiObject' is appended to the filename to indicate the type of search.    Comment 7,   For the """"Load Catalog Dialog"""", the chosen filename is severely truncated in the display.   I see """"Custom catalog in IPAC table format"""" in that dialog, even though I seem to be able to load csv and tsv files.    Fixing methods:   More space is shown to contain the chosen filename.   Fix the hint sentence that custom catalog in IPAC, CSV, TSV, VOTABLE and FITS table format are able to be loaded.    Other fixings:  Fixes the help link for 'table save' dialog and 'Load Catalog' panel.         """
"DM-17095","Story","obs_lsst",0.5,"Tests are very slow in obs_lsst","""The butler tests in obs_lsst take a very long time (12 minutes on my laptop just for imsim). It seems that this is almost entirely down to a butler being setup for every single test. Investigate whether the butler can be set up once per test class instead (there might be an issue with the global variable when tests run in parallel)."""
"DM-17327","Story","ts_main_telescope",3,"Support SAL on RPI platform for use as EAS generic sensor processor","""Many of the EAS sensors have a requirement for SAL support on an embedded system  (Raspberry Pi). Create a reference implementation and consult with the developers to deinfe the appropriate generic EAS XML for the various sensor types"""
"DM-17189","Story","ts_main_telescope",2,"Document the WEP with New Update","""Document the wavefront estimation pipeline (WEP) with new update to adapt the new scientific pipeline feature (tag: sims_w_2018_47). The obs_lsst replaces the obs_lsstSim. The phosim_utils is used to repackage the PhoSim amplifier outputs. """
"DM-17188","Story","ts_main_telescope",5,"Knowledge Transfer of Active Optics","""Teach David (PhD student in Stanford University) the background knowledge of active optics and the use of AOS codes (contains ts_tcs_wep, ts_tcs_wep_phosim, and ts_tcs_ofc). Discuss the AOS closed-loop simulation with PhoSim."""
"DM-17186","Bug","ts_auxiliary_telescope",1,"show_salpy_attributes.py fails for non-indexed components","""The ts_salobj script show_salpy_attributes.py fails for SAL components that are not indexed because it uses index 1 instead of 0. The fix is trivial."""
"DM-17185","Epic","ts_auxiliary_telescope",5,"Testing of ATThermoelectricCooler SW","""Testing of ATThermoelectricCooler SW Development"""
"DM-17183","Epic","ts_auxiliary_telescope",20,"Testing of ATWhiteLightSource SW","""Testing of ATWhiteLightSource SW"""
"DM-17173","Bug","Qserv",1,"QServ parser returning errors for UDF queries that used to work","""Per [~tatianag] report, the following queries are failing (they worked as of Nov 14, 2018):(    SELECT * FROM sdss_stripe82_01.Science_Ccd_Exposure WHERE scisql_s2PtInBox(corner1Ra,corner1Decl,0,-1,5,1) = 1 AND scisql_s2PtInBox(corner2Ra,corner2Decl,0,-1,5,1) = 1 AND scisql_s2PtInBox(corner3Ra,corner3Decl,0,-1,5,1) = 1 AND scisql_s2PtInBox(corner4Ra,corner4Decl,0,-1,5,1) = 1;   ERROR 4110 (Proxy): Query processing error: QI=?: Failed to instantiate query: ParseException:Error parsing query, near """"-1""""       MariaDB [(none)]> SELECT * FROM sdss_stripe82_01.Science_Ccd_Exposure WHERE (scisql_s2PtInBox(corner1Ra, corner1Decl, 0, -1, 5, 1)=1) AND (scisql_s2PtInBox(corner2Ra, corner2Decl,0, -1, 5, 1) =1) AND (scisql_s2PtInBox(corner3Ra, corner3Decl, 0, -1, 5, 1)=1) AND (scisql_s2PtInBox(corner4Ra, corner4Decl, 0, -1, 5, 1)=1);   ERROR 4110 (Proxy): Query processing error: QI=?: Failed to instantiate query: ParseException:Failed to instantiate query: """"SELECT * FROM W13_sdss_v2.sdss_stripe82_01.Science_Ccd_Exposure WHERE(scisql_s2PtInBox(corner1Ra,corner1Decl,0,-1,5,1)=1) AND(scisql_s2PtInBox(corner2Ra,corner2Decl,0,-1,5,1)=1) AND(scisql_s2PtInBox(corner3Ra,corner3Decl,0,-1,5,1)=1) AND(scisql_s2PtInBox(corner4Ra,corner4Decl,0,-1,5,1)=1)""""         MariaDB [(none)]> SELECT * FROM sdss_stripe82_01.Science_Ccd_Exposure WHERE scisql_s2PtInBox(corner1Ra,corner1Decl,0,-1,5,1) = 1 AND scisql_s2PtInBox(corner2Ra,corner2Decl,0,-1,5,1) = 1 AND scisql_s2PtInBox(corner3Ra,corner3Decl,0,-1,5,1) = 1 AND scisql_s2PtInBox(corner4Ra,corner4Decl,0,-1,5,1) = 1;   ERROR 4110 (Proxy): Query processing error: QI=?: Failed to instantiate query: ParseException:Error parsing query, near """"-1""""          """
"DM-17149","Story","pipe_tasks",0.5,"MergeDetectionTask PipelineTask mode should export peak schema","""The pipeline task mode of MergeDetection task is only writing out it's detection schema, but should also be writing out its peak schema, add this behavior."""
"DM-17148","Story","ctrl_mpexec",1,"pipeline task activator squashes import errors","""If the activator is being used to run or list, it will not find, or hide results for modules for which there was an import error, and report to the user that that module does not exists. This should at least produce a warning that there was a problem importing a module by python so the user can track down why there was a problem importing."""
"DM-17146","Story","pipe_tasks",0.5,"Fix storageClass for DetectCoaddSources PipelineTask","""At some point daf_butler became more strict and there was no testing to catch that all instances of Exposure should be ExposureF. Fix this in DetectCoaddSourcesConfig"""
"DM-17144","Story","Qserv",1,"Update qserv and qserv_deploy image","""- Update qserv and qserv_deploy container images an validate using CI  - Put all openstack script in `obsolete/` directories, final goal is not to have kubernetes provisioning script inside qserv_deploy, but to delegate it to underlying infrastructure  - update GKE procedure for creating k8s cluster"""
"DM-18261","Story","ts_environment|ts_middleware",3,"Support SAL on RPI platform for use as EAS generic sensor processor","""Many of the EAS sensors have a requirement for SAL support on an embedded system  (Raspberry Pi). Create a reference implementation and consult with the developers to deinfe the appropriate generic EAS XML for the various sensor types"""
"DM-18252","Story","ts_middleware",1,"SAL mentoring","""Continue SAL mentoring activities with Andrew, Tei-wei, Garry , Petr etc"""
"DM-17322","Story","ts_middleware",2,"EFD Writers optimization","""Change writers to implement transactions which batch sets of inserts for increased effciency"""
"DM-17219","Story","DM",1,"milestone upates","""1. Milestone for Science Platfiorm       Depends on DAX services for ADQL and Imgacutout        decide if it test uses the new CAOM model            2. DAQ milestone - nominally April as thats when Huffer the new DAQ (full) would be delivered. """
"DM-17214","Story","Firefly",8,"TAP search: Advance ADQL query panel for ","""Do the following:   * Write advance query panel part of the TAP search   * work with [~tatianag] and [~gpdf] to determine what should be in it."""
"DM-17213","Story","Firefly",8,"TAP Search: Spatial and temporal specialized search boxes","""To the following:   * Write top top right box on the TAP search panel - Spatial and time selection   * Work with [~tatianag] and [~gpdf] to determine what should be in it.   * Add analysis of tap schema to control what is displayed"""
"DM-17212","Story","Firefly",8,"TAP Search: Create a component to select tables and schema that is Firefly/IRSA viewer like","""Do the following:   * Write the top left side of the panel of the TAP panel   * Change the select tables on be one similar to IRSA viewer/firefly catalog   * Write this component   * Add button to be a placeholder for a advanced table select popup   * Anything else to complete this panel"""
"DM-17211","Story","Firefly",8,"TAP Search: Update the TAP panel layout/infrastructure to allow for concurrent work","""Do the following:   * Update layout to all for a blank spacial/time search panel   * Update layout to allow to a tab area with advance tap search panel - move existing dialog box.  Possibly  add a button to populate and switch tabs.   * Add area to select TAP search service.   * Any other clean up to allow for concurrent work on the TAP search panel"""
"DM-17210","Story","ts_management",3,"Confluence Page Organization","""Go through the teams Confluence page. Reorganize so that finding documentation becomes easier. Have had multiple conversations with team members and Jonathan Sick before making the actual changes as well as a tech talk where team members can give input. """
"DM-17207","Improvement","ts_auxiliary_telescope",1,"ts_salobj refinements","""A few refinements that would make ts_salobj a bit easier to use:  * All topics should have an instance of the data as attribute {{data}}. It makes sending commands and outputting telemetry and events much simpler and avoids the need for the CSC to create its own attributes containing received data.  * Add a {{set}} method to all topics that allows setting fields of the contained data.  * Use this contained data by default for methods that take {{data}} as an argument, e.g. {{put}} and {{start}}.  * Add {{set_put}} to {{ControllerTelemetry}} which calls {{set}} and then {{put}}, allowing you to update the data and output it with a single call. I anticipate that this will become the standard way to output telemetry.  * Add a {{set_put}} method to {{ControllerEvent}} that only puts the data if it has changed or has never been output. Again, I anticipate that this will become the usual way to output events.  * Hoist some names in {{test_utils}} up into the {{lsst.ts.salobj}} namespace, in particular the {{assertRaisesAckError}} and {{set_random_lsst_dds_domain}}  * Make {{heartbeat_interval}} an attribute of {{BaseCsc}} so it can easily be changed, e.g. for unit tests."""
"DM-17204","Bug","ts_middleware",2,"NDB Cluster constraint","""MySQL Cluster has constraints that are not present in mariadb particularly that there is a limit in the ammount of columns in a table (512 in MySQL Cluster and larger in mariadb). Currently there are CSCs publishing more than 512 attributes in their topics which prevent us from creating the tables in the EFD for those cases (MTM1M3 and DomeLouvers Telemetry, those I know and I don't know if there are more cases).    Reference:     [https://dev.mysql.com/doc/refman/8.0/en/mysql-cluster-limitations-database-objects.html]     """
"DM-17202","Story","ts_middleware",3,"Move SAL unit tests into one","""Move all the SAL unit tests into a single file so that when running under an automated test environment it is much faster to finish testing.     It is faster because unlike how it currently is, you need to start SAL services for every single topic. By having all the tests in a single file the SAL services only needs to start once."""
"DM-17200","Epic","ts_environment",5,"DIMM + EFD HW Integration","""DIMM + EFD HW Integration"""
"DM-17199","Epic","ts_environment",5,"Testing of DIMM SW","""Testing of DIMM SW"""
"DM-17198","Epic","ts_environment",5,"Finishing DIMM SW Development","""Finishing DIMM SW Development:   * CSC Development   * Integration with Turbina software   * Integration with vendor provided control software"""
"DM-17197","Story","ctrl_mpexec|pipe_base",2,"Support PipelineTask execution without writing init output datasets","""Running {{pipeTask}} with the same output collection and different quanta tries to write init outputs (schemas) multiple times, failing.  Provide (ideally) ways to run any combination of   - Preflight   - Initialization I/O   - Execution    or if that's too hard, at least make it possible to run Execution without Initialization I/O."""
"DM-17249","Improvement","ts_auxiliary_telescope",1,"Check target from controller for ATHexapod","""Make the CSC to check the target directly from the PI Controller. Currently it directly keeps record of the target."""
"DM-17248","Improvement","ap_verify",2,"ap_verify should create .json files in the workspace by default","""Currently, {{ap_verify}} creates its metrics files in the caller's working directory. A more compartmentalized way to handle the output is to put it in the workspace created with the {{\-\-output}} command-line argument. This will not interfere with the Butler (since the workspace is not a repository) or CI upload (which searches for files in the entire directory tree, see DM-16728).    The main complication is how to handle the {{\-\-metrics-file}} argument. The best option is probably to include an \{output} placeholder (making the default value """"\{output}ap_verify.\{dataId}.verify.json""""). This will avoid surprising behavior from making the directory implicit, and will be backwards-compatible with any scripts that already use {{\-\-metrics-file}}."""
"DM-17247","Story","HeaderService",1,"Fix unresolved conflict error on last merge to master","""Fix commit error on last commit: 4fc891f69ed99fa223f464564b31d495e6902a8ba"""
"DM-17227","Story","ts_auxiliary_telescope",2,"Update ATMCS interface","""Update ATMCS interface according to discussion with Patrick, Rolando and Russell    Changes:  - Add M3 motor encoder data to existing telemetry topics.  - Remove ATMountState enumeration values that overlap summary state.  - Remove M3State enumeration values that overlap summary state.  - Reorder fields in the {{mountEncoders}} telemetry topic to the standard order used everywhere else.  - Rename command topic fields that are ignored to {{ignored}}.  - Rename brake fields from {{engage}} to {{engaged}}.  - Remove {{m3RotatorDetentLimitSwitch}} to {{m3RotatorDetentSwitches}} and remove {{Detent}} from the field names.  - Remove redundant {{State}} suffix from {{ATMountState_}} and {{M3State_}} events, e.g. change {{M3State_DisabledState}} to {{M3State_Disabled}}.  - Add documentation for all topics (and fix existing incorrect documentation).  """
"DM-17299","Improvement","obs_lsst",3,"Clean up obs_lsst scripts","""Test scripts in {{bin/}} need to either go elsewhere or have names that are more clear. They'll get loaded into the default search path and nobody will know why {{processCcd}} does something totally different than {{processCcd.py}}.    In the Python library directory, the files {{segmentationToRafts.py}} and {{phosimToRafts.py}}, {{generateCamera.py}} are more like scripts, belong elsewhere (e.g. in {{bin/}}). They have  {\_\_main\_\_}} blocks and they do not look like they are meant to get imported by anything else so there is no reason to have them in the module.    These issues should be addressed before inclusion in lsst_distrib."""
"DM-17298","Story","Notebooks|Science Platform",8,"LSP Notebook scale test on Google Cloud","""Perform a large scale (cores greater than available at NCSA) test of notebook aspect deployed on the Google Cloud. Scheduled for Thursday, 01/17/19 12pm to EOB project time."""
"DM-17297","Story","meas_astrom",2,"Remove CatalogStarSelector","""Implement the adopted change of RFC-560, removing the unused CatalogStarSlectorTask"""
"DM-17294","Improvement","obs_lsst",1,"Move and/or document miscellaneous files in obs_lsst","""data/input/hack_python.txt needs at least an explanation of what it does    bin.src/makeFpSummary.py probably belongs somewhere else, not in obs_lsst."""
"DM-17289","Story","DM",1,"Monthly report","""write the Management summary"""
"DM-17288","Story","Firefly",8,"Test multicast on GKE","""Evaluate whether multicast can be used in a GKE cluster for multiple firefly servers."""
"DM-17284","Story","ctrl_mpexec",0.5,"Add ctrl_mpexec to lsst_distrib","""Last item for RFC-554 is to add new re-factored package to lsst_distrib."""
"DM-17281","Story","ap_verify",2,"Update difference imaging templates in datasets","""Both {{ap_verify_hits2015}} and {{ap_verify_ci_hits2015}} use very old coadds from HiTS 2014 data as templates for difference imaging. These should be updated with the latest and greatest (most likely CompareWarp coadds constructed from a subset of best seeing images)."""
"DM-17328","Story","ts_main_telescope",2,"Add MovingState substate to LinearStage CSC","""Add moving state substate to LinearStage xml and CSC. Involves adding Enum subclass and finishing detailed_state getter and setter.    Tested with localhost vm and embedded pc using chesterfield as remote. Linear Stages are now on separate USB ports and are capable of moving at the same time. They will not accept a moving command while moving. Script code has been modified accordingly. XML was adjusted for index-ability.    [Github Pull Request|https://github.com/lsst-ts/ts_LinearStage/pull/7]"""
"DM-17320","Story","ts_calibration",2,"Add settings & configuration implementation to TunableLaser api","""Add settings & configuration reader to TunableLaser api that is in accordance with the yaml specification. It will use pyyaml to parse and update settings. Currently blocked due to in-progress design of salobj configurable CSC."""
"DM-17319","Story","ts_calibration",2,"Add basic simulation_mode to TunableLaser hardware api","""As part of the new simulation mode for CSC, design and implement a simulation mode for the hardware. Mock serial port and return sensible values for registers.    Read only registers will set static value and writable registers will set whatever acceptable values are sent.    [Github pull request|https://github.com/lsst-ts/ts_TunableLaser/pull/9]"""
"DM-17318","Story","Third Party Software",0.5,"Update sqlalchemy to v1.2.16","""Update the EUPS version of sqlalchemy following RFC-564."""
"DM-17317","Story","ts_main_telescope",1,"Clean ts_statemachine and salpytools logic for LinearStage CSC","""The LinearStage has logic that is tied to the now deprecated ts_statemachine and salpytools. The hardware api shall be cleaned up of this logic. The statemachine api will be removed because salobj inherently handles state functionality. The project structure will also change to a more traditional pythonic structure. The zaber library will be upgraded to the latest one released.         [Github Pull Request|https://github.com/lsst-ts/ts_LinearStage/pull/6]"""
"DM-17315","Story","ts_qa",2,"Create Makefile tcl","""Create the tcl script that will produce a makefile for the cpp generated file. """
"DM-17303","Story","ts_auxiliary_telescope",1,"Prepare ATPointing and ATAOS for integration test","""This task will consist in making sure ATPointing and ATAOS run with the same version of SAL, write an OCS-Script to drive the test and run the test locally.     Final integration will happen when both systems can be deployed on the Test environment using our deployment strategy.     Artifacts:   * Docker container with ATPointing component   * Docker container with ATAOS component   * OCS-Script to drive the test    Required CSC:   * ATPointing   * ATAOS   * ScriptQueue          """
"DM-17384","Story","ts_management",1,"Write the Self-Evaluation","""Write the self-evaluation in Ultipro for the 2018 performance evaluation."""
"DM-17383","Story","dm_dev_guide",1,"Onboarding instructions for Nebula are confusing","""https://developer.lsst.io/team/onboarding.html#data-facility-resources states (or, at least, heavily implies) that everybody being onboarded to DM automatically gets issued with an account which provides access to Nebula.    Apparently, that's not actually the case: Nebula accounts are only available following the procedures at https://developer.lsst.io/services/nebula/index.html and are not issued automatically.    Please update the Dev Guide to make this clear."""
"DM-17382","Improvement","pipe_tasks",2,"Make CharacterizeImageTask a pipelineTask","""CharacterizeImageTask needs to be converted to a gen3 pipelineTask."""
"DM-17375","Story","astro_metadata_translator|obs_lsst",2,"Change license of astro_metadata_translator","""astro_metadata_translator has by default been using GPLv3. In order to encourage contributions from the astropy community in this ticket we will change the license to BSD 3-clause."""
"DM-17374","Story","ts_auxiliary_telescope",2,"Review initial ATHexapod code","""This task is to review the following ATHexapod tasks.    https://jira.lsstcorp.org/browse/DM-17161    https://jira.lsstcorp.org/browse/DM-17162    Since this review is expected to be rather involved, it deserves a task of its own."""
"DM-17373","Story","ts_pointing",1,"Go over pointing component contract status with Tiago","""The task is to meet with Tiago (and Andy Clements) and provide Tiago with the information he needs to take over management of the pointing component contract."""
"DM-17372","Story","ts_auxiliary_telescope",2,"Write analysis report on SmartDome software","""An action item out of the ATDome meeting relating to [https://confluence.lsstcorp.org/display/LTS/ATDome+Control+Issues] was to look at the vendor-supplied SmartDome software, identify what desired features are missing or already present somehow or how they could be met, and summarize options for making modifications.    The deliverable will be a report that addresses these topics."""
"DM-17371","Story","ts_qa",2,"Research Docker and Jenkins usages and integration","""This task covers the effort to learn how to use Docker and how it integrates with Jenkins.  The TSSW Jenkins environment was updated to be more DM like and therefore, requires using Jenkins to run jobs via Docker containers.  I need to time to learn and implement the testing in this new paradigm."""
"DM-17370","Story","ts_aos",2,"Update the AOS modules to Use the Tag: w_2019_02","""Update the ts_tcs_ofcPython, ts_tcs_wep, and ts_tcs_wep_phosim to use the scientific pipeline with the tag of w_2019_02. This is to adapt the update of obs_lsst."""
"DM-17369","Story","obs_lsst",2,"Enable sphinx documentation in obs_lsst","""obs_lsst needs to have the documentation build enabled. It still mostly uses doxygen strings (presumably as a hold over from the early days)."""
"DM-17368","Story","ts_qa",3,"Support M1M3 Mirror Lab testing - part 2","""This task covers the re-training on M1M3 control in support of Mirror Lab testing."""
"DM-17366","Story","ts_qa",2,"Get Pointing Component to build in the TSSW CI","""Get the Pointing Component tests created and running.  Get the Docker image from Andrés that has the PtgComp installed.  -Figure out how to run the vendor supplied Robot-Framework tests.-  """
"DM-17348","Story","ts_middleware|ts_qa",2,"Java Test scripts | part 1","""salgenerator should now be producing the C++ telemetry, commands, and event tests into a single file so that during automated testing the tests can be completed much faster than having to fire up a sal manager every time. Which currently is all we have.  This task is to do the same for Java. The reason there is part 1 to the task is I am not quite sure how it works. Once I identify what I need to know I can better estimate the length that this task will take me."""
"DM-17347","Story","ts_auxiliary_telescope",1,"Configurable speeds ATHexapod","""* Implement setMaximumSpeeds in the ATHexapod, this will be used from the configuration files.   * Update target position from the controller directly instead of following at a higher level """
"DM-17346","Story","ts_qa",3,"C++ Telemetry Test file","""Currently only the commands in c++ are being tested from a single file. This task is to complete tcl scripts to produce the telemetry tests into a single file as well."""
"DM-17345","Story","ts_middleware",3,"Stress test m1m3 EFD and Kafka writers","""Add kafka high data rate writers to the end machine in the mirror lab.  Run on a separate machine as well. Verify binary log backups"""
"DM-17344","Story","ts_qa",3,"C++ Events","""Currently only the commands in c++ are being generated into a single file. This task is to complete tcl scripts to produce the telemetry tests into a single file as well."""
"DM-17342","Story","ts_calibration",3,"Add simulation mode & settings to CBP CSC","""Add simulation mode to CBP CSC. Commands should return sensible values.    Add settings and configuration to CBP CSC."""
"DM-17341","Story","ts_middleware",2,"Verify SAL java with latest release","""# Test SAL java interface with aux tel camera CSC in simulation mode on the test hardware cluster.   # Have [~tjohnson] test with his latest auxtel camera code and the physical camera system."""
"DM-17412","Improvement","pipe_tasks",2,"Make MergeMeasurementsTask a valid pipelineTask","""MergeMeasurementsTask needs to be converted to a gen3 pipelineTask."""
"DM-17407","Epic","ts_main_telescope",5,"Finishing of CBP CSC Development","""Finishing of CBP CSC Development"""
"DM-17406","Epic","ts_main_telescope",20,"Integration of TunableLaser CSC","""Integration of TunableLaser CSC"""
"DM-17404","Epic","ts_main_telescope",5,"Finishing LinearStage CSC Development","""Finishing LinearStage CSC Development"""
"DM-17399","Bug","meas_algorithms",1,"Issue(s) with test_measure.py in meas_algorithms","""In the {{testFootprintsMeasure}} function in *tests/test_measure.py* in {{meas_algorithms}}, the test claims to """"Check that we can measure the objects in a detectionSet"""". All of the """"asserts"""" of the test occur within a loop over the sources in {{measCat}} ([here|https://github.com/lsst/meas_algorithms/blob/master/tests/test_measure.py#L147-L167]). HOWEVER, when I run this test, I get 0 detections, so that loop is never entered and no assertions get made (which I noticed when I was not seeing any dots on the sources in ds9 when updating the display code). It seems that something is seriously amiss if we are expecting (it looks like at least 3) detections but getting 0.  (I also think I see this as the line     in Jenkins artifact files, e.g. [here|https://ci.lsst.codes/job/stack-os-matrix/29286/artifact/centos-6.devtoolset-6.py3/lsstsw/build/meas_algorithms/tests/.tests/pytest-meas_algorithms.xml], so it's not just a local setup issue).    Also, in the {{testDetection}} function, nothing is actually """"asserted"""" in the function, so it seems that the """"test"""" is that it does not crash when running through the operations? Would a check on a (minimum?) number of detections be appropriate here?"""
"DM-17398","Story","ctrl_mpexec|pipe_base",0.5,"Support execution of incomplete graphs","""Michelle discovered an interesting issue while trying to run {{pipetask}} on a single Qunatum (extracted from a full graph). Graph {{traverse()}} method tries to determine prerequisites for a quantum execution by looking at quanta inputs and determining which other quanta produced those inputs. It works OK on a full graph but when single quantum is removed from a graph its prerequisites are not in the same graph anymore and {{traverse()}} currently does not like this (it crashes).      """
"DM-17397","Improvement","ts_middleware",1,"Improve error reporting for set and set_put","""{{BaseTopic.set}} and {{ControllerEvent.set_put}} both rely on {{getattr}} and {{setattr}} to do their work, neither of which gives a clear error when something goes wrong. Improve error reporting by catching the error and adding additional information (e.g. using exception chaining)."""
"DM-17395","Story","ci_hsc",1,"Write all outputs from CharacterizeTask in ci_hsc","""By default ProcessCcdTask does not write out all the outputs generated by CharacterizeImageTask. This ticket will set configs such that all outputs are written out when ci_hsc is run. This will aid in comparison checks and migration to gen3 middleware. This will not increase the run-time of ci_hsc, and will only minimally impact storage."""
"DM-17394","Bug","ctrl_mpexec",0.5,"Re-enable init-only option ","""It looks like in the DM-17038 refactoring an important option was """"factored out"""". Need to check for init-only in the new implementation of runPipeline method."""
"DM-17390","Story","pipe_tasks",8,"Convert CalibrateTask into a PipelineTask ","""Convert CalibrateTask into a Pipeline task"""
"DM-17437","Story","obs_lsst",2,"Add UC Davis camera support to obs_lsst","""In [obs_lsst #43|https://github.com/lsst/obs_lsst/pull/43] [~cslage] has added support for the UC Davis camera to obs_lsst.    We need to shepherd this through adoption into the DM codebase.   """
"DM-17433","Story","coadd_utils",1,"Remove unused code from coadd_utils","""Remove the {{Coadd}} class, any supporting code, and the {{makeBitMask}} function."""
"DM-17429","Story","obs_subaru",1,"PSFs on coadds are narrower than in model","""It has been observed that the PSF as measured on the coadd is narrower than the PSF model says it should be. This has found to be true on the warps as well, so we believe it's an artifact of warping. [~rearmstr] is experimenting with higher-order Lanczos kernels."""
"DM-17416","Story","pipe_base",0.5,"Fix origin parameter name in Gen2->Gen3 Butler shim","""The shim calls this parameter """"origin"""", but the actual Gen2 butler calls it """"imageOrigin""""."""
"DM-17454","Bug","obs_lsst",0.5,"Missed visit ID change in bin/runIsr","""It seems that {{runPipeline}} isn't really running an ISR processing because it can't find the data:      I believe this is because the visit numbering has changed in DM-17228 and {{visit=270095325}} should now be {{visit=201807241028453}}   """
"DM-17452","Bug","afw",1,"slots are not propagated into MultiMatch output schema","""I discovered DM-17451 because the output schema produced by MultiMatch does not include the {{slots}} that were defined on the input catalog, even if you ensure that they are defined on the schema that is passed in to MultiMatch.    I suspect a trivial fix for this is to add {{outSchema.setAliasMap(self.mapper.getInputSchema.getAliasMap())}} to multiMatch.py around line 37."""
"DM-17451","Bug","afw",1,"Invalid memory access for getX/getY when slots aren't defined","""Looks like we have an out-of-range memory access error hiding in the catalog centroid getters, if the catalog does not have centroid slots defined:        prints various nonsense values, like:        We should probably check the other getters for similar bugs."""
"DM-17449","Story","pipe_tasks",1,"Photocal not setting up DirectMatchTask correctly","""PhotoCalTask passes a config object as the first argument to the DirectMatchTask constructor, however DirectMatchTask defines butler as its first argument, not config. This causes the config object to be assigned to the butler argument. If the referenceObjectLoader is passed to DirectMatchTask's constructor then this has no impact. However if the referenceObjectLoader is None this will cause the task to fail.    See:  https://github.com/lsst/pipe_tasks/blob/master/python/lsst/pipe/tasks/photoCal.py#L256  and:  https://github.com/lsst/meas_astrom/blob/master/python/lsst/meas/astrom/directMatch.py#L42"""
"DM-17447","Story","ci_hsc",1,"Update ci_hsc preSfm command","""DM-17395 changed ci_hsc to write outputs for CharacterizeImageTask, but missed updating the SConsript for generating the pre-sfm run. This ticket fixes that."""
"DM-17446","Bug","ip_isr",1,"overscan improperly sets bounding boxes when leading/trailing columns are skipped","""Bounding box handling of `overscanNumLeadingColumnsToSkip` and `overscanNumTrailingColumnsToSkip` is incorrect."""
"DM-17442","Story","ts_main_telescope",2,"review laser tracker protocol interface docs","""Review laser tracker protocol interface docs, update text and diagrams to include new terminology (Laser Tracker CSC instead of Laser Tracker Controller, remove references to labview, etc). Our vendor, New River Kinematics, is proposing an API for communication between our CSC and their part of the code. Review this API and prepare feedback for meeting next week"""
"DM-17441","Story","ts_auxiliary_telescope",2,"Modernize ATDome simulator and make it the real CSC","""Improve the ATDome CSC as follows:  - Make it the real CSC, not just a simulator  - Update for XML changes in DM-17610  - Add a command for homing  - Reject attempts to move in azimuth or home while already homing  - Make the engineering commands that move individual doors safer (the usual commands that open or close both doors are always safe; they have internal sequencing) and add unit tests for them:  -- Reject attempts to move the main door unless the dropout door is fully open or fully closed  -- Reject attempts to move the dropout door unless the main door is fully open  - Rename the bin script to remove the """"_simulator"""" suffix and add a unit test for it  - Take a first pass at supporting configuration. The real code will have to wait until we have a standard for this."""
"DM-17489","Story","daf_butler|obs_subaru",2,"Initial prototype of Gen3 interfaces for human-curated master calibrations","""DM-16467 added some Python and bash scripts that add brighter-fatter kernel and defect datasets to a Gen3 repo.  These use direct SQL calls instead of the Registry API, and have been broken by changes on DM-16227.  This ticket will move that work into the {{daf.butler.Instrument}} class and its obs_* package specializations, allowing it to be done automatically by the {{gen2convert}} tool (in addition to fixing the breakage, of course).    Coming up with a new, consistent-across-obs-packages way to manage human-curated source for these datasets is definitely out of scope right now, but this might provide an example of how the Butler side of that might look to those who do design that."""
"DM-17487","Story","ts_management",1,"Write the Self-Evaluation","""Write the self-evaluation in Ultipro for the 2018 performance evaluation."""
"DM-17486","Story","ts_management",1,"Write the Self-Evaluation","""Write the self-evaluation in Ultipro for the 2018 performance evaluation."""
"DM-17485","Story","ts_management",1,"Write the Self-Evaluation","""Write the self-evaluation in Ultipro for the 2018 performance evaluation."""
"DM-17484","Story","ts_management",1,"Write the Self-Evaluation","""Write the self-evaluation in Ultipro for the 2018 performance evaluation."""
"DM-17483","Story","ts_management",1,"Write the Self-Evaluation","""Write the self-evaluation in Ultipro for the 2018 performance evaluation."""
"DM-17482","Story","ts_management",1,"Write the Self-Evaluation","""Write the self-evaluation in Ultipro for the 2018 performance evaluation."""
"DM-17481","Story","ts_management",1,"Write the Self-Evaluation","""Write the self-evaluation in Ultipro for the 2018 performance evaluation."""
"DM-17467","Story","obs_lsst",1,"Add obs_lsst to pipelines.lsst.io sphinx build","""Once RFC-569 is adopted and obs_lsst is added to lsst_distrib, the sphinx build in pipelines.lsst.io has to be modified to include obs_lsst."""
"DM-17491","Story","daf_butler",2,"Implement Butler deletion APIs","""Implement Registry.dissociate as well as a way to remove all Datasets from one or more Collections."""
"DM-17493","Story","daf_butler|obs_subaru",1,"Include Filter in Gen3 HSC raw formatter","""The Gen3 formatter class for HSC raw data doesn't call {{setFilter}} on the returned {{Exposure}}, which is a problem for downstream processing.  To fix that, we need to:   * add a {{makeFilter}} to {{FitsRawExposureFormatterBase}} in daf_butler, similar to the existing {{makeWcs}} and {{makeVisitInfo}} (including using it in the base class {{readInfoComponent}}.   * implement {{makeFilter}} in obs_subaru appropriately.    We'll probably have to call the {{afw.image.Filter}} constructor with {{force=True}} to try to avoid mucking with the global variables (and hope no one else does); a better solution will have to wait for RFC-541."""
"DM-17529","Story","Qserv",1,"Fix czar message table insertion bug","""Qserv czar is missing a length check at message table insertion; a too long error message can cause message insertion failure.  This may result in an empty message table, leading the czar to conclude that the query succeeded and subsequently attempt to access a non-existent result table."""
"DM-17525","Story","ts_auxiliary_telescope",2,"WLS end-to-end testing","""Need to develop tests that fully exercise the WLS CSC through SAL, where we send it a message or command through SAL, and then look for an event on SAL as a result. """
"DM-17523","Bug","obs_lsst",0.5,"Add RTM-006 back to raft_serial_data ","""[This commit|https://github.com/lsst/obs_lsst/commit/e5d76efe711834f2ebddeea01aeaf623f2611014#diff-db4cf806a9d1fc03bc687b05e5f549f5] and [this commit|https://github.com/lsst/obs_lsst/commit/6470ea684160c57387a3e893c779cd07661f8df4] moved the {{raft_serial_data}} dict from {{python/lsst/obs/lsst/ts8.py}} to {{python/lsst/obs/lsst/translators/ts8.py}}, but somehow omitted {{RTM-006}}.  This led to failures in ingesting  RTM-006 data.        """
"DM-17522","Story","ip_diffim",8,"Write getting started notes on ip_diffim","""Take what you learned on DM-16409 and turn it into a set of notes on the ip_diffim codebase — what are the key options? How is the code structured?    This shouldn't attempt to be comprehensive, user focused documentation: use it to draw out the key themes and options that you think we should schedule time to investigate over the next several months, and record what you wish you'd known when you were getting started a few months ago."""
"DM-17521","Improvement","ap_pipe",1,"Add warning when ap_pipe skips association","""In the review to DM-14019, [~cmorrison] pointed out that the results of association depend on the order in which exposures are fed into it, and that this can cause problems when rerunning a set of exposures where some are skippable and others are not. Modify {{ap_pipe}} to print a warning (using {{warnings.warn}} to avoid spam) either when skipping association is requested or when it happens."""
"DM-17515","Epic","ts_aos",2,"Unpack & Install M2 controller in Summit computer room","""Unpack and Install M2 controller in computer room; then achieve network connectivity.         This Epic will correspond to the following P6 Activity:   * T&SC-14040401-1010 Unpack & Install M2 controller in computer room"""
"DM-17514","Story","ts_environment",3,"Review of Besalco contract documents","""Review of Besalco contract documents..."""
"DM-17511","Story","ts_auxiliary_telescope",2,"Update ATMCS simulator based on updated XML and new knowledge","""The ATMCS simulator has some issues that need addressing:    * Updated XML, including M3 telemetry  * Motors should be enabled by standby->disabled and vice versa (the current logic is more complicated). That said, we are discussing whether there is some way to only enable a rotator if it is needed, in order to reduce heat load.  * Update limits based on current knowledge  * Output azimuth raw encoder counts in range [0, 360]*resolution and offset encoders by appropriate amounts when there are multiple encoders per axis  * Do not output m3InPosition and probably not m3PortSelected ([~rcantarutti]?) until the setInstrumentPort command is received.  * Enable tests that were accidentally left disabled"""
"DM-17510","Story","ts_middleware",1,"Create stories for CAP-9","""Work out details of CAP-9"""
"DM-17509","Story","Management",1,"Check Done Epics","""Spot check some epics marked done and make sure I can find deliverables."""
"DM-17508","Story","Management",2,"Risk review and Management board","""Go through risks assign to CAMS and also do review ahead of board .."""
"DM-17505","Bug","daf_butler",0.5,"Fix bug in associate implementation","""[~salnikov] notes that this bit:    [https://github.com/lsst/daf_butler/blob/master/python/lsst/daf/butler/registries/sqlRegistry.py#L548-L550]    is looping over {{refs}} many times, instead of just the outer loop.     """
"DM-17546","Improvement","ts_middleware",1,"Update script queue for ts_salob 3.8","""Update ts_scriptqueue to take advantage of features in ts_salobj 3.8:  * Use data contained in the topics  * Stop using test_utils    Also modernize the documentation layout to match the current template (T&S needs no top layer)"""
"DM-17545","Story","pipe_tasks",1,"Fix MeasureCoaddSources regression ","""Converting to pipeline tasks introduced a bug in runDataRef in MeasureCoaddSourcesTask, fix the bug."""
"DM-17544","Bug","Validation",0.5,"new refcats in validation_data repos are invalid off lsst-dev","""The symlink from {{validation_data_*/data/ref_cats}} that is supposed to go to {{../ref_cats}} instead goes to {{/project/wmwv/validation_data_*/ref_cats}}. This is true for each of the cfht, decam, and hsc repos.    Please make these symlinks relative, so that they are valid for non-lsst-dev checkouts."""
"DM-17543","Improvement","verify",1,"Rename lsst.verify.compatibility to gen2compatibility","""The {{compatibility}} package was originally proposed in [DMTN-098|https://dmtn-098.lsst.io/] as a subpackage of a {{lsst.verify.measurements}} package that would contain extra infrastructure. However, following RFC-550, this package was instead added to {{lsst.verify}}. Since {{lsst.verify}} is much broader in scope than the proposed {{lsst.verify.measurements}} would have been, the name {{compatibility}} has caused much confusion in the new context (what needs to be compatible with what?).    We can alleviate some of the confusion by renaming {{compatibility}} to {{gen2compatibility}}. This must be done before the {{MetricTask}} framework is widely adopted."""
"DM-17535","Bug","obs_lsst",1,"32 bits no longer suffice for imsim expId","""The {{expId}} calculation has changed and now it can be much larger, hence sometimes, with large visit IDs, expBits=32 is no longer enough:          So, I tried increasing {{ccdExposureId_bits}} to 36 bits, then it failed at processCcd characterizeImage detectMeasureAndEstimatePsf      It's okay to truncate the ID sent to {{rng}} because it just wants something deterministic and not-usually-the-same for different units of data."""
"DM-17533","Improvement","ts_middleware",1,"Make topic destructors more robust","""Make all topic destructors more robust in ts_salobj. Some assume attributes are present and they should not do that.    Also improve error output of test_main by using shtuil.which to look for the executable and suggesting scons or setup if not found."""
"DM-17560","Improvement","ts_middleware",1,"Add force_output argument to ControllerEvent.set_put","""Add {{force_output=False}} to {{ControllerEvent.set_put}} so we can assure output of the new event value.    Also skip keys that have a value of None in all {{set_put}} methods, making them easier to use for possibly omitted values.    Also remove some remaining instances of unnecessary use of {{DataType()}}"""
"DM-17550","Story","Alert Production",1,"Update DMTN-093 to describe alert schema versioning","""As developed in DM-17549."""
"DM-17547","Story","obs_lsst",1,"Integrate obs_lsst camera instructions into sphinx docs","""There is useful documentation in README files in obs_lsst that needs to be integrated into the sphinx documentation."""
"DM-17596","Story","ts_auxiliary_telescope",1,"Docker Struggle","""Fight with dockerfiles in attempt to get a working environment with sal, salobj, AND pymodbus, while nominally learning a bit about how docker is supposed to work"""
"DM-17593","Story","ip_diffim",8,"Investigate non-subtask “subtasks” in ip_diffim","""Per DM-12558, ip_diffim creates and uses Task objects without going through the regular subtask mechanism. Why? If this is necessary, we should document it and properly account for it on DM-12558. If it's not necessary, we should fix it by using {{makeSubtask}} so we can keep track of the execution time, etc, of these tasks in the regular way."""
"DM-17591","Story","ts_aos",1,"OFC Interface between the Algorithm and Control System","""Construct the OFC interface between the algorithm and control system."""
"DM-17562","Bug","afw",1,"Broken links in afw doxygen","""When I build {{afw}}, I get the following warnings:    I assume these are a side effect of removing some {{.dox}} files in DM-16855. Update these links so that they're valid; for example, the first two could probably be simple API links to the corresponding constants."""
"DM-17561","Story","ts_qa",1,"Update salgenerator tests to work with new docker infrastructure","""This task covers   * Time to research and learn about enabling SSH to Docker containers.   * Update the salgenerator tests to work with the Docker image   ** This may involve updating the tests to remove all SSH functionality."""
"DM-17654","Story","L1 Database",8,"PPDB Scaling Test in Google Cloud","""Perform PPDB scaling test in Google Cloud with other database technologies like postgres and using node configuration not available at NCSA."""
"DM-17653","Story","ImgServ",20,"Implement CIRCLE, RANGE, POLYGON in Imgserv SODA","""This ticket is to implement the shapes for image cutout, mandated by SODA 1.0,  as already marked ToDo in ImgServ SODA code base. The approach is to use the geometry functions in the priority 1) lsst/afw 2) astropy."""
"DM-17651","Story","log",2,"Forward lsst.log to Python logging","""When writing unit tests it is sometimes useful to check that a log message was created. Python provides {{TestCase.assertLogs}} for this purpose but this does not work with {{lsst.log}}. It would be useful to allow unit tests to temporarily forward {{lsst.log}} messages to Python {{logging}} so that they could be tested.    This would have to ensure that DM-15201 does not cause a logging loop.    Ideally C++ log4cxx messages could be forwarded but it seems much easier to focus on Python {{lsst.log}} messages."""
"DM-17650","Bug","Continuous Integration|Developer Infrastructure",0.5,"jenkins sierra-[34] build agents down","""The osx nodes jenkins uses for the build agents sierra-[34] have been down for a couple of days now."""
"DM-17642","Story","ts_aos",2,"Attend the DAQ Workshop at NCSA remotely","""Attend the DAQ workshop at NCSA remotely at 2/12 - 2/13 from 8 am in Tucson time. The confluence page is at: [https://confluence.lsstcorp.org/display/SYSENG/DAQ+2.5+API+Workshop+and+COB+installation+at+NCSA+Test+Stand]     """
"DM-17641","Story","ts_aos",1,"Review the SHWFS FAT Document and LSE-150","""Review the SHWFS FAT (factory acceptance test) document and presentation by the vendor and feedback the problems to Jacques. This task will also review the document of LSE-150."""
"DM-17640","Story","ts_aos",2,"Do the Unit Test of WEP Interface and Related Documentation","""Do the unit test of WEP interface between the algorithm and control system (MTAOS). This is to make sure the behaviors of WEP interface fulfills the need of control system. This task will do the related documentation contains the class diagram."""
"DM-17639","Story","ts_aos",1,"WEP Interface between the Algorithm and Control System","""Discuss and define the WEP interface between the algorithm and control system with Chris."""
"DM-17638","Story","ts_aos",2,"Do the Unit Test of OFC Interface and Related Documentation","""Do the unit test of OFC interface between the algorithm and control system (MTAOS). This is to make sure the behaviors of OFC interface fulfills the need of control system. This task will do the related documentation contains the class diagram."""
"DM-17626","Story","log",0.5,"Enable travis flake8 tests in log","""Enable travis flake8 checks in {{log}} so that branch protection can be enabled properly."""
"DM-17611","Story","daf_butler",1,"Performance optimizations to data ID code","""Profiling on DM-17496 revealed that the slow speed of preflight was not due to the big {{selectDimensions}} query, but rather follow-up data ID manipulations.    Improvements were also done and reviewed DM-17496, but I'm moving them here because they weren't actually relevant for that ticket, and the work that is relevant isn't done yet."""
"DM-17610","Story","ts_middleware",2,"Improve ATDome XML","""Improve ATDome XML as per discussions with [~pingraham] and Paul.    Command changes:   * Add a {{homeAzimuth}} command.   * For the {{moveShutterDropoutDoor}} and {{moveShutterMainDoor}} commands replace the field with a boolean named {{open}}; the TCP/IP interface doesn't support partially opening or closing a door.   * Rename the {{stopAllAxis}} command to {{stopMotion}}.   * Remove the {{stopShutter}} and {{stopAzimuth}} commands; the TCP/IP interface only supports stopping all motion.    Event changes:   * Modify {{settingsAppliedDomeController}} as follows:   ** Rename {{xActivated}} to {{xEnabled}} for all fields because this indicates whether detecting the condition is enabled, not whether the condition is detected.   ** Remove the {{learnManual}} field; the TCP/IP interface does not provide the information.   ** Add a {{homeAzimuth}} field to report the configured position of the home switch; this may be useful in conjunction with the {{homeAzimuth}} command and is output by the TCP/IP interface.  * Add a {{homing}} field to {{azimuthState}}. It could be made part of the {{state}} field but then we would need to treat the enums as bits for a bit mask and the XML doesn't seem to have good support for that.   * Modify {{settingsAppliedDomeTcp}} as follows:   ** Change portRange field to port.   ** Change ip to host and allow to be longer (to enable domain lookup).  ** Remove {{writeTimeout}}; the CSC doesn't use it.   * Remove the following events, as we will not be outputting them:   ** {{internalCommand}}   ** {{loopTimeOutOfRange}}   ** {{rejectedCommand}}   ** {{internalStatus}}   ** {{detailedState}} (and associated enum) because there is nothing to report beyond summaryState.   * Rename the allAxisInPosition event to allAxesInPosition.    Telemetry changes:   * Remove the following telemetry topics, as they are not output:   ** {{loopTime}}   ** {{timestamp}} telemetry topic; it is not output.  * Modify the position topic by renaming the dropout door fields from dropoutOpening... to dropoutDoorOpening... for consistency with the main door.    Enum changes:   * Remove the {{ShutterDoorState_NotInMotionState}} enum value; it cannot be output.   * Remove the {{AzimuthState_InMotionState}} enum value; it cannot be output.   * Remove the {{AzimuthState_StoppingMotionState}} enum value; it cannot be reliably output.   * Remove the redundant trailing {{State}} from {{AzimuthState_}} and {{ShutterDoorState_}} enums. For instance {{AzimuthState_NotInMotionState}} becomes {{AzimuthState_NotInMotion}} and {{ShutterDoorState_ClosedState}} becomes {{ShutterDoorState_Closed}}.  """
"DM-17609","Story","ts_dome",1,"Improve ATPneumatics XML","""Improve the ATPneumatics XML as per disussion with [~rcantarutti]    * Ditch the Position events because they are fully duplicated by the limit switch events.  * Add Invalid mirror cover state to handle the case that both an open and a closed switch are active for the same cover.  * Ditch the overlap of the “state” enums with summary state and shorten the names to remove redundancy and stutter, so that the MirrorCoverState enums become:    and the mirror vents state enum becomes:    * Delete the {{resetEStopTriggered}} event, rename the {{eStopTriggered}} event to {{eStopTrigger}} and set the {{triggered}} field appropriately.  * Add two new events for reporting m1 and m2 commanded air pressure (each with a single field), unless folks have a very strong desire to add fields to the existing m1AirPressure and m2AirPressure telemetry instead.  * Flesh out the Description and Units fields (including the units for pressure, which are Pa)."""
"DM-17608","Story","daf_butler",0.5,"Fix performance regression from SQLite transaction changes","""DM-17495 fixed the deadlocks we saw in SQLite Registries at the expense of adding much more aggressive locking.  That has caused a pretty dramatic slowdown in operations that make a large number of Registry calls without first starting an explicit transaction, at least on GPFS (because this results in many small transactions, and hence many lock/unlock calls in sequence).    A simple workaround for this (which may also be the best we can do long-term for SQLite) is to wrap such calls in an explicit transaction; that needs to be done now for {{gen2convert}} (the only tool we have right now that does not use explicit transactions) to fix a serious regression in ci_hsc performance."""
"DM-17606","Story","ts_calibration",1,"Publish ascii error codes to SAL & serial timeout to fault state","""Publish ascii errors as part of error code event in salobj. Handle serial timeout as fault state. Add simple retry to timeout to allow CSC to potentially continuing functioning."""
"DM-17605","Story","meas_deblender",1,"Implement S matrix normalization in scarlet","""To deblend crowded fields it is useful to model stars as a single point convolved with the PSF. Through experimentation [~pmelchior] and I discovered that normalizing the A matrix (colors) causes too much variation in the S matrix (morphology) updates. Instead it appears that normalizing the S matrix (and fixing a single pixel) for point sources and allowing the A matrix to encode both SED and intensity information works better.    This ticket is to give users the option to use either A matrix or S matrix normalization for each source."""
"DM-17604","Story","ts_calibration",1,"Prevent fault state invalid transition into fault state","""Inside of telemetry method, if a fault value is read in one of the registers, the laser will go into a fault state however, if the fault is not cleared before the next telemetry it will continue to go into a fault state which is not a valid transition.     The solution should check that the CSC is already in a fault state and not go into fault state."""
"DM-17603","Story","ts_qa",3,"Devise and implement the build and packaging process","""This task covers time to discuss with the TSSW team the particular needs of application building and packaging for deployment.  Most of the pieces already exist, but the process needs to be documented and formalized."""
"DM-17600","Bug","Qserv",8,"Improve qserv_deploy in order to fix DNS issue at CC-IN2P3","""UPDATE: DNS error was fixed by disabling the cache in CoreDNS configuration.    DNS is crashing using weave    - calico and flannel automated installation does not fix this issue, and, even worst, crash the nodes  - removing DNS cache seems to fix this issue  - an example procedure to cleanup DC2 data has been added"""
"DM-17659","Story","daf_persistence|display_firefly|meas_modelfit|Qserv|synpipe",0.5,"Fix F632 flake8 warnings","""The new flake8 version warns about F632 (using {{is}} rather than {{==}}) and this triggered a few flake8 failures over the weekend when the weekly tags were added.    The full list I can find:      """
"DM-17690","Improvement","ts_auxiliary_telescope",0,"Add error code argument to BaseCsc.fault","""Add an error code argument to {{BaseCsc.fault}} and emit the errorCode event when it is called."""
"DM-17688","Story","ts_management",1,"T&S Organization of Documentation on Confluence","""This task is to create the subsystem """"Confluence Template"""" that the T&S team will use. This template is planned to be used by the team to contain an overview of a single CSC. For example, some of the items on the template will specify who the product owner is, what the release strategy is and where the links to the Jenkins automated test builds are if they exist.     This task will also go over the time spent working with James and getting his CSC into one of these templates so that we can go through a test run with the template as well an example for a future Tech talk when I go over the teams documentation. """
"DM-17678","Story","ts_middleware",1,"SAL mentoring","""Continue SAL mentoring"""
"DM-17677","Story","ts_middleware",3,"Deploy SAL runtime RPMs","""Build and deploy SAL runtime as a set of RPM's (per CSC)  """
"DM-17676","Story","ts_main_telescope",2,"Review TMA FAT reports","""Review the final versions of the TMA FAT verification test reports"""
"DM-17675","Story","afw",1,"Resolve flake8 errors in afw","""The release of pycodestyle 2.5.0 has caused flake8 to be unhappy with the current {{master}} of afw. Please fix it.    Unhappy flake8/Travis: https://travis-ci.org/lsst/afw/builds/488690857  pycodestyle release notes: https://pypi.org/project/pycodestyle/2.5.0/  Relevant Slack discussion: https://lsstc.slack.com/archives/C2JP8GGVC/p1549313396138300"""
"DM-17672","Story","ts_auxiliary_telescope",1,"Make ATAOS listen for pointing component instead of mount.","""Instead of listening for the mount position from the ATMount, make ATAOS listen for the pointing component. """
"DM-17670","Story","meas_deblender",2,"Update scarlet notebooks and docs","""The scarlet docs currently fail building. There was probably a breaking API change at some point that needs to be fixed, and they also need to be updated with an example of using S matrix normalization to model point sources."""
"DM-17668","Epic","ts_environment",5,"Testing of Weather Station SW","""Testing of Weather Station SW"""
"DM-17667","Epic","ts_environment",5,"Finishing Weather Station SW Development","""Finishing Weather Station SW Development"""
"DM-17666","Story","ts_auxiliary_telescope",2,"Initial version of ATSpectrograph CSC using salobj","""Write the ATSpectrograph CSC using salobj. The main goal of this task is to create a CSC that is capable of running in simulation model. Stretch goal is to have it integrated with the hardware. But, since I'm not entirely familiar with the hardware, it may need a follow-up ticket to complete that. """
"DM-17664","Story","ts_environment",2,"Weather station (environment) CSC.","""Write down environment CSC that will capture data from the weather station and publish it to SAL. """
"DM-17663","Story","daf_butler",1,"Make Registry table names lowercase","""Oracle works much better with lowercase field names, and case-sensitivity is in general inconsistent in SQL databases.    We should do this after unifying Dimension names and link names on DM-17023, since that will eliminate the only current use of differently-conventioned names to refer to (essentially) the same concepts, and make a good chunk of the Registry table names lowercase already."""
"DM-17662","Bug","ts_middleware",2,"PyBind 11 ack bug","""I have a Data struct that looks like this    *.h*   class AckCmd   \{     public:       SALData_ackcmdC ackData;       AckCmd(int ack, int error, std::string result);   };    *.cpp*    AckCmd::AckCmd(int ack, int error, std::string result)   \{     ackData.ack = ack;     ackData.error = error;     ackData.result = result;   }        I then am binding it as follows        py::class_<AckCmd>(m,""""AckCmd"""", py::module_local(), py::dynamic_attr())               .def(py::init<int, int, const std::string &>())              ;       I have the `py::module_local()` tag because I was getting an `ImportError: generic_type: type """"*"""" is already registered!` error.    I have the `py::dynamic_attr()` tag to set the `ack`, `error` and `result` attributes of the ackData object.        However, when I enter the following within a python shell       >>> import SALPY_Library   >>> myAck = SALPY_Library.AckCmd( 1, 2, """"myack"""")   >>> print(myAck.ack)   Traceback (most recent call last):     File """"<stdin>"""", line 1, in <module>   AttributeError: 'SALPY_Scheduler.AckCmd' object has no attribute 'ack'   The attributes are not there. When using double tabbing to view the attributes of the object it doesn't show any of the attributes from the c++ struct.    >>> myAck.__   myAck.__class__(          myAck.__doc_             _myAck.__getattribute__(   myAck.__init_subclass__(  myAck.__ne__(             myAck.__repr__(           myAck.__subclasshook__(      myAck.__delattr__(        myAck.__eq__(             myAck.__gt__(             myAck.__le__(             myAck.__new__(            myAck.__setattr__(           myAck.__dict_            _myAck.__format__(         myAck.__hash__(           myAck.__lt__(             myAck.__reduce__(         myAck.__sizeof__(            myAck.__dir__(            myAck.__ge__(             myAck.__init__(           myAck.__module_          _myAck.__reduce_ex__(      myAck.__str__(            """
"DM-17660","Story","ts_qa",3,"Get the Ptg Comp vendor-supplied tests to run in LSST CI","""This is a continuation of DM-17366.  That task ended up only comprising getting the Ptg Component to build.  This task covers time needed to get the vendor-supplied automated tests running in the TSSW CI environment."""
"DM-17741","Bug","log",1,"pytest extra chatty on failed tests due to fonts and matplotlib","""The new changes that forward python log messages to lsst.log have resulted in pytest dumping a giant list of DEBUG messages related to {{matplotlib}} and/or {{font_manager}} after failed tests. This can require scrolling up through several pages of useless messages before you get to the actual pytest output.    [~tjenness] suggests either changing the default logging level we use when running pytest, or to configure our logger to ignore debug matplotlib messages.    Portion of an example """"Captured log call"""" from a failed fgcm test:    """
"DM-17739","Bug","ctrl_mpexec",0.5,"Recent update to TaskLoader breaks pickle","""[~mgower] reported issues with pickling QuantumGraph which produces diagnostics like this:    This seems to be related to last change in module import in TaskLoader."""
"DM-17726","Story","Third Party Software",3,"Update flake8 and pycodestyle to support max-doc-length","""With the release of new versions of pycodestyle and flake8 that support max-doc-length, we can update our eups packages to allow packages to use max-doc-length in their setup.cfg files."""
"DM-17722","Story","Firefly",8,"Upgrade react to 16.8","""Upgrade react and related components from 16.2 to 16.8    * don't upgrade redux   * upgrade any other react components.   * only do webpack and babel         Implemented:    * upgraded React.js to version 16.8  * converted AdvancedADQL to use react hooks which is a big feature of this release    The converted file make use of the new useState and useRef hooks, as well as demonstrate how updated props can be compared directly in the render function.  It serves as a test for the upgrade as well as demonstration of how new features are used.    Here is a complete changelog for react:  https://github.com/facebook/react/blob/master/CHANGELOG.md#1680-february-6-2019    This blog highlight some of the changes in v16, up to v16.7.  https://hackernoon.com/react-16-0-16-3-new-features-for-every-day-use-f397da374acf    Summary of the blog:    * Returning multiple elements from components with fragments (16.2)   <React.Fragment>   …   </React.Fragment>   or   <>   …   </>  * Returning strings and numbers from components  * Cancelling setState() to avoid rerendering  * Avoiding prop drilling with the official context API (16.3)  * Updating state based on props with getDerivedStateFromProps() (16.3)  * Re-rendering function components on props change with React.memo() (16.6)  * Easier access to context in class components with contextType (16.6)"""
"DM-17720","Story","daf_butler",2,"Improve user expression handling in pre-flight","""User expression is now passed to pre-flight as a plain string (even though that expression is parsed and checked for syntax in advance). This makes it difficult to do smart things with it like deducing table names from link names or converting it to true sqlalchemy construct.    I want to try to pass parsed tree to preflight and build sqlalchemy selection from that instead."""
"DM-17693","Story","ts_qa",2,"Create a Docker image for TSSW testing - part 2","""Continuation of https://jira.lsstcorp.org/browse/DM-17693    ------------------------------------------------------------------    This task covers   * time to research and learn about Docker.   * create a Docker image configured for testing.   ** miniconda or scl/ius for Python3 support   ** Robot-Framework   ** XML parser   ** dependencies"""
"DM-17769","Bug","ts_auxiliary_telescope",0,"Restore Explanation fields to the original urls in ATDome XML","""In DM-17610 I messed up by putting text in the Explanation fields for commands. It has to be a URL. Undo that change (while leaving the help in as XML comments for now so they can be used for Description fields if and when DM-17768 is implemented)"""
"DM-17758","Story","Firefly",3,"Update supported browser list and Webpack","""Update supported browser list. We usually do this every 12 to 18 months.    Typically we try to support the current browser version plus 2 back or any browser version in the last year.    Update support browser list:    * Safari 9 => 10  (current: 12)   * Chrome 62 => 67  (current: 71)   * Firefly 56 => 60 (current: 65)   * Edge  14 => 16 (current: 18)    Upgrading the supported list provides the following:   * Allows for more confidence in the testing of our products.   * Allows for more stable version of library since they are limited in testing of old browsers   * Give opportunity to use newer HTML/CSS features such as Grid layout   * Requires less polyfills and code transforms. This allows more native code and smaller load sizes."""
"DM-17753","Story","Notebooks",2,"Update Firefly notebook for jupyter_firefly_extensions","""The LSP now includes the Firefly extension for Jupyterlab. This extension has been integrated with the Firefly backend to {{afwDisplay}} and simplifies the startup of the Firefly viewer. This ticket is for updates to the Firefly notebook curated by SQuaRE that take into account the new capabilities provided by the extension. Some cleanup of Markdown will also be proposed."""
"DM-17752","Bug","Firefly",3,"No image display in Firefly JLab extension after kernel restart","""For a notebook using image display with {{jupyter_firefly_extensions}}, image display does not work after the Python notebook kernel is restarted and the notebook is re-executed. When the Jupyterlab browser tab is reloaded, the notebook executes fine again.    To reproduce, execute {{slate-widget-demo.ipynb}} that is one of the examples for the extension. Run all the cells once; then restart the Python kernel for that notebook; then re-execute. Image display does not work the second time around.    I have checked that {{channel}} and {{render_tree_id}} do not change.    For users, the workaround is to restart the Python kernel and to reload the browser tab, when wishing to re-execute a Firefly notebook."""
"DM-17747","Story","ts_middleware",1,"Russell Pybind 11 hack session","""I removed a bug that I introduced to develop. It prevented scons from being able to run. I plan on meeting for a day with [~rowen] to be able to hack out this feature. """
"DM-17818","Story","mops",3,"Set up initial test coverage monitoring for OpenOrb","""Set up test coverage monitoring for OpenOrb (our adopted orbit integration engine).    This includes:    * Having a make target to run the test coverage tools as 'make coverage'   * Have this target automatically invoked by one of the CI runs   * Have the results uploaded to a cloud test coverage visualization service.    We will be using [codecov.io|http://codecov.io] as the service for visualization of coverage reports.    The work will be on [https://github.com/mjuric/oorb/tree/ci-and-codecov], and will be PR-ed upstream upon completion. It depends on DM-17814 being merged."""
"DM-17817","Story","mops",3,"Set up initial CI for OpenOrb","""Set up continuous integration for OpenOrb (our adopted orbit integration engine).    This includes:    * Building on Mac and Linux with Anaconda compilers with Python 2.7, 3.6, 3.7   * Building on Linux (Ubuntu 16.04) with Ubuntu-supplied compilers and Python 2.7 and 3.5   * Builds are to be triggered by pushes/PRs to GitHub repository    We will be using the Azure Pipelines service, as we did with pytrax (DM-17027).      The work will be on https://github.com/mjuric/oorb/tree/ci-and-codecov, and will be PR-ed upstream upon completion. It depends on DM-17814 being merged."""
"DM-17816","Story","mops",3,"Add unit test framework to OpenOrb","""Add unit test framework to [OpenOrb|https://github.com/oorb/oorb] (our adopted orbit integration engine).    This includes:    * A make target so running 'make test' will execute all unit and integration tests   * A few example unit tests (for versioning functionality)   * Running the python/test.py integration test    Unit test framework will use pytest. The idea is that all code (including command line utilities) will be tested via pytest drivers (to maintain uniformity).    The work will be on [https://github.com/mjuric/oorb/tree/build-system-rework,] and will be PR-ed upstream upon completion."""
"DM-17813","Story","ts_main_telescope",2,"Review laser tracker protocol interface docs - part 2","""Review laser tracker protocol interface docs, update text and diagrams to include new terminology (Laser Tracker CSC instead of Laser Tracker Controller, remove references to labview, etc). Our vendor, New River Kinematics, is proposing an API for communication between our CSC and their part of the code. Review this API and prepare feedback for meeting next week"""
"DM-17812","Improvement","Qserv",8,"Worker database management in the Replication system","""*Objective*:   Extend the Replication system to support operations on the Qserv worker databases via worker's MariaDB service. The operations shall be broadcasted either to all known workers or a subset of those. Build the programmatic API and the command-line tool for that.    Further information on a scope of the project can be found at:  * [https://confluence.lsstcorp.org/display/DM/Worker+database+management]    """
"DM-17811","Story","ts_auxiliary_telescope",3,"White Light Docker packaging","""learn about how to package the CSC with docker, according to the grand LSE-150 plan. This has been ongoing for a while but will be a success when I have a docker container that runs the component and has all the required dependencies."""
"DM-17810","Story","ts_qa",1,"Review TMA FAT documents","""This task is for reviewing the TMA FAT documents.  Andrew Serio is leading this effort and tasked me to review a couple of documents, so this task tracks the time necessary to do so."""
"DM-17795","Story","DM",2,"Work more on LSO-011","""Need to work some more on the release scenarios and talk to some people about things like alert possibilities .."""
"DM-17794","Story","obs_lsst",1,"Modify exposure_id calculations in obs_lsst","""Following a discussion on community we have decided to adjust the calculation of detector_exposure_id and exposure_id to remove additional 0-padding between exposure ID and detector (3 digits for lsstCam rather than 4) and to have a maximum sequence number of 99,999 rather than 999,999. It would be good if we could get this done before v17.0."""
"DM-17782","Story","ts_main_telescope",2,"Initial M2 Software setup @ Summit","""Initial M2 Software setup @ Summit"""
"DM-17827","Story","pipelines_lsst_io",1,"Update doc/ directories of packages for latest standards","""These packages have doc/ directories that don't fit the current standards (mostly because they include package documention when they really only should have module documentation). This ticket is to fix these packages:   * afw   * base   * coadd_utils   * daf_butler   * display_ds9   * ip_diffim   * ip_isr   * jointcal   * log   * meas_algorithms   * meas_deblender   * meas_extensions_photometryKron   * meas_extensions_shapeHSM   * meas_extensions_simpleShape   * meas_modelfit   * obs_base   * obs_cfht   * obs_lsstSim   * obs_test   * pex_exceptions   * pipe_base   * pipe_drivers   * shapelet   * utils   * validate_drp   * verify    Also, there's a typo in the title of the {{lsst.meas.extensions.simpleShape}} module docs."""
"DM-17824","Story","DM",2,"Update LPM-251","""Update LPM-251 to include Open Data Framework and rework intro and title."""
"DM-17820","Improvement","ts_auxiliary_telescope",1,"Update ATPneumatics simulator for changes to the XML","""Update ts_ATPneumaticsSimulator for DM-17609"""
"DM-17831","Story","pipelines_lsst_io|sconsUtils",2,"Convert sconsUtils to sphinx documentation","""Currently sconsUtils requires that doxygen strings be used to create the documentation. This is done because sconsUtils requires that SCons be imported and that is only possible if SCons is importing sconsUtils. Since pydoc and sphinx import python code to extract documentation this makes it hard to use numpydoc.    For example:      It seems though that this is easy to work around. The following patch allows {{pydoc}} to work and opens the possibility of migrating sconsUtils away from doxygen.    {code:diff}  diff --git a/python/lsst/sconsUtils/__init__.py b/python/lsst/sconsUtils/__init__.py  index ee9f02a..6e3c456 100644  --- a/python/lsst/sconsUtils/__init__.py  +++ b/python/lsst/sconsUtils/__init__.py  @@ -1,4 +1,13 @@   # Explain what happens when you try to import outside scons  +# When building documentation you want to force a SCons import  +import os  +import sys  +  +if (""""pydoc"""" in sys.modules or """"sphinx"""" in sys.modules) and """"SCONS_DIR"""" in os.environ:  +    scons_path = os.path.join(os.environ[""""SCONS_DIR""""], """"lib"""", """"scons"""")  +    if scons_path not in sys.path:  +        sys.path.append(scons_path)  +   try:       import SCons.Script   except ImportError:  {code}  """
"DM-17845","Story","pipe_tasks",0.5,"Fix warnings in image coaddition","""Running {{AssembleCoaddTask}} with default settings produces multiple warnings: {{assembleCoadd WARN: Unable to remove mask plane NOT_DEBLENDED: Invalid mask plane name: NOT_DEBLENDED}}    These warnings are caused by the default value for the config option {{removeMaskPlanes}} including {{NOT_DEBLENDED}}, and would be fixed by removing it from the default."""
"DM-17840","Story","astro_metadata_translator|documenteer",1,"Create a Sphinx documentation site for astro_metadata_translator","""This ticket is to deploy [https://astro-metadata-translator.lsst.io|https://astro-metadata-translator.lsst.io/] to LSST the Docs. Since it's a standalone Python package, the deployment will be done from Travis CI (following the pattern of SQuaRE's Python packages).    As well, we'll add {{astro_metadata_translator}} to the intersphinx configuration of pipelines.lsst.io so that links will be automatically resolved."""
"DM-17837","Bug","obs_lsst",0.5,"Fix incorrect detector serial in TS8 RTM-004","""[~plazas] noticed that ingestion of TS8 RTM-004 was failing. It seems I mistyped 285 for 385 in the detector serial of S20. Fix the typo and the associated bug that cascaded in the error handling from this."""
"DM-17835","Story","Qserv",8,"Improve qserv_deploy configuration","""- Make qserv_deploy configuration clearer:    * Mount cfg/tmp path correctly:    - Allow to easily manage several configuration.  - Record which qserv_deploy version was used to install a given cluster  - Add pseudo /etc/password for NFS/LDAP setup?  - Test it to create a GKE cluster  - Test it on CC-IN2P3 cluster  - Update CI"""
"DM-17871","Story","pipe_tasks",0.5,"Add DcrAssembleCoaddTask to docs","""{{DcrAssembleCoaddTask}} is missing from [https://pipelines.lsst.io/v/daily/modules/lsst.pipe.tasks/index.html |https://pipelines.lsst.io/v/daily/modules/lsst.pipe.tasks/index.html,]and should be added."""
"DM-17866","Story","obs_lsst",3,"Support BOT data gen 2 ingest once data exists","""Following conversations around Feb. 8th 2019 in #dm-bootcamps (for some reason) it is noted that `obs_lsst` will need to be extended/enhanced to support BOT* data when it becomes available.    How this looks will depend on exactly when that happens, and whether version-able cameras are a reality by then, as this data will necessitate that.    *Bench for Optical Test - the IR2 test station where real data from the real camera will be taken as it is populated with rafts"""
"DM-17861","Story","Stack Documentation and UX",2,"Update developer guide instructions for managing change-controlled documents","""The current instructions for building change controlled documents are a bit convoluted in that they require the use of cherry-pick and leave unmerged branches hanging around.  This works against the idea of using protected master branches and results in confusing usage of pull requests.    At the recent CCB meeting it was decided to change approach and use a new process involving {{git revert}} and merging of pull requests to master once the document has been released."""
"DM-17859","Bug","Firefly",2,"jupyter_firefly_extensions server extension is failing in LSP","""The server extension for the Jupyterlab Firefly extension has not been working in the science platform since the {{d_2019_01_30}} daily. This manifests as a failure to connect to the Firefly server. The environment variables set by the server side of the extension, like {{fireflyLabExtension}}, {{fireflyURLLab}}, and {{fireflyChannelLab}} are undefined.    The quickest way to test the connection in Jupyterlab is to open the Command Palette, find the Firefly section and then Open Firefly. The tab that opens should show a large """"Firefly Ready"""" with the Firefly toolbars. When the server extension does not work, the tab is all white with a small """"Firefly Loading"""" message at the top.    The build environment changed to use Python and pip, from SCL (Software Collections) to EPEL (Extra Packages for Enterprise Linux).    The initial fix we will make in this ticket is to remove a {{pip install}} from the packages.json file, and to change the version to 0.2.2. """
"DM-17858","Story","ts_aos",1,"Develop and Support the Active Optics Closed-Loop Simulation in Phase 2","""Develop and support the active optics closed-loop simulation. This task will integrate the modules of ts_tcs_wep_phosim, ts_tcs_wep, and ts_tcs_ofcPython. This task will be a prototype of active optics closed-loop simulation. The prototype here will support the simulation of main telescope active optics system (MTAOS) in the final. This task is in the phase 2 of the development."""
"DM-17857","Story","JupyterLab",0.5,"HTTP 403 status from JupyterLab reported poorly","""When accessing a """"shareable"""" URL under {{https://lsst-lsp-stable.ncsa.illinois.edu/nb/user/$USER/lab/tree/notebooks/}} to a notebook for which the accessing user does not have permission, JupyterLab reports:  {quote}Cannot find template: """"403.html""""   In """"/usr/local/share/jupyter/lab/static""""  {quote}  This is undesirable, compared to the result when accessing a """"download"""" URL under {{https://lsst-lsp-stable.ncsa.illinois.edu/nb/user/$USER/files/notebooks/}}, which reports:  {quote}403: Forbidden   The error was:   user ktlim was not allowed.  {quote}"""
"DM-17856","Story","ts_qa",1,"Support M1M3 Mirror Lab testing - part 3","""This task covers the time spent to support M1M3 Mirror Lab testing."""
"DM-17855","Story","camera|DM",3,"Draft LSE document describing the adopted proposal","""The result of this RFC will be a proposal to the SE subsystem.  It will be put forward to the CCB and if approved, become a change controlled LSE document.  At that point, we can also add a requirement to the OSS that refers to that LSE document, if desired."""
"DM-17851","Epic","ts_auxiliary_telescope",5,"Finishing ATSpectrograph SW & Algorithm","""Finishing ATSpectrograph SW & Algorithm"""
"DM-17847","Story","meas_deblender",1,"Update defaults in scarlet and create changelog","""[~pmelchior] and I have found that some of the default parameters in scarlet need to be modified to more useful values.     1. Normalizing the morphology (S matrix) so that the peak value is set to unity is the most effective way to break the SED/morphology degeneracy, as opposed to the current method of normalizing the SED (A matrix). This provides a method to separate sources with similar colors but very different intensities and also converges more quickly than the current default normalization.    2. Turning off Nesterov acceleration. There appears to be an issue with combining our proximal gradient method with Nesterov acceleration, making the optimization algorithm asymptotic. It also appears to be even more unstable with the new normalization scheme, however using S matrix normalization _without_ acceleration still runs faster than A matrix normalization _with_ acceleration.    This ticket will also create a change log in scarlet to keep track of these and other modifications to keep users up to date with the changes. It will also make it easier to keep stack users up to date when updated versions of scarlet are imported into the stack."""
"DM-17881","Story","stack release",2,"Check weekly for regressions","""Make sure the weekly under consideration for the next release candidate does not have significant regressions from the previous major release."""
"DM-17876","Improvement","ts_auxiliary_telescope",1,"Update ATDomeSimulator for changes to ATDome","""The recent changes to the ATDome interface DM-17610 require an update to ATDome simulator in the ts_ATDomeTrajectory package.    While I'm in there I'll update the code to take advantage of cached data in ts_salobj 3.8 topics."""
"DM-17874","Story","log",2,"Remove hierarchical logging context","""Implementing RFC-570. Not sure what epic this belongs to."""
"DM-17914","Story","afw",1,"afw PhotoCalibTestCase failure using bleed environment","""Using a bleed version of the conda environment, afw test case PhotoCalibTestCase fails with the following error:         > self.assertEqual(photoCalib.getCalibrationErr(), calibrationErr)   E AssertionError: 161742302.08062094 != 161742302.08062097     """
"DM-17913","Improvement","ts_auxiliary_telescope",1,"Add a function to ts_salobj that enables a CSC from any state","""Add a function to {{ts_salobj}} that, given a {{Remote}} for a CSC will send standard state transition commands to put that CSC into the {{ENABLED}} state, regard of its current state. This function is essential for SAL scripts, but is sufficiently general purpose that it belongs in {{ts_salobj}}. Unfortunately it presently relies on reliably getting the summary state, which may not be possible until DM-18035 is fixed. It may be possible to hack around this but I'd like to see if we can get that ticket fixed before getting too ugly.    Also add support for {{BaseCsc.fault}} for outputting the {{errorCode}} event.    Also add a bin script to purge SALPY topics.    Simplify log handling so that log messages are sent as soon as they are requested. Eliminating the queue makes it much easier to assure that the last log messages are seen as a script or CSC is shut down."""
"DM-17912","Bug","ip_isr",1,"gen3 ip_isr can attempt to remove a non-existant dataset, causing KeyError","""If a config option is disabled, but a gen3 inputTypeDict entry doesn't exist, attempting to cull that entry to match the config can fail with a KeyError."""
"DM-17909","Story","ts_auxiliary_telescope",3,"Write ATPtg/ATMCS integration test script","""Write an integration test for ATPtg to ATMCS as a SAL script and add it to ts_standardscripts.    There may be some overhead because this is the first script added to that package."""
"DM-17903","Story","obs_lsst",1,"imsim ci_lsst tests fail with bad key ccd","""When running the ci_lsst imsim tests they fail in the calibration construction phase with a bad key:      It is likely a problem with the configurations for imsim in that the default keys are being used rather than the ccdKeys override."""
"DM-17942","Story","ts_calibration",2,"TunableLaser fix Jenkinsfile","""In order to get Jenkins to pass the unit tests, the Jenkinsfile needs to be changed because of some environment factors.     Started writing a dockerfile that contains all dependencies needed to run TunableLaser CSC as docker container. Have gotten through most of the setup with eups. Once the file is complete, upload to dockerhub and pull image in Jenkinsfile. """
"DM-17932","Story","ctrl_mpexec",1,"Validate object type when reading pipeline or graph from pickle","""cmdLineFwk can read pre-built pipeline and quantum graph from pickle file, but it is not presently checking that object of correct type is read which can lead to exceptions in other places. Need to add simple check of the type of the object that was read."""
"DM-17930","Story","ts_qa",1,"Support M1M3 Mirror Lab testing - part 4","""This task covers the time spent to support M1M3 Mirror Lab testing."""
"DM-17929","Story","ts_auxiliary_telescope",2,"Update Illumination system coordination script and move to standard scripts","""Take Tiago's script that coordinates the monochromator, electrometer and fiber spectrograph to perform the steps needed when taking a flat field.    This script will serve as an example to future script composers."""
"DM-17952","Story","ts_aos",5,"Develop and Support the Active Optics Closed-Loop Simulation in Phase 3","""Develop and support the active optics closed-loop simulation. This task will integrate the modules of ts_tcs_wep_phosim, ts_tcs_wep, and ts_tcs_ofcPython. This task will be a prototype of active optics closed-loop simulation. The prototype here will support the simulation of main telescope active optics system (MTAOS) in the final. This task is in the phase 3 of the development."""
"DM-17951","Story","ts_aos",2,"Integrate the AOS Closed-Loop Simulation with Jenkins Server","""Integrate the AOS closed-loop simulation with Jenkins server. I have the problem to let the Jenkins to get the repos existed in the docker image. This task will solve this problem and make sure the simulator can do the automatic unit tests on the Jenkins server."""
"DM-17964","Story","DM",2,"Draft external code policy","""Draft a policy for including external code into data release production processing    This will be added to DMTN-106 to start a discussion at least.    Then perhaps something will go in LDM-294 or another controlled document."""
"DM-17956","Story","jointcal",2,"Add option to output chi2 files at each outer fit iteration","""To get more information about the details of jointcal's fitting processes, we can output the """"chi2 contributions"""" file at each stage of the {{_iterate_fit()}} """"outer"""" python loop. This will provide some more details, without being too overwhelming. This would be a boolean config option (named {{writeChi2ContributionFilesOuter}}?) that defaults to False. The output files would follow the same naming convention as the initial/final ones, with the fit iteration appended.    This would also be a good time to clean up how {{saveChi2Contributions()}} generates the names of the files: we should pass some kind of format string to it and use a combination of {{find}} and {{replace}} in C++ to generate the two file names for the measured and reference stars. {{_iterate_fit()}} should also output a count for each iteration, so that we can more easily associate these new files with the outer fit loop log messages (which will have that count in their filename).    We need to decide whether to write the files before or after the fit loop: the current """"initial_chi2"""" file is written immediately after the model is constructed, before any of the """"initialization steps"""" are taken, while the """"final"""" step happens after all fitting is complete.    Should this option also result in the """"initialization steps"""" also being logged, or should the existing {{writeChi2ContributionFiles}} be modified to do that? The 3-4 initialization steps are by far the largest chi2 change, and have outlier rejection turned off, so they are both qualitatively and quantitatively different from the fit loop."""
"DM-17985","Story","ts_auxiliary_telescope",2,"Rewrite monochromator CSC using SalObj","""The current monochromator CSC, currently written in LabView, has an issue that we are unable to solve. I will re-write it using salobj. """
"DM-17984","Story","ts_auxiliary_telescope",2,"Rewrite request_script script.","""request_script.py is a utility script to interact with the queue. It was written some time ago with an old version of sal and when I did not have a clear idea where to put it. I will re-write the script using the newest version of SAL and will put in in ts_scriptqueue.    =============================================    The ui module contains two submodules; a model interface and a command line front end. The model hosts a global ui for the script queue and the front end provides the interface to interact with it (both input and output).    For the front end I'm using a the python cmd standard library, with the possibility to extend it to use cmd2. This gives user some nice capabilities like auto complete and helper. functions. One of the main issues with that library is that it is not asyncio friendly, so I had to do some workaround and rely on SAL to store the information until the user request it. The idea of having the process running all the time and rely on cmd is to recycle the remote to talk to the queue. The previous version was really slow since you had to subscribe to the remote every time you run the script.    I think this script will probably be a useful utility at early stages of interacting with the queue. I did not included tests for the ui modules. I think this could be a good addition for a next release, but I could also think about some simple tests to perform.    Also, updates timeouts for the script queue.     """
"DM-17978","Story","astro_metadata_translator",0.5,"Visit id not being cast as int","""If the header card being used to generate {{visit_id}} is a string, it can end up as a {{str}} in the {{ObservationInfo}}. [^test_hdr.txt] """
"DM-17977","Improvement","ts_auxiliary_telescope|ts_main_telescope",1,"Improve handling of failed configuration by the script queue","""The script queue has some bugs and quirks in handling failed configuration. The most important is that if configuring a script fails then the script can end up as the current script. Do the following:  - Add a unit test  - Change the {{ScriptInfo.configured}} property to be True only if configuration succeeds and add property {{ScriptInfo.configure_failed}}  - Make sure {{ScriptInfo.process_state == ConfigureFailed}} if configuration fails. At present it is terminated before this has a chance to occur.    Also make the {{stopScripts}} command more reliable about removing scripts; if a script has managed to stay on the queue despite being done then remove it."""
"DM-17976","Story","ts_middleware",1,"SAL mentoring","""Continue SAL++ mentoring"""
"DM-17975","Story","ts_main_telescope",2,"Backup m1m3 test campaign EFD data","""Backup all the EFD data collected during the M1M3 test campaigns at the mirror lab.    Retrieve the EDF machine and integrate back into the simulation cluster.    Copy data to NCSA if a destination location is provided"""
"DM-17974","Story","ts_middleware",2,"Adjust SAL hashcode for types support","""Change the implementation of SAL hash codes to include control over topic names as well as DDS types. This should avoid namespace collisions when CSC XML is updated"""
"DM-17973","Story","Firefly|SUIT",1,"Please document all Firefly-related URLs that are currently used in LSST","""Please document, and note in this ticket where it's documented, all URLs currently in use in any Firefly application that is in use or planned to be in use in LSST (default data portal, slate, time series viewer, etc.).    Before our closeout I want to be sure that we have a coherently laid out scheme for these."""
"DM-17970","Story","ts_qa",1,"Install Labview","""Install Labvier on my machine. and try to get the ts_sal Labview program running. I will be needing to run this for development. """
"DM-17969","Story","ts_qa",2,"Add tests to Jenkins","""Get the newly created single file cpp scripts running on jenkins. This should improve speed at which the tests are ran. This because behind the scenes when your program does any interaction with DDS there is a lot of overhead. By having all the tests in a single program this overhead is started only once.    Hopefully we reduce the jenkins build time by using these test programs rather than running each individual program. """
"DM-17967","Improvement","ts_auxiliary_telescope",1,"Add target event to ATMCS","""Add a new event to ATMCS that provides the commanded target, so users don't have to """"tap"""" commands to see what the MCS is trying to do.    Update ATMCS simulator accordingly.    This will make the integration test between ATPtg and ATMCS much easier, so I am increasing its priority."""
"DM-18028","Improvement","ts_auxiliary_telescope|ts_main_telescope",0,"Allow BaseScript.main(descr=None)","""At present {{BaseScript.main}} requires the descr argument, but most scripts will not accept descr as a constructor argument. Modify {{BaseScript.main}} to use None as the default for {{descr}} and only pass the argument if the value is not None."""
"DM-18026","Story","ts_auxiliary_telescope",2,"Investigate pymodbus/ADAM channel issue","""The white light source needs to continuously read four analog channels on the ADAM 6024 device, which the KiloArc device uses to signal errors and some additional information about the hardware state. My test hardware can only simulate a signal on one channel at a time, and I discovered that my assumptions about how I would read the other channels are apparently wrong. It's possible that this component could work with only one channel (the error signal) but I'd like to figure out what's amiss."""
"DM-18024","Story","ts_auxiliary_telescope",3,"State transitions for white light source CSC","""WLS CSC needs to implement state transitions:    -upon receiving relevant SAL commands    -upon receiving an error signal from the KiloArc hardware    -in the event of communication loss between host computer and ADAM hardware"""
"DM-18019","Story","DM",2,"Create note on security of images ","""Steve Kahn asked for a """"paragraph"""" on image security by next week."""
"DM-18012","Improvement","ts_auxiliary_telescope",2,"Add showSchema command to the script queue. ","""Each script available to the queue have different sets of configuration parameters. To know them, we currently have to look into the code… It would be very helpful to be able to “ask the queue” what are the parameters of a specific script are. Ideally, when the queue receives such a command it would not put the script to run on the queue, but rather, read the configuration parameters from it and publish it through an event.     I think that it would suffice to get the docstring from the {{configure}} method and output that to SAL.       {code:python}  In [1]: from lsst.ts.scriptqueue.test_utils import TestScript  Could not import lsstcppimport; please ensure the base package has been built (not just setup).      In [2]: print(TestScript.configure.__doc__)  Configure the script.            Parameters          ----------          wait_time : `float`              Time to wait, in seconds          fail_run : `bool`              If True then raise an exception in `run` after the """"start""""              checkpoint but before waiting.          fail_cleanup : `bool`              If True then raise an exception in `cleanup`.            Raises          ------          `salobj.ExpectedError`              If ``wait_time < 0``. This can be used to make config fail.  {code}    Although I'm not sure how that would work for non-python scripts.  """
"DM-18010","Epic","ts_auxiliary_telescope",5,"Finishing ATMonochromator SW Development","""Port ATMonochromator from LabView to Python."""
"DM-18007","Story","L1 Database",2,"Install software and services on PPDB gcloud machines","""We have two beefy """"machines"""" in Google cloud for our tests (ppdb-test-server and ppdb-test-client), need to install all software that is necessary for the tests:   * for client I just need lsst stack with dax_ppdb in it, plus the database backend driver for potgres (I think I used psycopg2 at in2p3)   * for server we need more or less recent version (10?) of Postgres installed from RPMs, properly configured"""
"DM-18036","Story","Test Data",3,"Convert stack demo refcat to HTM indexed","""{{lsst_dm_stack_demo}} uses an astrometry.net reference catalog. In order to remove a.net support from the stack, we need to convert this refcat from a.net format to HTM Indexed format. [~krughoff] claimed he had some code to do such conversions in the past.    Converting the existing refcat is probably better than creating a new refcat because any changes to the refcat contents would be reflected in changes in the demo output, and we don't want to have to go and vet those changes again."""
"DM-18033","Bug","ts_auxiliary_telescope|ts_main_telescope",1,"ts_scriptqueue unit tests failing on some machines","""One or the other of the npytest_x unit tests is not reliable on some machines. In particular nopytest_script_queue.py sometimes (?) fails for [~tribeiro] and test_stop_scripts in nopytest_queue_model.py usually times out on my work iMac (but runs reliably on my identical home iMac).    Unfortunately for the test failures I see, they go away if I only run the failing test so each test is clearly not running completely independently. Two things I would like to try:  - Measure the time it takes to start each script and the time it takes to configure it and report the max time, standard deviation and mean time for each of these when running all tests.  - For nopytest_queue_model.py use a unique SAL index for each script, in case that reduces interference between tests (though I don't see why it should).  - Put a pause at the start of the failing test to see if giving SAL a chance to clean things up helps."""
"DM-18032","Story","Design Documents",2,"Update descriptions of DM L2 milestones","""Review LDM-503, and ensure that each L2 milestone has a coherent description of what it involves.    For most of them, this will likely involve checking in with the relevant milestone ”owners” — see the list of action items from the [Nov 2018 DMLT|https://confluence.lsstcorp.org/display/DM/DM+Leadership+Team+Face-to-Face+Meeting%2C+2018-11-06+to+08]."""
"DM-18031","Story","Firefly|SUIT",2,"Add CADC TAP service to default list on Firefly TAP interface prototype","""03/12/2019 CADC TAP service was added to the list of Firefly TAP services.    [http://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/tap/] is often unresponsive, when called from IPAC. CADC #75724 was created for this issue with the following response from Patrick Dowler at CADC:       {quote}  We have been able to reproduce this and it seems to be a strange network issue... could be some network security equipment near our end. We did also discover that https seems to resolve it and we have recently converted all our web services to use https only (in the capabilities docs - not yet propagated in IVOA registries)    I don't think we will be able to solve this for http but https appears to work so I will close the ticket. Thanks again for bringing it to our attention - I found evidence in logs that it also effected other services as well.{quote}       Firefly is now using     [https://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/tap] end point.         02/22/2019    Please add the CADC TAP service at [http://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/tap/] as soon as reasonably possible to the standard list of TAP services in the Firefly TAP search screen. This is a very useful service for testing, both because of content and because it's based on the same code that [~cbanek] is using for the LSST TAP service.    This service has both ObsTAP (ObsCore format, table {{ivoa.ObsCore}}) and CAOM2 image metadata collections, which are a valuable resource for our development.    At this moment, something goes wrong when trying to manually access this service. The message  {quote}Failed to get schemas for [http://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/tap/:] Error: Error from Server for command tableSearch: code: 504, text:  {quote}  appears. However, I can verify manually and/or with TOPCAT or [http://saada.unistra.fr/taphandle?url=http%3A//www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/tap/] that the {{TAP_SCHEMA.schemas}} table is available."""
"DM-18067","Story","afw",2,"Add fluxMag0 PhotoCalib factory function","""While working on DM-10156, I found that it would in fact be useful to have a factory function that took the {{Calib}}-style {{fluxMag0}}/{{fluxMag0Err}} and returned a {{PhotoCalib}}. I implemented it on that ticket, but it stands alone, so I'm going to cherry-pick it here to save the poor reviewer of DM-10156 a little bit of effort."""
"DM-18065","Bug","ip_isr",1,"Bad logic in saturation interpolation config options","""[~mfisherlevine] was just puzzled as to why it didn't look like the interpolation of saturated pixels had been turned off despite having set {{doSaturationInterpolation=False}}.  To stop the interpolation from ocurring, he had to set {{doSaturation=False}}.  The docs say:  {code:python}  doSaturation = pexConfig.Field(          dtype=bool,          doc=""""Mask saturated pixels?"""",          default=True,      )    doSaturationInterpolation = pexConfig.Field(          dtype=bool,          doc=""""Perform interpolation over pixels masked as saturated?"""",          default=True,      )  {code}  indicating some false logic in the task.  It looks like the fix should happen with a check for {{doSaturationInterpolation}} here: https://github.com/lsst/ip_isr/blob/master/python/lsst/ip/isr/isrTask.py#L1216    If these configs are meant to operate entirely independently, (a perhaps unlikely, but _possible_ use case: the run() method was passed an image that had the SAT bit set elsewhere), this should be indicated clearly in the docs to avoid potential confusion along the lines """"why are/aren't saturated pixels getting interpolated if I set {{doSaturation=False}}/{{doSaturationInterpolation=True}})."""
"DM-18039","Story","Qserv",8,"Troubleshoot data loading","""- create GKE cluster for [~selles]  - load data inside GKE cluster  - study logs for qserv and dataloader"""
"DM-18108","Story","ts_qa",2,"SAL v3.9 testing","""This task covers the time to review the proposed combined SAL-generated test interfaces."""
"DM-18102","Bug","Firefly",1,"Firefly table overlay of coord_ra, coord_dec has stopped working","""Uploading a table to Firefly with {{coord_ra}} and {{coord_dec}}, units of radians, worked as of a few months ago. In testing a Firefly notebook for DM-17753, in the past two weeks, the overlay of sources does not show up and is not present in the layers.    To reproduce: go to the [PR for DM-17753|https://github.com/lsst-sqre/notebook-demo/pull/17] and run that notebook in the LSST Science Platform Notebook Aspect.         Fix: regex error in pattern match."""
"DM-18101","Story","ts_environment",5,"Develop documents for HVAC Linux upgrade software contract","""To develop statement of work that leads to generate purchase order for getting Linux upgrade software to be utilize in main telescope HVAC system"""
"DM-18124","Story","ts_qa",2,"Time server installation on the summit network","""Review documentation procedures and perform installation of time server onto Summit network."""
"DM-18123","Story","Firefly",8,"TAP Search: Relayout TAP UI","""Relayout the TAP search panel UI according to the screen shot attach.   * Target area and table area division should be about 40/60 and resizable    * Add help the indicates one-way to ADQL query panel       |Change layout according to attached mock-up.   * TAP search panel is now resizable   * Bottom section is expand/shrink when resizing   * Column constraint toolbar is separated and placed on top for better symmetry   * Message added to Advanced ADQL panel to warn user of lost query when switching back to Basic   * Added loading mask to Select Constraints when waiting for data to be loaded|    TODOs: * All labels should be reviewed.   *    ** Submit change request as needed.    Known Issues: * Left panel of Constraints (spatial/temporal section)   *    ** Has awkward alignment when expanded   ** Horizontal scrolling will not appear when shrink   ** Minor, collapsible icon and label not aligned   * Service Provider is default to {{IRSA}}, but is not shown in input field.|            """
"DM-18120","Story","ap_verify",1,"Remove --silent command-line argument from ap_verify.py","""{{ap_verify.py}} originally had built-in support for SQuaSH upload, but it was removed in DM-16536. The frequently used {{--silent}} command-line argument, which disables SQuaSH upload, was deprecated.    Remove the deprecated {{--silent}} argument after Science Pipeline release 18.0 but before release 19.0."""
"DM-18117","Story","ts_auxiliary_telescope",1,"Investigate ADAM functionality for loss of network connectivity scenario","""Right now, if the ADAM device is sending a voltage signal to the KiloArc, it will continue to send that signal until it receives a command to stop. The failure mode we are concerned about is, what happens if the CSC loses its connection to ADAM or crashes. Is there a way to detect that from the ADAM device, and stop sending the power signal as a result? This task is to investigate this. If there is not, then the higher level Illumination CSC will need the ability to cut power to the ADAM device, to ensure that the KiloArc can be gracefully powered down in the event of a CSC failure."""
"DM-18116","Bug","SUIT",8,"Enum filtering fails if the value contains semicolon","""UCDs often have semicolon separator between words. If we are filtering UCDs by selecting the values with semicolon from the list of values (""""categories""""), it fails.    Test case:   1. [http://localhost:8080/firefly/firefly-dev.html?__action=layout.showDropDown&visible=true&view=TestTAPSearch]   2. Use GAIA tap service.   3. Search in ADQL tab: SELECT column_name, ucd FROM tap_schema.columns WHERE ucd like '%meta.main%' .    3. In the result table, click column filter, click arrow next to ucd filer box, check 2 last entries (""""pos.eq.ra;meta.main"""" and """"pos.eq.dec;meta.main"""") from the list, and click filter link.   4. Table load error is displayed: _Invalid statement: """"ucd"""" IN ('pos.eq.dec_         _FIREFLY-59 has been created._         _June 21, 2019_     _ticket has been expanded to more filtering capabilities, (AND OR) conditions are available now._  |As reported, filtering fail when the value contains semicolon. Because we were using semicolon to separate conditions, this messes up the underlying query statement.  Instead of just fixing the problem, I went ahead and allow the conditions delimiter to be either {{AND}} or {{OR}}. Although this added a useful requested feature, it also may require updates to our online help. Please coordinate with the appropriate people after merging.  Sample conditions:  {{> 0 and < 50 or is NULL}}  {{< 0 or > 100}}  {{in ('m31', 'm41') or is NULL}}|         """
"DM-18115","Improvement","ts_middleware",0,"AckError str and repr should include the added fields","""{{AckError}} str and repr should include the extra fields """"error"""" and """"result"""". That way tracebacks and such will display the information."""
"DM-18168","Improvement","ts_middleware",0,"Remove workarounds for DM-18035 from ts_salobj","""I have had to add some hacks to ts_salobj to work around DM-18035: late joiners do not reliably get topic data. Once that is fixed use this ticket to clean up the code."""
"DM-18167","Bug","display_firefly",2,"display_firefly needs to handle viewer_ids properly","""In the LSST Science Platform Notebook Aspect, when using the Firefly for Jupyterlab extension, the {{lsst.display.firefly}} backend needs to properly set the viewer id when displaying an image. Then that will fix the problem of restarting a notebook kernel and having display of images going to the newly opened Firefly tab.    [~roby] found the problem area in the {{lsst.display.firefly}} code and it has been tested."""
"DM-18161","Story","ts_main_telescope",1,"Plan M1M3 Support","""Work on planning for future M1M3 support work"""
"DM-18160","Story","stack release",1,"Add note about the Calib->PhotoCalib replacement to v17 Release Notes","""Sometime in the next month, I will be replacing {{Calib}} with {{PhotoCalib}} (DM-10153). We need a note in the Release Notes for v17 to prepare people (the transition is not fully backwards compatible)."""
"DM-18159","Story","ts_qa",3,"Update SAL tests for v3.9","""SAL v3.9 contains two new features   * RPM packagaing   * Combined interface modules    This task covers the effort required to update the tests for these new features.    There is also a desire to improve/increase the level of Java testing at the SAL layer.  This task also covers some time to work on this."""
"DM-18158","Improvement","ts_middleware",0,"Clean up RemoteCommand waiting","""The code that waits for command acks in {{RemoteCommand}} is hard to follow. Clean it up.    Also enable_csc fails if the summary state cannot be obtained due to DM-18035. Make it more robust."""
"DM-18154","Improvement","ts_auxiliary_telescope",2,"Remove azimuthDirection from the target event","""We have agreed to remove the {{azimuthDirection}} field from {{trackTarget}} command of ATMCS and make the azimuth and rotator angles absolute in TPC-163. This ticket is to update the XML and the ATMCS Simulator.    The ATMCS will also have to be updated.    One question: which is indirectly related:  * Should the azimuthCalculatedAngle field of the mountEncoders event be in the range 0, 360 or -270 to 270? We should make sure that the XML has the correct information.    MTPtg and MTMount should probably get the same treatment, but on a different ticket. Whether we actually do it depends on what the MTMount vendor says (they may have already coded it this way!)."""
"DM-18148","Story","Requirements Documents",2,"Create the initial model of the Batch Production Services requirements in MagicDraw","""Attached to [DM-16084|https://jira.lsstcorp.org/browse/DM-16084] is an Excel spreadsheet with Batch Production Services requirements.   Please ingest them into the LSST model.  The spreadsheet contains a second sheet with opening paragraphs and the list of authors if needed.    Also, please note that that in one of the requirements (row 4) we reference LSE-81 as the parent requirement."""
"DM-18139","Story","atmospec",8,"Add functions for making and applying gain flats","""Given a list of gains per-amplifier, apply them as if flatfielding.    Write a function to make this into a fake flatfield, so that it can be applied as part of ISR if required."""
"DM-18134","Story","atmospec|obs_ctio0m9",2,"Get atmospec pipeline working with ctio0m9 data","""We already have obs_ctio0m9, but some of the data we have from that telescope is not compatible with the obs_package as it stands, as they kept changing which amps they read out, and in what configuration.    With the help of Augustin, pick a few files with the same layout, and for which there exist a few biases (and other calibs if/as required) and get them readable.    This might mean making a temporary fork of obs_ctio0m9 to get things working.    Build the calibration products, and get processStarTask running on it.    Necessary because we want to test this pipeline with absorption spectra before going on sky, and the lab will only ever provide emission spectra, not to mention it would be nice to have a more realistic PSF."""
"DM-18132","Story","atmospec",2,"Change how astropy models are dealt with in SpectralExtractionTask","""Sort out how/where the functions are defined, so that the can be evaluated neatly with the fitted params."""
"DM-18129","Story","ts_aos",1,"Realize the OFC Interface Classes to MTAOS in Phase 1","""Realize the OFC interface classes (in ts_ofc) to let the MTAOS to use. Chris and I discussed and defined the interface classes in the last sprint. I plan to realize them for Chris to be able to use with the real calculations instead of interface only. This is the phase 1 of task."""
"DM-18128","Story","ts_aos",3,"Use the yaml Format in Configuration File of OFC","""Use the yaml format instead of txt format to do the configuration file management. The yaml is the standard in DM team for the configuration files. Since I never use the yaml before, this task will take some time for me to learn the use of yaml with Python."""
"DM-18127","Story","ts_aos",2,"Update OFC to Use the DM Repository Template","""Update the ts_tcs_ofcPython to use the DM repository template. This will use the eups to do the package management and scons to build the repository. This is a preparation to put the AOS modules into the scientific pipeline (this means the user can use 'eups -k -r .' to declare the module). This task will also need to modify the code to fulfill the PEP-8 coding style."""
"DM-18203","Bug","meas_algorithms",1,"numpy unicode warnings in readTextCatalogTask.py","""Running meas_algorithms tests locally, I see a number of the following warnings:        It looks like this code is used by the refcat ingester."""
"DM-18201","Story","DM Subsystem Science",1,"Write job advertisement for the DM Science Validation Scientist","""The role of the DM Science Validation Scientist, as described in [LDM-294|http://ls.st/LDM-294] and [LDM-503|http://ls.st/LDM-503] will relocate to  LSST HQ in Tucson as a 100% role from mid 2019"""
"DM-18196","Story","ap_association|dax_ppdb",1,"Fix afw schema missmatch between ap_association and dax_ppdb","""Schemas are slightly misaligned between ap_association and dax_ppdb. This causes a crash in running ap_pipe on round-tripped diaObjects. This ticket will add the nessacary columns (validityStart, validityEnd, lastNonForcedSource) to the default diaObject schema in ap_association"""
"DM-18184","Story","Firefly",2,"upgrade babel to address some security concerns","""Both Babel and ESlint are behind and should be upgraded.   * For ESLint there are also the rules to react functional components that can be added.   * We are currently using Babel 6.26, upgrade to the most recent 7.4.   * We are currently using ESlint 4.5, upgrade to 5.1    _Babel Helpful docs:_   * [https://babeljs.io/]   * [https://babeljs.io/docs/en/v7-migration\|https://babeljs.io/docs/en/v7-migration]    _ESLint Helpful docs:_   * [https://eslint.org/]   * to add react functional component rules   ** [https://reactjs.org/docs/hooks-rules.html#eslint-plugin]   ** {{npm package: eslint-plugin-react-hooks}}    _Driving reasons:_   * We like to keep Babel up-to-date for support purposes.   * Github posted by security vulnerability alert at [https://github.com/Caltech-IPAC/firefly/network/alerts].   * Babel 7 also adds better JSX support for react fragments.    A similar ticket in IPAC Firefly team has been scheduled for July sprint.  [https://jira.ipac.caltech.edu/browse/FIREFLY-74]      [|https://jira.ipac.caltech.edu/browse/FIREFLY-74]"""
"DM-18181","Story","daf_butler",8,"Provide tool to validate datastore template configurations","""DM-17025 added the ability to validate a DatasetRef against a selected file template. Now we need the ability to be able to test that every single registered DatasetType is consistent with the corresponding file template (for datastores that support file templates).    We also need to be able to form a DatasetRef for every DatasetType and every instrument to check that instrument specializations also conform.    It should probably also check that every one of those DatasetRefs has a corresponding formatter assigned.    Chained datastores will have to forward the validation to each contained datastore noting that not all datastores have to support all datasetTypes in a chained datastore.    I am assuming this should be a command that is run on demand rather than something that occurs every time the butler is instantiated."""
"DM-18175","Story","ts_qa",3,"Implement the build and packaging process for one AuxTel CSC","""Continuing the effort to implement the build and packaging process for T&S CSCs."""
"DM-18173","Story","ts_auxiliary_telescope",2,"Auxtel Calibration System integration and test in the lab","""Now that the software components for the calibration system are up and running again I'll be able to run some integration tests in the lab. I'll take this opportunity to properly debug an document any SAL/ScriptQueue related issue I encounter.     Required Components:    - ATMonochromator  - FiberSpectrograph  - Electrometer  - ATSpectrograph  - ATCamera      Additional components:    - White Light Source  - Chiller     * - Additional components are those that are not required for the tests but will be added if available.     The artifacts of this task will be """"at least"""" a script to run the Calibration system and probably one that also involves the ATCamera and ATSpectrograph, as well as confluence page with description of the issues encountered and jira tickets.    """
"DM-18172","Story","ts_auxiliary_telescope",2,"Write script to take standard detector characterization dataset(s)","""This task captures the work required to write and test a script to take standard detector characterization dataset(s) for ATCamera. """
"DM-18169","Story","ts_main_telescope",2,"Plan M1M3 Thermal Work","""Work on and Finish thermal initial plan."""
"DM-18305","Technical task","SUIT",0.5,"Specify exactly the number of cores and GB to be used for Firefly/Portal pods on the LSP instances","""This sub-ticket of DM-18304 just asks the Portal team to specify precisely the number of cores and GB to be allocated to each Firefly pod on the NCSA LSP instances {{lsst-lsp-int}} and {{lsst-lsp-stable}}.    The idea is to get the numbers on the record on this ticket.  Subsequently as part of Portal close-out work this information will be included in the deployment manual.    The actual Kubernetes configuration modifications will be done on DM-18304."""
"DM-18297","Improvement","ts_auxiliary_telescope|ts_main_telescope",1,"Make it easy to run a single script from the command line, for testing","""I would like a simple way to configure and run a single script from the command line and see its SAL outputs. This is intended to support development by making it easy to run the script without needing the script queue. I realized the need when writing the ATPtg/ATMCS integration script.    It may be that [~tribeiro]'s run_queue UI is enough, but I was hoping for something even simpler -- something that didn't use the script queue at all.    I initially thought of just expanding {{BaseScript.main}} but that is a non-starter because scripts are intentionally not on the $PATH. Instead I think it has to be a standalone script that accepts the name of the script to run. The interface and code can be based on [~tribeiro]'s run_queue UI.    To make this safe without colliding with a script queue I suggest that it fail if the script queue is alive."""
"DM-18292","Story","ts_aos",5,"Attend SpatialAnalyzer training (Including Travel) ","""Attend Spatial Analyzer training event in Los Angeles, March 12-14, plus travel days"""
"DM-18291","Story","ts_auxiliary_telescope",3,"Lab Testing for White Light Source CSC","""Hook the ADAM box and our CSC up to the actual KiloArc device in the lab, and try sending commands to it. """
"DM-18290","Story","ts_auxiliary_telescope",2,"Implement Detailed State on White Light CSC","""Implement detailed state on the WLS CSC. This will simply be an enumeration of the hardware states that we can receive from the KiloArc. Since we already react to an error signal from the KiloArc, this won't change CSC behavior, it is strictly about reporting more information."""
"DM-18283","Story","ts_main_telescope",3,"Write a generic camera SAL XML and CSC","""Write a new set of XML for a generic camera CSC and implement it with ts_salobj.    Required items:   * Set Exposure Time   * Set ROI   ** Top, Left, Width, Height   * Set Full Frame (short cut for the set ROI command)   * Start Live View   * Stop Live View   * Event indicating live view ip / tcp port for image data   * Event indicating current exposure time   * Event indicating current ROI   * Event for camera specific properties (key / value pair basically)   * Event for camera make / model   * Telemetry for temperature"""
"DM-18282","Story","ts_middleware",2,"ReConfigure hardware cluster EFD","""Update SAL runtime and writers on hardware test cluster pLAN EFD"""
"DM-18320","Story","HeaderService",2,"Update to make FITS files ingestable","""The FITS files generated by the ATArchiver using the headers created by the HeaderService had to be adjusted to proper ingestion."""
"DM-18318","Story","ap_association",8,"Create initial subset of timeseries features for DIAObject","""While we wait for a complete list of DIAObject timeseries features (https://jira.lsstcorp.org/browse/DM-11962) it will be useful to have various simple statistics to assist with exploring AP processing outputs.  The implementation is not expected to be final.    In a brown bag discussion, we suggested the following (all computed on calibrated fluxes):   * max   * min   * mean   * std   * skew   * median   * MAD   * percentiles ([5,25,50,75,95])   * Stetson J   * Linear trend   * max delta flux/delta t   * average flux error"""
"DM-18313","Story","DM",1,"February 2019 Monthly report","""write summary"""
"DM-18312","Story","DM",2,"Prepare and deliver talk to Kitt Peak Docents","""Talk Tuesday March 5th 18:00"""
"DM-18311","Story","ts_auxiliary_telescope",1,"Add an option to keep the files generated by salgenerator in make_salpy_library","""Sometimes, when trying to debug SAL communication,  it is useful to have the test scripts generated by salgenerator. I think it would be helpful if make_salpy_lib has an option to keep those files. """
"DM-18341","Story","Firefly",20,"implement the multi-cast alternate recommended by DM-17601","""Using multi-cast to do service discovery does not work in GKE environment, and also it requires low-level hardware configuration. DM-17601 was created to explore the alternate way to accomplish service discovery. It recommended using redis. This is the implementation ticket.          <text taken from PR>    *Objective:*  The objective is to implement an alternative to multicast cache peer discovery mechanism. Multicast is not supported in the cloud, making Firefly unable to scale horizontally.    The implemented alternative is to use a publish-subscribe messaging system for peer discovery. The flow is similar to multicast in which it relies on a periodic heartbeat message from each active peer to determine ‘liveliness’. Subscribing to the same channel determine the membership of the group.    *Implementation Details:*  A custom CachePeerProviderFactory is created to determine which discovery mechanism to use based on configuration.  Messaging is implemented using Redis server and Jedis client. The preferred deployment of Redis is via Docker. Jedis dependencies were added to Firefly.     """
"DM-18340","Improvement","ts_auxiliary_telescope",1,"Update ATDomeTrajectory to use the target event from ATMCS","""The ATDomeTrajectory CSC presently tries to use the pointing component to get its target, but a much better choice is the new {{target}} event from ATMCS. Update it accordingly."""
"DM-18339","Improvement","ts_auxiliary_telescope",1,"Fix W505 errors ts_ATDome","""Check for and fix W505 errors (doc strings and comments too long) in ts_ATDome, ts_ATPneumaticSimulator and ts_standardscripts"""
"DM-18358","Improvement","ts_auxiliary_telescope",1,"ATSpectrograph updates","""The current version of ATSpectrograph was developed while the linear stage was not working. The control algorithm needs to be properly implemented. We are also missing the feature where it is possible to select filter and grating by name instead of only id.  """
"DM-18357","Improvement","ts_auxiliary_telescope",2,"Improvements on request_script","""After using the new version of {{request_script}} for a couple of weeks I have gathered some new features that will be really helpful (I am also glad to hear that people liked the script and think we will be using it for a while). This task is to add some of the requests I've got to improve the script.    Add user login/logout. To be able to coordinate multiple people interacting with the same instance of {{request_script}}, add a log in/out functionality. This is not to provide any kind of authentication but rather to inform users if there is anyone using at the time. Basically when someone enters the shell it will have something like:  {code:bash}Please, log in with a user handle (use your slack username to make it easy to contact you).  (login): tribeiro  (cmd[tribeiro]): logout  Please, log in with a user handle (use your slack username to make it easy to contact you).  (login):  {code}    Check usability of [asynccmd|https://pypi.org/project/asynccmd/]. This is an asyncio capable version of cmd. It would make the script much more responsive if it can be incorporated.    Add unit test.     limit number of script in the past queue.    Improve parameter parsing for the run command.      """
"DM-18355","Story","Notebooks",1,"Sorting images in the nublado spawner page","""The images in the drop down menu of the LSP spawner are currently sorted by date. This is ok, but it makes it a bit hard to find a specific image, especially if it is ancient (i.e., the preceding major release). It would be nice to instead sort by image name. I think this would mostly have the effect of being a sort by category and then a sort by date within category (at least if the naming conventions hold). I could see arguments for major release, weekly, daily (from least populated to most) or daily, weekly, major release (from most recent to least).    This will require changes to [scanrepo.py|https://github.com/lsst-sqre/jupyterhubutils/blob/master/jupyterhubutils/scanrepo/scanrepo.py]"""
"DM-18354","Story","afw",1,"afw test fails due to assertEqual on float","""Using a bleed version of the conda environment, afw test case PhotoCalibTestCase fails with the following error:       """
"DM-18352","Technical task","ctrl_execute|ctrl_platform",2,"update allocateNodes.py with ability to start HTCondor with partitionable slots","""May not be required if HTCondor pool is available for use instead of Slurm.    Need partitionable slots for efficient use because certain pipeline tasks need more memory/cpus than others."""
"DM-18342","Story","squash",0.5,"Add ci_id, ci_url and squash_id as InfluxDB fields instead of tags","""{{ci_id}}, {{ci_url}} and {{squash_id}} are sequential numbers. If mapped to InfluxDB tags that will   [increase InfluxDB series cardinality|https://docs.influxdata.com/influxdb/v1.7/concepts/schema_and_data_layout/#discouraged-schema-design] which is not recommended.    We should add {{ci_id}}, {{ci_url}} and {{squash_id}} as InfluxDB fields instead."""
"DM-18363","Story","Qserv",1,"Fix Qserv centos-llvm builds","""The Qserv centos7-llvm builds have been failing for a long time now, in the ANTLR4 package, on an include of standard library header {{<algorithm>}}.  Track this down and fix."""
"DM-18401","Improvement","Qserv",3,"Minor code refactoring and cleanup in the Qserv Replication system","""A few minor projects to improve the quality of the code:  * eliminating _std::_ in the CC files  * fixing Doxygen documentation  * fixed syntactical and grammatical errors in comments  * replace absolute names of methods in logging statements and exception messages with the compiler-provided string ___func___  * fix indentations  * eliminate or add empty lines as required by the LSST C++ Style Guide  * fix class declarations to comply with the Style Guide"""
"DM-18397","Story","Requirements Documents",2,"Release new version of LSE-61 with LCR-1425/LCR-1463/LCR-1465 incorporated","""Work with [~mrodriguez] to update the LSE-61 MagicDraw model for the final release of approved LCRs LCR-1425/LCR-1463/LCR-1465 and create a new version of LSE-61 PDF for upload to Docushare.     This includes checking the output from the latex docgen, adding flowdown from OSS, and adding priorities to the newly added requirements."""
"DM-18394","Bug","ap_verify",1,"Crash when running ap_pipe on calexp templates","""Trying to call {{ap_pipe}} on {{ap_verify_hits2015}} with a calexp template crashes with an error. This appears to be caused by the change to {{ImageDifferenceTask.refObjLoader}} in DM-10242, and can be fixed by explicitly configuring {{config.differencer.refObjLoader}} in {{ApPipeTaskConfig}}. In hindsight, this means that we were previously testing calexp templates using a different reference catalog for {{ProcessCcdTask}} and {{ImageDifferenceTask}}!    Although this issue should never come up in {{ap_verify}} work (the loader subtask is created only if {{config.differencer.doSelectSources = True}}), we use modified versions of the dataset configs frequently enough that we should probably configure {{config.differencer.refObjLoader}} in {{ap_verify_hits2015}} and {{ap_verify_ci_hits2015}}. This will prevent unexpected crashes when other config parameters get overridden on the command line."""
"DM-18391","Story","ts_middleware",0,"scons should only build Test and Script libraries if running tests","""The current scons system builds the Test and Script libraries for almost all commands. It should only do so when running tests, and not cleaning."""
"DM-18389","Story","ts_middleware",2,"Understand what's going on with the EFD","""Understand what's going on with the EFD"""
"DM-18388","Story","ts_auxiliary_telescope",2,"Learn script queue","""Learn script queue. Review documentation:     https://confluence.lsstcorp.org/display/LTS/Running+the+script+queue+with+containers"""
"DM-18382","Story","ts_auxiliary_telescope",3,"Write an ATDomeTrajectory/ATDome/ATMCS integration script","""Write a script to test the integration of ATDomeTrajectory, ATDome and ATMCS. Put it in ts_standardscripts."""
"DM-18377","Story","ts_middleware",3,"Opensplice representative meeting","""Consult with Opensplice reps"""
"DM-18374","Story","ts_main_telescope",1,"Hexapod/Rotator documentation review","""Review the Hexapod/Rotator documentation received from MOOG."""
"DM-18371","Story","ts_management",2,"Confluence Doc stubs","""This task is to create stubs for all the CSC's. I will create the template pages that the relevent CSC developers need to populate. This will help get the ball rolling as to how our teams documentation needs to look like. """
"DM-18370","Story","ts_middleware",2,"OpenSplice Representative meeting","""This task will be to meet with the OpenSplice folks that will be meeting here from Tuesday to Thursday. I will attend all sessions. """
"DM-18424","Story","ts_middleware",1,"Remove heartbeat event from subsystem XML","""Once the blocking ticket is completed, the heartbeat event in all subsystem XMLs need to be removed."""
"DM-18421","Story","ts_auxiliary_telescope",1,"Add function set_summary_state","""Add a new function {{set_summary_state}} to {{ts_salobj}} that allows us to put a CSC into any valid summary state.    This will primarily be used to enable or disable CSCs but it may also be handy for changing configuration (by moving it to STANDBY, then the next desired state)."""
"DM-18418","Story","ts_middleware",1,"Read the EFD Related Documents ","""Review the EFD related documents and attend the related meetings."""
"DM-18409","Bug","SUIT",2,"Loading mask z-index is breaking natural stacking order of the components","""In TAP Search panel, loading masks for Spatial/Temporal area and Column Constraints area prevent user from selecting another schema or table, while loading mask is displayed.    If loading-mask css class did not set z-index, the components would be displayed correctly, and select drop-down would appear on top of the loading mask.    Whenever possible, we should avoid using z-index, so that our components are following the natural stacking order, described in the link below:    https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/Stacking_without_z-index"""
"DM-18406","Story","templates",5,"Add templatekit.yaml files to lsst/templates","""The purpose of this ticket is to implement {{templatekit.yaml}} files in the templates repository. These files customize and refine the experience of generating files and projects from Slack with tempatekit and templatebot. {{templatekit.yaml}} files are being concurrently designed in DM-18405."""
"DM-18451","Story","dax",1,"TAP: set schema_index in TAP_SCHEMA.schemas table","""In TAP_SCHEMA.schemas table, 'schema_index' is used to order schemas by importance.     Currently, gaiadr2 with non-existing table comes first, wise_00 comes last.    Please, set schema_index so that """"sdss_stripe82_01"""", """"wise_00"""", and """"tap_schema"""" come first, followed (if they need to be kept) by non-existing or dev. datasets. """
"DM-18440","Story","ts_middleware",2,"Document MySQL Cluster limitations + review MariaDB High Availability MaxScale","""Check MySQL Cluster limitations we are currently having and document them in confluence. As this task was shorter than expected I will investigate how MariaDB High Availability MaxScale works."""
"DM-18439","Story","ts_middleware",2,"Attend DDS workshop","""Remotely attend the DDS workshop."""
"DM-18438","Story","daf_butler",2,"Specify string lengths in PosixDatastoreRecords table","""We do not currently specify string lengths for DatabaseDict tables. Update the constructor used from PosixDatastore to include lengths for the fields.  This is done currently in code because the tables are dynamic and each datastore gets to name the table to use."""
"DM-18433","Technical task","ctrl_iip",3,"C++ code that uses yaml files needs to point at the new location for those files.","""The C++ code which loads config files (YAML and otherwise) needs to be modified to point at the locations to which the YAML has moved.      """
"DM-18430","Story","ts_middleware",2,"Attend the DDS Workshop","""Attend the DDS Workshop. The agenda is here:    [https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=LTS&title=Opensplice+Vendor+Visit]     """
"DM-18494","Story","ap_association",8,"Mimic the meas_base plugin system for use in ap_association, DiaObject summary metrics","""Currently all the summary statistics created in DM-18318 are haphazardly listed in a single function and run as a block. This ticket will make the summary statistics run configurable, expandable, etc. by mimicking the measurement plugin system implemented for the measurement tasks within meas_base."""
"DM-18490","Story","ap_verify|verify",2,"Move TimingMetricTask to verify","""Due to a misinterpretation of RFC-550, DM-16536 left {{TimingMetricTask}} in {{ap_verify}}.    Provisionally, this involves moving {{lsst.ap.verify.measurements.profiling.TimingMetricTask}} to {{lsst.verify.commonMetrics.TimingMetricTask}}, and updating documentation and tests accordingly."""
"DM-18488","Story","Third Party Software",1,"Update pyyaml to v5.x","""pyyaml 5.1 is out. Test it with the stack and use it if all tests pass. Includes some fixes that are needed for python3.7.  """
"DM-18484","Story","ts_qa",1,"Export the SAL generated HTML to the project webserver","""There is a need to automatically update the SAL HTML definition pages on the LSST project page, [https://project.lsst.org/ts/sal_objects/].  It would be good to have the Jenkins build publish these page, however there is an issue getting the data off the AWS hosted server.  This task covers the time it will take to investigate, propose and implement a solution."""
"DM-18483","Story","ts_middleware",2,"Attend DDS workshop - Rob","""Attend the DDS workshop."""
"DM-18456","Story","ts_auxiliary_telescope",2,"Test ATHexapod CSC at the summit","""Test ATHexapod CSC at the summit. Tests performed were:   * Execute the CSC and see if reponds to commands   * Check possible bugs and document them   * Create next tasks to have a working version for ATHexapod CSC"""
"DM-18454","Story","ts_auxiliary_telescope",2,"Test ATDome vendor interface ","""Test ATDome vendor interface, prior to going to the summit I will add a minimum set of test I will try at the summit.    All of these are done manually using the telnet interface, if unit testing is required can be discussed later.    Tests to perform:    * open/close shutters   ** main door *{color:#00875a}(DONE){color}*   ** dropout shutter *{color:#00875a}(DONE){color}*   ** synchronized *{color:#00875a}(DONE){color}*   * rotate to various positions{color:#00875a} *(Move just fine)*{color}   * phase wrap {color:#00875a}*(DONE)*{color}   ** (meaning go to 330 degrees, then go to 30 degrees... and it should only move 60 degrees)   * go to home position *{color:#00875a}(DONE){color}*   * open shutter then stop in the middle of the command {color:#00875a} *(DONE but not recorded as it was as expected)*{color}   * close shutter then stop in the middle of the command  *{color:#00875a}(DONE){color}*   * values out of range {color:#00875a}*(DONE)*{color}   * move commands while it is moving     *    ** dome shutter  *{color:#00875a}(DONE){color}*   ** azimuth{color:#00875a} *(DONE, it does the latest command)*{color}   * home command while it is moving {color:#00875a}*(DONE)*{color}   * emergency stop while it is moving {color:#00875a}*(DONE for shutter, same behavior as for the next test)*{color}   * emergency stop then move *{color:#00875a}(DONE for shutter){color}*   * Invalid commands *{color:#00875a}(DONE){color}*    All tests should be recorded in a text file exactly how I get responses from telnet"""
"DM-18453","Story","ts_middleware",2,"Deployment environtment for MySQL Cluster + CSC","""Work with [~avillalo] to deploy the MySQL Cluster + CSC to replicate some of the issues we've been experimenting:   * High memory usage"""
"DM-18452","Story","Qserv",8,"Backup Qserv data for GKE/Wise cluster","""Write a procedure to backup/restore all Qserv data for Qserv on GKE.  Data will be backup inside a Google storage bucket.  """
"DM-18509","Story","DM",8,"CADC meeting","""Discussions with CADC on a range of topics including TAP etc . and travel time"""
"DM-18508","Story","DM",2,"Kavli workshop telecon and doc update","""Chair telecon March 15 – prepare - updates to doc"""
"DM-18501","Story","ts_management",2,"ts_xml CSC overview table generator.","""This task is to get the CSC overview table automatically generated by the xml. It is also to add the different tags withing the SALGenerator.xml to have the values that we want it to have to be displayed on the table."""
"DM-18500","Story","ts_middleware|ts_qa",2,"Java Test scripts | part 2","""This is the second half effort that will capture the work for the Java. More details to be put after completing the first half. I imagine the first half will be getting my machine able to build the tasks and learning how the binding works."""
"DM-18514","Story","DM",2,"Prepare for AMCL ","""Prepare talk with Zeljko for AMCL on April 1.     """
"DM-18513","Story","ts_middleware",2,"Install the MySQL Cluster with Puppet on local machine","""Install the MySQL Cluster with Puppet on local machine in Tucson.    This is to be familiar with the baseline software setup. This task will also try to compare the MySQL Cluster and InfluxDB (NoSQL) and discuss with Andres.    The puppet script by Andres V. is here:    [https://github.com/avillalobos/lsst_devops]"""
"DM-18512","Story","ts_aos",2,"Realize the OFC Interface Classes to MTAOS in Phase 2","""Realize the OFC interface classes (in ts_ofc) to let the MTAOS to use. Chris and I discussed and defined the interface classes in the last sprint. I plan to realize them for Chris to be able to use with the real calculations instead of interface only. This is the phase 2 of task.    This task will focus on the algorithm verification (coordinate transformation) and functional units test of control interface classes."""
"DM-18511","Story","ts_aos",3,"Translate the OFC Code of LabVIEW to Python","""Translate the LabVIEW code (ts_tcs_ofc) related to the coordination transformation from ZEMAX to subsystems to Python code (ts_ofc, I renamed the ts_tcs_ofcPython to ts_ofc to fulfill the eups package name requirement). This is to translate the OFC calculated DOF in ZEMAX coordinate to the hexapod position and actuator forces in the subsystem's coordinate system."""
"DM-18529","Story","validate_drp",3,"Add unique parts of aggregated dataids to the job metadata","""Currently only the filter is passed through to the job metadata.  In some cases, there is additional metadata that can be passed on.  For example, some metrics are produced on a per tract basis.  A general way to do this is to create a dictionary that has just the entries that are common over the full list of data ids passed on to {{runOneFilter}} [here|https://github.com/lsst/validate_drp/blob/e350b0cd818a6640ea27be1ff037cf698d316a1b/python/lsst/validate/drp/validate.py#L293]."""
"DM-18527","Story","ts_auxiliary_telescope",1,"Write ""slew telescope"" script","""Write a initial version of the """"slew telescope script"""". """
"DM-18522","Story","ts_environment",1,"Initial test of DIMM CSC with vendor software. ","""Testing of the software integration between DIMM CSC and vendor provided software. """
"DM-18521","Story","ts_environment",1,"Integrate DIMM with vendor software. ","""We got updated information about the interface to the DIMM software. This task is to start integrating the software. """
"DM-18520","Story","ts_auxiliary_telescope",1,"ATPointing + ATAOS integration test","""Finalize ATAOS and ATPointing integration test"""
"DM-18542","Story","DM",1,"Provide JSR reposnses ","""Victor has sent the JSR response template - fill in DM part"""
"DM-18574","Bug","ts_calibration",1,"Electrometer CSC outputs incorrect URL for large file collection","""The electrometer outputs a large file which is collected for the LFA, however, the URL it's providing is incorrect. The directory and naming structure also appears odd (but is probably all the same bug).    the Electrometer file string being reported is:  `https://127.0.0.1/1-1553029665.151835`  whereas the proper string should be:  `http://10.0.100.133:8000/1-1553029665.151835.fits`    so http instead of https, wrong IP, missing port, missing """".fits"""" - files are being put in:  `/home/saluser/ts_electrometer2/electrometerFitsFiles/1` """
"DM-18573","Bug","pipe_analysis",1,"Fix bug for running on DC2 data introduced by DM-13202","""A minor bug was introduced in DM-13202 in that it assumed that """"ccd"""" is a valid dataId key.  This is not true for DC2 data."""
"DM-18557","Story","dax",2,"Column UCDs","""Bug:    sdss_stripe82_01.RunDeepSource has variance for 'ra' has wrong ucd: """"stat.variance;pos.eq"""" instead of """"stat.variance;pos.eq.ra""""         Possible improvement:    sdss_stripe82_01.DeepCoadd and sdss_stripe82_01.Science_Ccd_Exposure - there are 5 columns with ucd=""""pos.eq.ra"""" and 5 columns with ucd=""""pos.eq.dec"""". Center ra, decl cols can be marked with extra ucd word """"meta.main"""" if we'd like people to search on it. Then ra would have ucd=""""pos.eq.ra;meta.main"""" decl would have ucd=""""pos.eq.dec;meta.main"""".         In general, using meta.main is helpful, when there are several columns with the same ucd"""
"DM-18556","Story","pipe_analysis",8,"Adapt visit and coadd qa analysis scripts to run on DESC DC2 outputs","""This will concentrate on adapting the visit and coadd analysis scripts to run on DC2 data. The colorAnalysis script will be addressed on a separate ticket."""
"DM-18553","Story","obs_lsst",3,"Demonstrate WCS inconsistency with WFS chips in phosim","""It appears that phosim assumes the eimages it produces are always oriented in focal plane coordinates when it pastes on the rough WCS.  This is true of all science detectors, but appears not to be true for the wavefront sensors, which are rotated 90 deg in each subsequent corner raft.    This leads to a rough WCS that is wrong for the WFS chips.  See the following figure.  RA and Dec labeled as inferred from the attached WCS.  Red circles are the pixel positions from the phosim {{centroid.txt}} file.  The blue circles are the RA/Dec positions from the input file to phosim.  All circles are annotated with: object identifier, RA/x, Dec/y.    As you can see the relative positions of object 0 and object 1 are flipped in RA/Dec relative to x/y.  My interpretation is that this means the translation from RA/Dec to pupil coordinates in phosim and the ray tracing step are being done correctly.  I think the issue just comes from an incorrect assumption for {{CRPIX}} and possibly the {{CD}} matrix when computing the WCS.     !labeled.png!    P.S. It's possible the bulk offset is due purely to distortions in the optics that the simple WCS does not account for. """
"DM-18552","Improvement","ip_isr",1,"Support for new brighter-fatter kernels reverted","""DM-13293 created support for new-style brighter-fatter kernels, specifically in b14fc9a134e7937ea703f4b93a9a79429136d7b7.    It was easy back then to support both the new style kernel objects, and the old, HSC-style numpy arrays, as Subaru still had its own isrTask.    However, during the great ISR merge, this was no longer the case, and only the HSC-style kernels are now supported.    The change was reverted here:    https://github.com/lsst/ip_isr/commit/141792033a1ca1d5d97d72520d06508c51e9a28c#diff-3a9973baa2fe4526d09a95e405f90269L599    We need to be able to do both."""
"DM-18549","Story","ts_middleware",3,"Investigate OpenSpliceDDS native python api","""Prototype a SAL API based in the OpenSpliceDDS native python interface,  and add distribution to ts_opensplice for V6.9 community including the python  asserts pre-built"""
"DM-18548","Story","ts_auxiliary_telescope|ts_middleware",3,"Upgrade pLAN EFD","""Rebuild the pLAN EFD with the tables corresponding to tag 3.8.41  and prepare RPM's for switch to 3.9.0. Install OpenSplice debug tools"""
"DM-18547","Story","ts_main_telescope",8,"M1M3 Thermal FPGA Development Part 1","""Start development of the thermal system FPGA."""
"DM-18589","Improvement","ts_auxiliary_telescope",2,"Improve queue behavior when script fails to load.","""The queue is not properly reporting when a script fails to load. For instance, following an import or syntax error… I think we need to monitor the result of the script execution and take appropriate measurements… Specially right after loading it…    Ideally it would be nice if the add command is rejected if the script is not able to load at all, but I understand it is hard to identify load errors from different type of errors. So I guess, the queue must be able to check the execution returned value and would be good to get some traceback information.   """
"DM-18588","Story","Notebooks",2,"Create stub pip package to test installation on nublado","""We have a test case, LVV-T768, that tries to verify that code is installable in the nublado system.  I would like a stub pip package that we control that is essentially a no op (maybe it prints some amusing message).  The name will be {{sqre-pip_install_test}}."""
"DM-18582","Bug","ts_auxiliary_telescope",0,"A few ts_scriptqueue tests fail with recent ts_salobj","""[~tribeiro]'s lsst/queue:ospl6.9-sal3.9 Docker container dated 2019-03-21 causes a few ts_scriptqueue tests to fail: timing out when waiting for a process to terminate. I have also seen this in ts_salobj and fixed that as part of DM-18344.    It appears that SAL components run as subprocesses take longer to exit than they used to, so a longer timeout is required."""
"DM-18581","Story","DM Subsystem Science",1,"Write meeting abstract and description for AMCL","""Provide abstract for the AMCL meeting """
"DM-18576","Story","astro_metadata_translator",1,"Issue warnings if translator methods are shadowed","""Shadowing can happen if you add en explicit translator method and forget to remove it from the constant or trivial mappings list. Check for this scenario and warn.  Also check that const/trivial methods are not being inherited from a parent and overriding the versions defined in the current class."""
"DM-18605","Bug","Developer Infrastructure",2,"TSS Jenkins Executor offline","""The TSS Jenkins executor has hit the 50 gig alert limit again and has gone offline."""
"DM-18601","Story","Third Party Software",2,"Investigate newer SQLAlchemy versions","""With the merge of DM-18367 we are getting many DeprecationWarnings from sqlalchemy when running the test in daf_butler (about 85 of them).  This seems to be down to some new code paths being used from within sqlalchemy.    We are currently running 1.2.16.  On this ticket I will see if 1.2.18 gets rid of the warnings and possibly try the new 1.3 series.    The current warning comes during schema creation:  """
"DM-18598","Epic","ts_auxiliary_telescope|ts_calibration|ts_qa",5,"Testing of Electrometer (AuxTel) SW","""Testing of Electrometer (AuxTel) SW"""
"DM-18596","Story","ts_main_telescope",2,"Run Laser Stabilization test for TunableLaser","""As part of Nick's visit, he discovered that the laser suffers an unknown power degregation by 10 percent that appears to correspond with one of the temperature registers starting to run hot.     The vendor has asked us to run the test with a data dump from the laser before and after the test."""
"DM-18592","Story","ts_middleware",1,"Add standard tests to ts_salobj for use by other packages","""Several CSC test are repeated in most packages that use ts_salobj, including:  * Check standard summary state transition commands  * Check that the bin.src script that runs the CSC works    Write these tests in ts_salobj in a way that they can be used by other packages, e.g. by providing a base class for CSC unit tests.    Also add documentation with suggestions for how to test CSCs, SAL components and Scripts.    Also convert at least one other package to make sure the new code is usable."""
"DM-18624","Story","afw",2,"speed up Table pickling","""With Schema pickleable (DM-17950), I can now use ProcessPools to parallelize reading data. But pickle/unpickle of SourceCatalogs seems to be preventing that from actually providing a speed boost. I've found at least one obvious place to gain a big chunk of speed. I'll spend a little more time looking for others."""
"DM-18621","Story","atmospec|obs_base|obs_lsst",5,"`Too many CR pixels (max 500000)` when running `constructDark.py` on auxTel dark","""When running `constructDark.py` on an auxtel dark (2019030800135, see below), the following error appears:          lsst::pex::exceptions::LengthError: 'Too many CR pixels (max 500000)'         Visual inspection of     """"AT_O_20190308_000135-ats-wfs_ccd.fits"""" (see directory below) shows that there are not as many CR's.    -Data (see IMGTYPE in headers for types, which follows the entry in [https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=SYSENG&title=LogBook+for+AuxTel+camera+diagnostic+data+taking] under MAR08, 2019):     /project/plazas/data/auxtel_DMCS_images_2019-03-08/cal    -ID:     WARN: Unable to process DataId(initialdata=\{'imageType': 'DARK', 'dayObs': '2019-03-08', 'visit': 2019030800135, 'detector': 0, 'detectorName': 'S00'}    -Command run:    * constructDark.py /project/plazas/calibrations_auxtel_mar20_REPO --calib /project/plazas/calibrations_auxtel_mar20_CALIB/ --output /project/plazas/calibrations_auxtel_mar20_OUTPUT/ --id imageType='DARK' --batch-type none --clobber-config    stack: """"w_2019_11"""" with branch """"tickets/DM-18051"""" of """"obs_lsst"""""""
"DM-18618","Story","Continuous Integration|Developer Infrastructure",1,"jenkins 2019-03-25 security advisory","""[https://jenkins.io/security/advisory/2019-03-25/]"""
"DM-18611","Story","ts_middleware",2,"Update LSE-229","""This task covers the time needed to update LSE-229.  It is a draft document covering the middleware communication design."""
"DM-18610","Story","afw",40,"Add fields, limited mutability, and trim/assembly-state tracking to cameraGeom","""Add additional functionality to cameraGeom to reflect use cases identified in obs_lsst, while bringing obs_lsst usage in line with the intent of the cameraGeom design.  This includes:   * Add additional amplifier/detector fields for flips in pre-raw to raw transmission.   * Add accessor to get (computed) raw readout corner.   * Rename methods that always reflect assembled state to make this explicit in the names; deprecate the old names.   * Add new fields that track the trim/assembly state.   * Add new accessors for bounding boxes and readout corner that utilize trim/assembly state.   * Add setters for all fields, along with runtime freezing: only frozen Detectors can be added to an Exposure, but an unfrozen Detector can be obtained by copying a frozen Detector.    At least some of these changes are API changes and will need an RFC.  I'd like to prototype them out on this ticket branch first."""
"DM-18638","Story","validate_drp",1,"Check for at least 2 visits in AMx metric calculation.","""Running `matchedVisitMetrics`for DM-17830 was yielding AM1 of 0 for HSC WIDE tracts 9615 and 9697 which have visits numbers in the single digits. AM1 is the median of the RMS of the distances between 2 stars in N visits. Closer inspection revealed that more than half of the RMSs were exactly zero, which is why the median was exactly zero.  [~wmwood-vasey] quickly found the problem which was that if a pair appeared in exactly one visit, the stdev([one distance]) was exactly 0  and not NaN.    Require at least 2 distances before computing their stdev.    [~wmwood-vasey] will investigate the potential bias is in the median RMS as a function of N.    This change will increase our reported AMx reported in squash."""
"DM-18671","Story","ts_middleware",1,"Add ts_sal unit tests for DM-18491 and DM-18637","""Add ts_sal unit tests to test DM-18491 current time issues and DM-18637 get newest topic after get oldest does not always return the most recent value."""
"DM-18667","Story","display_firefly|SUIT",3,"Add support to display_firefly for obtaining and passing along an authorization token for Firefly","""Based on the API support for authentication tokens to be added to {{firefly_client}} under DM-18666, this ticket asks that {{display_firefly}} be modified to support both:  * manually supplying an authorization token for Firefly when the display object is created, and  * automatically picking up an appropriate token from a TBD mechanism in the Python process environment established by the Notebook Aspect (e.g., this may be from an environment variable with an agreed-upon name, or from a dot-file).    The second subtask requires, of course, that the """"TBD mechanism"""" has been defined.  This will require work on the Notebook Aspect / Nublado as well.    In each case, the token should then be passed down to the underlying {{firefly_client}} object.    Care must be taken to be aware the different servers that might be used and to respect overrides that may be in place.  The """"second subtask"""", it-just-works, method is initially only required to work for whatever the active LSP-instance default Firefly server is (including any system-configured overrides to that).  If the _user_ wishes to use a different server, s/he may be required to supply an appropriate token manually."""
"DM-18656","Bug","ctrl_iip",1,"Version 5.1 of PyYAML breaks DMCS if safe_load() is used","""An upgrade to PyYAML 5.1 now gives a warning on using the yaml.load() method.   Switching to yaml.safe_load() causes the DMCS to fail with the following:      {code:python}  [srp@lsst-l1-cl-dmcs iip]$ python DMCS.py  Extracting values from Config dictionary L1SystemCfg.yaml  Logs will be written to /tmp/DMCS.log  CONSUMER THREADS: amqp://DMCS:DMCS@141.142.238.10:5672/%2ftest_at_srp  DMCS seems to be working  In On OCS Msg, msg is: {'ACK_ID': 'START_INT_ACK_76', 'IMAGES_IN_SEQUENCE': '3', 'IMAGE_ID': 'AT_C_20181111_000602', 'IMAGE_INDEX': '2', 'IMAGE_SEQUENCE_NAME': 'MAIN', 'MSG_TYPE': 'DMCS_AT_START_INTEGRATION', 'REPLY_QUEUE': 'dmcs_ack_consume'}  Processing message in OCS message callback  Message and properties from DMCS callback message body is: %s (""""{'ACK_ID': 'START_INT_ACK_76', 'IMAGES_IN_SEQUENCE': '3', 'IMAGE_ID': 'AT_C_20181111_000602', 'IMAGE_INDEX': '2', 'IMAGE_SEQUENCE_NAME': 'MAIN', 'MSG_TYPE': 'DMCS_AT_START_INTEGRATION', 'REPLY_QUEUE': 'dmcs_ack_consume'}"""", <BasicProperties>)  enabled is set to: False  In On OCS Msg, msg is: {'ACK_ID': 'READOUT_ACK_77', 'IMAGES_IN_SEQUENCE': '3', 'IMAGE_ID': 'AT_C_20181111_000602', 'IMAGE_INDEX': '2', 'IMAGE_SEQUENCE_NAME': 'MAIN', 'MSG_TYPE': 'DMCS_AT_END_READOUT', 'RESPONSE_QUEUE': 'dmcs_ack_consume'}  Processing message in OCS message callback  Message and properties from DMCS callback message body is: %s (""""{'ACK_ID': 'READOUT_ACK_77', 'IMAGES_IN_SEQUENCE': '3', 'IMAGE_ID': 'AT_C_20181111_000602', 'IMAGE_INDEX': '2', 'IMAGE_SEQUENCE_NAME': 'MAIN', 'MSG_TYPE': 'DMCS_AT_END_READOUT', 'RESPONSE_QUEUE': 'dmcs_ack_consume'}"""", <BasicProperties>)  In INCR scbd, new ack_id is AT_END_READOUT_ACK_001542  Exception in thread Thread-dmcs_ack_consume:  Traceback (most recent call last):    File """"/usr/lib64/python3.6/threading.py"""", line 916, in _bootstrap_inner      self.run()    File """"/home/srp/dev/ctrl_iip/python/lsst/ctrl/iip/Consumer.py"""", line 365, in run      self._connection.ioloop.start()    File """"/usr/local/lib/python3.6/site-packages/pika/adapters/select_connection.py"""", line 461, in start      self._poller.start()    File """"/usr/local/lib/python3.6/site-packages/pika/adapters/select_connection.py"""", line 721, in start      self.poll()    File """"/usr/local/lib/python3.6/site-packages/pika/adapters/select_connection.py"""", line 1114, in poll      self._dispatch_fd_events(fd_event_map)    File """"/usr/local/lib/python3.6/site-packages/pika/adapters/select_connection.py"""", line 831, in _dispatch_fd_events      handler(fileno, events)    File """"/usr/local/lib/python3.6/site-packages/pika/adapters/base_connection.py"""", line 410, in _handle_events      self._handle_read()    File """"/usr/local/lib/python3.6/site-packages/pika/adapters/base_connection.py"""", line 464, in _handle_read      self._on_data_available(data)    File """"/usr/local/lib/python3.6/site-packages/pika/connection.py"""", line 2041, in _on_data_available      self._process_frame(frame_value)    File """"/usr/local/lib/python3.6/site-packages/pika/connection.py"""", line 2175, in _process_frame      self._deliver_frame_to_channel(frame_value)    File """"/usr/local/lib/python3.6/site-packages/pika/connection.py"""", line 1568, in _deliver_frame_to_channel      self._channels[value.channel_number]._handle_content_frame(value)    File """"/usr/local/lib/python3.6/site-packages/pika/channel.py"""", line 996, in _handle_content_frame      self._on_deliver(*response)    File """"/usr/local/lib/python3.6/site-packages/pika/channel.py"""", line 1125, in _on_deliver      header_frame.properties, body)    File """"/home/srp/dev/ctrl_iip/python/lsst/ctrl/iip/YamlHandler.py"""", line 39, in yaml_callback      pydict = self.decode_message(body)    File """"/home/srp/dev/ctrl_iip/python/lsst/ctrl/iip/YamlHandler.py"""", line 50, in decode_message      tmpdict = yaml.safe_load(body)    File """"/usr/local/lib64/python3.6/site-packages/yaml/__init__.py"""", line 162, in safe_load      return load(stream, SafeLoader)    File """"/usr/local/lib64/python3.6/site-packages/yaml/__init__.py"""", line 114, in load      return loader.get_single_data()    File """"/usr/local/lib64/python3.6/site-packages/yaml/constructor.py"""", line 43, in get_single_data      return self.construct_document(node)    File """"/usr/local/lib64/python3.6/site-packages/yaml/constructor.py"""", line 52, in construct_document      for dummy in generator:    File """"/usr/local/lib64/python3.6/site-packages/yaml/constructor.py"""", line 404, in construct_yaml_map      value = self.construct_mapping(node)    File """"/usr/local/lib64/python3.6/site-packages/yaml/constructor.py"""", line 210, in construct_mapping      return super().construct_mapping(node, deep=deep)    File """"/usr/local/lib64/python3.6/site-packages/yaml/constructor.py"""", line 135, in construct_mapping      value = self.construct_object(value_node, deep=deep)    File """"/usr/local/lib64/python3.6/site-packages/yaml/constructor.py"""", line 92, in construct_object      data = constructor(self, node)    File """"/usr/local/lib64/python3.6/site-packages/yaml/constructor.py"""", line 420, in construct_undefined      node.start_mark)  yaml.constructor.ConstructorError: could not determine a constructor for the tag 'tag:yaml.org,2002:python/object/apply:datetime.time'    in """"<byte string>"""", line 2, column 14:      EXPIRY_TIME: !!python/object/apply:datetime.time  {code}  """
"DM-18655","Story","ts_auxiliary_telescope",1,"Improve Electrometer documentation in the XML","""    Improve Electrometer documentation in the XML"""
"DM-18642","Story","ts_auxiliary_telescope",2,"Fix ATHexpod CSC bugs","""Fix ATHexapod bugs, this includes:   * Update motion detection to use in-built queries inside the PI controller properly  {color:#00875a}*(DONE by waiting until is ready for next command after doing any motion)*{color}   * Define pivot setup at the start properly. The pivot cannot be configure if the hexapod is in an angle, so trying to configure when starting if the hexapod was left with an angle different to 0, will fail the start command. Need to be discussed with Patrick. *{color:#00875a}(DONE by removing Pivot from settings){color}*   * Prior to executing command, check if the controller is ready to receive command, if not wait until ready (with a certain timeout)  *{color:#00875a}(DONE by waiting until is ready for next command after doing any motion){color}*   * Fix initialization, current initialization fails due that it takes some time to reference the hexapod at the start. If we don't initialize the Hexapod and there's no reference due to reference lost (lost of power), we won't be able to command it.Need to be discussed with Patrick. {color:#00875a} *(DONE by waiting until is ready for next command after doing any motion)*{color}"""
"DM-18703","Bug","ip_isr",1,"constructFlat.py --config isr.doCrosstalkBeforeAssemble=False raises a LengthError exception","""Here's a full command line that produces the error:    and the last several lines of the traceback (full log attached):  """
"DM-18690","Story","Firefly|SUIT",8,"Implement maximum record limit in TAP query screens in Firefly","""04/03/2019    [https://github.com/Caltech-IPAC/firefly/pull/783]    """"Row Limit"""" field is displayed at the bottom of the TAP Search, along with """"Search"""" and """"Cancel"""" buttons. It is propagated to the server and is translated into MAXREC parameter of the search request. We allow to disable it by clearing.    tap.maxrec.hardlimit property (default 10000000) is a config property. If MAXREC is set, it can not exceed this value.  defaultMaxrec is an application property (default 50000 for Firefly). It is the default value for MAXREC parameter.    Other changes:   * Filters are now shown by default in the TAP result tables   * Removed 'tables.showInfoButton' app property and made it a table option instead.   * Fixed Service URL select box style: the text was truncated a bit on the bottom and selected item was shown in white, which was hard to see on light green.    03/28/2019    In the Firefly TAP search UI, we need a way to specify an upper limit on the size of the query result.    This limit should be independent of any """"TOP (nnn)"""" clause that may be included in the user's ADQL query text. If both are present, the desired effect is that the smaller of the two limits will determine the size of the query result.    After extensive discussion in the IPAC LSST group, we propose to put the UI element for this limit in the """"grey bar"""" at the bottom of the TAP search screens in which the """"Search"""" and """"Cancel"""" buttons already appear. The UI element must appear in both """"single table"""" mode and in the type-my-own-ADQL mode, and _should be in exactly the same location in the grey bar_ so that it does not """"move"""" when changing modes. (This emphasizes that it is a global property of TAP searches via Firefly.)    The UI element should allow the user to type in a non-negative integer (yes, I think 0 should be allowed - see the IVOA standards' discussion of {{MAXREC=0}} for the reason), as well as to select suggested numbers from a menu. The menu must always contain at least one entry: a """"hard limit"""" that cannot be exceeded even by typing. The value here should be the lesser of a """"Firefly hard limit"""" (which should be a Firefly application-level configuration parameter) designed to preserve correct, if perhaps sluggish, performance, and any TAP-service-specific hard record limit (which might, for instance, have been returned from a {{.../capabilities}} endpoint query or from the Registry).    The native Firefly hard limit on a good-sized server with the current implementation might be somewhere in the 2M-5M range.    A _default_ value should also be provided in the menu, and pre-selected in a new search session. This should also be controlled by a configuration parameter so that it can be application-specific, and this should be coded so that it can be overridden by a number obtained from the Registry. (A {{defaultMaxRecords}} parameter does exist.) A number like 5000 may be appropriate here.    *This ticket does not ask for the work of actually querying the Registry or the {{.../capabilities}} endpoint.* The work on this ticket is only intended to _facilitate_ adding those features at a later date.    The above describes the *UI*.    The *implementation* should ultimately be based on the use of the {{MAXREC}} DALI parameter to the underlying TAP service. However, we first need to determine whether LSST's TAP service supports this (and check IRSA and NED as well). It may be that we need a fallback to editing the ADQL query to add, or, if necessary, modify a user-provided {{TOP (nnn)}} clause."""
"DM-18689","Story","scisql",0.5,"Fix scisql build with Python 3.7","""Environment update to Python 3.7 seems to have busted the scisql build.  The problem seems to be an incompato in the """"waf"""" build too used by scisql.  The waf project has already implemented a fix; this needs to be tested with scisql and upstreamed there if it addresses the build issue."""
"DM-18686","Bug","ctrl_iip",1,"represent time properly throughout ctrl_iip python code","""While debugging something, I saw a date being constructed in the DMCS add_seconds method did this:    {code:python}      def add_seconds(self, intime, secs):          basetime = datetime.datetime(100, 1, 1, intime.hour, intime.minute, intime.second)          newtime = basetime + datetime.timedelta(seconds=secs)          return newtime.time()  {code}    (Day is set to Jan 1, year 100).    Which it shouldn't do.  A survey throughout this code must be done to fix things like this and represent time in a consistent manner."""
"DM-18685","Bug","ctrl_iip",0.5,"Change all yaml.load() instances to yaml.safe_load()","""There are a number of yaml.load() invocations that need to be changed to yaml.safe_load().  This may require a fix similar to what was implemented in YamlHandler.py, for DM-18656."""
"DM-18683","Improvement","cp_pipe",40,"Review Craig's PR and merge","""[~cslage] has submitted a PR here:    https://github.com/lsst/cp_pipe/pull/10/    I will make any changes necessary to bring this to comply with DM standards (effectively doing a """"review"""" but in the more efficient way where I just make the changes - quicker for both parties here). I will then check with Craig that I haven't ruined his work, and merge.    [~swinbank] has blessed this model.    """
"DM-18678","Story","Third Party Software",2,"Update to boost 1.69","""Clang version 10.0.1 (clang-1001.0.46.3) on macOS Mojave can not build boost 1.68.  v1.69 looks to have some fixes for the problem so we need to upgrade (Jenkins currently uses an older clang so may not have the problem since we know 1.68 builds fine with version 10.0.0 (clang-1000.10.44.4))."""
"DM-18677","Story","ts_auxiliary_telescope",2,"Test ATHexapod CSC fixed at the summit","""Test ATHexapod CSC fixes from at the summit. Fixed should be done in: https://jira.lsstcorp.org/browse/DM-18642"""
"DM-18676","Story","ts_auxiliary_telescope",3,"Finish first release for electrometer","""    Clean up Electrometer python code and add limits when applies (for example integration time should be limited). Also create a docker image for deployment.    Update:    * Configuration to use the API from salobj   * update intensity in events to """"CurrentValue"""" or """"Measurement"""" according to Patricks comments in [https://github.com/lsst-ts/ts_xml/pull/83#discussion-diff-279486587R15]"""
"DM-18675","Story","ts_auxiliary_telescope",1,"Improve Electrometer documentation inside python","""     Improve Electrometer documentation inside python"""
"DM-18674","Story","ts_auxiliary_telescope|ts_calibration",3,"Re-package Electrometer","""This task is to re-package electrometer to follow new standards and make it work with dm-stack (and Tiagos Docker image)."""
"DM-18743","Improvement","Qserv",2,"Improve tracking of the asynchronous operations (jobs/requests) in the Replication System","""The following pattern is often seen in the current implementation of the Replication system:    And while it has its own benefits (such as implementing a periodic heartbeat reports on the operations, or an ability to cancel long operations after a certain timeout which might be shorter than the one the asynchronous activity would normally last for), the pattern suffers from certain problems:  * the same code appear in multiple (a few dozens as of today) locations  * it requires making non-obvious choices on the duration of intervals in the BlockPost class's constructor.    Hence a goal of this effort is to implement a more efficient method for synchronizing threads with the asynchronous operations of the *Request* and *Job* classes.    Further details on this subject, including in-depth analysis of the proposals, and the final choice can be found at the following document:  * https://confluence.lsstcorp.org/pages/viewpage.action?pageId=102471961"""
"DM-18738","Epic","ts_ait|ts_main_telescope",5,"Support for Camera Hexapod installation and test with CCW","""Support for Camera Hexapod installation and test on TMA     Corresponding P6 Activity:   * T&SC-140403-1700   ** M2 Hexapod installation and test on TMA         CCW: Camera Cable Wrap."""
"DM-18737","Epic","ts_main_telescope",5,"Support for M2 Hexapod System Ready for Integration","""Support for M2 Hexapod System Ready for Integration         Corresponding P6 Activity:   * T&SC-140403-1300   ** M2 Hexapod System Ready for Integration"""
"DM-18731","Story","ts_middleware",1,"Configure MariaDB + efdwriters and Influx + efdwriters in La Serena","""Configure MariaDB + efdwriters and Influx + efdwriters in La Serena and run MTM1M3 simulator for testing """
"DM-18730","Story","ts_aos",3,"Research the InfluxDB and Kafka","""Do the research of InfluxDB and Kafka and learn how to use them. This is based on the discussion of EFD meeting:    [https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=LTS&title=2019-03-29+EFD+Meeting+notes]     """
"DM-18729","Story","ts_aos",1,"Use the Yaml Configuration File Format Phase 1","""Use the yaml configuration file format phase 1. This task will use the yaml to manage the configuration files. This task is the phase 1."""
"DM-18726","Story","Qserv",0.5,"Fix Qserv container builds","""Qserv container builds seem to be now picking up binary tarballs, which is causing a shebang lossage with {{pytest}} when {{eups distrib}} tries to build the {{db}} package.    Proposed fix is to first install {{pytest}}, then run {{shebangatron}}, then install {{qserv}}."""
"DM-18723","Epic","ts_ait|ts_main_telescope",5,"Support M2 mirror coating chamber activity","""Support M2 mirror coating chamber activity in Chile"""
"DM-18708","Story","obs_lsst",1,"Investigate ingest problems with BOT data","""There have been reports of some issues with ingest of BOT flat field data. [~tjohnson] has given me a file to use for the investigation."""
"DM-18744","Story","meas_deblender",2,"Create presentation for DESC BTF","""Write my portion of presentation on the LSST deblender for the April 1st DESC Blending Task Force meeting. This will describe the work to use a new normalization scheme, choosing the proper PSF model, issues with PSF convolution in HSC and (likely) LSST, and the new architecture."""
"DM-18839","Story","daf_butler",8,"Remove explicit registry close in the butler","""In working with oracle, exceptions were being thrown related to connections not being closed properly, leading to the addition of the __del__ method in the butler to make sure the connections were properly cleaned up in registry held by the butler.    This however had the side effect of creating an exception when a butler was used in a single threaded way. The temporary solution to that was to add an explicit close method to the butler to make sure everything was finalized before garbage collection (as __del__ is not predicable in the timing or ordering when it is evoked.    This ticket will explore why this is all necessary, and address what is causing the unexpected behavior. """
"DM-18838","Story","daf_butler",1,"Fix butlerRoot in OracleRegistry","""The butlerRoot change missed a file in the Oracle registry, this fixes that."""
"DM-18781","Story","Continuous Integration",1,"Mojave on jenkins are failing to find pip","""The mojave builds are failing with the following error:  {quote}  + pip install virtualenv  /Users/square/j/ws/release/tarball/osx/10.9/clang-1000.10.44.4/miniconda3-4.5.12-1172c30_tmp/durable-67d1fe51/script.sh: line 3: pip: command not found  script returned exit code 127  {quote}    An example failing build is [here|https://ci.lsst.codes/blue/organizations/jenkins/release%2Ftarball/detail/tarball/4040/pipeline/].  Which is calling code [here|https://github.com/lsst-sqre/jenkins-dm-jobs/blob/fd5ab2e1c2b73eb8ec08550bf7e9bcfa125154a3/pipelines/release/tarball.groovy#L610]"""
"DM-18754","Story","Continuous Integration",1,"macOS Jenkins nodes need to change default matplotlib backend","""The nightly failed because macOS mojave does not interact well with the JSON loading test of validate_drp.  Some of the plotting tests result in a segv with the TkAgg matplotlib backend (some strange interaction with tkinter and macOS).  The fix is to add {{~/matplotlib/matplotlibrc}} to the worker nodes and have a line in that file saying {{backend : Agg}}."""
"DM-18753","Story","ts_auxiliary_telescope",2,"Deploy docker containers for key auxtel simulators","""Using Tiago's docker container method, deploy key Auxiliary Telescope simulator containers down in lab. """
"DM-18750","Improvement","ts_auxiliary_telescope",1,"Make ScriptQueue automatically find standard and external script directories","""Enhance ScriptQueue to find the standard and external script directories if those constructor arguments are None, make None the default, and make the command line arguments optional.    The default values will be given by environment variables {{TS_STANDARDSSCRIPTS_DIR}} and {{TS_EXTERNALSCRIPTS_DIR}}. If one uses eups then these will be automatically defined. For deployment one must either explicitly define these or provide the information on the command line."""
"DM-18749","Improvement","obs_lsst",8,"Create defects file for the AuxTel sensor","""Deliverable is the defects for the AuxTel sensor in the right format for it to be applied by ISR.    This work follows from some work being done by [~plazas] on TS8 data, so shouldn't be too hard to run that code, but the output will need putting into the right format for ISR application. See {{obs_subaru}} for details on how this is currently done (I think an ASCII file is parsed at scons-time and turned into a FITS file which is then retrieve by the butler, but _not_ via the calib registry, but I could be wrong)."""
"DM-18748","Bug","obs_lsst",3,"Missing ExpTime in auxTel teststand images cause ingestImages.py to abort","""3 auxtel teststand images from 03/29/2019 failed to ingest with the following output:              """
"DM-18864","Story","afw",1,"Update afw to support undefined values in FITS headers","""DM-9873 added support for {{None}} to be added to PropertyList. Update afw FITS reading to support undefined values."""
"DM-18863","Story","daf_butler",2,"Investigate and fix warnings in daf_butler","""Changes to daf_butler introduced some behavior that cause sqlalchemy deprecation warnings to be thrown. This ticket will find out why they are being thrown and attempt to fix our code or prevent the warnings from being thrown."""
"DM-18861","Improvement","ts_auxiliary_telescope",1,"Enhance ""how to write a SAL script"" documentation","""Improve the """"how to write a SAL script"""" documentation to add clarity and fix glitches."""
"DM-18860","Improvement","ts_auxiliary_telescope",2,"Update ATDome to be configured in the standard way","""Make ATDome configurable in the standard fashion:  * Update ATDome to inherit from {{salobj.ConfigurableCsc}}  * Add a schema  * Add an ATDome directory to {{ts_config_attcs}}."""
"DM-18855","Story","pex_exceptions",1,"Pex exceptions TypeError should not inherit from RuntimeError","""In working on DM-9873 I was getting confusing test failures because sometimes a pex_exceptions C++ TypeError was turning up in Python as a RuntimeError.  It transpires that DM-9435 changed the C++ side such that TypeError inherits from LogicError but did not change the Python interface wrapper.  This ticket will change the Python side to inherit from LogicError rather than RuntimeError."""
"DM-18851","Story","ts_hardware|ts_middleware",1,"Spec and create requisition for phase 2 EFD hardware","""Specify the configuration and price the phase 2 EFD servers, then   create a requisition for their purchase. Separately spec the add-ons  (nVME, SSD, HD)"""
"DM-18849","Improvement","cp_pipe|obs_subaru",8,"Make crosstalk coefficient calculation code in obs_subaru generic","""Take the code in https://github.com/lsst/obs_subaru/blob/master/python/lsst/obs/subaru/crosstalk.py and:    * Make it camera-agnostic  * Make it comply with coding standards  * Put it in {{cp_pipe}} (the old code can be removed later, so this needn't be considered a _move_, it's just a new cp_pipe task for now)    Then, use this task and some darks from the AuxTel chip to calc xtalk coefficients for DM-18050.    If it looks like the code if specifically for working with darks then the task should be named as such. If it looks like it will be sufficiently generic to work with saturated stars/CBP exposures then it should have a more generic name.    Output should be a written with a {{butler.put()}} with an appropriate dataset type defined in {{obs_base datasets.yaml}}."""
"DM-18847","Story","ts_dome|ts_main_telescope",5,"MTDome SW Planning Meetings at Vendor Site (EIE-Italy)","""MTDome SW Planning Meetings at Vendor Site (EIE-Italy)"""
"DM-18846","Story","ts_dome|ts_main_telescope",5,"MTDome SW Planning Meetings at Vendor Site (EIE-Italy)","""MTDome SW Planning Meetings at Vendor Site (EIE-Italy)"""
"DM-18842","Story","ts_middleware",2,"Install SAL 3.9 built EFD writers to test pLAN machine","""Build the EFD writers against SAL 3.9 and deploy to a test machine on the pLAN  cluster to evaluate compatibility issues"""
"DM-18841","Story","ts_middleware",3,"Install InfluxDB and writers to EFD test machine","""Install  and test the EFD writers for Influxdb built against the latest OpenSplice"""
"DM-18840","Story","ts_middleware",1,"Test Kafka with M1M3 simulator data","""Test the performance of writing the EFD data to the Kafka brokers  provided by the DM test setup, use the M1M3 simulator to generate the maximum  data rate"""
"DM-18881","Story","Science Platform",1,"Provide Bob Blum with an LSP account","""See triggering ticket for discussion."""
"DM-18875","Bug","ctrl_iip",2,"test upgrades of out-of-date python support packages for ctrl_iip","""Pika is very out of date, with the release we're using, 0.11.2, out in November 30, 2017.  There have been nine releases since then, and the most current version is 1.0.0, released on March 27th, 2019.         Usually this wouldn't be a big deal, but there are constructor and method signature changes between these releases, so we have to go through and get the code changed.   This is going to have to be tested on a separate system that we're using now.      Deploying this when it goes live is going to have to be a staged deployment, since we have to make sure all the machines we are deploying to will have the current version of ctrl_iip that supports it."""
"DM-18874","Bug","ctrl_iip",0,"Multiple threads use single Pika publisher","""ATArchiver (and possibly other code) uses multiple threads to service consumer callbacks, but they all share a single publisher.  Pika specifically warns against doing this.       {quote}  Is Pika thread safe?    Pika does not have any notion of threading in the code. If you want to use Pika with threading, make sure you have a Pika connection per thread, created in that thread. It is not safe to share one Pika connection across threads, with one exception: you may call the connection method add_callback_threadsafe from another thread to schedule a callback within an active pika connection.  {quote}  """
"DM-18869","Story","ts_main_telescope",5,"LabVIEW Training","""Time spent going to Labview training. """
"DM-18887","Story","Developer Infrastructure",0.5,"Add privileges to the T&S S3 role","""The T&S group would like some added privileges for their S3 bucket credentials.  Specifically, they would like to execute {{aws s3 website s3://sal-topic-registry --index-document index.html}}.  This is so they can serve things directly from the buckets.    They would also like delete privileges."""
"DM-18885","Story","jointcal",0.5,"Log number of MeasuredStars in Associations","""Looking at the recent log from the failed 300 visit jointcal run by [~ikedahr], I noticed that I don't appear to ever log the total number of MeasuredStars in jointcal. This is an important number to help estimate memory pressure.    It's probably simplest to count and log it at the end of {{Associations::selectFittedStars()}}."""
"DM-18906","Bug","verify",1,"Use safe YAML loading in verify","""{{verify}} produces some warning messages about use of the unsafe and now-deprecated {{yaml.load}}. Please update the code as described on [Community|https://community.lsst.org/t/update-of-pyyaml/3631]."""
"DM-18905","Bug","dax_ppdb",1,"Use safe YAML loading in dax_ppdb","""{{dax_ppdb}} produces some warning messages about use of the unsafe and now-deprecated {{yaml.load}}. Please update the code as described on [Community|https://community.lsst.org/t/update-of-pyyaml/3631]."""
"DM-18895","Story","jointcal",1,"Use std::ptrdiff_t as index type in jointcal Eigen objects","""[~price] noticed that the use of {{unsigned}} (== uint32, usually) as the index type for Eigen matrices in jointcal _might_ be a problem:   * Eigen docs appear to want a signed integer;   * our number of sources in some of our processing is approaching 2^31.    There's no hard evidence that this is what's causing the segfault we're seeing when processing the (larger, still-proprietary) HSC UltraDeep, and since {{unsigned}} should be able to handle 2^32, I'm personally skeptical that this is the problem.  But it should be easy to fix, and a good thing to do regardless, especially for the first reason.    {{std::ptrdiff_t}} is probably the right choice to use instead - that will be a signed integer as large as the pointer type (i.e. int64, usually), and hence the largest unsigned type that's actually usable as an index.     """
"DM-18911","Improvement","ts_auxiliary_telescope",2,"Evaluate dds for ts_salobj using asyncio","""Do a preliminary evaluation of the feasibility of using the OpenSplice dds package for ts_salobj. See how it can be made to work with asyncio.    Start with [~dmills]'s feature/Prototyping_for_ddes_python_api branch of ts_sal."""
"DM-19156","Improvement","Qserv",0,"Improvements to the deployments scripts to support the new Ingest system","""This ticket has been split into multiple tickets to make the code review easier. The corresponding branch has been eliminated. And the PR request has been closed w/o reviews with notes indicating reasons for that. Please, disregard this ticket!"""
"DM-19154","Improvement","ts_auxiliary_telescope",1,"Add RemoteCommand.set_start","""Add new coroutine RemoteCommand.set_start and appropriate unit tests.    Update ts_salobj and ts_scriptqueue to use the new capability.    This will be very easy, but I plan to wait until DM-18344 is merged in order to reduce conflicts."""
"DM-19153","Story","verify_metrics",5,"Fix further spec definitions for validate_drp in verify_metrics","""This also involves updating how {{validate_drp}} discovers specs in the report making process."""
"DM-19152","Improvement","ts_auxiliary_telescope",1,"Add a short sleep after every SAL function call","""Add a short sleep after every SAL funciton call, as recommended by [~dmills] and implemented in ts_sal unit tests DM-19139."""
"DM-19127","Story","HeaderService",2,"Update EDF/HeaderService LFO monitoring script","""We need to auxiliary diagnostic scripts to monitor the payload from the LFO messages from HeaderService and EDF. These need t be updated."""
"DM-19075","Bug","jointcal",1,"jointcal is ignoring `writeChi2FilesOuterLoop`","""When implementing DM-17956, I introduced a bug: jointcal should only set {{writeChi2Name}} in the outer minimization loop if {{writeChi2FilesOuterLoop}} is True. Otherwise, the """"outer loop"""" chi2 CSV files are always written (which is bad, because they're big). Fortunately, it's an easy fix."""
"DM-19015","Bug","meas_mosaic",1,"HSC warp making is broken with doApplyUberCal=True","""makeCoaddTempExp.py with doApplyUberCal=True to use meas_mosaic outputs fail to build warps despite the input data exist. A small example to reproduce on lsst-dev is:       {code:java}makeCoaddTempExp.py /datasets/hsc/repo/ --rerun RC/w_2019_14/DM-18300:private/user/name --id tract=9615 filter=HSC-G patch=4,8 --selectId ccd=0..8^10..103 visit=26050^26036^26060^26032   {code}  This doesn't really """"fail"""" (and no logs in ERROR or FATAL level) but instead gives many confusing/misleading warnings and produce no outputs:              The log is misleading; this is DM-16537 about the generic exceptions. I troubleshoot a bit and trace to this line   [https://github.com/lsst/meas_mosaic/blob/6e395ac11a625c877374f99e2bed771b427835b6/python/lsst/meas/mosaic/updateExposure.py#L103]    where a non-empty header is obtained but no photoCalib is returned (that {{photCalib}} is {{None}} there). Feels like a bug in afw or meas_mosaic files; I paused there to file this ticket. Besides the bug, it'd be nice if the {{None}} calib is caught earlier."""
"DM-18917","Story","ts_middleware|ts_qa",1,"CPP single file program output update","""Currently the output generated from the c++ single file programs are not descriptive enough. This makes it difficult to be parsed by the current automated test pipeline in place. This task is to modify the output to be more descriptive.     Example of the desired output is in the following link  https://docs.google.com/document/d/1M3ZDKKYpGXBDOgwese2kYT_cisGXg8y6JT040SHNxPU/edit"""
"DM-18914","Story","meas_base",1,"Jenkins docs build failure","""As of 2019-04-08, [Jenkins is failing|https://ci.lsst.codes/job/sqre/job/infra/job/documenteer/436/display/redirect]. Error is:  """
"DM-19208","Story","Design Documents",1,"Provide description for LDM-503-10a","""Level 2 milestone LDM-503-10a has appeared in PMCS, but has the (very minimal) description """"LSP"""".    Based on discussions between [~gpdf] and [~fritzm] the following text (from the linked Confluence page) is proposed for LDM-503-10a:  {quote}This test demonstrates the successful integration of a single-sign-on federated authentication system, and a basic authorization system, with the three Aspects of the LSST Science Platform (Portal, Notebook, and API), with the API Aspect containing at least a TAP service.  It will be demonstrated on a Kubernetes cluster provided by NCSA.  It is not required for authorization to be applied at the database level; it is sufficient for this milestone to apply at the TAP level.  Data served will remain that from the original PDAC work, i.e., SDSS Stripe 82 and/or WISE.  {quote}  In addition, we propose the creation of a further milestone with the following short description:  {quote}This test demonstrates the ingest and service of an """"LSST-like"""" dataset in an instance of the LSST Science Platform at NCSA.  The dataset is expected to be based on the HSC public data release(s) and should include both images and catalogs.  The ingest should be performed through a version of the Science Data Model Standardization mechanism for generating concrete datasets compatible with the DPDD.  Catalogs should be available through TAP and queryable from both the Portal and Notebook Aspects.  Image metadata should be available through an ObsTAP service (and preferably also through an SIAv2 service, but this is not mandatory for this milestone), and images should be available from the URLs provided by the metadata service(s).  Image cutouts should be available through a SODA service.  Images should be queryable from both the Portal and Notebook Aspects, and there should be a well-defined relationship documented between API-based and Butler-based access to images.  {quote}  Note that these milestones reflect functional capabilities of the LSP itself, and represent steps on the way to the capabilities needed by LSST science users.  Other milestones capture issues associated with the usability of the LSP for commissioning activities.    Dates for these milestones will be determined in consultation with the LSP project manager, [~frossie].       ----  -Please provide a more descriptive title (-[~womullan] -suggests “LSP with Authtentication and TAP”) and a brief description of the contents of this milestone.-    -Refer to [https://github.com/lsst-dm/milestones/pull/10/files] for examples of the sort of descriptive text we're looking for. Something following the general pattern of:-  {quote}-""""This test demonstrates the successful execution of a prototype Alert Generation science payload (LDM-148, LDM-151), processing data from precursor surveys at a relatively small scale using compute resources at the LSST Data Facility at NCSA.""""-  {quote}  -or-  {quote}-This milestone records successful transfer of an image equivalent to one raft from the DAQ at the summit to reliable storage in the LSST Data Facility at NCSA, from where it will be made available for scientific evaluation through the LSST Science Platform.-  {quote}"""
"DM-19207","Story","afw",1,"Remove deprecated Calib interfaces after next release","""After v18 is released, we can remove the deprecated {{getCalib}}/{{setCalib}} accessors on {{Exposure}} (both in table, and image), {{ExposureInfo}}, and the deprecated {{Calib}}-style interface in {{PhotoCalib}}. """
"DM-19204","Story","Notebooks",1,"Include explanatory text in DASK notebooks.","""Add explanatory text to the exploratory dask notebooks so users can follow along."""
"DM-19203","Story","Developer Infrastructure",1,"Update generic event payload for settingsVersions event","""Add fields to settingsVersions event and allow payloads to be maximum  variable string size"""
"DM-19195","Bug","ts_middleware",2,"Attempting to get or put a topic segfaults if not subscribed","""Attempting to get or put an event or telemetry topic causes a segfault in SAL if one has not first subscribed to the event. This is demonstrated by the following unit tests in {{test_sal.py}}: {{test_evt_no_registration}} and {{test_tel_no_registration}}. Oddly enough this does not appear to cause a segfault for commands -- see {{test_cmd_no_registration}}.    In all cases I think this should raise an exception instead of segfaulting.    As part of fixing this issue please enable the unit tests listed above.    I consider this fairly low priority, despite being a segfault, because it is fairly easy to work around and ts_salobj seems to do a good job of preventing users from running into this."""
"DM-19189","Story","pipe_analysis",8,"Update flux limit for computing statistics to be based on S/N ","""The qa scripts in {{pipe_analysis}} were written and tuned based entirely on HSC-SSP data.  Now that we are moving to generalizing the scripts to work on any dataset produced by the lsst stack, certain hard-coded values need to be adapted to be appropriate for the dataset of interest.  As [~erykoff] points out in DM-18635, one such setting that requires adjustment is the minimum flux limit used for computing the basic statistics (mean and stddev) for the various metrics.  While it is currently a config parameter (whose default was set for HSC and specified by RHL), it would be even better to set this limit based on a S/N cut (e.g. S/N>100 would also match what {{validate_drp}} is using).  Once the new setting has been tested and shown to be the better option, make it the default, but allow for an override option in the configs to force a fixed mag cut (i.e the current behavior)."""
"DM-19166","Improvement","ts_middleware",1,"The SAL objects in unit tests should only publish or subscribe","""The unit tests in ts_sal have some SAL objects that registered both as publishers and subscribers to the same topic. Until DM-18915 it seemed to work, but it was never a good idea. Update the tests accordingly."""
"DM-19162","Story","HeaderService",2,"Update HS to run with new CCS code version","""Need to update and test the HS once CCS is updated on the NCSA L1 TestStand to remove the 1e6 factor in the timeStamp that went from micro seconds to seconds"""
"DM-19221","Story","dax",2,"pyvo doesn't work with TAP async","""Async queries don't work well with pyvo, because of uws:result XML elements in the response it looks like.  Works with TOPCAT.  Works without those elements around (this is how pyvo tests it)"""
"DM-19220","Improvement","ts_auxiliary_telescope",1,"Update ts_ATDomeTrajectory for changes in ts_ATDome v0.4.0","""Read commanded azimuth from the new {{azimuthCommandedState}} ATDome event rather than {{position}} ATDome telemetry.  """
"DM-19219","Story","ts_main_telescope",2,"M2 software deployment support","""Give support to run the m2controller inside the cRio"""
"DM-19242","Bug","afw",1,"Recent changes to afw compression broke macos builds","""https://github.com/lsst/afw/pull/447 seems to have broken macos builds.  Also might be unstable on centos?    https://ci.lsst.codes/blue/organizations/jenkins/stack-os-matrix/detail/stack-os-matrix/29661/tests"""
"DM-19240","Bug","ctrl_iip",2,"exposed credentials for services","""There are a large number of user/credential pairs in the YAML configuration files.  This should NOT be in GitHub, and should be in a secure directory in the user's space.  Additionally, there are about 28 user/credential pairs;  there should be one pair that all daemons use, since the extra pairs serve no useful purpose."""
"DM-19239","Story","ts_main_telescope",2,"M2 Support part 2","""Give software support to M2 at the summit"""
"DM-19236","Bug","afw",0.5,"Remove errant cout when reading old Calibs","""Looks like one of my debug statements from writing the PhotoCalib code to read old calibs got left in. This ticket is to remove it.    """
"DM-19229","Improvement","ts_auxiliary_telescope",1,"Update dometrajectory_mcs script for changes to ATDome","""Update the auxtel/integration_tests/dometrajectory_mcs script for changes to ATDome v0.4.0. Also fix the fact that although the script fails right now, the unit test still passes.    Finally, add the missing set_summary_state script (we have the code and the unit test, but no script) and see about adding a test of the script itself to the unit test."""
"DM-19226","Improvement","Qserv",8,"Implement a framework for sampling monitoring parameters of Qserv workers ","""Extend the Replication system to sample internal monitoring parameters (status, on-going queries, used chunks, etc.) from Qserv workers via XRootD/SSI. Collect and aggregate (if needed) results in memory of the Master Replication Controller. Extend the REST API of the Master Replication Controller to report results to a client application (Python tool or a Web application) for further display and analysis.    Specifically:  * extend the Protobuf protocol to allow requesting (from workers) and passing back (to the Master Replication Controller) the monitoring data  * implement a worker """"command"""" (an XRootD/SSI service) sampling monitoring data and packaging it into a JSON object o be sent back to  the Master Replication Controller via XROOTD/SSI and Protobuf  * implement a *QservMgtRequst* and *Job* classes for making monitoring requests from the Replication system's controllers  * add REST handlers to class *replica::HttpProcessor*  * figure out (discuss with the colleagues) which monitoring parameters need to be sampled and define a schema of the JSON object sent back to the Controller  * implement a basic Web-based display for the monitoring samples """
"DM-19258","Story","HeaderService",3,"Update EXPTIME, SHTTIME, OBS-BEG keywords","""Need to update EXPTIME to capture the request exposure time from the takeImages command.    The computed exposure time from shutter motion profile will be now directed to SHTTIME. Finally, DATE-BEG will be added to comply with LSE-400."""
"DM-19251","Improvement","ts_auxiliary_telescope",2,"Update ATMCS Simulator to not enable unused axes","""Once DM-17775 is implemented update the ATMCS simulator to match and make sure the integration tests that use ATMCS still work.    The changes are as follows:  - The only rotator drive that is enabled is the one that M3 is pointing to (neither if M3 is pointing to PORT3).  - allAxesInPosition applies to the axes that are actually in use, as one might expect.  """
"DM-19250","Story","ts_management",1,"Help Andrew with TSSW Documentation","""Help Andrew with TSSW documentation.    Met with Jonathan Sick and Andrew to discuss documentation tooling.    Wrote a barebones Java documentation example using Orchid."""
"DM-19249","Story","ts_calibration",1,"Experiment with thorlabs flipper communication potential","""thorlabs flipper has a purpose as a potential part of a csc. Explore the potential communication protocols. Looking into pyusb as a possible library. Working on solving pyusb permission error. Probably need to write a udev rule to give the device the proper permissions."""
"DM-19248","Story","ts_auxiliary_telescope",1,"Reorganization of jupyter notebooks Phase I","""The notebooks on pontus need a reorganization. Things should be located by username."""
"DM-19247","Story","ts_aos",3,"Evaluate the InfluxDB with SAL","""This task will evaluate the integration between influxDB and influx_writer of SAL. This task will also benchmark the performance of InfluxDB to use the SSD, NVME, or hard disk.    Compare the MariaDB quary language and InfluxDB quary language.    Evaluation steps:   # Check with the AT CSC owners with the telemetry rate according to the page: [https://confluence.lsstcorp.org/display/SYSENG/Auxiliary+Telescope+Control+Computers+in+Tucson]   # Clone the ts_sal repository to the /home/ttsai. Install the SAL and build the AT CSC test scripts I need. Make sure the sal version is 3.9 and opensplice version is 6.9.   # Change the test telemetry script to run infinity times (iseq in C++) with the correct telemetry frequency (delay_1s in C, the first argument is sec and the second is nano-sec).   # Run the test for SSD, NVME, and Disk.   # The path variable of """"LSST_EFD_HOST"""" gives the IP_address of influxDB.   # I can do """"./some_writer >& log.1 &"""" to run the writer in the background. And I can use """"tail -f log.1 to see the log file"""".   # Once I changed the cpp file, I can go to the """"stand_alone"""" directory and do """"make -f Makefile.sacpp_blahblak_pub"""" to build the code in the same directory.   # I can also do the above modifications by python."""
"DM-19246","Story","ts_aos",2,"Document the Change of WEP Code","""This task will document the change of code at this moment and test the sphinx as the documentation tool."""
"DM-19245","Story","ts_aos",3,"Use the Yaml Configuration File Format Phase 2","""This task will use the yaml to manage the configuration files. This task is the phase 2. I need to merge the lsst an comcam configuration files."""
"DM-19243","Story","ts_middleware",3,"Investigate Kafka for Influx EFD implementation","""Investigate Kafka for Influx EFD implementation."""
"DM-19265","Story","meas_mosaic",1,"Jacobian lost in meas_mosaic photometric solution","""It looks like we lost the Jacobian from the meas_mosaic photometric solution with this deletion from DM-10156:   [https://github.com/lsst/meas_mosaic/commit/6e395ac11a625c877374f99e2bed771b427835b6#diff-ad69537790bfe1f2b36095cbbc6f80a9L709]   I noticed this in comparing meas_mosaic-calibrated magnitudes between the w_2019_10 and w_2019_14 RC2 reprocessings, which look like:   !compareVisit-v1228-diff_base_GaussianFlux-sky-gals.png|width=450!     """
"DM-19287","Story","ts_auxiliary_telescope",1,"study chiller communication protocol","""read chiller docs, learn about how it likes its packets assembled. This is a duplicate of TSS-3457, which was accidentally created under the wrong project"""
"DM-19286","Story","ts_main_telescope",2,"TMA Task list & meeting","""Confluence page link:   * [https://confluence.lsstcorp.org/display/LTS/17-4-19+Meeting+notes]"""
"DM-19281","Story","ts_main_telescope",2,"Early April ASC work","""early april work on the ASC, including meetings and reviewing the requirements doc and CSC/T2SA API spec. This ticket duplicates TSS-3459, which was created under the wrong project."""
"DM-19278","Story","ctrl_iip",0.5,"Fix Scoreboard initialization","""During initial refactoring, it wasn't apparent how the Scoreboard and its subclasses were being utilized.  In looking at it now, it appears it has always been doing a reload of the configuration file the main class was loading.  This was discovered  when doing DM-19240 and loading of Credentials had to be put in there until the config reload could be dealt with.  I'm creating this ticket to eradicate the reloading of the config/credential files."""
"DM-19276","Improvement","ImgServ",5,"Implement build system for ImgServ off pre-built LSST stack image","""The new system to build the Docker image needs to achieve the following:   # Use latest official stable build from Square with CentOS and LSST stack, and build a multi-stage Docker file in ImgSev, as a standalone app.   # Pull in and build/install the dependencies or requirements, e.g. uwsgi.   # Pull in ImgServ, off the master OR feature branch, setup to run with scons.     """
"DM-19274","Story","ts_auxiliary_telescope",2,"Reorganize script in standard and external script repository","""After Robert visit we discussed ways to reorganize the way we write and store SAL Script so the code is mode re-usable from other SAL Script and usable from notebooks. I will implement this reorganization to the currently existing scripts and will write some example notebooks to show how that is achieved. """
"DM-19272","Story","pipe_tasks",5,"Make script for creating skymaps in gen3 bulter","""The script makeSkyMap.py currently uses command line tasks to create and ingest a skymap into a gen2 butler. This ticket will create an equivalent script for the gen3 butler.    This ticket will have a simple command line parser that will not attempt to capture all options or allow setting configs from the command line. That work will be captured by a future ticket which will encompass command line parsing for scripts in a generic way to work across all gen3 middleware scripts."""
"DM-19268","Story","ts_management",2,"Update documentation for CSC overview","""Updated the time I spend this sprint on documentation to focus on getting the csc overview completed. The original titles of this task was to get the templates created for the various code repo's."""
"DM-19311","Improvement","Third Party Software",0.5,"Please update to pybind11 2.2.4","""After updating to the latest weekly T&S is seeing a lot of warnings when building ts_sal as described here: https://github.com/pybind/pybind11/issues/1444 -- our pybind11 is using an API that has been deprecated in Python 3.7.    pybind11 2.2.4 fixes this issue. Could we please update to that?"""
"DM-19293","Improvement","afw",0.5,"Clean up photoCalib examples in docstrings","""Meredith pointed out some improvements to the PhotoCalib docstrings, including incorrect values in the {{fluxField}} examples. I'll try to clean them up to make the docs more useful."""
"DM-19292","Story","ap_pipe",8,"Compare detection rates to Gaussian noise for HiTS processing","""This ticket is to effectively repeat the relevant portions of the DMTN-006/DMTN-021 analysis for our current HiTS processing to bound our false positive rates.  This ticket is simply to perform the work in a notebook, but it is expected that future work will incorporate relevant portions into the metrics system."""
"DM-19331","Story","astro_metadata_translator",2,"Fix detector name for HSC","""The HSC detector name was being read from the T_CCDSN header but this value does not match common usage.  The names are defined in the obs_subaru camera geom files of the form RAFT_NUMBER where raft is 0 and 1 and numbers are zero-padded two digits.    Currently raft is not a concept used in obs_subaru."""
"DM-19328","Story","pipe_tasks",3,"Investigate cause of small differences in Uber calibrations from w_2019_[06/10/14]","""While validating the fix in DM-19265, it was noted that there are differences in the uber calibration results from both {{jointcal}} and {{meas_mosaic}} between recent weekly runs of the RC2 dataset.  As the plots on DM-19265 show, there have been some subtle changes from {{w_2019_06}}\-to\-{{w_2019_10}}\-to\-{{w_2019_14}}.  The differences are small (stdev of difference is at the sub mmag level), but it is still important that we understand where they originated.  Since both algorithms are affected, the route cause must be something that effects both.  A first guess would be something about how object selection is being done."""
"DM-19318","Bug","Notebooks",0.5,"Notebook command-line tools: zip is installed but not unzip","""In recent builds available in the Notebook Aspect, the {{zip}} utility is available but not the {{unzip}} utility.  This is arguably a bug, and in particular causes {{zip -T}} to fail.    Please either provide both or neither (but preferably both)."""
"DM-19372","Story","ctrl_mpexec",0.5,"Produce warning message when QuantumGraph is empty","""When pipetask makes an empty QuantumGraph it would be useful to notify user about that, people get confused if everything looks OK and there are no messages, but then nothing is executed. I think it deserves a WARNING message if graph is empry, maybe we can also print some INFO like number of quanta in a graph.  Understanding why graph is empty is a more complicated (existential) problem, it will be addressed on a separate ticket."""
"DM-19370","Improvement","webserv",2,"Use ImageServ image in webserv Kubernetes deployment","""Now that ImgServ build has been implemented as standalone image using prebuilt weekly builds from CentOS/lsst_stack, it's time to modify the k8s deployment to use that image, essentially splitting existing webserv service into the new dax-imageserv, and the rest.               """
"DM-19366","Bug","afw",1,"afw unit tests do not run on some platforms","""DM-10384 did away with {{lsst.geom}}'s subpackages, replacing them with a monolithic {{lsst.geom}} package. This change broke the backward-compatibility aliases provided by {{lsst.afw.geom}} for DM-14429. Some runs of {{pytest}} or {{scons}} try to import these aliases, and crash.    In the discussion of this issue on [#dm|https://lsstc.slack.com/archives/C2JPL2DGD/p1555091757000700], it was informally decided to simply remove the broken aliases instead of updating them -- no code will be broken by this change, since the existing aliases are unusable anyway."""
"DM-19363","Story","ts_middleware",1,"Make OpenSplice RPM relocatable","""To better support the SLAC build and test system for CCS, the OpenSplice RPM needs to be made relocatable."""
"DM-19362","Story","ts_calibration",1,"Acquire new data using new configuration(s) of calsys_takedata.py Script","""Take new dataset for monochromator characterization using new configuration values for calsys_takedata.py to see if an issue with an earlier data set is fixed.    Fixing calsys_takedata.py as it somehow became broken. Code was added to finish writing a csv file to user supplied directory that downloaded electrometer and fiber spectrograph fits files. The code was copy and pasted from the narrowband version of the script and was not completely changed over.         Fixes were implemented as part of the following PR - [https://github.com/lsst-ts/ts_externalscripts/pull/4]"""
"DM-19358","Story","DM Subsystem Science",2,"Presentation to DESC PSF Task Force","""Prepare and give a ~50 minute talk to the DSC PSF Task Force, on DM's perspective on PSF modeling."""
"DM-19357","Story","HeaderService",2,"Update the salEvent Call in salpytools for SAL v3.9","""In version 3.9 of SAL, it looks like the the function {{mgr.salEvent}}  to publish an event is no longer supported and needs to migrated to {{mgr.salEventPub}} now."""
"DM-19355","Technical task","DM Subsystem Science",1,"Assist with TVS Roadmap ","""As the TVS Science Collaboration prepare their roadmap to science, I have been participating as their DM liaison to ensure the roadmap contains correct (and DPDD-ified) language about the LSST data products."""
"DM-19354","Story","ts_auxiliary_telescope",1,"Test ATDome vendor interface v2","""The AT Dome vendor provided a new version based on comments provided as part of DM-18454. This ticket is to test this new version both at the TCP/IP vendor interface level and the CSC level."""
"DM-19389","Improvement","geom",1,"Convert lsst.geom to numpydoc","""Enable Sphinx output of {{lsst.geom}}, and move corresponding topic documentation to {{doc/}}. Note that {{lsst.geom}} does not need any Numpydoc conversion as such because, except for {{testUtils.py}}, all its components are defined in C++."""
"DM-19383","Story","obs_lsst",0.5,"Fix BOT translator when DARKTIME is present","""[~echarles] reports that ingest of BOT is failing because there is a typo in the dark time calculation. This code has not been tested before since DARKTIME has never previously been written to files. The fix is trivial."""
"DM-19382","Story","ip_isr",8,"Refactor and reorder ISR steps to support writing pre-interpolated pixels","""At DRP Team meeting April 3 2019, we discussed the steps in ISR that could be reordered in order to support storing pre-interpolated pixels (that have had ISR applied to them so that they can be meaningfully swapped in downstream processing).     The interpolation step before brighter-fatter is necessary. Therefore, we decided to reorder ISRTask as follows:    * First ISR Steps…  * Interpolate  * Do Brighter-Fatter Correction  * Put the pre-interpolated pixels back into the now BF-corrected raw.   * …Continue ISR…  * Saturated/NaN pixels and defects are *masked only*  (no interpolation)  * Second to last step: write out pre-interpolated pixels  * Last step:  Interpolate the *union* pixels masked for interpolation (sat/bad/nan)    [~rhl] pointed out that it is more correct to interpolate the union of all regions that need to be interpolated rather than  in separate stages for each of SAT, BAD, NaN. In addition to the extra steps of reinserting pre-interp pixels, this tickets also includes refactoring to separate the masking step and interpolation steps in {{maskAndInterpNan}}, {{maskAndInterpDefects}}, and maybe {{saturationIntepolation}}.  """
"DM-19428","Story","Third Party Software",0.5,"Add eups python as a dependency of pybind11","""[~jbosch] points out that our pybind11 eups package doesn't depend on numpy and astropy when in fact it technically should (and eigen as well I think)."""
"DM-19412","Story","afw|pipe_drivers",1,"Bad CCD rotations in visualizeVisit.py","""Something seems to be going wrong in the application of NQUARTER in visualizeVisit.py (maybe it's being applied twice, or maybe not at all).  [~lauren] suspects this was broken in DM-19371, and that the fix involves the new {{obeyNQuarter}} clause: [https://github.com/lsst/afw/commit/f154d3474b433e269d65c697c02cd1738e918942]"""
"DM-19409","Story","geom",1,"Add getCenter to Box2I","""Many region specifications (DS9, STC) define boxes in terms of center and width. Box2D has a {{getCenter()}} method but it would be useful if {{Box2I}} also had one to allow for more seamless usage."""
"DM-19399","Story","ctrl_iip",0,"Build files need to generically point to dependent libraries","""The build files for this package have hard-coded locations to some of the packages they link against.  This needs to be fixed to use environment variables which point at the root of those packages, so that the build files will work in different environments and/or when the locations of those packages changes."""
"DM-19398","Story","ctrl_iip",1,"Tests directory should be brought up to DM compliance","""The tests in the test directory need to be looked at in order to bring them up to DM standard testing.  Some of the tests require external services (Redis, RabbitMQ), and will only on systems that can access those services.  Those tests shouldn't be run  so that when the services aren't available."""
"DM-19393","Story","ip_isr|obs_subaru",1,"Fix HSC y stray-light lookup In Gen2","""DM-15862 broke y-band stray-light calibration lookup in Gen2 (which has always been a hack) by hard-coding a path, then deferring a fix for that to DM-16805.    That more complete fix will still have to wait for that ticket, but I'll try to get a fix for Gen2 only done here.     """
"DM-19453","Story","ts_middleware",1,"Whitelisting Supported Generic Interfaces in SAL","""In the _SALSubsystems.xml_, the _Generics_ attribute should be converted from a boolean to a whitelist. This list is the generic commands and events that the CSC WILL support and implement. Only those items list here should be transitioned into the CSC API."""
"DM-19440","Story","ts_auxiliary_telescope",2,"Docker Container problems","""There was a review I did for Russell called slew scripts that would help me get up to speed on how docker containers work and how the team is using the scripting language. During the review I was having problems with getting my containers to get installed, I went through the process once on my centos machine, and again on my Mac. James also found a solution that solved the space problem that I was having on the cent os. This tasks is to cover the time spent on this effort. """
"DM-19474","Bug","ts_auxiliary_telescope",0,"Remove the char0 field from the array topics of Test","""When I wrote the Test XML I thought """"char"""" as the C type, but """"char"""" is actually a synonym for """"string"""". Arrays of strings are not permitted so remove the """"char0"""" field from each arrays topic: command """"setArrays"""", event """"arrays"""" and telemetry """"arrays"""". Update ts_salobj accordingly."""
"DM-19464","Story","ImgServ",5,"Add DAX imgserv and metaserv builds to jenkins-dm-jobs","""Add standalone dax_imgserv, and dax_metaserv docker builds to Jenkins CI, under the old webserv, as moniker.         As Josh suggested, this is to be done via a PR on lsst-sqre/jenkins-dm-jobs."""
"DM-19458","Bug","meas_algorithms|meas_extensions_psfex",1,"FieldValidationError usage incorrect in many tasks","""While looking up how to use {{FieldValidationError}}, I discovered that several of our existing instantiations of it are incorrect and would thus raise an exception themselves! It takes {{(field, config, msg)}}, and I found 4 uses that just pass {{msg}}.    It is probably worth cleaning up the docstrings of this custom exception at the same time."""
"DM-19491","Story","meas_algorithms",2,"Enumerate options for creating new HTM Indexed refcats","""After some slack discussion, [~krughoff], [~ctslater], and [~erykoff] have all provided me with some suggestions about how to make refcats.    There are the DR2 .csv files on lsst-dev here: {{/project/shared/data/gaia_dr2/gaia_source/csv}}    and a Parquet version here: {{/project/shared/data/gaia_dr2/gaia_source.parquet}}    {{meas_algorithms}} has {{IngestIndexReferenceTask}}, which I've been told is very slow. [~erykoff] suggested using {{fgcmOutputProduct._outputStandardStars}} from {{fgcmcal}}, but it does not handle proper motion or parallax or many of the other fields. I should run some simple tests to see just how slow the """"standard"""" code is and make some guesses as to what might be necessary to speed it up. And similarly, compare it with [~erykoff]'s code and decide whether we should just use something like that. As part of this, I should look at reading Parquet vs. CSV."""
"DM-19488","Story","ts_aos",1,"Evaluate the InfluxDB to be the EFD Candidate","""This will evaluate the performance of InfluxDB with the SAL influxwriter on SSD, NVME, and spinning disk."""
"DM-19485","Story","daf_butler",0.5,"Fix length of instrument name in gen 3 butler schema","""Currently the schema reserves 8 characters for the instrument name. This is insufficient for many instruments. Change to 16."""
"DM-19479","Story","metaserv",5,"Build metaserv image in its own Docker container","""The proposal here is to apply the same framework established in imgserv to build a standalone container image for metaserv, to be taken out of webserv container, which can then be deployed to lss-lsp-int and lsst-lsp-stable.    After this work, the webserv container, which built lsst_stack from source, can be retired from DAX."""
"DM-19475","Story","ts_auxiliary_telescope",2,"setup connection to chiller","""The chiller is set up in the lab with an N-Port ethernet-to-rs232 converter. Figure out how to get that talking to the whitelight CSC."""
"DM-19518","Story","ts_auxiliary_telescope",2,"Setup Sundararaman development environment ","""I would be using this task to set up my development environment, Research the libraries I would need for fiberSpectrograph c++ code to be imported to python. Mostly R&D and setting up hardware. """
"DM-19515","Story","ts_middleware",2,"Go Through Sal Issue and clean up","""Go through the SAL issues we currently have and identify which ones are high priority, low priority, and which we can delete."""
"DM-19514","Story","ts_main_telescope",3,"TMA Meetings / Working with Shawn / Agenda Work","""This task will cover the effort going over the TMA Agenda which will include meetings with Shawn to go over and assist in any activities. Meeting with Sandrine to cover high level view of the TMA project that she has agreed to go over with me. And reading documentation with Tiago to gather knowledge and better assist in identifying what requirements we are missing or need from Tekniker. """
"DM-19513","Story","ts_calibration",1,"Experiment with C# .net framework for thorlabs flipper","""Downloaded control software from thorlabs which contains the libraries necessary for the .net framework. Followed their example for the MFF101 flipper to flip back and forth, setup .net framework using mono(a cross platform implementation of the .net framework). Flipper example would not compile because native c dll were only compatible with a windows c library."""
"DM-19512","Story","ts_main_telescope",3,"Grab and build TMA PXI simulator & Install EUI on Simulation Cluster","""Pull down the code from Docker hub and using their instructions build onto the Simulation Cluster."""
"DM-19511","Story","ts_main_telescope",1,"Write conda recipe for ts_tunablelaser","""Write a conda recipe that works for the ts_tunablelaser."""
"DM-19510","Story","ts_middleware|ts_qa",3,"Update SAL C++ event messaging tests to use the single-file interfaces","""This task is to track the effort to update the SAL messaging tests.  I want to maintain the individual message testing, so updating the scripts that generate the tests will be somewhat tricky."""
"DM-19509","Story","ts_qa",1,"TSSW Jenkins service configuration","""This task covers time needed to setup and configure the TSSW Jenkins environment.   * Install and run Docker on the host   * Get the ts_xml job configured and running"""
"DM-19508","Story","ts_main_telescope",1,"Preparation for TMA workshop","""My time has been requested to help prepare the team for the TMA workshop visit in June.  This task covers the time needed to attend meetings, read documentation and other efforts, as needed."""
"DM-19507","Story","ts_middleware|ts_qa",5,"Update SAL C++ telemetry messaging tests to use the single-file interfaces","""This task is to track the effort to update the SAL messaging tests.  I want to maintain the individual message testing, so updating the scripts that generate the tests will be somewhat tricky."""
"DM-19506","Story","meas_algorithms",1,"Adjust defect FITS files to be compatible with DS9","""The FITS region files we are writing use LSST pixel 0,0 as origin.  This means that when the regions are loaded into DS9 the regions are shifted by a single pixel.  Adjust the output of the region to correct for this (and also adjust when reading back in)."""
"DM-19495","Story","DM Subsystem Science",1,"Liaise with Stars, Milky Way, and Local Volume Science Collaboration","""All activities as the DM liaison to the Stars, Milky Way, and Local Volume"""
"DM-19528","Improvement","ts_auxiliary_telescope",1,"Update ATMCS Simulator to use absolute angles","""Update the ATMCS simulator to use absolute angles, now that ATPtg has been updated to do so.    If practical, also implement DM-19251 at the same time."""
"DM-19547","Bug","ctrl_iip",0.5,"scoreboard date reported as 1900-01-01","""values for 'EXPIRY_TIME' is being reported as having date 1900-01-01;  the time is correct, just the date is off."""
"DM-19544","Story","Science Platform",1,"Oversee creation of LSP Review LIT tickets with DM admins","""The DM admins can help with entering LIT tickets"""
"DM-19543","Story","Science Platform",2,"Evaluate LSP review committee's recommendations and map to LIT tickets","""Review the recommendations in the LSP review report, flatten the structure so that 1 item can be mapped to 1 LIT ticket.      """
"DM-19541","Story","ts_auxiliary_telescope|ts_pointing",3,"Test latest version of pointing component with SAL 3.9","""Vendor released latest version of pointing component. Initial tests showed some issues with the component that need to be addressed and may have shown an issue with SAL 3.9/SalObj 3.11.0. This task will be used to continue testing the pointing component  and SAL.     Following Dave's suggestion I will spin up a EFD for the components to monitor the SAL traffic. I will also use this task to document a procedure on running integration and test on stage machines.     Documentation will go here:     https://confluence.lsstcorp.org/display/LTS/Integration+Testing+and+Deployment+Development+Procedure    """
"DM-19539","Story","DM",1,"Create TOR for Image working group","""Action from QAWG - to set up a group to look into needs for image display."""
"DM-19535","Improvement","cp_pipe|pipe_tasks",1,"Move MakeBrighterFatterKernelTaskRunner to cp_pipe/pairedVisitTaskRunner","""Several tasks in calibration product production (and some others actually) will work on visit pairs rather than single visits.    There is already an implementation of a custom TaskRunner in {{cp_pipe/makeBrighterFatterKernel.py:MakeBrighterFatterKernelTaskRunner}}. This should be made into a utility in {{cp_pipe}} so that its other tasks can use it, rather than either reinventing the wheel, or importing something misnamed and in the wrong place.    1) Move that task runner out of {{makeBrighterFatterKernel.py}}   2) Get {{makeBrighterFatterKernelTask}} to work using the new runner."""
"DM-19567","Story","DM",1,"Creat script to simulate forwarder for OR#1","""take a file every N second s and put it in another directory"""
"DM-19595","Story","ap_pipe",2,"Make new ap_pipe rerun with latest weekly","""We should do new ap_pipe reruns on the HiTS2015 dataset approximately monthly with the latest weekly stack. In this case, we will not regenerate the coadd templates and will just use the CompareWarp coadds which are a few months old."""
"DM-19583","Story","daf_butler",3,"Investigate butler gen 3 configuration system","""The butler yaml configuration system might need some tweaking. Investigate [~mgower]'s problem and possibly adjust how overrides work."""
"DM-19579","Bug","ts_auxiliary_telescope",2,"The same command IDs are being used by different commands","""It appears that in ts_sal 3.9 every command topic starts with the same private_seqNum (some large integer). As a result the same seqNum is being used by all the different commands.    Two solutions that come to mind (and I'm sure there are others):    1) Use another existing ackcmd field or add a field that identifies which command the ack is for. For instance an integer that specifies the index of the command in the known command topics.    Then one can use a different content-filtered ackcmd reader for each command, for instance in SALPY using the ackCommand_x and getResponse_x functions will do exactly what a user might expect.    Does SAL provide similar functions for other languages?      2) Divide the sequence numbers up so that each command has its own range of sequence numbers. Each command writer starts out with the minimum value and rolls over when it hits the maximum.    This is a simpler change, but it means that code must (continue to) read one ackcmd topic to read acks for all commands. For instance one would use getResponse_start to read acks for all commands, including enable, disable, exitControl... which is surprising, to say the least.    salobj has not been doing this and so has a subtle bug I need to fix. I wonder how many other languages have the same bug?    (You could fix the bug using content filtered readers based on seqNum range, but that sounds riskier and hackier than using a separate field to identify the command).  """
"DM-19578","Story","ts_middleware",3,"Assist developers with ADlink cases for DDS","""Submit cases to the ADlink issue management system and assist with   investigation on the LSST side (of dds native python interface usage)"""
"DM-19577","Story","ts_main_telescope",3,"Prepare for TMA software workshop","""Attend planning meetings, review documents and software in preparation  for  the planned June workshop on TMA software at Tekniker"""
"DM-19569","Story","ts_auxiliary_telescope",3,"Update ts_ScriptQueue to use the dds version of ts_salobj","""Update ts_ScriptQueue to use the version of ts_salobj based on dds. This is primarily intended to exercise the new version of ts_salobj."""
"DM-19602","Story","ts_auxiliary_telescope",1,"Test ticket DM-19601","""Test:  DM-19601"""
"DM-19601","Story","ts_auxiliary_telescope",1,"Update ATHexapod reference logic and add init command","""Add the logic discussed in ticket https://jira.lsstcorp.org/browse/DM-18642 :       So we should certainly add a SAL command, regardless. (To do a position reference)  We should avoid movement in the disabled state, so on the start command, check the reference. If it's good, then continue as normal without re-referencing. If the reference is bad, then on enable, execute a reference and tell the user a reference is happening and therefore it might take more time.    Also add a reference event that checks and announce if the controller is properly referenced."""
"DM-19599","Improvement","ctrl_iip",2,"Run services as one user, out of one directory.","""Currently, services run as different users (ARCHIE, DM, etc) depending on the type of service.  Code has to be installed in multiple home directories, separate configuration information and log files are written at each of these users.   The log file issue has been resolved, and files are written to a directory listed in the configuration file.    The software install has to be in one common directory where the code exists and is invoked by all services on that system all running as one user.    I suggest /opt/lsst/ctrl_iip for the $CTRL_IIP_DIR and DM as the user."""
"DM-19633","Bug","ts_middleware",0,"The ups table lost crucial info and make_idl_files is broken","""The recent merge to develop of ts_sal has broken the use of ups and also my new make_idl_files script. I had not realized that [~dmills] ripped out the new """"sal pydds"""" salgenerator command, which make_idl_files used to generate the all-in-one IDL file (ts_sal/test/idl-interfaces/validated/sal/sal_revCoded_<component_name>.idl) needed by dds. Fortunately we can use """"sal cpp"""" instead, though it's a lot slower and less efficient.    For the future it would be really nice to have a salgenerator command that would make the IDL file without building anything extra (such as C++) except, preferably, a file of enums as Python enum.IntEnum instances."""
"DM-19628","Story","Qserv",20,"Worker CSV loader service","""Implement a loading service within existing Replication System's workers. The service will initially support data in the TSV format. The services will create MySQL partitions in the chunk tables as per the super-transaction identifiers. Implement a command-line application which would accepts pre-partitioned TSV files and perform all required interactions with the Master Replication Controller (via the HTTP REST API). There will be a suite of simple integration and performance testing applications (scripts) to drive the parallel loading."""
"DM-19627","Story","meas_algorithms",2,"Add text file serialization to meas_algorithms Defects class","""It was noted on RFC-595 that the creation of the Defects text files to be stored in the data repositories is distinct from Defects.  It would be more useful for people creating defects lists if the Defects class could serialize to the text format.    [~rhl] also requests that metadata be stored in the text files (at least the format version number and the detector name and instrument).  To satisfy that requirement I will see if I can write out in the Astropy ECSV format."""
"DM-19623","Story","daf_butler",2,"Change sqlalchemy syntax in addDimensionEntryList","""sqlalchemy has a few different ways to insert multiple objects at a time, change to one that works across more databases reliably."""
"DM-19622","Story","daf_butler",0.5,"Make PosixDatastore's internal table lowercase","""DM-17633 failed to lowercase PosixDatastoreRecords, as it's defined in a totally different way from the rest of the schema.  Fix that."""
"DM-19618","Story","ci_hsc",2,"Allow gen3.py to be called with an external butler configuration","""Currently the butler configuration used for gen 3 testing in ci_hsc is hard coded into the lsst.ci.hsc.gen3 module.  This makes it hard to use for oracle testing where we want to override the configuration.  Update gen3.py to be a class allowing an override butler and add command line to the gen3.py script to use that functionality."""
"DM-19616","Story","meas_algorithms",8,"Make IngestIndexReferenceObjectsTask multiprocessing capable","""In order to be able to generate a Gaia (or PS1-DR2) reference catalog in a reasonable amount of time, we need a way to process files in parallel. The existing IngestIndexReferenceObjectsTask is not capable of running in parallel. One approach that should be fairly simple is to use multiprocessing plus file locking: lock each output catalog before appending."""
"DM-19615","Story","ip_isr",1,"Change raw storage class in isr task","""The gen3 butler storage class in IsrTask does not match what it is ingested as, fix this."""
"DM-19614","Story","obs_subaru",3,"Write transmission curves in writeCuratedCalibrations","""Transmission curves should be written to the butler when writing human curated calibration products"""
"DM-19610","Improvement","ctrl_iip",2,"Update to SAL 3.9","""We're in the process of updating to SAL 3.9.  This story will contain the subtasks we need to do in order to complete that work.s"""
"DM-19637","Story","Qserv",0.5,"Moar fix Qserv CI container builds","""more Alpine incompatos in container build script..."""
"DM-19636","Story","Qserv",1,"Fix Qserv CI container builds","""Recent change of Jenkins build workers to Alpine broke Qserv container build scripts"""
"DM-19650","Story","meas_deblender",2,"Ensure scarlet failures are propagated to the stack","""scarlet has internal diagnostic information and flags that are set but not passed to the LSST stack. {{ScarletDeblendTask}} needs to be updated to update the catalogs with the relevant flags."""
"DM-19646","Story","ts_main_telescope",2,"Check software installed by vendor in laptop and Desktop","""Laptop and main computer is with Doug. I will check the startup and software installed on the PC and laptop before we ship it to Chile. Review documentation that were delivered along with the devices."""
"DM-19644","Improvement","ts_auxiliary_telescope",2,"Use a single remote to interact with all scripts","""The ScriptQueue should use a single Remote to communicate with all scripts, rather than creating a separate remote for each script. This is trivial with the dds version of salobj and would also be easy with SALPY if it ever exposes the hidden fields in topis."""
"DM-19643","Story","ts_auxiliary_telescope",1,"Investigate using select to read data with dds in ts_salobj","""For the dds version of salobj I am presently using one dds.WaitSet per topic, which takes one thread per topic. However, it may be possible to use dds select to have a single thread that reads all topics. That should be more efficient and scale better for the Watcher. Look into this and implement it if practical."""
"DM-19641","Story","obs_subaru",1,"Use jointcal instead of meas_mosaic in obs_subaru HSC coaddition","""Use jointcal instead of meas_mosaic!     We've done sufficient QA, integration work and improvements to believe this is now working at least as well as meas_mosaic. This doesn't require an RFC because it just affects obs_subaru  (RC2 reprocessing and future HSC data releases)."""
"DM-19663","Story","HeaderService",2,"Update States Enumerations to use ""SAL__STATE_STATENAME""","""The enumeration (integers) of the CSC states need to be updated in salpytools. Instead of using the detailed states, it should the SAL__STATE_CSCNAME from now one."""
"DM-19659","Story","ts_aos",3,"Update ts_phosim to use eups and yaml","""Update ts_phosim (from ts_tcs_wep_phosim) to use eups and documenteer and add dependency to ts_wep. This is to unify the package manager and reduce the code redundancy. This task will also update the configuration files to use the yaml format."""
"DM-19656","Story","HeaderService",3,"Write utility to test transitioning states for a generic CSC ","""As part of the testing of and development of CSC, and in particular for the L1 NCSA Test Stand we need a utility that can test and verify the reception and acks of command for transitioning states. This is particularly useful when testing new version of SAL."""
"DM-19686","Story","JupyterLab",2,"Interactive matplotlib plots work if notebooks are rendered from the ""classic"" view","""The matplotlib plots rendered in notebooks served within JupyterLab do not have the standard interactive controls.  I believe this is a conscious decision, but users find the interactive controls useful enough that, in some cases, users are specifically using the classic (""""tree"""") view of the notebooks in order to have this feature.    [~frossie] suggested that we look into whether the JL position is flexible on this."""
"DM-19685","Story","ts_middleware",3,"Identify slowdown in SAL command acks","""Try to pinpoint the slowdown in SAL command acks that [~tribeiro], [~spietrowicz] and I are seeing. In particular:  - See if it is present OpenSplice 6.10  - If it still present there then try to come up with a simple case that shows the problem.  - If the problem is in dds file an ADLink support ticket. If not, try to figure out how SAL could be improved.    Note: I see the problem (or what I think is the problem) in dds salobj."""
"DM-19682","Story","obs_lsst",1,"Fix DAYOBS calculation and allow for gen2 header correction for ingest","""[~rhl] reported that the gen2 butler dayObs quantity is not being calculated correctly. It is always assumed to be calculated from the date and not from the DAYOBS header. This needs to be fixed to only use the date if DAYOBS is missing.    Additionally, since this is a gen2 ingest model parameter and not part of the gen3 data model, the value does not get corrected if there is a FITS header correction file. Update ingest so that header fixups occur on ingest even outside of metadata translation."""
"DM-19681","Story","dm_dev_guide",1,"Clarify who has authority to override coding standards","""https://developer.lsst.io/coding/intro.html#stringency-levels currently refers to the TCT and the “lead developer”, neither of which are meaningful."""
"DM-19679","Bug","Science Platform",0.5,"Please parameterize the ID provider in the LSP instance config","""(Emergent from a configuration problem that emerged on 2019-05-08; see Slack #dm-lsp and #dm-lsp-coord for more information.)"""
"DM-19677","Story","pipe_tasks",1,"Disable writing postISRCCDs in ProcessCcdTask","""Per [discussion on Slack|https://lsstc.slack.com/archives/C2JPMCF5X/p1557330175343800?thread_ts=1555439400.008300&cid=C2JPMCF5X], {{ProcessCcdTask}} should set {{doWrite=False}} on it's {{IsrTask}} subtask.    And please also make sure there aren't unnecessary overrides in obs packages."""
"DM-19671","Story","daf_butler",1,"setConfigRoot sometimes needs to not update the root","""[~dinob] is running into problems with {{Butler.makeRepo}} whereby the registry specified from his external config (which happens to be an in-memory sqlite) is being overwritten by a default value assuming a SQLite file on disk with butlerRoot.    I think it is reasonable to assume that if makeRepo is being called with a populated config and that that config has {{registry.root}} defined, that the caller of makeRepo does not want makeRepo to override the values. Should makeRepo attempt to create the tables in the provided root? What about {{datastore.root}}?    It's a fairly small change to allow setConfigRoot to not override root if root is already present in config (we have to call it anyhow because it copies items over as well as updating the root). I think a flag to setConfigRoot (""""overrideRoot""""?) defaulting to False would work which would be True when called from makeRepo and would be forwarded to overrideParameters or else not even pass toUpdate to overrideParameters."""
"DM-19704","Story","HeaderService",1,"Update logging in ATHS/salpytools to also direct to a file","""Update logging on the salpytools section of ATHS to be directed to a file in addition that to the screen."""
"DM-19702","Story","ts_auxiliary_telescope",2,"Make ATAOS configurable and add handling of lookup tables","""In preparation for the tests in Chile, I'll finalize the ATAOS CSC by making it a configurable CSC and adding support for the lookup tables. """
"DM-19697","Story","ts_middleware",3,"Proposed additions to the ackcmd topic: Origin and command ID","""I propose that the {{ackcmd}} topic be enhanced to add a field for the """"origin"""" datum of the command that triggered the ack and another field for """"host"""" if """"origin"""" is not unique. This will make it simple for the commanders to only pay attention to ackcmd messages meant for them.    The present situation is risky because there is no way to tell which commander an ackcmd topic is intended for. A recent change to the way private_seqNum was incremented makes this far more likely because the starting number is now the same for all commanders (for a given command).    Also I suggest adding field to commands that identifies the command (perhaps the integer position of the command in the list of commands, or a hash generated from the command name -- anything the commander wants as long as it is a 1:1 mapping between command name and identifier). The component being commanded will copy this field to the ackcmd topic.     This is less crucial than the first suggest change, but it seems simpler than relying on ranges of sequence numbers. If nothing else we can more easily debug problems since the person doing the debugging won't have to work out the range of sequence numbers that applies to a particular command.    I suggest that this ticket replace DM-19579 as a more thorough solution."""
"DM-19695","Story","ci_hsc",1,"ci_hsc fails tests on NFS","""Since moving Jenkins to NCSA one of the ci_hsc tests fails because the clean up code attempts to clear out a directory but some files are still open and owned by the process. On local filesystems this works fine but on NFS deleted but open files become temporary files and {{rmtree}} gets upset when they hang around.  tempfile.TemporaryDirectory does not know about those open files and does not run rmtree with the flag to ignore errors.    The fix is either to move the clean up code to tearDown or else see if a {{del}} works."""
"DM-19694","Story","meas_algorithms",2,"Make Defects presize internal tables.","""Currently, the internal table that holds the defects in {{Defects}} is not presized, so is not contiguous in memory.  This is to make sure the table is contiguous from construction time."""
"DM-19720","Story","pipe_tasks",5,"Change multiband.py to support meas_extensions_scarlet","""Modify multiband.py deblender command line task to use meas_extensions_scarlet instead of the scarlet functionality in meas_deblender"""
"DM-19717","Improvement","ip_isr",1,"Add setup_module to ip_isr unit tests.","""Memory testing was not enabled correctly for all ip_isr unit tests."""
"DM-19710","Story","astro_metadata_translator",1,"Add astro_metadata_translator corrections for older HSC data","""Older HSC files can have incorrect DATA-TYP headers, causing some science frames to be ingested as calibrations and probably vice versa.  The OBJECT headers seem to provide values that could be used instead if we can completely enumerate the values used for calibrations; given the finite time duration of the problem.  [~furusawa.hisanori] also reports that the STARS database at NAOJ should be updated with correct values for these, so we could also query that to obtain more complete corrections for all potentially-incorrect files.    Priority for this ticket should be to get in a fix that enables the correct Gen3 Butler ingestion of all affected science frames in the RC2 dataset, which I can provide a complete list of later.  We can create a new ticket for a more thorough fix if the solution here is more localized.    [~tjenness], please steal this if you think you'll have time to work on it today.  If not I'll be bugging you about the best way to approach putting the corrections in astro_metadata_translator."""
"DM-19709","Story","cp_pipe",20,"Write a first version of a defect finding task","""Lab testing of ComCam motivates a first pass at developing some long-overdue calibration product production code, as this will allow the ComCam commissioning team to efficiently assess performance as a function of temperature (among other things) as they acquire lab data over the (past and) coming weeks.    The ticket will cover making a first pass at writing a defect finding task to support this work.    Defect Task:   * Find bright & dark pixels from darks and flats   * Persist as ASCII text files so they can be treated as defects in the normal (old & bad) way   * Summary stats for each amp (and for each sensor)    Task should be able to run on either single master calibs (both darks and flats), or a list or raw input files, processing each as it should, and applying pixel-wise cuts to reduce the false-positive rate, _i.e._ making use of being fed multiple raw inputs."""
"DM-19731","Story","obs_subaru",2,"Investigate inaccuracy of initial HSC WCSs","""Gen3 ingest needs to be able to generate inclusive on-sky regions for all visits, using raw WCS and potentially camera geometry.  As those initial WCSs are inaccurate, we expect to need to pad somehow to ensure the region always includes the true region, even if it's much larger.    As a result, we need to look at the difference between some initial HSC WCSs and their post-astrometry counterparts.    This investigation could also be informative for future attempts to fit initial astrometry with as few free parameters as possible."""
"DM-19726","Story","Developer Infrastructure",3,"update efd-kafka prometheus deployment","""The {{prometheus-operator}} chart, in addition to providing CRDs for configuring prometheus scraping, bundles some extra goodies, such as grafana dashboard, that are not present in the {{prometheus}} chart."""
"DM-19732","Improvement","ip_isr",1,"remnant ip_isr debug statement left in","""An errant debug fits write was left in."""
"DM-19743","Story","ts_ait",3,"Knowledge transfer 1 - ATDome M2 ATHexapod","""Create documentation for:   * Document how M2 is connected to the computer   * Document how to configure AuxTel Dome cRios    * Document how to configure PI Hexapod"""
"DM-19742","Story","ts_auxiliary_telescope",1,"Test new release for the cRio software on ATDome ","""Test new release for the cRio software for ATDome. This should stop shutter commands when using the emergency stop."""
"DM-19740","Bug","ts_middleware",1,"Fix dependency for EFD runtime RPM","""The EFD runtime RPM requires _tclsh_ but the current version doesn't resolve that correctly. That dependency resolution needs to be corrected for the RPM to install without using special flags."""
"DM-19739","Story","ts_auxiliary_telescope|ts_pointing",1,"Add atmcs data to atptg_ataos integration test","""Update the atptg_ataos integration test to include getting target status from the atmcs instead of the atptg component for the ataos."""
"DM-19733","Story","meas_deblender",8,"Make scarlet models more general","""In order to implement symmetry in the new deblender we need to move to a model that allows components to have more control over the parameters they require (to include fractional pixel shifts dy and dx) and how their updates are calculated (to calculate updates to dy and dx). This requires an update to scarlet."""
"DM-19764","Story","ts_aos",3,"MTAOS - WEP Algorithm Integration","""Integrate the WEP into MTAOS."""
"DM-19762","Story","ts_auxiliary_telescope",3,"Write tracking integration test for atptg, atmcs, ataos, athexapod & atpneumatics","""The test should set a starting altitude, azimuth and tracking_duration. It will then check that as tracking occurs that no CSCs go into a fault state. """
"DM-19761","Story","jointcal|pipe_tasks",2,"Test run gaia dr2 refcat with jointcal and/or processCcd","""-I have created a """"symlink repository"""" for HSC at {{/scratch/parejkoj/hsc}} (should be group-writeable by {{lsst_users}}), which we can use to do a trial run of processing data with the Gaia DR2 catalog in jointcal and/or processCcd. This is easier than moving data or symlinking into the read-only {{/datasets/ref_cats}}.-    We now have a {{/datasets/refCats/htm/v1/gaia_DR2}} symlink to my {{/scratch}} gaia refcat, which we can use to do a trial processing run with this new catalog in jointcal.    [~hchiang2]: can you please help me start an appropriate HSC run (PDR1, RC2 or something else small-ish I don't really care) using this? I'm not sure what we need to do to test it other than just demonstrating that it runs to completion: it has more sources than Gaia DR1, but not more than PS1, and it's still only usable for astrometry."""
"DM-19758","Story","ts_main_telescope",3,"Prepare for TMA software workshop","""Prepare for the upcoming workshop, review code and build instructions, review documentation and suggest improvement, update agenda and add details"""
"DM-19757","Story","System Integration and Test",2,"Review EAS XML and add topics as necessary","""Review the current EAS XML and add items as necessary to cover the entire EAS sensor suite in type and number. Create ts_sal runtime thereof."""
"DM-19756","Story","ts_middleware",3,"Create updated RPI SAL SDK image","""Rebuild the SAL  V3.9 and OpenSplice V6.9 for the Raspberry Pi environment and create an SDK image for use by the EAS contractor"""
"DM-19752","Bug","obs_lsst",0.5,"monowl string parse in gen2 butler ingest of ts8 data","""uncovered a slight issue with ingest, had put in MONOWL into the comcam (ts8) headers, but they were as strings, and ingest barfed saying it couldn't do a logical comparison or some such... I got around it by deleting the card and explicitly adding it as an int.    original error returned:    """
"DM-19751","Story","Middleware",1,"Study the Kubernetes","""Take a free course ([Scalable Microservices with Kubernetes)|https://classroom.udacity.com/courses/ud615] on Udacity to learn the Kubernetes with the microservice."""
"DM-19750","Story","ts_aos",2,"Test the updated AOCLC with PhoSim","""Test the AOCLC with PhoSim and the WEP and OFC interface classes. This is to test the updated code in the [DM-19749|https://jira.lsstcorp.org/browse/DM-19749]."""
"DM-19773","Story","ts_auxiliary_telescope|ts_calibration",1,"Debug device not detected issue","""Compiled C++ program does not detect the USB Spectrograph (FiberSpectrograph) connected to the Linux machine. Debugging to figure out if its a hardware or software issue"""
"DM-19772","Story","Developer Infrastructure",1,"SQRE network routing reconfig post NOAO core changes","""NOAO/Tucson CIS is planning to re-plumb the core network on Saturday, 2019-05-18.  DM Jenkins OSX builds will need to be disabled/reenabled before/after this work and a console cable will need to be connected to the SQRE layer3 switch for manual reconfiguration."""
"DM-19771","Story","ts_auxiliary_telescope|ts_calibration",2,"Debug FITSIO LabVIEW Library error","""Debug CFITSIO library error and get the .so file working with the current version of fits library. This is a prerequisite to update FiberSpectrograph code to use SAL version 3.9."""
"DM-19770","Story","ts_main_telescope",1,"Backup Hexapod and Rotator management PC and support requests from SLAC","""Tony Johnson has started working on Rotator and has sent us a bunch of questions. This task will be used to support SLAC and also to backup harddrive of Management PC without which Tony would not be able to operate the rotator. """
"DM-19768","Story","jointcal",1,"Fix jointcal handling of coordinate errors","""Since we didn't have a refcat with coordinate errors, I couldn't write a test of jointcal's use of them. And thus I got it wrong: disabling {{config.astrometryReferenceErr}} resulted in an exception because the error field is {{coord_raErr}} not {{coord_ra_err}}!    Unrelatedly, but I might as well fix it as part of this work: it looks like jointcal is trying to apply colorterms when loading the astrometry reference catalog. That is both not necessary, and unhelpful when the astrometry refcat doesn't have useful photometry (e.g. Gaia). Might as well fix that on this ticket, too."""
"DM-19766","Bug","astro_metadata_translator",2,"DECam instcals fail to process with invalid DateTime","""When a user ingests a DECam instcal and runs {{exposure.getVisitInfo().getDate()}}, it returns an empty DateTime. ProcessCcd naturally assumes a non-empty DateTime and fails with a """"DateTime not valid"""" error.    We think this problem originates in {{astro_metadata_translator}}, which likely was made to work with DECam raws and not DECam instcals. Instcals are apparently missing some of the expected header keywords.    This ticket is to fix things so ingested instcals have proper DateTimes and to add a test (presumably in {{astro_metadata_translator}}) that checks an instcal header.    See the full discussion on Slack [here|https://lsstc.slack.com/archives/C2JPMCF5X/p1557874729491100]."""
"DM-19791","Story","ts_auxiliary_telescope",2,"Update tai_from_utc in ts_salobj to handle leap seconds","""In ts_salobj DM-19385 I coded {{Domain.tai_utc}} to return a hard coded number, with the intention that the code be changed to use a better solution (e.g. emulate ts_sal) at some point. This ticket is for that """"better solution"""".    Also we need a function that returns the current TAI, not just tai_from_utc. Most of the time we only want the current time. The main use case for tai_from_utc is converting the received time sample metadata provided by DDS to the private_rcvStamp field in read DDS samples. See DM-21097 for that function.    I propose to use astropy. But we have to update astropy whenever a leap second was due and it will probably give slightly incorrect answers near a leap second. To quote a warning from the documentation for {{astro.py.time.TimeUnix}}:    and {{astropy.time.Time.now()}} uses {{datetime.utcnow}} and the {{datetime}} library does not handle leap seconds."""
"DM-19780","Story","Requirements Documents",1,"Revise LCR-1554 (corrections to LSR and OSS regarding flowdown of SRD ellipticity correlation requirements)","""Produce a revised version of the requirements proposal in LCR-1554, to take into account concerns expressed at the voting stage by Austin and Bill G."""
"DM-19811","Story","ts_aos",1,"Setup the Linux Desktop","""Setup the linux desktop returned by IT. The system OS was re-installed. This task will install the needed application and personal settings for the software development environment."""
"DM-19810","Story","ts_main_telescope",1,"Backup HexRot Management PC for copy to SLAC","""SLAC needs a copy of the Hexapod Rotator management pc software"""
"DM-19807","Story","daf_butler|obs_base",0,"Avoid savepoints in Gen3 ingest and bulk conversions","""The savepoints used to implement nested transactions are taking the bulk of the time in raw and calibration in Oracle.  See if we can implement lighter-weight, Python-side nested transactions for at least some operations."""
"DM-19802","Improvement","jointcal",2,"Fix jointcal ra/dec bounding box calculations","""[~sogo.mineo] noticed that jointcal does not correctly calculate the field center and radius to load the reference catalog. If the center is near 0/360, the radius may end up being ~360º, causing out of memory errors due to all of the refcat being loaded. The calculations at {{jointcal.py:524}} need to be redone to properly handle that wrap-around. SpherePoint should help with this."""
"DM-19801","Story","alert_packet|alert_stream|sample-avro-alert",1,"Gracefully handle failure to retreive alerts from disk","""Per https://github.com/lsst-dm/alert_stream/issues/23, when {{sendAlertStream.py}} tries to read a file which contains no data, it throws a {{ValueError}} with a pretty obscure traceback. Please handle this more gracefully."""
"DM-19812","Story","dm_dev_guide",1,"Remove rule on return value policy from pybind11 style guide","""The consensus on RFC-597 was that the [return value policy rule|https://developer.lsst.io/pybind11/style.html#the-reference-internal-policy-shall-be-used-for-functions-or-properties-giving-write-access-to-internal-data-members] in the pybind11 style guide is unneccessary, so remove it. Developers will be expected to directly apply the pybind11 documentation concerning return value policies."""
"DM-19827","Story","DM",3,"Set up JSR 2019 review presentation outline","""set up the review slide deck .. help to structure the sessions ahead of DMLT F2F"""
"DM-19822","Improvement","Documentation",1,"Updates to ""adding a new package to the build"" developer docs","""I recently created the {{ap_pipe_testdata}} package, and found some places where the developer guide could be clarified.    1. Specify in what cases an RFC is *not* required to add a new package. My pair coder and reviewer agreed with my interpretation that a new testdata package is not """"intended for distribution to end users"""" and I therefore did not need an RFC.    2. Configure things on GitHub for the new package:   * Disable squash and rebase merging (this part is pretty clear as-is)   * The part that's not clear is the steps provided to configure branch protection for master. The screenshots and directions are outdated; the services on the """"Integrations and services"""" screen appear to be deprecated and I am not sure where one would put a """"simple Travis script"""" like the flake8 example. I had to click """"Add rule"""" from the """"Branches"""" screen to get to a screen similar to """"Branch protection for master"""" as shown in the dev guide. However, without something checked under """"Require branches to be up to date before merging,"""" it does not let me add a new """"rule."""" So I skipped this. In my situation with a new testdata repo, it seems rather superfluous anyway since there is no code. More guidance is needed here.   * Set the team membership properly. Specifically, for a package like mine, set it to both """"Data Management"""" and """"Overlords."""" This is the step I misunderstood and inadvertently skipped. Please explain what team membership is, how to set it properly (why is there a team called Overlords?!), and mention that Jenkins will pass even if you don't do this, but the daily/weekly build will fail.    3. Explicitly say that you must add {{setupRequired(new_package_name)}} or {{setupOptional(new_package_name)}} to the appropriate {{other_package/ups/other_package.table}} files, i.e., any stack package which imports the new package. And if there are C++ dependencies involved, you also need to update the appropriate {{other_package/ups/other_package.cfg}} files. (Please note that giving the full example path to the files which must be updated is helpful throughout, even when there is a link included.)    4. Add the new package to {{lsst/repos/etc/repos.yaml}} following the conventions there. *Merge this change to master before you attempt to run Jenkins;* it is a special case exemption from the usual code review process.    5. If it is a Git LFS-backed repo (which mine was), add optional dependencies to {{lsst/lsstsw/etc/manifest.remap}} following the conventions there. Include this in the code review (do not merge it in advance like you must do for the changes in {{lsst/repos}})."""
"DM-19818","Bug","daf_butler",1,"Fix Gen3 Butler pickling broken on DM-19638","""DM-19638 added a new butler constructor argument and broke pickling."""
"DM-19832","Story","ts_aos",2,"set up windows host for t2sa","""need to setup a windows server with a static IP on the LSST network, with a SpatialAnalyzer license. It will host the vendor's T2SA application, which is an intermediary between the alignment CSC and the laser tracker hardware."""
"DM-19828","Story","meas_mosaic",3,"Investigate oddness in error propagation with meas_mosaic's photoCalib","""In working on DM-19189, I have been looking at the S/N distributions of the various fluxes  (raw instrumental and calibrated) from single frame processing (where here {{S/N = flux/fluxErr}} from the catalog).  The S/N distributions look as expected for the raw instrumental fluxes, the calibrated values based on application of the photoCalib of {{jointcal}} outputs, and the {{meas_mosaic}} solution using the """"old style"""" calibration (i.e. using {{meas_mosaic}}'s own {{applyMosaicResultsExposure()}} function – which uses the persisted {{fcr}} dataset to apply the calibration).  However, the S/N distribution when applying the {{photoCalib}} from {{meas_mosaic}} is not at all as expected (plots to be attached). Look further into this pathology and what might be causing it."""
"DM-19853","Bug","ImgServ",2,"SODA examples at LSP service endpoints need to return the right host names","""This is reported by KT.  Currently it's returning the pod name (via gethostbyname()) in the links  returned for /examples.     The correct hostname should be the k8s namespace:  lsst-lsp-int-dax, lsst-lsp-stable-dax."""
"DM-19848","Epic","ts_main_telescope",20,"TMA Work Phase 1","""TMA Training & Review of Labview-based vendor software in Tucson & Spain.    Also any on-going work & support regarding the TMA."""
"DM-19847","Epic","ts_main_telescope",20,"Coating Chamber Software Support","""Initial Reviewing / Learning of Coating Chamber Vendor Software    This will also include:   * learning/support during M2 coating   * support during M1M3 coating   * possible training at VA for WICOM"""
"DM-19845","Improvement","ImgServ|metaserv",1,"Bring up imgserv and metaserv on lsst-lsp-int-dax","""Need to configure these DAX services to run in the new Kubernetes environments on LSP."""
"DM-19839","Story","pipe_tasks",2,"Fix bug in recent DcrCoadd PSF calculation","""The PSF calculated for DcrCoadds in DM-19517 fails in some cases for Decam data. The source detection task that was used incorrectly scales the source detection threshold, and can result in no sources being detected. The detection Task should be switched to the base version, and it should possibly only be a warning if psf measurement fails, rather than an error."""
"DM-19871","Story","obs_base",1,"Fix validity range end in Gen3 calibration bootstrapping","""The bootstrap scripts added on DM-19638 upgrade Gen2's dates to Gen3's datetimes without adding one day to the end dates.  Because those intervals are inclusive instead of half-open, that means we end up with a day-long gap between adjacent intervals."""
"DM-19859","Story","ts_qa",2,"Add XML tests for Unit and Description fields","""Add tests on ts_xml for <Unit> and <Description> fields, in accordance with [https://confluence.lsstcorp.org/display/LTS/SAL+XML+Unit+Definition+-+Discussion].  Also, add tests for XML Version; see VERSION file in the repo."""
"DM-19858","Bug","Firefly|SUIT",1,"Ensure that Portal / Firefly deployments are insensitive to trailing slashes on the application root","""Please ensure that all deployments of Firefly applications visible to LSST are insensitive to the presence of a trailing slash at the application root.    E.g., """"lsst-lsp-stable.ncsa.illinois.edu/portal/suit"""" vs. """"lsst-lsp-stable.ncsa.illinois.edu/portal/suit/""""    This should apply to lsst-demo, to Adam's /firefly deployments, and to the actual Portal application(s)."""
"DM-19857","Story","ap_verify",2,"Update ap_verify to use new DECam defect ingestion","""Now that we have a new way to ingest DECam defects, we need to update ap_verify and the two ap_verify datasets (ap_verify_hits2015 and ap_verify_ci_hits2015) to use this new mechanism."""
"DM-19887","Story","skymap",0.5,"Switch skymap to geom rather than afwGeom","""SkyMap uses lots of lsst.afw.geom when it mostly only needs to use lsst.geom.  Replace the afwGeom where appropriate."""
"DM-19886","Story","HeaderService",5,"Preserve blank line from templates into output header files","""The Header Service reads in the primary and segment hdu from templates that define the content of the headers. The fitsio (Erin Sheldon's) module doesn't not preserve or store this at the moment. We need to make a request to make sure that these can be read, stored and passed on to the output files created by the HeaderServiuce."""
"DM-19885","Story","ts_qa",3,"Export the ts_xml job into the TSSW Jenkins environment","""This task covers the work to finish the export of the ts_xml job into the TSSW Jenkins instance.   * Configure and run the ts_xml job.   * Create a Jenkins user on the LSST GitHub organization to use for Job Credentials."""
"DM-19884","Story","ip_isr",1,"Add configs to __all__ in isrTask.py","""The {{RunIsrConfig}} class was omitted when {{__all__}} was added to {{isrTask.py}}.  This breaks running `RunIsrTask` more than once with the same rerun but different data ids.  Adding the configs fixes this."""
"DM-19881","Story","ts_auxiliary_telescope",2,"Make dds salobj compatible with SAL","""dds salobj is not compatible with SALPY. See the last comment for details of what was wrong."""
"DM-19880","Story","ts_auxiliary_telescope",3,"Update scripts in ts_standardscripts for schema+dds scriptqueue","""Update the scripts in ts_standardscripts to work with dds ts_salobj and schema+dds ts_scriptqueue"""
"DM-19877","Story","obs_lsst|pipe_drivers|pipe_tasks",1,"Replace PropertySet.get with getScalar or getArray","""DM-19873 is changing the API of PropertySet.get() such that it will now return a default value rather than raising KeyError. Before that can happen, all extant calls to {{get()}} must be replaced to avoid any surprises.    The approach I will take is to change get() so that it always throws an exception and then wait for tests to fail. This may lead to some remaining usage of {{get()}} in code that is not used."""
"DM-19876","Bug","ctrl_iip",1,"Remove old SAL C++ code, and update requirements.txt ","""Remove old SAL command C++ code.  The code is from a previous version of SAL, and wouldn't work anyway.  Any commands we may need will be created in another ticket. Also update requirements.txt"""
"DM-19875","Story","ts_auxiliary_telescope",0,"Clean up Script and ScriptQueue XML","""The Script and ScriptQueue XML both use topic-specific enumerations when shared would probably be better (and certainly more common).    This is especially important for Location but also useful for ScriptState and ScriptProcessState. I am less convinced about the three metadata enumerations, but using the same technique for all is simplest."""
"DM-19874","Improvement","ip_isr|obs_decam",8,"Add support for decam illumcor calibration products","""Partway through DM-18417, it became clear that illumination correction appears to be needed to eliminate false positive sources from difference imaging on nights with high sky brightness. While illumination correction is a standard step in the DECam community pipeline (CP), and """"illumcor"""" CP data products exist for the HiTS2015 dataset, we have never used them with the LSST Science Pipelines.    This ticket is to add the ability to ingest, and subsequently use during ISR, the illumination correction calibration products provided by the DECam community pipeline. They are multi-extension FITS files much like the """"cpBIAS"""" and """"cpFLAT"""" masterCals we have been using, and should be able to be ingested and used in a similar way.    There will be Mappers."""
"DM-19873","Story","daf_base",2,"Implement PropertySet.getitem and return get()","""Following the adoption of RFC-596:  * Add getitem support (returning scalars in all cases)  * Undeprecate {{get()}}, modifying it to return scalars and to support a default value.  * Investigate adding {{update()}} method."""
"DM-19890","Story","ts_ait|ts_auxiliary_telescope",2,"Auxiliary Telescope in-dome software test","""Ticket for the work being done in Chile with Aux Tel. """
"DM-19905","Story","ts_aos",1,"Attend the ComCam MIE Pre-ship Review","""Attend the ComCam MIE Pre-ship Review:    [https://confluence.lsstcorp.org/display/LTS/MIE+Pre-ship+Review]"""
"DM-19902","Bug","afw",0.5,"String representation of Observatory coordinates flips lat/lon","""The string representation of the Observatory class prints """"W"""" following the latitude and """"N"""" following the longitude. These should be switched."""
"DM-19897","Story","ts_main_telescope",8,"M1M3 Support and Thermal Documentation","""Write up some informal documentation on the M1M3 support system and M1M3 thermal system."""
"DM-19896","Story","ts_aos",2,"Document the use of AOS closed loop simulation","""This task is to document the use of AOS code by the docker-compose with the PhoSim. This task will also prepare the related docker image for Chris to write the organizer script with MTAOS.    This task also reviews the TSSW Organization and Management Document (DM-19898). """
"DM-19894","Story","Middleware",2,"Play the Kubernetes API","""This task is to play the Kubernetes API by gcloud sdk to be familiar with it."""
"DM-19891","Story","meas_algorithms",1,"Fix __eq__ for defects class","""Zipping the bboxes only works if objects are same length, so check that first."""
"DM-19919","Story","ts_auxiliary_telescope",0,"Update test_enumerations_present for changes to Script enums","""In DM-19875 I updated Script and ScriptQueue enums to be shared. This requires a trivial change to ts_sal's test_sal test_enumerations_present method because it changes the Script enum names.    I will implement the ticket, but I leave it to [~dmills] and [~rbovill] when to merge it, since it should be coordinated with the next release of ts_xml."""
"DM-19916","Story","daf_butler",2,"Investigate URI inconsistencies in daf_butler LocationFactory","""In a [GitHub pull request|https://github.com/lsst/daf_butler/pull/160] [~dinob] makes the case that URIs in the Location classes are not working properly.  His fix is not quite right so take the PR and see if it's possible to fix things such that URIs with relative paths are properly handled."""
"DM-19908","Story","ts_main_telescope",2,"M2 Support part 3","""Give support on the software for the M2"""
"DM-19952","Story","ts_main_telescope",1,"Partially update HeaderService for dds salobj","""Convert some of hslib https://github.com/lsst-dm/HeaderService/blob/master/python/HeaderService/hslib.py for salobj as an example of how to do it."""
"DM-19972","Bug","Firefly",2,"ds9 region file upload dialog misplaced the information","""The """"load region file"""" dialog has the information text """"No file chosen"""" outside the dialog.   Please see the attached screen.  My local Firefly build version:   Version v2018.2  Type Development  Build Number 0  Built On Fri Apr 26 16:32:00 PDT 2019  Git commit 3c4c504b8          FIREFLY-96"""
"DM-19969","Story","ts_qa",1,"Coordinate the v3.10.0 Release of SAL and XML","""I was tasked with coordinating the Release of SAL and XML v3.10.0.  This task is to track that work."""
"DM-19968","Bug","ts_auxiliary_telescope",0,"Fix sphinx errors in ts_scriptqueue","""ts_scriptqueue v2.0.0 has some sphinx errors caused by trying to export ScriptState. The fix is trivial."""
"DM-19964","Story","ts_aos",2,"Read the ts_MTAOS Code and Document","""Read the ts_MTAOS code and document to be familiar with it. This task will also to learn the Python asyncio library to have an initial understanding of how to use it. This task also plans to read the code of ts_salobj."""
"DM-19962","Story","ts_ait",5,"First week at the summit","""Shadow Tiago, learn about integration, work on auxiliary telescope slewing, develop unit tests for ATTCS"""
"DM-19961","Story","obs_subaru",0.5,"Add region padding to HSC config for Gen3 raw ingest ","""The investigations on DM-19731 did not (as promised there) yield config changes on DM-19638.  Add the config that fell through the cracks."""
"DM-19982","Story","ts_aos",3,"Integrate ts_MTAOS with PhoSim","""Integrate ts_MTAOS with PhoSim for the AOS close loop simulation. This task will update the xml file for the intra- and extra-focal visits."""
"DM-19994","Story","DM Subsystem Science|Requirements Documents",2,"Flow down LCR-1554 changes to DMSR","""DMS-REQ-0362 derives from the OSS ellipticity correlation requirement OSS-REQ-0390.  As the latter requirement was long incorrect, presumably DMS-REQ-0362 is as well and the corrections from LCR-1554 will need to be flowed down to it, and, given the nature of the LCR, additional DMSR requirements may be needed to parallel new ones added at LSR and OSS level."""
"DM-19991","Story","meas_deblender",3,"Apply changes from deblending sprint to master","""To complete the DRP deblender sprint from May the changes must be pushed to master. This ticket includes pushing the required changes to scarlet and updating {{meas_extensions_scarlet}}, {{pipe_tasks}}, and {{pipe_drivers}} with the appropriate changes so that scarlet v0.5 can be run on LSST."""
"DM-19989","Story","meas_algorithms|technote",8,"Document how to generate a refcat","""The steps required to turn a collection of files from some archive into an LSST-style reference catalog need to be written down so that the next catalog is easier to generate. A DM Tech Note seems like the appropriate place for such a description."""
"DM-20020","Improvement","ts_auxiliary_telescope",1,"Update script queue to use get_scripts_dir functions for script paths","""Update ts_scriptqueue to use the {{get_scripts_dir}} functions in ts_standardscripts (that function exists) and ts_externalscripts (that function will be added as part of this ticket)."""
"DM-20019","Bug","afw",2,"Fix pickling of String Fields","""While finishing DM-19616, I noticed a problem with the multiprocessing Pool and a schema that contained a {{String}} {{Field}}. I added a test to afw that reproduces this error, and I will fix it on this ticket.        My guess is that I need to tweak the pybind11 {{py::pickle}} code in {{schema.cc}}, possibly special-casing the String FieldBase type."""
"DM-20010","Story","ts_ait",5,"Summit week 2","""Continue summit work, including ATTCS unit tests, slewing and dome integration tests, hitting e-stop button when we accidentally slew the telescope into a crane, etc.    Returning to Tucson fri/sat"""
"DM-20008","Bug","obs_lsst",1,"AuxTel translator in obs_lsst needs TSTART adjusted","""The current TSTART date in {{obs_lsst}} _LsstAuxTelTranslator_ is stopping ingestion of files now that we are past that date. Since we still do not have """"mountain"""" headers, that date needs to be adjusted further into the future to accommodate the situation."""
"DM-20046","Improvement","meas_algorithms",1,"Cleanup docstrings in detection.py","""As part of our weekly brown bag discussion, we did a deep dive into SourceDetectionTask and noticed a number of confusing or misleading docstrings. Here are the notes I took during the brown bag. I'll try to translate these into cleanups shortly, so I don't forget:    {quote}  DetectionConfig: threshold, thresholdValue  DetectionTask:      detectFootprints: doSmooth & sigma      convolveImage: under what circumstances would you not want `doSmooth==True`?  Better document relationship between reEstimateBackground and thresholdParity? - `applyThreshold` has a fun pair of `if`s, which might then be removed in `clearUnwantedResults`    remove `makeSourceCatalog = run  {quote}"""
"DM-20045","Bug","ts_auxiliary_telescope",1,"Fix azimuth comparison in DomeTrajectoryMCS","""lsst.ts.standardscripts.auxtel.integration_tests.DomeTrajectoryMCS has a bug: it compares azimuth without taking wrap into account."""
"DM-20052","Story","HeaderService",1,"Rename DDSSubcriber to DDSSubscriber","""There was a misspelling on salpytools that named a function  DDSSubcriber, it has been changed to to DDSSubscriber. The HeaderService need to be updated to reflect this simple change."""
"DM-20048","Bug","SUIT",2,"Unauthenticated Redis database - lsst-sui-tomcat01.ncsa.illinois.edu","""This is a recreation of a jira ticket submitted by NCSA security in our internal ticket system:    """"Qualys scan has found an instance of Redis that seems to allow unauthenticated connections on lsst-sui-tomcat01.ncsa.illinois.edu    We would like to make sure only authorized users and hosts are able to connect to this redis instance. There is concern that maybe the Jupiter hubs users/machines can connect to this database."""""""
"DM-20073","Story","astro_metadata_translator",2,"Add ability to construct ObservationInfo from kwargs (or allow properties to be changed)","""Currently an ObservationInfo can only be constructed from the metadata of an observation. There are some cases where it would be useful to create an ObservationInfo from either kwargs or else update values in an ObservationInfo after creation (currently they are immutable).    DM-19978 would be simplified if an ObservationInfo could be constructed from known values."""
"DM-20072","Story","Documentation",3,"Create support infrastructure for author handling in LSST commissioning papers","""For the commissioning papers (and overview paper) we need a scheme for managing author lists in a standardized way.  The overview paper has some infrastructure for this but the scripts need to be modified to separate the author list for a specific paper from the author full name and affiliation.    In theory the name and affiliation information should come from contacts DB. In the interim I will use an intermediary YAML file."""
"DM-20067","Story","ts_auxiliary_telescope",2,"Update at_tracking to use salobj 4.0","""Update the newly written at_tracking integration test to use salobj 4.0."""
"DM-20115","Bug","ts_auxiliary_telescope",2,"Fix circular dependency between ts_scriptqueue and ts_standard/eternalscripts",""" ts_externalscripts and ts_standardscripts depend on ts_scriptqueue because that is where {{BaseScript}} is defined.    ts_scriptqueue depends on ts_externalscripts and ts_standardscripts in order to find the scripts in those packages. (This is an optional dependency in the ups table).    This is a real nuisance so I propose to break the dependency by moving {{BaseScript}} into ts_salobj. It's a bit of clutter there, but otherwise we need a new package, which seems overkill for a single class and its unit tests.    For simplicity I propose to merge DM-18012 first, then implement this ticket. After both are merged to develop I will tag new versions of ts_salobj and ts_scriptqueue."""
"DM-20113","Story","Requirements Documents",1,"Prepare LDM-635 for RFC","""At DMLT meeting in early June I was told to prepare LDM-635 for RFC. This mainly requires I fix the sort order of the requirements."""
"DM-20110","Story","ts_calibration",2,"Containerize LinearStage CSC","""Containerize the LinearStage CSC into a docker file. """
"DM-20109","Improvement","ip_isr",2,"Improve ip_isr log messages to be more explicit","""The log messages in ip_isr occasionally contradict what actually happens due to config/data conflicts.  This is most obvious in the fringe application.  This ticket will review the log messages and add clarifications about no-ops and surprises."""
"DM-20108","Story","HeaderService",1,"Header service should not defer python imports","""The header service failed yesterday whilst operating because a deferred import to Astropy could not be completed. The header service should do all required imports at launch time so that we can detect problems early."""
"DM-20106","Story","ts_main_telescope",5,"TMA Software Workshop","""TMA Software Workshop in Spain with vendor."""
"DM-20089","Bug","ts_auxiliary_telescope",1,"Update remaining code in ts_standardscripts for scriptqueue 2.1","""In DM-19880 I missed some code that needs updating for ts_scriptqueue 2.1. Fix this!"""
"DM-20078","Story","mops",5,"Solar System Collaboration Sprint #2","""Participate in the SSSC Sprint #2.    Prepare the materials for the LSST status update presentation, update the SSSC github with most recent source code and binaries."""
"DM-20132","Story","ts_auxiliary_telescope",1,"Rebuild containers with SAL 3.10 and redeploy containers in the lab.","""I'll have to make some updates do the docker and compose files to accomplish this task. I'll create this task to capture the work. """
"DM-20129","Story","meas_extensions_scarlet",5,"Create unit tests for meas_extensions_scarlet","""Currently there are no unit tests for {{mea_extensions_scarlet}}. Tests should be implemented to ensure that changes in the stack do not break this package."""
"DM-20128","Story","meas_extensions_scarlet",13,"Create unit tests for scarlet","""The old unit tests need to be modified and new tests need to be created for scarlet v0.5. A separate ticket will be created for unit tests in the {{meas_extensions_scarlet}}."""
"DM-20125","Story","Developer Infrastructure|ts_main_telescope",2,"Review spec and order PXI substitute hardware","""To properly test the TMA software in Tucson a PXI like system will be installed using a standard desktop PC. Review the spec for such a machine and issue a req for it"""
"DM-20124","Story","ts_main_telescope",2,"Review updated TMA deployment documents","""Review the latest set of deployment documents for the TMA"""
"DM-20123","Story","Infrastructure|ts_middleware",3,"Prepare new EFD hardware for upgrades","""Manage the preparation of the new EFD hardware (24 dell servers) so that they can be upgraded before shipping to Chile. Test proposed upgrades on a sample machine and then issue a req for same"""
"DM-20121","Story","ts_auxiliary_telescope",3,"Make GenericCamera configurable","""For this task I'll convert the GenericCamera CSC to use ConfigurableCSC. I'll also add some tests."""
"DM-20155","Story","ts_auxiliary_telescope",1,"Deploy docker AT_CSCs with SAL 3.10(Lab)","""Update containers and write documentation on deploying docker containers. [https://confluence.lsstcorp.org/pages/viewpage.action?pageId=110233227]         Specific CSCs included are Electrometer, LinearStage, Monochromator, ATSpectrograph (built by Tiago deployed by Eric, but remains untested)."""
"DM-20154","Story","obs_base",8,"Implement new initial WCS design","""The close of DM-19951 describes a new design for how we create an initial WCS from the raw exposure VisitInfo metadata. This ticket is to implement that design. In summary:    * Write tests against sensor bounding boxes on known data (e.g. {{testdata_*}}).  * Write a new function to create a SkyWcs from VisitInfo and Detector ({{createInitialSkyWcs}}?).  * Call that function from {{exposureFromImage}}.  * Reorder the reading of raw VisitInfo and WCS metadata to deal potential metadata stripping problems.  * Check that all existing cameras use this code path, and not some custom Exposure metadata handling.  * Turn off {{addDistortionModel}} in ISR for all cameras, so that the above WCS does not get overwritten."""
"DM-20153","Story","ts_auxiliary_telescope",0,"Remove unused content from ts_externalscripts","""Delete unused content from ts_externalscripts:  * unused utility functions  * CalSysTakeData (use the version in ts_standardscripts instead)  * LaserCharacterization (superseded by a Jupyter notebook)"""
"DM-20152","Story","ts_auxiliary_telescope",2,"Update the LaserCoordination script for dds salobj and schema-based configuration","""Please update the LaserCoordination script in ts_externalscripts to be compatible with dds salobj (ts_salobj v4.1) and schema-based scripting (ts_scriptqueue v2.1).    I suggest you update the script for ts_scriptqueue v2.1, which means the schema is returned using a property named {{schema}}. There is an update in review that will make trivial further changes (truly trivial and I'm happy to do the work), but I think we'd really like to have a version of ts_externalscripts that works with ts_scriptqueue v2.1 before I make the additional changes for ts_scriptqueue v2.2.    Please also fix flake8 issues. scons found the following:      Here are some resources:  * https://community.lsst.org/t/changes-in-salobj-4-the-dds-version/3701/2  * https://community.lsst.org/t/changes-to-sal-script-schemas-and-dds/3709/2  * DM-20089 shows the same update for some scripts in ts_standardscripts  * I am happy to answer questions about the conversion process  * [~ecoughlin] wrote LaserCoordination and can answer questions about the script"""
"DM-20151","Story","ts_auxiliary_telescope",2,"Update CalSysTake*Data scripts for dds salobj and schema-based configuration","""Please update the scripts CalSysTakeNarrowbandData and CalSysTakeData in ts_externalscripts for dds salobj (ts_salobj v4.1) and schema-based configuration (ts_scriptqueue v2.1).    Notes:  * ts_standardscripts already has an updated version of CalSysTakeData. I strongly recommend that you start from that, instead of what's in ts_externalscripts, and try to figure out the differences (if any). If there are no differences then please consider deleting the version in ts_externalscripts!  * I suggest you update the scripts for ts_scriptqueue v2.1, which means the schema is returned using a property named {{schema}}. There are updates coming that will make trivial further changes (truly trivial and I'm happy to do the work), but I think we'd really like to have a version of ts_externalscripts that works with ts_scriptqueue v2.1 before we make those changes.  * For the scripts you keep please add {{from calsys_take... import *}} to {{auxtel/\_\_init.py\_\_}}  * Please fix flake8 errors.    Resources:  * https://community.lsst.org/t/changes-in-salobj-4-the-dds-version/3701/2  * https://community.lsst.org/t/changes-to-sal-script-schemas-and-dds/3709/2  * DM-20089 shows the same update for some scripts in ts_standardscripts, including CalSysTakeData  * I am happy to help as wanted."""
"DM-20150","Story","HeaderService",1,"Comments shifted one character to right in current header","""When looking at a header created yesterday from AuxTel the first two blank keyword comments  are shifted one character to the right:      """
"DM-20145","Story","ts_auxiliary_telescope|ts_main_telescope",2,"Write SAL XML for the Watcher","""Write SAL XML files for the Watcher in ts_xml"""
"DM-20143","Story","afw",1,"Improve handling of blank keyword comments in FITS headers","""The HeaderService is now writing FITS headers to raw data that include header cards using 8 blank characters as the special comment keyword.  This is completely within the standard but the reader code in afw.fits is confused and stores them as keyword {{""""""""}} and value {{None}}.  This confuses things when output files are written.    Fix the reader. It may be simpler to move these blank keyword comments into {{COMMENT}} fields in PropertyList.  Since the order is lost once comments are read there is nothing to be gained from retaining the distinction between the two types of comments."""
"DM-20134","Story","HeaderService",5,"HeaderService should compute RA/DEC from AZ/EL","""     For ATHeaderService The keywords {{RASTART/END}} and {{DECSTART/END}} must be calculated from the above AZ/EL keywords by the HS"""
"DM-20169","Story","astro_metadata_translator",2,"Enable header fixups for decam and cfht","""On Slack there has been a request for fix_header to work for DECam data. Currently there is no search path available. Update to allow CFHT and DECam to have search paths defined. It may also be necessary to patch the obs packages to call fix_header."""
"DM-20160","Story","meas_extensions_scarlet",1,"Fix stackclub notebooks to use meas_extensions_scarlet","""We need to fix the stackclub notebooks so that users in the science collaborations can make use of scarlet v0.5 and the new {{meas_extensions_scarlet}} package. This ticket includes updating the stack club tutorials and using a selection of the last scarlet DESC-BTF slides for a quick presentation to stack club."""
"DM-20159","Story","Qserv",8,"Learn about k8s operators and provide a qserv-operator POC","""It seems a Qserv operator for k8s would be useful. I'll study how to build that first."""
"DM-20200","Story","ts_aos",3,"Update the ts_wep to Use the Eimage","""Update the ts_wep to Use the eimage. The [DM-19837|https://jira.lsstcorp.org/browse/DM-19837] had updated the phosim_utils and obs_lsst to ingest the eimage by butler."""
"DM-20198","Epic","ts_main_telescope",20,"Dome Work Phase 2","""This epic is to contain all work for the Dome.   This is a continuation from:   * DM-18309"""
"DM-20197","Epic","ts_environment|ts_facilities",20,"EAS Work Phase 2","""This epic is used to hold all stories associated with the Environmental Awareness System (EAS).   This is to continue work from:   * DM-17215   * DM-18732"""
"DM-20196","Epic","ts_arch",20,"T&S Deployment Phase 2","""This epic contains stories for all deployment work.   This is phase 2 for:   * DM-17888"""
"DM-20195","Epic","ts_middleware|ts_qa",40,"Middleware Testing Process & Infrastructure Phase 2","""This epic holds all the stories associated with testing the SAL & EFD."""
"DM-20194","Epic","ts_middleware",20,"EFD Work Phase 2","""This is hold the stories for all work done on the EFD.   This is continuation of    * DM-18555     """
"DM-20192","Improvement","ImgServ",5,"Refactor the Jenkins build job for Imgserv","""This revamp is motivated by streamlining the docker build process for SODA imgserv, including support for running unit testing framework in Jenkins-CI.    These are the 2 main tasks:  1) Remove obsolete dax / webserv job (eups build) 2) Enhance the docker build pipeline for dax_imgserv by breaking it into 3 separate stages: build, test, publish.          """
"DM-20190","Epic","ts_auxiliary_telescope|ts_main_telescope|ts_middleware",5,"T & S Documentation Phase 2","""This is the epic that will handle all the documentation stories.   This is phase 2 from:   * DM-18378     """
"DM-20184","Epic","ts_calibration|ts_main_telescope",20,"Alignment System (ASC)","""This epic will contain the stories for development and integration of the Alignment System.   This is phase two for:   * DM-17468   * DM-17469   * DM-18756     """
"DM-20183","Story","ts_middleware",2,"EFD writers indicating working but no information received","""After the issue on Friday with the EFD writers was fixed, the writers indicated that they were functioning. However, no information was received and inserted into the DB."""
"DM-20180","Epic","ts_environment",5,"DIMM & WeatherStation Development","""This epic contains the stories for the development for the DIMM and the Weather Station.  This needs to be done in conjunction with on-sky of the Auxiliary Telescope.   This is phase 2 of    * DM-17200   * DM-17668     """
"DM-20174","Epic","ts_ait|ts_auxiliary_telescope|ts_middleware|ts_pointing|ts_qa",20,"AT Software Component Integration at Calibration Hill","""This epic holds the stories for all auxiliary telescope integration work that is happening.  This is phase two of epics:   * DM-16913   * DM-16914   * DM-16915   * DM-16943   * DM-16944         Integration to be partitioned as follows:   # ATPointing + ATMCS integration    # ATPointing + ATDome + ATDomeTrajectory integration   # ATPointing + ATMCS + ATDome + ATDomeTrajectory integration        # ATPointing + ATAOS integration    # ATAOS + ATPneumatics + ATHexapod integration   # ATPointing + ATAOS + ATPneumatics + ATHexapod integration    Required CSCs:   * ATPointing   * ATMCS   * ATDome   * ATDomeTrajectory   * ATAOS   * ATHexapod   * ATPneumatics   * ScriptQueue   * Scripts    Resources Required:   * Integration & Test Environment   * SAL   * EFD   * AuxTel Scripts    Confluence links:   * [Auxiliary Telescope Mount and Mount Control System|https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=LTS&title=Auxiliary+Telescope+Mount+and+Mount+Control+System]"""
"DM-20173","Epic","ts_auxiliary_telescope|ts_middleware",20,"Integration and testing of AT software components","""Continuation of epic DM-16910.    This epic contains stories for testing and integration of software components at the Tucson Location - dealing mainly with the pLan testing and/or any other set up for integration testing in Tucson   # Allocate Linux Machines to private network   # Connect other AuxTel devices (embedded PCs, analog I/O, etc.) to private network   # EFD setup   # Puppet Deployment of EFD"""
"DM-20232","Story","alert_stream",1,"Pin version of fastavro in use in alert_stream","""Per https://github.com/lsst-dm/alert_stream/issues/24, the latest release of fastavro is incompatible with the serialized alert data in lsst-dm/alert_stream.    Long term, we need to fix the data. Short term, pin the version of fastavro to one that works in the Dockerfile."""
"DM-20222","Bug","ts_auxiliary_telescope|ts_main_telescope",0,"recommendedSettingsVersion information incorrect","""The recommendedSettingsVersion field of the settingVersions is mis-computed by ConfigurableClass: it needs to cwd to the config directory before running the git describe command."""
"DM-20205","Story","pipe_base",20,"Refactor PipelineTask interface","""This ticket will be done in two parts  * Refactor the interface used to write PipelineTasks, with knowledge learned prepairing for the gen3 demo, in preparation for a design review  * Take input from a design review and create the final interface"""
"DM-20203","Story","ts_qa",3,"Configure a Jenkins job to create daily RPMs and push to Nexus yum repo","""Create a Jenkins job to build the SAL library RPMs, push them to the AWS S3 buckets and then push them into the Nexus3 yum repo."""
"DM-20202","Story","astro_metadata_translator",2,"Fix CFHT MegaPrime rotator type and angle in metadata translator ","""CFHT MegaPrime has its rotator angle set to NaN in {{astro_metadata_translator}}, and its rotator type to UNKNOWN. Since it is on an equatorial telescope, we can just pre-compute the correct value, set {{rotType=SKY}} and set those in the translator and they will be correct for everything (or at least correct enough to provide an initial guess).    There are diagrams on this page that may help figure out the correct on-sky rotation angle, though it's not as helpful as the DECam diagrams:    https://www.cfht.hawaii.edu/Instruments/Imaging/Megacam/specsinformation.html    One open question is whether we need to set a {{rotatorHandedness}} (when +Y is north, is +X is east or west?) value in {{VisitInfo}}, or whether we can easily get that from the camera geometry. At present, {{VisitInfo}} does not preserve this information, because [~rowen] assumed it would be managed by the camera geometry."""
"DM-20201","Story","astro_metadata_translator",2,"Fix DECam rotator type and angle in metadata translator","""DECam has its rotator angle set to NaN in {{astro_metadata_translator}}, and its rotator type to UNKNOWN. Since it is on an equatorial telescope, we can just pre-compute the correct value, set {{rotType=SKY}} and set those in the translator and they will be correct for everything (or at least correct enough to provide an initial guess).    The diagram on this page should help figure out the correct on-sky rotation angle.    http://www.ctio.noao.edu/noao/node/2250    One open question is whether we need to set a {{rotatorHandedness}} (when +Y is north, is +X is east or west?) value in {{VisitInfo}}, or whether we can easily get that from the camera geometry. At present, {{VisitInfo}} does not preserve this information, because [~rowen] assumed it would be managed by the camera geometry."""
"DM-20244","Story","ip_isr",1,"Gen3 ISR task broken wanting dataset illum ","""With w_2019_24 and its ci_hsc repo, running the Gen3 ISR task failed     For example, to reproduce:        The error is       """
"DM-20240","Story","ts_auxiliary_telescope",0,"Update ts_sal tests for no char0 Test arrays field","""Update ts_sal unit tests for DM-19474: remove char0 field from all Test array topics: setArrays command, arrays event and arrays telemetry."""
"DM-20257","Story","ts_environment",5,"To develop MQTT software interface to communicate SAL with HVAC telemetry","""Install MQTT broker, to accept communications from SAL applications and HVAC telemetry"""
"DM-20256","Story","alert_packet|alert_stream|sample-avro-alert",1,"Provide licensing & copyright information for alert distribution code","""Currently, there is no licensing or copyright information in either of the alert_stream or sample-avro-alert repositories.    Since this code (or, possibly, some ZTF-derived variation of the same) is now popping up in [various|https://github.com/lsst-uk/lasair/blob/e6baca8a68a43de0f66a9a5848697dfb11545023/src/alert_stream_ztf/python/lsst/alert/stream/alertProducer.py] [places|https://github.com/astrolabsoftware/fink-broker/blob/1378d4066d4540e05632e1c9b5a872d3ba4b2013/fink_broker/alertProducer.py] (apparently in some cases with copyright claims added and released under an Apache license!), we should make sure that it is properly attributed and licensed so that this is all above board."""
"DM-20251","Improvement","ap_verify",2,"Improve documentation for how to register metrics with ap_verify","""{{ap_verify}}'s metrics are configured using several {{MetricsControllerConfigs}}, but currently this fact is only documented in the command-line reference. Add clearer documentation (perhaps even a full tutorial), delegating to the {{verify}} documentation for the details of the actual configuration."""
"DM-20250","Story","lsst-texmf",1,"Update DM glossary to refer to the EFD as the “Engineering and Facility Database”","""Per [discussion on Slack|https://lsstc.slack.com/archives/C2K6YMTK2/p1561046699106000], the full name of  the service often referred to as “the EFD” is “the Engineering and Facility Database”, following LTS-210. Please update the DM glossary appropriately.    (Bonus points for fixing any other documents which define the acronym without referring to the standard glossary)."""
"DM-20271","Story","HeaderService",1,"ATHeaderService needs to publish offline detailed state","""As specified by LSE-209, there are two detailed states in offline that should be published. The ATCamera XML contains the appropriate information and can be used as an example.     The CAP ticket is here:  https://jira.lsstcorp.org/browse/CAP-224"""
"DM-20270","Story","ts_aos|ts_main_telescope",1,"Review the M2 Document of Phase 1","""Review the documents of M2 to have an initial understanding of status. This is the phase 1."""
"DM-20269","Story","ts_aos",3,"Support the AOS Closed-loop Simulation With Eimage","""The repository of ts_wep has been updated to support the eimage. This task will test the update in ts_ofc and ts_phosim repositories. The PhoSim will be used to verify the closed-loop simulation with Eimage."""
"DM-20267","Story","Documentation",1,"Add required README.txt to /datasets/refcats/htm","""The developer guide [""""Responsibilities"""" section|https://developer.lsst.io/services/datasets.html#responsibilities-on-ingest-or-maintenance] notes that datasets need a readme, and has a specific note about where the refcat readme goes. We have no such readme for any of the {{/datasets/refcats}} subdirectories. I'll writeup a description of the Gaia DR2 data and attempt to add some description of the other existing {{htm/v1}} refcats."""
"DM-20266","Story","HeaderService",1,"Remove DetailedState enumeration from ATHeaderService XML","""The top-level detailed enumeration is unnecessary as CSCs should not repeat summary states in detailed states and should be removed from the XML.    This captures the work from:  https://jira.lsstcorp.org/browse/CAP-225"""
"DM-20264","Story","Continuous Integration|Developer Infrastructure",1,"Test Jenkins required","""A test Jenkins is required in order to test that the changes implemented in DM-18112 have no impacts on the existing builds."""
"DM-20261","Story","ts_auxiliary_telescope|ts_calibration",2,"Test SAL 3.10 FiberSpectrograph RPM","""Test and ensure all the required files are in 3.10 rpm folder in [https://project.lsst.org/ts/lsstrepo/] 3.10 tag."""
"DM-20275","Story","ts_auxiliary_telescope",3,"ts_salobj 4 cannot hear SAL 3.10 command acks","""ts_salobj 4 cannot seem to communicate with ts_sal v3.10.0. The symptoms are that events and commands are transmitted, but command acknowledgement is not received. Also I have seen segfaults if I create the SALPY object and the salobj Domain and Remote in the same process, when things finish shutting down. But this does not seem to happen if they are in separate processes.    Add a unit test for this that uses SALPY_Test. Add ts_sal as an optional dependency of ts_salobj since the SALPY_Test module will be there.    I tried to use the ADLink Tester tool but it cannot find anything to connect to. so I get no information from it, alas."""
"DM-20287","Story","ip_isr",2,"Fix logging in IsrTask","""I found log messages from ISR saying:      This incorrectly uses the new python string formatting (missing a leading {{f}} on the string). However, we generally want log messages to defer the formatting, so the old {{%f}} style should be used instead.    I suggest auditing other recent changes to the logging for similar bugs."""
"DM-20280","Bug","Continuous Integration|Developer Infrastructure",0.5,"jenkins agent-ldfc-0 did not come back online after NCSA 06/23 maintaince","""It appears that the pod has been stuck in terminating status for the last 12 hours.      """
"DM-20302","Story","meas_extensions_scarlet",1,"Fix PSF normalization bugs in scarlet","""While updating the API in scarlet some of the tests related to PSF normalization broke. Since I am the one who wrote the tests it will be easiest for me to diagnose the cause of the differences and the code and or the tests to give the correct results."""
"DM-20335","Story","ts_auxiliary_telescope",0,"make_idl_libs.py fails if ts_sal and ts_idl are on separate volumes","""The ts_sal script make_idl_files.py uses {{os.rename}} to move the generated IDL file to ts_idl. Unfortunately this call fails if the source and destination path are on different file systems, as can easily happen when using Docker.    The simplest fix is to copy the IDL files instead of moving them."""
"DM-20334","Story","Design Documents",1,"Release approved version of LSE-319 following LCR-1728","""LCR-1728 on LSE-319 has been approved by the CCB and the PM.  It now needs to be released in order to reach the CCB """"Fully Implemented"""" state.  Most of this work, for a LaTeX/Github/LTD-based document, falls to the proposer, with final steps done by [~mckercher].      This tickets asks for the appropriate branch and tag management in the document release process to be done, with the products provided to Rob for final release."""
"DM-20333","Story","ts_aos|ts_main_telescope",1,"Review the SHWFS and Guider Codes by Vendor","""Review the SHWFS and guider code by vendor (the developer is Pauline in France). The goal is to evaluate if LSST could take this code and change them or if we needed Pauline to help us (which would require a change request).    The new Factory Acceptance Test Review dates are July 18th and 19th and Sandrine would like to have an answer by then."""
"DM-20329","Story","ts_aos",2,"Update the ts_MTAOS xml for Description and Unit","""Update the ts_MTAOS xml for description and unit. The related tests in ts_xml will be done by Rob. This task will also take time to be familiar with the unit module in astropy."""
"DM-20328","Story","DM Subsystem Science",1,"Put website in place for algorithms workshop ","""Work with the communications team to put in place the workshop website and set up short link to ls.st/<>    Website request form: https://project.lsst.org/website-request"""
"DM-20325","Story","verify",1,"Add option to get password securely from dispatch_verify.py","""Currently, the SQuaSH password for {{dispatch_verify.py}} is supplied via environment variable or command line option.    On shared systems, neither mechanism is very secure.  This ticket will add an option to prompt for the password when the script is run interactively."""
"DM-20317","Story","ip_diffim|pipe_tasks",2,"DCR model performance improvements","""While processing Decam data for DM-15340 I identified a few places in building the DCR model that could be made more efficient. These improvements speed up the calculation by 5 - 40%, depending on the properties of the input exposures."""
"DM-20314","Story","ts_auxiliary_telescope",0,"Add units and update subsystem metadata to Script, ScriptQueue and Test","""Add units and update metadata in SALSubsystems.xml for the Script, ScriptQueue and Test SAL components."""
"DM-20373","Story","daf_butler|obs_base",2,"Move FitsRawFormatterBase from daf_butler into obs_base","""I ran into ci_hsc failures due to gen2/gen3 getter comparisons, meaning I need to update the gen3 raw readers to look like the changes I made to the gen2 ones. In order to allow both butlers to use the same underlying code, we need to move {{FitsRawFormatterBase}} from daf_butler into obs_base. [~jbosch] suggested this change."""
"DM-20342","Story","obs_lsstSim",1,"Fix typo in eImageIsr","""DM-19382 changed the name of a keyword in {{ip_isr.interpolateFromMask}} from {{growFootprints}} to {{growSaturatedFootprints}}, but did not update {{obs_lsstSim.processEimage}} which calls it, breaking it."""
"DM-20428","Story","ts_middleware",3,"SAL updates for salobj feature requests - part 1","""Update SAL to include a set of features  to improve interaction with salobj based components  This will be a multi task effort over the next 2 sprints"""
"DM-20384","Improvement","ap_pipe",2,"Clarify usage of make_ppdb.py script","""A third-party guide to using {{ap_pipe.py}} suggests using command-line arguments to {{make_ppdb.py}} but passing the database config to {{ap_pipe.py}} through a file. This is not recommended usage (if the two scripts are configured the same way it's harder to make a hard-to-debug mistake), but the current Sphinx docs don't actually say that the two scripts accept the same config.    Clarify that {{make_ppdb.py}} is configured exactly the same way as {{ap_pipe.py}}, including taking config files written for {{ApPipeConfig}}. This might be worth putting on a separate topic page under """"Using lsst.ap.pipe"""" -- not a tutorial or walkthrough, but just a page explaining what {{make_ppdb}} is and why we need it."""
"DM-20378","Story","pex_config",2,"System for deprecating Config fields","""While working on DM-20154, I wanted to mark a Config field as deprecated, but we have no system for doing that (other than just adding a docstring). [~ktl] suggested an approach on slack, which was fairly simple to implement. I'll also add a note to the dev guide on how to use it as part of this ticket."""
"DM-20431","Story","meas_extensions_scarlet",2,"Re-Implement symmetry in scarlet","""[~nlust] created a branch during the deblender sprint that included a significantly improved algorithm for symmetrizing scarlet models, along with an improved centering algorithm motivated by [~jbosch]. This ticket is for implementing [~nlust]'s code in scarlet master and the LSST stack."""
"DM-20441","Bug","daf_butler",0.5,"catch-all exceptions in gen3 butler should use `raise from`","""While debugging some changes I made related to the new astrometry code, I tripped over the {{except Exception as e:}} at {{posixDatastore.py::309}}, which swallows the initial exception. This, and any other such broad exception catching in daf_butler should use {{raise from}} exception chaining, so that the original exception information does not get lost."""
"DM-20440","Story","display_firefly",0.5,"Update sample footprints notebook in display_firefly","""The HSC-Footprints notebook in the {{display_firefly}} repository predates the Firefly extension, and also points to a data location for reprocessed HSC data that is no longer valid. Update the notebook."""
"DM-20439","Story","ts_auxiliary_telescope",2,"Make ts_salobj unit tests more reliable","""There are three issues:  * test_csc_utils.py sometimes fails with a timeout when setting the final state to OFFLINE. I am virtually certain the problem is that the CSC exits before the final state is reported.  * test_salpy.py succeeds for me, but reports a segfault after reporting success. The segfault is caused by creating a SALPY object and a dds domain in the same process. I don't know why, but it's easy to avoid that.  * test_salpy.py fails for Tiago sometimes. I have not been able to reproduce this."""
"DM-20457","Story","ts_auxiliary_telescope",0,"Fix SAL XML for Script, ScriptQueue and Test","""Make the XML for Script, ScriptQueue and Test meet our new requirements of having a non-empty Description and Units entry for each topic and fields.    Also fix an existing problem where some topic-level Explanation fields were present that should have been Description fields (from before Description was supported for topics)."""
"DM-20471","Story","ts_auxiliary_telescope",0,"Fix SAL XML for Watcher","""The new Watcher XML (DM-20145) has a few errors:  - Use of Explanation instead of Description for topics  - No description for the heartbeat event"""
"DM-20469","Story","ctrl_iip",2,"Fix log times to use UTC with Z","""Fix log times to use UTC with Z"""
"DM-20482","Story","ts_aos|ts_main_telescope",3,"Communicate the M2 Server and cRIO Phase 1","""It looks like there is no communication between the m2 server and m2 cRIO now. Need to construct the communication to let the cRIO to run. There is a risk here that it looks like the m2 laptop can not talk to the cRIO also. Need some time to dig into this. This is the phase 1."""
"DM-20481","Story","ts_aos|ts_main_telescope",2,"Review the M2 Document of Phase 2","""Review the documents of M2 to have an initial understanding of status. This is the phase 2."""
"DM-20497","Story","HeaderService",2,"Update ts_xml for the HeaderService for version 4.0.0","""The xml for the HeaderService on ts_xml needs to be update for the upcoming release of ts_xml version 4.0.0"""
"DM-20492","Story","HeaderService",3,"Changes to HeaderService for ts_xml version 3.10.2","""The newest xml (version 3.10.2) introduced several changes to the message content sent by ATCamera. The HeaderService needs to be modified for this reason."""
"DM-20491","Story","ts_auxiliary_telescope|ts_calibration",2,"Update units and desciption for CSCs","""Update units and description for CSCs FiberSpectrograph, HR, Monochromator."""
"DM-20488","Story","cbp",0,"Update doc layout for cbp using the modern standard","""Update the documentation layout for the cbp package using the modern standard which eliminates the unnecessary """"cbp"""" subdirectory and moves """"lsst.cbp"""" up to the top level.    Upload the new documentation."""
"DM-20499","Improvement","afw",1,"Add basic stringification to SkyWcs","""To aid in debugging and identifying different SkyWcs objects, we should add at least some very basic str and repr support (using the existing {{toString}} method: it's already called by {{operator<<}}). I'll add some basic support now, and if we want more in the future we can expand it."""
"DM-20529","Story","ts_ait|ts_auxiliary_telescope",1,"Container deployment in Chile with SAL 3.9. ","""This task is to capture the work needed to (re)deploy the CSCs, Jupyter notebooks and EFD containers in Chile for the upcoming on-sky test with the Auxiliary Telescope. """
"DM-20524","Story","obs_lsst",1,"Add deepDiff_diaObject dataset types and correct deepDiff_diaSrc templates","""1.  Add {{deepDiff_diaObject}} datasetType     -- This is still a bit experimental.  It's being used and tested through DESC DC2 and {{dia_pipe}}, so it seems appropriate to just include these datasetTypes here in {{obs_lsst}} and not propagate to {{obs_base}}.  2. Correct deepDiff_diaSrc datasetType templates to use {{%08d}} to format {{visit}}.    Original work done by [~rearmstr].   [~wmwood-vasey] 's work is to do some light reformatting and testing."""
"DM-20545","Story","JupyterLab",8,"Dask client loses connection with the cluster","""We have been seeing situations where the client in a notebook will lose communication with the dask cluster it is constructed with.  The cell appears to just be hung.  Sometimes it does come back, but not for a long time.  The attached notebook will show this behavior on a weekly 20 build.  Just run the cell with {{len(df)}} a few times to see this behavior."""
"DM-20541","Story","obs_base",1,"Determine if any existing obs packages have a flip from PIXELS->FOCAL","""To better understand RFC-605, we need to determine if any of our existing obs packages have a flip in their pixel->focal transform. We think they are all defined as looking """"down"""" on the focal plane, but we need to check.    1. Load the cameraGeom for each obs package.  2. Compute determinant of pixel->focal transform.  3. If determinant is negative, there is a flip.  """
"DM-20540","Story","utils",0.5,"Remove long deprecated methods from utils package","""The {{utils}} package has had some methods that have been deprecated for years. Remove them."""
"DM-20536","Story","ap_association",2,"Can't count on `obj_idxs` being in bounds","""While trying to run ap_pipe with {{preConvolution=True}}, some dataIds failed on the ap_association stage. eg:    which is from {{[https://github.com/lsst/ap_association/blob/master/python/lsst/ap/association/association.py#L612]}}    This looks like some failure mode where the distance is returned as {{inf}} for some {{diaSources}}, (despite your not having set an upper bound) which produces the expected behavior of returning a flag value = n points (in this case 4):    I'm not sure WHY it thinks that inf is greater than inf, but regardless, I'd expect this to just return no matches.    Can reproduce from {{/datasets/hsc/repo/rerun/private/yusra/RC2/ap_pipe/w_2019_26_preConv}} with {{  ap_pipe.py /datasets/hsc/repo --calib /datasets/hsc/repo/CALIB/ --template /datasets/hsc/repo/rerun/private/yusra/RC2/ap_pipe_templates_noSkyCorr --rerun RC/w_2019_26/DM-19560-sfm:private/yusra/RC2/ap_pipe/w_2019_26_preConv --configfile ./configfile.py --no-versions  --longlog --id visit=19712 ccd=49 --reuse-outputs-from=all --clobber-config}}"""
"DM-20546","Story","afw",2,"Cleanup some afw deprecations","""afw has some deprecated code that is not formally marked with the new {{@deprecated}} scheme. Some of these have been deprecated for many years. For deprecations over a year old, remove them. For others try to use the modern scheme.    This ticket is not fixing the {{afw.geom}} deprecations described in DM-17566."""
"DM-20570","Bug","ap_verify",2,"Pipeline failure treated as ap_verify success","""{{scipipe/ap_verify}} build [#286|https://ci.lsst.codes/blue/organizations/jenkins/scipipe%2Fap_verify/detail/ap_verify/286/artifacts] was unable to run the full pipeline. However, this was counted as a successful build in Jenkins. It appears that, while  {{ap_verify}} correctly generated metrics from the failed run, it did not return any error code to the shell. Fix this behavior so that failed processing runs can be detected by CI."""
"DM-20565","Story","afw",0.5,"Remove afwGeom aliases for geom","""The {{afwGeom}} aliases for Point, Extent, and others that are now defined in {{geom}} must be removed prior to the release of v20.0."""
"DM-20558","Story","ip_diffim",8,"Investigate rescaling the coadd variances for difference imaging templates","""[~yusra] identified in the June '19 False Positive Sprint that the variances were wrong by 10-15% (  https://nbviewer.jupyter.org/github/yalsayyad/dm_notebooks/blob/master/examples/DiaSourceCensusCcdVisitNight-HSC-RC2.ipynb).  This is likely due to pixel covariances introduced by coaddition and warping.  This ticket is to investigate rescaling the variances appropriately with {{ScaleVariance}}."""
"DM-20553","Story","ctrl_iip",2,"Pending messages can cause a crash in the OCSBridge","""If a pending RabbitMQ is received before all of the SAL proxy devices have topics registered, a message will attempt to be processed and cause a crash."""
"DM-20584","Story","ts_ait|ts_auxiliary_telescope",1,"Container deployment in Chile with SAL 3.10","""Task to capture the work needed to deploy the containers in Chile with SAL 3.10. """
"DM-20582","Bug","Continuous Integration|Developer Infrastructure",0.5,"unable to rebuild jenkins builds","""Per [~nlust]    """
"DM-20575","Story","meas_algorithms",0.5,"Remove meas_algorithms deprecated functions from defects.py","""The meas_algorithms functions must be removed from defects.py prior to the release v19.0.0"""
"DM-20573","Story","obs_lsstSim",1,"Remove obs_lsstSim package from lsst_obs metapackage","""The obs_lsstSim package must be removed from the lsst_obs metapackage and moved to legacy prior to the release v20.0.0"""
"DM-20667","Story","ts_auxiliary_telescope",2,"Create conda version of develop-env","""Create a conda environment and document detailing how to use said environment."""
"DM-20661","Story","ts_aos|ts_main_telescope",1,"Check the LabVIEW Dependency in M2 Cell Code","""Check the LabVIEW dependency for M2 Cell code, which should be the windows version."""
"DM-20615","Story","ctrl_iip",2,"create python command to send logevents","""This command will be able to send startIntegration, endReadout and largeFileObjectAvailable logevents."""
"DM-20603","Story","ctrl_iip",8,"Design for ComCam Archiver","""Work for design of ComCam Archiver."""
"DM-20585","Story","meas_extensions_scarlet",1,"Add meas_extensions_scarlet to lsst_distrib","""Implementation of RFC-606."""
"DM-20702","Improvement","ap_verify|verify",2,"Create memory usage metric","""Create a {{MetricTask}} that captures the [{{MaxResidentSetSize}} from timeMethod|https://github.com/lsst/pipe_base/blob/master/python/lsst/pipe/base/timer.py#L100]. The task can be written by cargo-culting {{lsst.verify.tasks.TimingMetricTask}}. Add metrics for {{ApPipeTask}} and its direct subtasks to the default {{ap_verify}} config. Note that astropy supports [data size units|https://docs.astropy.org/en/stable/units/standard_units.html#prefixes].    One outstanding question is how to define aggregation (which is still the responsibility of the {{MetricTask}} for now). For running time across multiple CCDs a sum is the natural choice; it's less natural for memory usage because the aggregated data IDs weren't necessarily run together."""
"DM-20692","Story","ip_isr|pipe_tasks",20,"Convert PipelineTasks to new api","""DM-20205 introduces a new api for pipeline tasks. This ticket will update the existing pipeline tasks to use this new api."""
"DM-20727","Story","ts_aos",5,"Study the Algorithm of DOF with Camera Rotation Phase 1","""This task is to study how to rotate the DOF with the camera rotation angle. This task will use the PhoSim to do the evaluation and verification. This task will focus on the OPD-level first. This means only the OFC will be used. The use of WEP will be in the following tasks."""
"DM-20726","Story","ts_aos|ts_main_telescope",2,"Communicate the M2 Server and cRIO Phase 2","""In the phase 1 [DM-20482|https://jira.lsstcorp.org/browse/DM-20482], I found the port: 55555 is hard-coded by M2 cell code to listen to M2 server. I issued the JIRA ticket ([IHS-2398|https://jira.lsstcorp.org/browse/IHS-2398]) for the help. This task is to check the communication between M2 cell and cRIO after the IT helped to open the port and fix the problems if the communication can not work even the port is unblocked."""
"DM-20712","Story","ctrl_bps",3,"Operator-type user test run ci_hsc","""Operator-type user test run ci_hsc reporting problems to developer"""
"DM-20711","Story","ctrl_bps",3,"Improve code documentation/style","""Improve code documentation/style"""
"DM-20705","Story","ctrl_mpexec|daf_butler|pipe_base|pipe_tasks",1,"Track down Gen3 processing failures in MergeMeasurementsTask","""On Slack ([https://lsstc.slack.com/archives/C2JPT1KB7/p1563485540182700), |https://lsstc.slack.com/archives/C2JPT1KB7/p1563485540182700):]    [~hchiang2] writes:  {quote}{color:#1d1c1d}The other SciPi error I saw was{color}    {color:#1d1c1d}But if I try to reproduce it directly, I'm seeing{color}  {quote}  This affects 19/79 quanta.  An example of one that failed is at    That's (tract=9615 patch=77)."""
"DM-20755","Story","ts_qa",2,"Remove several CSCs and update the tests accordingly","""This story covers the time necessary to remove the   * ATCalCS   * ATEEC   * ATThermoelectricCooler   * MTCalCS   * Sequencer    CSCs from ts_xml and update the tests appropriately."""
"DM-20754","Story","ts_middleware",2,"Coordinate the v4.0.0 Release of XML","""This story covers the time necessary to cut the v4.0.0 release of ts_xml, and make appropriate updates to the various XML and SAL tests and CI jobs."""
"DM-20751","Story","validate_drp",2,"Fix nightly validate_drp build","""The merge of the new defects work broke validate_drp because there are no defects in the repository, but that step is not skipped.    The fix is to add defects to the {{validation_data_drp}} package."""
"DM-20742","Story","obs_base",2,"Add ""raw_header_wcs"" datasetType to butler","""To fully implement RFC-616, we need a way to get the original FITS WCS from a raw file. As proposed in that RFC, this will be a """"raw_header_wcs"""" datasetType in the butler (gen2 and 3)."""
"DM-20734","Story","ts_main_telescope",3,"simulate correction loop in alignment system","""Build up alignment system so we can run a simulated correction loop.         In this version of the simulation we aren't actually moving the mirror, we're just reading the simulated variance of the instrument. So for now I measure each component a semi-random number of times to simulate iterations in the loop. """
"DM-20733","Story","ts_main_telescope",1,"Office move","""move to room 202, set everything back up"""
"DM-20771","Story","ip_isr",1,"IsrTaskConfig.numEdgeSuspect field duplicated","""It appears at [line 255|https://github.com/lsst/ip_isr/blob/4e3c610941f9a3dc4c7bc1469fe72bcc4d0858d2/python/lsst/ip/isr/isrTask.py#L255] and at [line 437|https://github.com/lsst/ip_isr/blob/4e3c610941f9a3dc4c7bc1469fe72bcc4d0858d2/python/lsst/ip/isr/isrTask.py#L437] of {{isrTask.py}}."""
"DM-20770","Bug","meas_astrom",1,"Unhelpful error message from PessimisticPatternMatcherB","""The call {{PessimisticPatternMatcherB(ref_array[:, :3], self.log)}} in matchPessimisticB.py around line 387 generates the error message  {quote}ValueError: negative dimensions are not allowed  {quote}  when {{ref_array}} is empty. Next time someone's in the code, could we improve the error message?  It happens when there are no possible matches from the reference catalogue."""
"DM-20769","Story","ts_qa",1,"Update Units and Description for CSCs","""Update units and descriptions for the following CSCs. Per Tiago's request.        * ATAOS   * ATMonochromator   * ATSpectrograph   * ATTCS   * DIMM   * Environment   * Electrometer"""
"DM-20765","Story","ts_aos|ts_main_telescope",1,"Update the CSC MTM2 xml for Description and Unit","""Update the MTM2 xml for description and unit. The related tests in ts_xml will be done by Rob. There is the document provided by Harris for the description. The unit will be based on my best guess if needed."""
"DM-20764","Bug","ts_qa",0,"Test CSC has wrong units","""The Test_Commands.xml has the wrong units (seconds) in one of its units items.   Will set it to the correct units item (second)."""
"DM-20761","Story","ts_aos",0,"Add CWFS package to base develop-env image","""Add the following package as a docker container based on develop-env image. [https://github.com/bxin/cwfs]"""
"DM-20760","Story","ap_association",2,"Drop DiaSources if RA/DEC is NaN and throw warning.","""The Ppdb has a non-Null constraint on RA/DEC. However, depending on the algorithm used to compute a source centroid (and translate into RA/DEC using the WCS), NaN values can result.    This ticket will tests for NaN values in the DiaSource table, drop those objects, and throw a warning to the log with the offending DiaSource id."""
"DM-20805","Story","ts_auxiliary_telescope|ts_middleware",0,"Split EFD writer image into one stream per container instead of three","""Split EFD writer image into one stream per container instead of three"""
"DM-20803","Bug","ts_middleware",1,"Add a simulator column to the ts_xml / SALSubsystem.xml","""Please add a new item to the Subsystem tag in the ts_xml/sal_interfaces/SAL_Subsystems.xml that will signify whether a CSC has and/or contains a simulator.   The idea is this information will then appear on the ts_xml lsst.io page for reference by the project.    As always, let me know if you have any questions."""
"DM-20782","Story","meas_extensions_ngmix",1,"Update meas_extensions_ngmix to meet coding standard","""This package was not following python coding standards. Update and add travis check."""
"DM-20812","Story","daf_butler|ip_isr|obs_subaru",1,"Rename TablePersistable storage classes in gen 3 to drop TablePersistable","""[~jbosch] requests that we change all the storage class names starting with {{TablePeristable}} to drop that prefix.  The storage class should not be describing how the dataset type should be stored and by definition they are persistable."""
"DM-20808","Story","squash",1,"Expand Kapacitor rules to alert on failed validate_drp for HSC and CFHT separately","""We recently found that the deadman alert on the {{validate_drp}} processing in the nightly was just looking at any data landing in the {{validate_drp}} measurements.  This meant that the if just one failed, there would be no notification."""
"DM-20807","Story","HeaderService",3,"Test HeaderService and other CSC at NCSA for ts_xml version 4.0.0","""The newest xml (version 3.10.2) introduced several changes to the message content sent by ATCamera. The HeaderService needs to be modified for this reason."""
"DM-20814","Bug","meas_extensions_scarlet",1,"Fix broken tests in meas_extensions_scarlet","""{{meas_extensions_scarlet}} tests are missing the {{setup_module}} function. For some reason this did not cause the tests to fail when built locally or with Jenkins, but did prevent the weekly build."""
"DM-20830","Story","templates",1,"Add support for LSST IT technotes","""LSST IT would like a technote series called {{ittn}}, with the repos hosted at https://github.com/LSST-IT"""
"DM-20858","Story","ts_qa",3,"Train backup on the XML/SAL release process","""As I will be traveling for much of September and October, [~cwinslow] has agreed to learn the SAL/XML release process in order to stand-in during my absence."""
"DM-20856","Improvement","ts_auxiliary_telescope",1,"Enhance ATDomeTrajectory SimpleAlgorithm to use cos(el)","""ATDomeTrajectory's SimpleAlgorithm presently bases its decision on whether to move the dome on the difference between telescope and dome azimuth. Scale that difference by cos(el) to reflecting the fact that azimuth difference can be larger at higher elevation."""
"DM-20850","Story","pipelines_lsst_io|Stack Documentation and UX",1,"Add a task index page to pipelines.lsst.io","""Add a index page for every task in {{lsst_distrib}} to https://pipelines.lsst.io.    This is a simpler version of the process-context-based documentation sections designed in https://dmtn-030.lsst.io/#processing-section, but it's something that is doable now with little effort.    This index page could either be linked from the homepage, or from a [Task framework page|https://dmtn-030.lsst.io/#frameworks-section]."""
"DM-20848","Bug","ts_auxiliary_telescope|ts_main_telescope",1,"The showSchema ScriptQueue command and its unit test are both broken","""The showSchema ScriptQueue command unit test is broken and INRIA reports that the command does not output the desired event.    The unit test is broken because the doit method is never called in an event loop.  Fix the unit test and any bugs that show up in the code being tested."""
"DM-20843","Story","ts_main_telescope",1,"Review the Documents of Hexapod and Rotator Phase 1","""Review the documents of hexapod and rotator in phase 1."""
"DM-20863","Story","documenteer|pipelines_lsst_io",1,"Reduce font size of code samples in pipelines.lsst.io docs","""The code sample font size in the theme for pipelines.lsst.io (https://github.com/lsst-sqre/lsst-sphinx-bootstrap-theme) ought to be just a bit smaller so that an 80-character wide code sample can fit."""
"DM-20860","Bug","Firefly",8,"WCS match fails for image with east - right","""Some image with east-right are failing to align and rotate north correct.    Please see attachments for illustration of the problem.     IPAC Firefly ticket [https://jira.ipac.caltech.edu/browse/FIREFLY-179]"""
"DM-20902","Bug","ap_association|verify",1,"FractionUpdatedDiaObjectsMetricTask should expect 0 DIAObjects","""Currently, {{FractionUpdatedDiaObjectsMetricTask}} raises {{MetricComputationError}} if there are 0 pre-existing DIAObjects. However, this is normal in the context of verification, which always starts with an empty PPDB. Therefore, the behavior of this task when there are no DIAObjects to update should be changed to return {{None}} (i.e., the metric is not applicable) rather than raising an exception (i.e., the task's calculations failed)."""
"DM-20900","Story","ts_management",5,"Attend the Project Community Workshop","""This is the event at 8/12 - 8/16. The website is at:    [https://project.lsst.org/meetings/lsst2019/]"""
"DM-20899","Story","ts_main_telescope",3,"Review the Documents of Hexapod and Rotator in Phase 2","""This task is to continually review the document of hexapod and rotator. Record the questions and get the knowledge transfer from the previous owner.    The ticket for ssh help is [IHS-2490|https://jira.lsstcorp.org/browse/IHS-2490]."""
"DM-20915","Story","daf_butler",1,"Add stringification to Formatter","""DM-20842 added a location attribute to Formatter. It would be helpful if {{str(Formatter)}} returned the formatter name and location.  Also require the fileDescriptor argument."""
"DM-20913","Story","ts_aos|ts_main_telescope",1,"Check the M2 MATLAB Tool","""Check the M2 MATLAB tool."""
"DM-20910","Story","ts_middleware",2,"Design salobj to Kafka feeder","""Design the salobj to Kafka feeder and negotiate with [~afausti] and [~jsick] about details of the schema. I hope they will be willing to change the Avro schema to match the DDS topics.    Another point to discuss is to consider using the IDL or Python topic data classes, instead of the XML files, to create the Avro schema. However, unless doing such a change requires me to write some code, this is a side issue.    Figure out how to write unit tests for this code.    The product will be a preliminary implementation, not necessarily tested."""
"DM-20907","Bug","Qserv",1,"Synchronization bug in the Qserv worker monitoring service","""The current implementation of the qserv worker monitoring service has a synchronization bug which (reproduced under right operational conditions) crashes Qserv at the following location:    It turns out the monitoring code is iterating over a mutable collection of schedulers which may be sorted by other threads. The code where this happens is:    Reinforce the algorithm to acquire a lock before iterating over the collection."""
"DM-20924","Story","astro_metadata_translator",2,"Release astro_metadata_translator to PyPI","""Do a formal release of astro_metadata_translator to PyPI.  This will include determining a formal version number and tagging the repository."""
"DM-20922","Bug","ap_verify",2,"ap_verify can't handle --id with empty argument","""[~Parejkoj] discovered that {{ap_verify.py}} will misunderstand the {{\-\-id}} argument if it is followed by anything other than a data ID (e.g., {{ap_verify.py \-\-id \-\-output lotsOfRepos}}). Modify the argument parser so that the ID is optional, if this can be done without making {{\-\-id}} mandatory."""
"DM-20921","Improvement","ap_verify",1,"Clarify that ap_verify needs to be set up before running ap_verify.py","""The usage instructions in the dataset repositories assume the user already has a Stack set up. Make it explicit that the user needs to set up either {{ap_verify}} or {{lsst_distrib}} before running {{ap_verify.py}}. Reword both the readme and the Sphinx docs, if appropriate."""
"DM-20918","Improvement","ImgServ",5,"Implement BAND  in SODA to specify the wavelength intervals","""Per Section 3.3.4 BAND of SODA 1.0 spec, the BAND parameter defines the wavelength interval(s) to be extracted from the data using a floating point number.    In LSST, the concept has been described using filters: u, g, r, i, z, y    Mapping these filters to corresponding BAND parameter values and recognizing them inside the code will be the gist of this ticket."""
"DM-20917","Bug","ImgServ",2,"In SODA shape CIRCLE, radius should be in degrees by default","""Per Section 3.3.1 POS of the SODA 1.0 spec, all longitude and latitude values (plus the radius of the CIRCLE) are expressed in degrees in ICRS.    In addition to SPACE as delimiter to separate the values, COMMA was desired during testing. """
"DM-20935","Story","ts_management",5,"PCW2019 - Rob","""Story covering time at the LSST PCW for 2019."""
"DM-20933","Epic","ts_management",40,"Epic to track folks time at the PCE","""This epic is used to track time taken in the PCW (All-hands) meeting"""
"DM-20931","Story","SUIT",2,"Implement pinning of Firefly version in suit repo","""Per today's discussion, this ticket asks that the {{suit}} package be modified to include a script that encapsulates the full build process for that package, including its dependency on an explicitly specified version of [Caltech-IPAC/firefly|https://github.com/Caltech-IPAC/firefly].    (The equivalent of this already exists in the IPAC Jenkins scripts repo for Firefly/suit builds, so the task here is just to ensure that that information is in the {{suit}} repo itself, to facilitate LSST-driven builds of the package.)    The Firefly version may be specified in the script itself or in a supporting data file.  [~gpdf] has a mild preference for the latter, decoupling the build _logic_ from the version numbering.    This is a high-priority task as we wish to converge with LSST on an LSST-maintainable build process by the end of FY19."""
"DM-20929","Story","pipe_tasks",2,"Fix bug in DcrAssembleCoadd when running with slurm","""DcrAssembleCoaddTask fails when running on Decam data on lsst-dev using slurm, though the same data runs fine using AssembleCoaddTask. I've copied the error below, which appears to be caused by the coaddInputs not being set up properly before trying to use them to compute a coaddPsf.       {code:}dcrAssembleCoadd FATAL: Failed on dataId=DataId(initialdata={'filter': 'g', 'tract': 0, 'patch': '12,12'}, tag=set()): LengthError:     File """"include/lsst/afw/table/Catalog.h"""", line 186, in lsst::afw::table::CatalogT<RecordT> lsst::afw::table::CatalogT<RecordT>::subset(const ndarray::Array<const bool, 1>&) const [with Recor  dT = lsst::afw::table::ExposureRecord]      Mask array with 4 elements applied to catalog with 8 elements {0}  lsst::pex::exceptions::LengthError: 'Mask array with 4 elements applied to catalog with 8 elements'/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/18.0.0-8-g24ce6f0f+8/python/lsst/pipe/tasks/scaleVariance.py:147: RuntimeWarning: invalid value encountered   in sqrt    snr = maskedImage.image.array/np.sqrt(variance.array)  Traceback (most recent call last):    File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/18.0.0-2-g0ee56d7+10/python/lsst/pipe/base/cmdLineTask.py"""", line 388, in __call__      result = self.runTask(task, dataRef, kwargs)    File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/18.0.0-2-g0ee56d7+10/python/lsst/pipe/base/cmdLineTask.py"""", line 447, in runTask      return task.runDataRef(dataRef, **kwargs)    File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/18.0.0-2-g0ee56d7+10/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/18.0.0-8-g24ce6f0f+8/python/lsst/pipe/tasks/dcrAssembleCoadd.py"""", line 294, in runDataRef      warpRefList=warpRefList)    File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/18.0.0-2-g0ee56d7+10/python/lsst/pipe/base/timer.py"""", line 150, in wrapper      res = func(self, *args, **keyArgs)    File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/18.0.0-8-g24ce6f0f+8/python/lsst/pipe/tasks/assembleCoadd.py"""", line 525, in runDataRef      inputData.weightList, supplementaryData=supplementaryData)    File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/18.0.0-8-g24ce6f0f+8/python/lsst/pipe/tasks/dcrAssembleCoadd.py"""", line 471, in run      dcrModels = self.prepareDcrInputs(templateCoadd, warpRefList, weightList)    File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/18.0.0-8-g24ce6f0f+8/python/lsst/pipe/tasks/dcrAssembleCoadd.py"""", line 395, in prepareDcrInputs      psf = self.selectCoaddPsf(templateCoadd, warpRefList)    File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/18.0.0-8-g24ce6f0f+8/python/lsst/pipe/tasks/dcrAssembleCoadd.py"""", line 1136, in selectCoaddPsf      psf = measAlg.CoaddPsf(ccds[goodVisits], templateCoadd.getWcs(),    File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/afw/18.0.0-10-g6da83990c/python/lsst/afw/table/_base.py"""", line 117, in __getitem__      return self.subset(key)  lsst.pex.exceptions.wrappers.LengthError:     File """"include/lsst/afw/table/Catalog.h"""", line 186, in lsst::afw::table::CatalogT<RecordT> lsst::afw::table::CatalogT<RecordT>::subset(const ndarray::Array<const bool, 1>&) const [with Recor  dT = lsst::afw::table::ExposureRecord]      Mask array with 4 elements applied to catalog with 8 elements {0}  lsst::pex::exceptions::LengthError: 'Mask array with 4 elements applied to catalog with 8 elements' {code}   """
"DM-20946","Story","ts_management",5,"PCW 2019","""Attend PCW 2019"""
"DM-20943","Story","Management",5,"LSST 2019 meeting","""Attend LSST 2019 project meetings"""
"DM-20942","Story","Developer Infrastructure|ts_middleware",5,"Test and release SAL V4","""Test the new features of SAL V4 and the deployment mechanisms"""
"DM-20941","Story","verify",1,"Remove python_future dependency from lsst.verify","""Remove use of the {{future}} package in {{lsst.verify}}.    Also fix third party packages that were accidentally removed in DM-17205."""
"DM-20937","Story","afw|ip_isr",1,"Add deprecation warnings for to-be-removed distorted WCS functions","""The changes in DM-20154 should result in some code being deprecate-able. {{makeDistortedTanWcs}} and {{computePixelToDistortedPixel}} are the first ones that comes to mind, but there may be others (e.g. in ip_isr). We should use the deprecation decorators so we can remove that code later."""
"DM-20952","Story","templates",0.5,"Update latex technote template to use latexmk","""The current Makefile for the [technote_latex template|https://github.com/lsst/templates/tree/master/project_templates/technote_latex] runs xelatex and BibTeX manually. However, this fails on the first-run experience because there aren't any citations, and BibTeX fails. Using latexmk is a solution because it's smart enough to know whether BibTeX needs to be run in the first place or now."""
"DM-20963","Bug","verify",1,"inspect_job.py broken","""It is no longer possible to run {{inspect_job.py}} from the command line:      Figure out what happened and fix."""
"DM-20978","Story","afw|base",1,"Stub out base lsstimport and move lsstcppimport import to afw","""After some investigation by [~ctslater] we have learned that the {{lsst/\_\_init__.py}} files do not need to import {{lsstimport}} from the {{base}} package. The library loader flags are no longer relevant for our pybind11 packages.    Furthermore we have learned that the {{lsstcppimport}} _is_ required but is only required by some packages that are using afw C++ interfaces.    We therefore propose the following:    1. Replace lsstimport.py with an empty stub file that does nothing.  2. Force afw to import lsstcppimport.    In a later ticket we will remove the {{lsst/\_\_init__.py}} files from all the LSST python packages. Once that is done {{lsstimport.py}} can be removed from {{base}} package."""
"DM-20999","Story","ts_aos|ts_main_telescope",3,"Check the SAL Telemetry in M2 Controller","""Check the SAL Telemetry in M2 controller. In the previous time, I had rebuilt and re-deployed the M2 cell code in cRIO and there is the connection between M2 controller and cRIO now. However, it looks like there is no SAL telemetry. This task will dig into code to try to fix it."""
"DM-20998","Story","ts_main_telescope",1,"Review the Walk-through Record of Hexapod and Rotator Software","""Review the walk-through record of hexapod and rotator software in the following link:    [https://confluence.lsstcorp.org/display/LTS/Software+Code+Walkthrough#/]         PS. Put the story point of [DM-21014|https://jira.lsstcorp.org/browse/DM-21014] here."""
"DM-20997","Story","ts_ait|ts_aos|ts_main_telescope",3,"Attend the LabVIEW Core 3 Training","""Attend the LabVIEW core 3 training in CA."""
"DM-20985","Story","ts_middleware|ts_qa",2,"Create the pub sub program","""A continuation of [] creating the scripts to generate the .robot files that test the single file Java Telemetry programs."""
"DM-20984","Story","ts_management",2,"Moving Work and logistics","""Substantial time was taken out of my week meeting renters to rent my home. Visiting the vet to prepare required paperwork for the move. Visiting dealerships to sell my car. Emailing Erin and the rest of HR to get my ticket planned. Calling the airlines to ensure my dogs can board. Meeting with the movers to move all my household goods.     This task capture that time."""
"DM-21007","Story","Documentation",1,"Investigate setting up an information for community brokers public facing webpage ","""Many members of community broker teams are not LSST project members and so do not receive information communicated via usual project channels (slack, community).  An LSST 'information for brokers' webpage similar to the [LSST Information for Scientists|https://www.lsst.org/content/lsst-information-scientists] page could be a good way to communicate with the wider community"""
"DM-21004","Improvement","jointcal",2,"Add writeInitialModel option to jointcal config","""Ian Dell'Antonio (appears not to be on Jira) described a jointcal bug on slack where all of the on-sky residuals after initialization were NaN, but the tangent plane values were reasonable. The existing debug information jointcal can provide was not enough to readily narrow down the source of this; there may be something pathologically wrong with the initial model. To help debug such problems, we need a way to write out the initial model to disk. A {{writeInitialModel}} option in the jointcal config that just dumps text files for each model component would be a good start: I think all of the AstrometryTransforms have useful string representations."""
"DM-21003","Bug","pex_exceptions",0.5,"pex_exceptions wrapper exceptions should only inherit from one kind of python exception","""pex_exceptions exception wrapper, likely as a residual effect of future usage from python, inherits from multiple python exceptions. This seems to break some tests, as in the case of a test case from utils. The inheritance should be simplified."""
"DM-21014","Story","ts_aos|ts_main_telescope",0,"Fix the M2 Configuration Editor by MATLAB","""Fix the M2 configuration editor by MATLAB, which has the broken GUI with missing button, text, and configuration files.         PS. Use the story point of [DM-20998|https://jira.lsstcorp.org/browse/DM-20998]."""
"DM-21013","Story","daf_butler",2,"Add description for daf_butler expression parser","""We need to add documentation for the expression syntax understood by exprParser."""
"DM-21009","Story","daf_butler",5,"Refactor S3 and Posix datastores to remove code duplication","""The new S3Datastore duplicates a lot of logic from PosixDatastore. This is fine in the short term but we need to try to refactor a bit to prevent bugs appearing when a fix is made in one datastore but not the other."""
"DM-21032","Story","ts_middleware",3,"Coordinate the v4.0.0 Release of SAL","""This task covers the time to release v4.0.0 of SAL, update the tests accordingly, as well as work with [~cwinslow] to train him on the SAL release process."""
"DM-21031","Story","ts_middleware",2,"Coordinate the v4.1.1 Release of XML","""This task covers the time to release v4.1.1 of the XMLs, as well as work with [~cwinslow] to train him to cover this work when I am unavailable."""
"DM-21016","Improvement","obs_base|obs_decam|obs_lsst|obs_subaru",8,"Handle DECam instrument signature data in gen3","""DM-20763 dealt with ingesting DECam data, but punted on managing the instrument signature data. This will require at-minimum implementing {{writeCuratedCalibrations}}.    I've linked a variety of DECam calibration-related tickets as """"related', since we can maybe close some of those as won't fix once this is done (since they might be gen2-specific)."""
"DM-21043","Story","Qserv",5,"Qserv log diet: use named context for query ID","""Bunch of logging messages from qserv uses explicit """"QI=12345"""" (or """"QI=12345:123"""") to identify query ID. It would be better to replace it with a logging context if possible."""
"DM-21039","Bug","jointcal",0.5,"Fix calib reference in plot_photoCalib","""[~lauren] pointed out on slack that I'd missed a `calib` reference in jointcal's plot_photoCalib script:    https://github.com/lsst/jointcal/blob/master/bin.src/plot_photoCalib.py#L143    I need to fix that, and I should check if any of the other bin/ scripts in jointcal have a similar issue."""
"DM-21035","Story","ts_environment",1,"Upgrade DIMM CSC to salobj 4 and make it a configurable CSC","""DIMM CSC needs to be upgraded to SalObj 4 and also become a configurable CSC."""
"DM-21055","Story","ctrl_mpexec",2,"Do not fill output collection if QuantumGraph is empty.","""John Parejko was having issues with re-running pipeline on output collection:  https://lsstc.slack.com/archives/C2JPT1KB7/p1566508300359600      I do not expect to be written if QuantumGraph is empty , need to check what is happening."""
"DM-21053","Story","meas_mosaic",1,"Officially deprecate meas_mosaic","""The implementation of RFC-617's DM-20548 effectively breaks {{meas_mosaic}} and the RFC calls for its deprecation. Please perform the necessary steps to remove it from {{lsst_distrib}} and move it from the lsst GitHub organization to that of lsst-dm (as a legacy repo?)"""
"DM-21078","Bug","obs_base|pipelines_lsst_io",0.5,"Fix pipelines.lsst.io build issue from d_2019_08_23","""Since {{d_2019_08_23}} the pipelines.lsst.io builds have been breaking. ([#599|https://ci.lsst.codes/job/sqre/job/infra/job/documenteer/599/display/redirect])    The issue seems to be in {{obs_base}}:    """
"DM-21072","Bug","ts_middleware",0,"Add LOVE events","""LOVE is now a SAL component. Add suitable events."""
"DM-21097","Story","ts_auxiliary_telescope",1,"Improve the current_tai salobj function to read TAI directly if available","""In DM-20849 I added a {{current_tai}} function to ts_salobj. However, it works by calling {{time.time()}} and converting it to TAI using {{tai_from_utc}}. This is likely to be slightly off very near a leap second transition. (Fortunately we are not expecting one anytime soon, so there is time to deal with this).    The proposed long-term solution is to call Linux function {{clock_gettime(CLOCK_TAI, ...)}}. There are a few subtleties:  * By default this will return UTC, not TAI. Only on systems with a an NTP or PTP daemon configured to set the current TAI-UTC will this actually return TAI. We need to decide how to handle this. At present very few of our current CSCs have ptp or ntp configured such that CLOCK_TAI returns the correct value. This will, of course, change -- at least for deployed software. I am less sure if we can make it happen for our development environments.  * Even if TAI-UTC is not zero it may still be incorrect. That is harder to handle and I do not propose to try to detect it in salobj. It can easily be checked in the Watcher or by an EFD monitor.  * Some operating systems do not have CLOCK_TAI, including macOS. However, we think all our deployment or development systems support CLOCK_TAI.    Options include:  * Silently return UTC (as SAL does). I hate silent failures, but it makes for simple code and is a appropriate choice if our systems are almost always correctly configured (even our development environments).  * Raise an exception. This seems far too drastic.  * Return TAI (correct the time using AstroPy). This is rather complex, but I believe it necessary if we adopt this code now, because few CSCs have ptp or ntp correctly configured.    I think salobj should also provide a way to test CLOCK_TAI, e.g. return TAI-UTC. CSCs could do this as they start up and log a message if ptp is mis-configured.    I am inclined to do two things:  1) Silently return UTC  2) As a CSC starts up test the value to see if it matches UTC, and if it does, log a warning about clock error.    Another option is to use ts_sal directly, but this has several issues:  * At present ts_sal only makes the functions available as part of a SALPY library, and in particular as part of the SAL object. It is not safe to construct a SAL object in code that uses OpenSplice dds (it leads to segfaults). In any case we will want a smaller more focused library.  * We still have to perform the checking mentioned above. ts_sal's getCurrentTime function silently returns UTC not TAI unless something such as an ntp or ptp daemon is properly configured."""
"DM-21117","Story","dm_dev_guide",0.5,"Document sqrbot-jr create project and create file usage in developer guide","""The developer guide should reference the usage of {{@sqrbot-jr create project}} and {{@sqrbot-jr create file}}:    - To create technotes  - To create new repositories  - To create license boilerplate and preambles  - To create documentation topics"""
"DM-21110","Story","ts_middleware",1,"SAL 4 is adding content that looks extra and unwanted to IDL files","""The SAL 4 branch is adding some fields to the revcode IDL that I suspect are not wanted. I don't know if older SAL also does this.    After all the command and events, but before the """"ackcmd"""" topic I see these entries, which stand out because they are indented (just as shown here). One command with no name and one logevent with no name:    I suspect these should not be present and am worried they may confuse code that tries to parse the IDL, such as the sal/kafka producer (it will parse IDL files to find descriptions and units)."""
"DM-21106","Story","ts_middleware",2,"Please add a salgenerator command that just generates the rev-coded IDL","""Please add a salgenerator command that just makes rev-coded IDL files (e.g. sal_revCoded_ATCamera.idl) -- the files used by dds salobj.    The main purpose is to speed up generation of these IDL files, since there would be no need to create C++ or other source code."""
"DM-21104","Bug","Third Party Software",0.5,"Upgrade GSL to v2.6 to see if this fixes intermittent failures to build gsl on macOS","""A few times a month, Jenkins fails to build {{lsst_distrib}} because one or the other macOS platform cannot build the {{gsl}} package.  It is always due to an include file not being found, but the files differ.    [https://ci.lsst.codes/job/scipipe/job/lsst_distrib/732/artifact/osx-10.14.clang-1000.10.44.4.py3/lsstsw/build/gsl/_build.log] is an example."""
"DM-21103","Bug","verify",0.5,"lsst.verify seems to be broken","""If you unpack the attached tarball and run test_load_metrics.py, you will find that it works on w.2019.29 but not on w.2019.33.  test_load_metrics.py just tries to load a MetricsSet from a local directory.  The commissioning team was planning to use this sort of interface in building its test notebooks."""
"DM-21138","Story","ts_aos|ts_main_telescope",1,"Check the M2 MATLAB Tools with Functions by Harris","""Check the M2 MATLAB tools with functions provided by Harris. The attached files ([^FunctionsForLSST.zip]) are the missing functions provided by Harris. This is a follow-up task of [DM-21014|https://jira.lsstcorp.org/browse/DM-21014]."""
"DM-21132","Story","ts_main_telescope",1,"SalObj 4 Bootcamp","""SalObj 4 Bootcamp"""
"DM-21130","Story","ts_auxiliary_telescope",1,"Please add asynctest to Docker images","""Please add the https://github.com/Martiusweb/asynctest package to Docker containers used for Python T&S software. This adds some useful support to unittest, including the ability to write asynchronous test cases directly, e.g.:    instead of    (which silently does nothing if one forgets the event loop call)"""
"DM-21129","Improvement","afw",1,"Improve ""unsupported operand types"" error for afwImage arithmetic","""If a user tries to add two images, or multiply an image by a constant, or do any kind of not-in-place image arithmetic, they get an unfriendly {{TypeError: unspotted operand type(s)}}.    This ticket is to clarify the error message and suggest an alternative, for example, """"afwImages must be modified in place, e.g., if you want image1 + image2, try image1 += image2."""""""
"DM-21147","Story","dm_dev_guide",2,"Update capitalization guidelines in dev guide as per RFC-623","""Update the developer guide as proposed in RFC-623."""
"DM-21164","Story","efd",3,"Extend example notebook from Angelo to complex use cases","""Extend the notebook produced in DM-21067 to show more complicated investigations.  Examples would be:    * Correlating series from different measurements in the EFD: current vs. temperature or similar  * Show how to investigate annotations in a notebook.  * Log entries with telemetry streams."""
"DM-21158","Story","ts_aos|ts_main_telescope",2,"Upgrade the M2 Cell Control System in cRIO to LabVIEW 2018 SP1","""This task is to update the M2 cell control system in cRIO to use the LabVIEW 2018 sp1 32 bit version. It is using the LabVIEW 2015 sp1 32 bit at this moment. The followings are the steps:   # Install the LabVIEW 2018 sp1 32 bit version and related toolboxs in the windows laptop.   # Fix the M2 cell projects for the possible interface changes between the LabVIEW 2015 sp1 and 2018.   # Deploy the M2 cell code to cRIO.   # Test the connection between M2 controller and cell."""
"DM-21156","Bug","ctrl_iip",2,"Transition to FAULT state should also disable heartbeat","""Transitioning to the FAULT state should also disable the heartbeat, which it currently doesn't do, but should."""
"DM-21154","Bug","ctrl_iip",1,"Bad credentials for authentication to rabbitmq server cause ungraceful failure","""Ran into an issue where bad login credentials to attach to the RabbitMQ server caused  repeated failures (many repeated logging messages).   When this happens, it should be caught gracefully."""
"DM-21153","Story","pipe_tasks",2,"Fix bugs in DcrAssembleCoaddTask from PipelineTask merge","""The merge of DM-20692 changed the call signature of {{AssembleCoaddTask.processResults()}}, which is used in {{DcrAssembleCoaddTask}}.  The breaking change was not caught by existing unit tests."""
"DM-21180","Improvement","Qserv",0.5,"Change the default logging level of the XRootD/SSI","""The current logging level for {{XRootD/SSI}} is set to {{DEBUG}}. This results in the large amount of (mostly - useless) messages stored in the Qserv {{mysql-proxy}} log file. A goal of this development is to change the level to {{WARN}}."""
"DM-21175","Story","ts_ait|ts_auxiliary_telescope|ts_main_telescope",1,"Try using a single DDS sample cache shared by the script queue and scripts","""The ADLink consultant we hired suggested that we use a single DDS cache shared between the script queue and scripts in order to speed up starting up scripts (apparently it will greatly reduce the time required to wait for historical data).    [~dmills] suggests adding the following to the ospl.xml file pointed to by OSPL_URI  (ie the global configuration):        I think the relevant bit is:  """
"DM-21171","Story","pipe_tasks",8,"Create task to add local PhotoCalib and WCS value to source table rows","""As part of the ScienceDataModel we need to have calibration products available for use in the Functors in the SDM code. One solution to making these products available is to compute their local values and store them per row in the afw tables output by various SciencePipelines tasks. This ticket will implement a task to perform this operation."""
"DM-21169","Improvement","obs_lsst",5,"Add Corner Rafts with correct positions and rotations to obs_lsst","""The nominal positions and orientations of the CCDs in the corner rafts can be found on page 4 of ls.st/lca-13381.   [~roodman] can provide details on the as-built rotations and offsets."""
"DM-21167","Story","ap_association",8,"Migrate ap_association fully to new DiaCalculation plugin system for time-series features.","""Remove pervious code in ap_association that produces static and time-series features and replace them with the new DiaCalculation measurement pluggin system created in DM-18494"""
"DM-21196","Story","ts_middleware",2,"Raise exception if remote is called but not fully ready","""Currently, if the start_task is not run (and awaited) then it is possible to use a remote and it will timeout (or not respond) until it comes alive. This ticket is to implement the functionality that will raise an exception if it is not completed, and provide an error message to use the start_task to avoid the exception"""
"DM-21194","Story","ts_auxiliary_telescope",2,"Convert AVS mock into spectrograph simulator","""Once I have the the complete FiberSpectrograph code written in DM-21188, I should lift the {{unittest.Mock}} system into a separate importable class ({{FiberSpectrographSimulator}}?), so that it can be used by the CSC and any CSC unittests. The simulator should have a way to disable the patches as well, to restore the real spectrograph communication."""
"DM-21192","Story","ts_middleware",3,"Coordinate the v4.2.0 Release of XML","""This task covers the time to release v4.2 (or whatever it gets tagged with) of the XMLs, as well as work with [~cwinslow] to train him to cover this work when I am unavailable."""
"DM-21191","Story","ts_middleware",5,"Coordinate the v4.0.0 Release of SAL","""This task covers the time to release v4.0.0 of SAL, update the tests accordingly, as well as work with [~cwinslow] to train him on the SAL release process."""
"DM-21189","Bug","ctrl_iip",2,"Fix issue where exception can be thrown on sending basic_cancel on closed channel","""There's an issue in the Consumer object where it's possible to send a basic_cancel on a closed connection.  The current code checks for the existence of the channel, rather than checking whether the channel is open or not."""
"DM-21187","Story","obs_lsst",3,"Camera name is wrong in YAMLCamera files","""The generated camera YAML files always have """"lsstCam"""" as the name of the camera. This is not true for AuxTel or test stands.  This needs to be fixed."""
"DM-21186","Story","obs_lsst",2,"Rename auxTel to LATISS","""The name of the camera on AuxTel is LATISS.  Unfortunately we call the camera AuxTel in obs_lsst. It would be much clearer to use the proper name.    I think so long as AuxTelMapper class is still called the same name (so existing gen2 repos don't need to change) that everything else can be changed to LATISS and Gen3 (see DM-16297) can use the correct name."""
"DM-21181","Story","afw",2,"Add getLocalCalibration function to PhotoCalib","""DM-21171 needs access to the local calibration from PhotoCalib. No currently exposed function within PhotoCalib takes a point and returns the local calibration and error. This ticket will create such a function and expose it within python."""
"DM-21213","Story","mops",8,"Implement Gauss's method for IOD","""Baseline IOD and OD package will likely be pyoorb / oorb but we need to validate some of its basic functionality so having a python implementation of IOD is useful. To that end, we need an implementation of Gauss's method to get an estimate of an initial orbit from a linkage.     Enhancing Gauss's method with different methods to find the velocity at the time of the second observation is necessary especially when dealing with different observing arcs. Supporting velocity methods include Gibbs and Herrick+Gibbs.           """
"DM-21212","Improvement","cp_pipe",40,"Update existing cp_pipe tasks to pipelineTasks","""The new tasks for cp_pipe will need to be ready to work with the gen3 butler/as pipelineTasks in the near future, which likely requires some sort of plan.  This ticket is to remind everyone of that fact."""
"DM-21209","Story","ts_environment",8,"Implement HVAC telemetry into XML files","""Compile telemetry generated by HVAC control software. Organize the telemetry into XML files and generate updated version of MQTT publication software."""
"DM-21208","Improvement","ImgServ",5,"Pixels without data in images retrieved via SODA service set to zero","""In [this|https://github.com/lsst-sqre/notebook-demo/blob/master/LSST%20SODA%20Tutorial.ipynb] notebook there is a demonstration of using the SODA service.  In one case, a circular cutout is retrieved.  The resulting image is the shape of the circumscribing square with the unpopulated pixels set to zero.  This has the problem that it makes it impossible to tell programmatically which pixels are in the cutout and which are not.    There are two solutions I came up with when talking to [~cbanek]:  1) Set the pixels with no data to {{NaN}} instead of 0  2) Return a masked image instead of an image    I would prefer option 2, and I believe the standard supports it, but would be OK with option 1 if there are technical reasons to prefer it."""
"DM-21207","Story","ip_diffim|meas_algorithms|pex_config",1,"Remove deprecated Policy usage from pex_config, ip_diffim, and meas_algorithms","""In DM-21065 we deprecated the use of Policy as an API argument in ip_diffim and meas_algorithms and announced they would be removed after release 19.0.    This ticket is to remove those deprecated APIs (retaining the PropertySet implementations) and to remove pex_config.makePolicy."""
"DM-21206","Story","ts_middleware",1,"xml build","""build xml and sal with rob. There will be no errors and everything will go smoothly."""
"DM-21200","Story","HeaderService",2,"Update CSC transition script to capture timeout in Remote","""The current script {{csc_send_to_state}} fails to transition {atHeaderService} at the Tucson test stand. Tiago Riviero suggest to add an {await} to the {Remote.start_task}"""
"DM-21227","Story","ts_aos",1,"Migrate the Test Jobs on Jenkins from DM to TSSW","""Migrate the test jobs on Jenkins from DM to TSSW. The following repositories will be moved: ts_wep, ts_ofc, ts_phosim, and ts_MTAOS."""
"DM-21240","Story","obs_lsst",0.5,"Fix usage of auxTel in obs_lsst config files","""DM-21186 didn't quite finish the job and some config files still refer to auxTel."""
"DM-21237","Story","ip_diffim",2,"BBox error in some DCR image differencing templates","""Some images have been failing during image differencing using the DCR-matched template, that succeeded with a standard coadd template. These images appear to fail for patches covering the extreme edges of the area with data, but more investigation is needed. Example error message below:     {code:python}    apPipe INFO: Running ImageDifference...  apPipe.differencer INFO: Processing DataId(initialdata=\{'ccdnum': 44, 'filter': 'g', 'visit': 410929, 'date': '2015-02-17', 'object': 'Blind15A_40'}, tag=set())  apPipe.differencer.getTemplate INFO: Using skyMap tract 0  apPipe.differencer.getTemplate INFO: Assembling 6 coadd patches  apPipe.differencer.getTemplate INFO: exposure dimensions=(2048, 4096); coadd dimensions=(5424, 2740)  apPipe.differencer.getTemplate INFO: Constructing DCR-matched template for patch \{'datasetType': 'dcrCoadd_sub', 'bbox': Box2I(minimum=Point2I(60087, 34140), dimensions=Extent2I(13, 1960)), 'tract': 0, 'patch': '14,8', 'numSubfilters': 3}  apPipe FATAL: Failed on dataId=\{'ccdnum': 44, 'filter': 'g', 'visit': 410929, 'date': '2015-02-17', 'hdu': 48, 'object': 'Blind15A_40'}: LengthError:    File """"src/image/Image.cc"""", line 89, in static lsst::afw::image::ImageBase<PixelT>::_view_t lsst::afw::image::ImageBase<PixelT>::_makeSubView(const Extent2I&, const Extent2I&, const _view_t&) [with PixelT = float; lsst::afw::image::ImageBase<PixelT>::_view_t = boost::gil::image_view<boost::gil::memory_based_2d_locator<boost::gil::memory_based_step_iterator<boost::gil::pixel<float, boost::gil::layout<boost::mpl::vector1<boost::gil::gray_color_t> > >*> > >; lsst::geom::Extent2I = lsst::geom::Extent<int, 2>]   Box2I(Point2I(-60087,-34140),lsst::geom::Extent2I(0,0)) doesn't fit in image 13x1960 \{0}  lsst::pex::exceptions::LengthError: 'Box2I(Point2I(-60087,-34140),lsst::geom::Extent2I(0,0)) doesn't fit in image 13x1960'    /software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pex_config/18.1.0-4-gc96e915/python/lsst/pex/config/config.py:1276: FutureWarning: Config field ccdProcessor.isr.doAddDistortionModel is deprecated: Camera geometry is incorporated when reading the raw files. This option no longer is used, and will be removed after v19.   FutureWarning)  /software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/ap_association/18.1.0-8-g5734da6/python/lsst/ap/association/mapApData.py:185: YAMLLoadWarning: calling yaml.load_all() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.   table_list = list(yaml.load_all(yaml_stream))  /software/lsstsw/stack_20190330/python/miniconda3-4.5.12/envs/lsst-scipipe/lib/python3.7/site-packages/astropy/units/function/logarithmic.py:43: RuntimeWarning: invalid value encountered in log10   return dex.to(self._function_unit, np.log10(x))  Traceback (most recent call last):   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/18.1.0-4-g6c9d669+5/python/lsst/pipe/base/cmdLineTask.py"""", line 388, in __call__   result = self.runTask(task, dataRef, kwargs)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/18.1.0-4-g6c9d669+5/python/lsst/pipe/base/cmdLineTask.py"""", line 447, in runTask   return task.runDataRef(dataRef, **kwargs)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/18.1.0-4-g6c9d669+5/python/lsst/pipe/base/timer.py"""", line 150, in wrapper   res = func(self, *args, **keyArgs)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/ap_pipe/18.1.0-4-gcd8f52c+10/python/lsst/ap/pipe/ap_pipe.py"""", line 202, in runDataRef   diffImResults = self.runDiffIm(calexpRef, templateIds)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/18.1.0-4-g6c9d669+5/python/lsst/pipe/base/timer.py"""", line 150, in wrapper   res = func(self, *args, **keyArgs)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/ap_pipe/18.1.0-4-gcd8f52c+10/python/lsst/ap/pipe/ap_pipe.py"""", line 276, in runDiffIm   return self.differencer.runDataRef(sensorRef, templateIdList=templateIds)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/18.1.0-4-g6c9d669+5/python/lsst/pipe/base/timer.py"""", line 150, in wrapper   res = func(self, *args, **keyArgs)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/18.1.0-15-gc153667b/python/lsst/pipe/tasks/imageDifference.py"""", line 353, in runDataRef   template = self.getTemplate.run(exposure, sensorRef, templateIdList=templateIdList)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/ip_diffim/18.1.0-9-gae7190a+1/python/lsst/ip/diffim/getTemplate.py"""", line 153, in run   visitInfo=exposure.getInfo().getVisitInfo())   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/ip_diffim/18.1.0-9-gae7190a+1/python/lsst/ip/diffim/dcrModel.py"""", line 386, in buildMatchedExposure   bbox=bbox, wcs=wcs, mask=mask)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/ip_diffim/18.1.0-9-gae7190a+1/python/lsst/ip/diffim/dcrModel.py"""", line 349, in buildMatchedTemplate   refModel = self.getReferenceImage(bbox)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/ip_diffim/18.1.0-9-gae7190a+1/python/lsst/ip/diffim/dcrModel.py"""", line 274, in getReferenceImage   return np.mean([model[bbox].array for model in self], axis=0)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/ip_diffim/18.1.0-9-gae7190a+1/python/lsst/ip/diffim/dcrModel.py"""", line 274, in <listcomp>   return np.mean([model[bbox].array for model in self], axis=0)   File """"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/afw/18.1.0-15-gbf79fb8fa/python/lsst/afw/image/slicing.py"""", line 262, in __getitem__   return self.subset(box, origin=origin)  lsst.pex.exceptions.wrappers.LengthError:    File """"src/image/Image.cc"""", line 89, in static lsst::afw::image::ImageBase<PixelT>::_view_t lsst::afw::image::ImageBase<PixelT>::_makeSubView(const Extent2I&, const Extent2I&, const _view_t&) [with PixelT = float; lsst::afw::image::ImageBase<PixelT>::_view_t = boost::gil::image_view<boost::gil::memory_based_2d_locator<boost::gil::memory_based_step_iterator<boost::gil::pixel<float, boost::gil::layout<boost::mpl::vector1<boost::gil::gray_color_t> > >*> > >; lsst::geom::Extent2I = lsst::geom::Extent<int, 2>]   Box2I(Point2I(-60087,-34140),lsst::geom::Extent2I(0,0)) doesn't fit in image 13x1960 \{0}  lsst::pex::exceptions::LengthError: 'Box2I(Point2I(-60087,-34140),lsst::geom::Extent2I(0,0)) doesn't fit in image 13x1960'  {code}"""
"DM-21232","Epic","ts_main_telescope",13,"Support for Hexapod/Rotator System Ready for Integration in Phase 2","""Continued changes and support for M2 Hexapod System to be ready for Integration    Corresponding P6 Activity:    T&SC-140403-1300 - M2 Hexapod System Ready for Integration"""
"DM-21262","Improvement","ts_auxiliary_telescope",1,"Get agreement on how alarms should be escalated for the Watcher","""Folks generally seem to agree that some really important alarms should be escalated to off-site personnel if not acknowledge in time. This ticket captures the work of coming to an agreement on *how* this escalation will be done, e.g. via a phone call (which will probably require a paid subscription to some service), text message, slack message or some combination of techniques."""
"DM-21261","Improvement","ts_auxiliary_telescope",2,"Implement auto-unack and auto-ack in the Watcher","""Implement the following features in the Watcher:  * unack (snooze): an acknowledged alarm will un-ack itself after a specified period if the condition persists.  * auto-ack: a stale alarm will auto-ack itself after a specified period (as long as the alarm remains stale).    There will be a default duration for each of these feature, which can be overridden by the alarm rule. A suitable duration (probably 0) will mean """"never"""".    The default duration will be a configuration parameter for the CSC. Rule-specific durations may be part of the rule configuration, but it depends on the rule author."""
"DM-21248","Bug","obs_base",0.5,"cameraMapper _standardizeExposure should not try to create a WCS for each amp","""After DM-20154, updates were made to {{\_standardizeExposure}} which now creates a WCS from visit metadata.  The problem is that {{\_standardizeExposure}} is called _per amp_ when reading raws, which leads to a cascade of warnings with {{obs_lsst}} because there are a lot of amps, and the {{visitInfo}} hasn't been created yet with the appropriate metadata to create a WCS.  However, even if the warnings aren't there, it is unnecessary and inefficient to create a WCS for each amp, when this should be done once at the ccd-level after assembly (and after the appropriate metadata has been created).    I believe this should be a quick fix that simply checks if it is called with the amp level before trying to set the wcs.  At the same time maybe the per-amp setting of the filter is also unnecessary?"""
"DM-21246","Story","daf_butler",2,"Allow deferred passing of run/collection to Butler","""While working on ingest and especially gen2convert, I've found it frustrating to need to pass a collection/run to Butler at construction, rather than later, when calling get/put/ingest.  We often need an object that represents the combination of a Registry and a Datastore _without_ specifying a collection/run.    I think we should add optional """"run"""" kwargs to all Butler write operations and """"collection"""" kwargs to all read operations, and make the corresponding construction arguments an optional way to provide defaults for these.    As a side note, I think I'd like to eventually move to having Butler support lookup with ordered sequence of collections rather than just a single one.  We could anticipate that by making the new kwargs for read operations a """"collections"""" sequence rather than than a """"collection"""" scalar, even if we don't implement support for more than one yet, but I'm also willing to defer that for later."""
"DM-21286","Story","sconsUtils",1,"Enable Astropy download cache","""In Jenkins HOME is not available to tests so the Astropy cache directory is not shared between processes.  This leads to IERS table files being downloaded every single time a tests are run. Sometimes the download fails and that usually causes test failures that waste developer time. Forwarding HOME to the test environment would fix this but we are concerned that this may introduce side effects into the test environment. Astropy provides another mechanism via the XDG_CACHE_HOME environment variable.    If this variable is not set we should set it to {{~/.lsst/}} and create an {{astropy}} directory for the cache.  Do not forward XDG_CONFIG_HOME since that might affect tests using astropy."""
"DM-21281","Story","ts_auxiliary_telescope",1,"Test activating an already-activated spectrograph, and add unittests as necessary","""[~rowen] pointed out that we should probably be testing the {{AvsIdentity.DeviceStatus}} field returned by {{AVS_GetList}} for values other than {{1}}. The vendor docs don't say enough about under what conditions the {{0,2,3}} states can be set, so I'll just have to play with the device some to see if I can get any of them to trigger. If I can, I'll add some tests of those states, so that the controller can provide useful error messages if it encounters them."""
"DM-21276","Improvement","afw",2,"Ensure all prescan/overscan accessors exist","""Camera generation from yaml and FITS disagree on naming of serial/parallel vs horizontal/vertical, and disagree on the existence of all types of -scans.  Ensure accessors exist so that any nomenclature works correctly."""
"DM-21269","Story","ts_main_telescope",5,"Update the Middleware Code by Moog to Use the Latest SAL Version","""Update the middleware code by Moog to use the latest SAL version. At this moment, the ts_sal 4.0 is unavailable. Therefore, the latest version of ts_sal and ts_xml will be used. The code update might be needed for the possible DDS/ xml interface changes. This task will also try to find a way to test the code even though the hexapod/ rotator cRIO controller and hardware are unavailable."""
"DM-21304","Improvement","ts_auxiliary_telescope",1,"Add async method for handling new summary state to BaseCsc","""Add an asynchronous method to BaseCsc that is called when the summary state changes, e.g. handle_summary_state. This will be the new preferred way to handle changes to summary state (leaving report_summary_state to just report the new state) and the base class will do nothing, so CSCs will not have to call super().handle_summary_state(...)    This may be a bit tricky because it needs to be called whenever report_summary_state is called, and that is called from two synchronous functions: fault and the summary_state setter. The following might work:    * Have fault start handle_summary_state but not wait for it to finish  * Deprecate the summary_state setter and stop using it in salobj. Just set self._summary_state directly when necessary rather than add a new synchronous public method. CSCs should not set this value.  * Have the summary_state setter start handle_summary_state but not wait for it to finish. I don't see much choice.  * When setting summary_state internally as part of a normal state transition call handle_summary_state before report_summary_state, so if something goes wrong one can go directly to fault state without claiming to have gone into the desired state (since the CSC never actually makes it to the new state).  * If report_summary_state or handle_summary_state raises an exception go into fault state. Ideally the CSC would already have faulted, so this is merely a fallback. This requires error codes to not be globally unique."""
"DM-21301","Story","daf_butler",2,"pipetask --register-dataset-types doesn't work with Postgres registry on AWS","""pipetask {{--register-dataset-types}} doesn't work with the RDS registry. It should work even if the dataset type already exists.     For example,     """
"DM-21299","Story","ts_qa",1,"Update SAL tests to verify significant files exist","""It might be nice to have tests that verify significant data files and executables exist and are in the correct location before running the salgenerator builds."""
"DM-21295","Story","System Integration and Test",5,"Setup and support M1M3 EFD for summit test campaign","""Clone the old EFD machine using a copy of the disk. Install and setup in  EFD machine at the summit. Support the test activities."""
"DM-21291","Improvement","ts_auxiliary_telescope",1,"Update ts_scriptqueue unit tests to use asynctest","""Update the unit tests in ts_scriptqueue to use asynctest."""
"DM-21327","Improvement","afw",8,"Replace ExposureInfo implementation with homogeneous map","""{{lsst.afw.image.ExposureInfo}} is currently implemented in terms of a {{lsst.afw.typehandling.GenericMap}}. However, this class is brittle and difficult to use (see, e.g., DM-21216 and DM-21268), nor do we use its heterogeneity in {{ExposureInfo}}: we are only interested in storing {{lsst.afw.typehandling.Storable}} and {{shared_ptr<Storable>}}, and the only application for the former is incompatible with {{Storable}} due to custom persistence. Thus, {{GenericMap}} makes {{ExposureInfo}} difficult to use and maintain while not providing any needed functionality.    Reimplement {{ExposureInfo}} in terms of a homogeneous map from strings to {{shared_ptr<Storable>}}. This map should have its own class in order to encapsulate strongly-typed handling of {{Storable}} (the one form of heterogeneous type support in {{GenericMap}} that we do use). Unlike {{GenericMap}}, this class need not have a separate interface or a Python API, since it will exist only as an implementation detail of {{ExposureInfo}}."""
"DM-21324","Story","HeaderService",2,"Fix missing logging for HeaderService sub-modules","""The migration to {{ts_salobj}}  introduced a bug to the HeaderService were logging is missing from the sub-modules."""
"DM-21308","Story","fgcmcal",3,"Update pipe_tasks to allow for changing external calibrations","""Update {{pipe_tasks}} and related configs to allow coadditions with different external {{PhotoCalib}} and {{SkyWcs}} calibrations, supporting {{jointcal}}, {{fgcmcal}}, and {{fgcmcal_tract}} for photometric calibrations, and {{jointcal}} for astrometric calibrations.  Terminology is now matched to DM-21950.    Originally: Following on DM-20161, with fgcmcal tract-based calibrations, run RC2 coadds."""
"DM-21338","Story","ts_middleware",1,"Update ts_xml.lsst.io with new CSC developers","""As folks have left the T&S team and CSCs have been redistributed, the listing at ts_xml.lsst.io is in need of a refresh."""
"DM-21336","Epic","ts_auxiliary_telescope|ts_main_telescope",20,"Telescope Script Development Part 2","""This is  a continuation of DM-20173 & DM-20176    which was a continuation of DM-16910    This Epic is to allocate resources to script development, irregardless of components the scripts are working on.  Non-specific integration work should go here."""
"DM-21331","Improvement","ts_middleware",1,"Modernize the way tasks are run in scriptqueue","""Modernize the following:  * Use {{asyncio.run}} instead of {{asyncio.get_event_loop().run_until_complete}}  * Use {{asyncio.create_task}} instead of {{asyncio.ensure_future}} where it is safe to do so.  * Make sure there is an event loop before any domain, remote or CSC  * Use {{ScriptQueue.amain}} to run the ScriptQueue instead of making a separate parser  * Run scripts using {{amain}} instead of {{main}}  * Update unit tests to use {{asynctest}}"""
"DM-21328","Story","ts_auxiliary_telescope",2,"Modernize the way tasks are run in salobj","""Update salobj for Python 3.7 as follows:  * Use {{asyncio.run}} instead of {{asyncio.get_event_loop().run_until_complete}}  * Use {{asyncio.create_task}} instead of {{asyncio.ensure_future}} where practical. Stick to ensure_future in library code for backwards compatibility, especially with {{request_script.py}} in ts_scriptqueue which runs the event loop in a very unusual way that is not compatible with {{create_task}}.    To make this easier I added class method `amain` to `BaseCsc` and `BaseScript` and deprecated `main`.    Note that code should make sure an event loop exists when constructing a `Domain`, `Controller` or `Remote`, but we can't enforce that as long as we have {{request_script.py}}  """
"DM-21357","Story","daf_base",1,"Add items() method to PropertySet/PropertyList","""Prior to DM-16297 when a header was merged in astro_metadata_translator the resultant header was always a dict and never a PropertyList.  In DM-16297 that is changing because PropertyX can now support for dict-like methods and the conversion to a dict is not required, and also the result of the merge must be able to be sent to afw and it is important that the type does not change.    This breaks pipe_drivers which expects the result from merge_headers to support the {{items()}} method and PropertyX does not.  On this ticket I will add {{items()}} using the existing {{\__iter__}} support."""
"DM-21355","Bug","afw",1,"A NaN value in a PropertySet can cause an abort when reading WCS","""When reading a WCS with {{readFitsWcs}} in {{afw}}, then a {{SIGABRT}} is thrown if the associated {{PropertyList}} has a value for a {{NaN}} because {{astshim}} complains that fits header cards cannot contain {{NaN}} (even though I believe this is just a convenience and no fits headers are persisted in this way).    The fix according to [~tjenness] is to check for a {{NaN}} on line 351 of {{frameSetUtils.cc}}: https://github.com/lsst/afw/blob/7c0af834f66868c8a223af827bd0fe110619bc2e/src/geom/detail/frameSetUtils.cc#L351 and replace it with a legal sentinel value."""
"DM-21353","Story","Developer Infrastructure",1,"Test Science Pipelines software build with CentOS8","""CentOS 8 will be released imminently. We need to check that lsst_distrib can be built with it as a precursor to dropping CentOS6 from Jenkins and replacing it with CentOS8.  """
"DM-21351","Story","obs_base|obs_test|pipe_base",0.5,"Move pipe_base tests to obs_test to normalize dependencies","""pipe_base depends on obs_test in order to run its unit tests.  This adds an indirect dependency from pipe_base on obs_base.    We'd like to both start adding Tasks for Gen3 data repository management (e.g. ingest) to obs_base (well, we've already done so, but don't yet import them at package scope) and keep meas_* from depending on obs_test.  This would accomplish both.    Work on this is already at least mostly done on DM-20864; this ticket will cherry-pick those changes in order to land them a bit faster than the rest of that ticket."""
"DM-21349","Story","ctrl_iip",1,"Fix information exchange between ATArchiver and ArchiveController","""The ArchiveController has information about which directories below the top level storage area should be used to put images.  The ATArchiverCSC needs to message the ArchiveController in order to get this information, otherwise everything ends up in the top level area."""
