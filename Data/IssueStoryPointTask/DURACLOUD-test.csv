"issuekey","type","components","storypoint","title","description_text"
"DURACLOUD-733","Bug","Utility",2,"Sync Tool: CPU Utilization","""The Sync Tool, when run, tends to use a very large percentage of the CPU. As noted by SaaS4, running the Sync Tool continuously for 10 days kept the CPU on their server pegged at 100% the entire time.  It seems likely that the high CPU utilization is due to the constant generation of MD5 checksums for each file. This would be a particular issue when the file set contains a large number of very small files.  This task is to investigate the reason behind the heavy CPU usage. Ideally a fix could also be included."""
"DURACLOUD-736","Bug","UI",1,"Loading throbber disappears before content item is loaded.","""Not a huge problem, but is slightly confusing if there is a lot of latency:  1.  click on a space and then click a content item. 2. notice that the """"loading..."""" throbber flashes and then disappears before the new content is loaded.  """
"DURACLOUD-737","Story","Utility",3,"SyncTool: Preserve local file timestamp information","""Based on feedback from the State of North Carolina, they would like the sync tool to preserve the local timestamp information for individual files (both the creation and modified dates/times). They would like this information passed into DuraCloud via the sync tool, available for viewing within DurAdmin, and then retrieved/restored properly by the retrieval tool when content is downloaded."""
"DURACLOUD-739","Story","Utility",2,"Timestamp collection utility","""This task is to create a utility which can loop through a set of directories and capture the timestamp information (Creation Date, Modified Date, Access Date) on each of the included files. That timestamp info should be written to a file (so that it can be archived locally) as well as written as metadata to each files's corresponding DuraCloud content item. (The expectation here being that the Sync Tool has already done the work of moving each file to DuraCloud.)  The capability to capture time stamp information was added to the NIO package in Java 7 (http://docs.oracle.com/javase/7/docs/api/java/nio/file/attribute/BasicFileAttributes.html), thus this utility will need to be built and run using Java 7.  This task is in direct response to needs expressed by the State of North Carolina archives and libraries. Everyone in their offices uses Windows (either 7 or XP), so this utility needs to be tested on Windows."""
"DURACLOUD-743","Story","Utility",1,"Sync Tool: Clean up log output","""The Sync Tool currently logs a variety of """"errors"""" when it is running normally. Many of these log statements have to do with calls to determine if a file currently exists in DuraCloud. The attached file includes errors showing up in the log (provided by users at UTK.)  This task is to clean up the logging outputs so that only actual errors are logged as such."""
"DURACLOUD-742","Bug","UI",2,"UI: Number of items displayed count not always updated properly","""The """"Showing X of X"""" text at the top of the Content Item pane (with a space selected) is not always correct. Examples:  1. Select a space, notice text at top of content list: """"showing 1 - 200 of X"""", switch storage provider, notice text is not cleared 2. Select a space, notice the """"showing X of X"""" text. Select several content items and delete them. Notice that the """"Showing """" numbers don't change."""
"DURACLOUD-741","Bug","Services",1,"Bit integrity comparison reports have incorrect header","""The reports generated by Bit Integrity Checker and Bit Integrity Bulk have incorrect headers. The header value is """"space-id <\t> content-id <\t> MD5"""" but should be something like """"space-id <\t> content-id <\t> MD5-file <\t> MD5-provider <\t> comparison-result""""."""
"DURACLOUD-746","Story","Utility",2,"Sync Tool: Add option to not overwrite changed files","""This task is to add an option to the Sync Tool which ensures that it does not overwrite any existing DuraCloud content. This means that when a file on the local file system, which has previously been added to DuraCloud, changes, it is not simply uploaded again.  There are a few choices that need to be made for this new feature to be added: 1. When a file already in DuraCloud changes on the file system, is the updated file transferred to DuraCloud or not. If so, the original file will likely need to be renamed to prevent collision. 2. How is the list of updated files communicated to the user. Are they printed to the console (stdout), or written to a file? Is this consistent between interactive mode and run-to-completion mode? 3. How does this feature impact the upload tool?  A comment from the State of North Carolina about how they envision this feature:  """"Our ideal upload tool would allow us to specify a local directory to update in the cloud, and the tool would then identify and upload new files (new files defined by file name and path), and alert us to any files that have changed (same file name and path but new checksum hash) and not upload the files that have changed (or upload them in a way that doesn't overwrite the files in the cloud). We would want to make sure that the process of uploading content is kept totally separate from any risk of editing existing content in storage."""""""
"DURACLOUD-747","Bug","Services",2,"Dup-on-Change: Add an option for default duplication setting, to handle newly created spaces","""With the updates to the Duplicate-on-Change service for 2.1, it no longer duplicates newly created spaces. This is fine for multi-tenant instances, but not for enterprise instances, where users may be adding new spaces frequently."""
"DURACLOUD-751","Bug","UI",1,"UI: Large bit integrity reports cannot be displayed","""For spaces with a large amount of content, the UI option to view the service report in a nice table does not work. This option is presented in the UI on the green health check bar, as well as on the services tab. If the """"report"""" link is selected for one of these large spaces, the UI brings up the white display box, then the user waits for a rather long time (while DurAdmin is attempting to read the entire report file into memory so that it can be displayed) and eventually an error is shown indicating that not enough memory is available.  To fix this, the size of the report file should be checked. If the size is over some reasonable threshold, the report link should perform a file download (of the raw report) rather than attempting to display the chart."""
"DURACLOUD-755","Story","UI",2,"Secondary storage provider should be read only via the UI","""As the synchronization of content between storage providers becomes automated (DURACLOUD-642), it becomes unnecessary for users to edit content in their secondary provider. In order to maintain an assurance that content remains consistent between providers, the ability for users to make changes at their secondary storage provider should be removed. They would still be able to view and download all content, but no add/update/delete operations would be allowed.  This task is to update the DurAdmin UI to ensure that users with role user/admin/owner do not have write access to secondary stores."""
"DURACLOUD-757","Bug","Storage",1,"Content properties are being overwritten when content stream changes.","""When the content of an item changes locally and is resynced to duracloud, the custom metadata (properties and tags) are wiped out.  To reproduce follow these steps:   1. add a file using the upload applet 2. add a custom property and tag to the content item. 3. change the file on your local machine by adding text to the end of it. 4. resync it using the upload applet. 5. verify that the content metadata is no longer there.  Another symptom of this problem:  if you log in as userX on the initial content item creation and then login as userY when uploading the changed content item, notice """"creator"""" property changes from userX to userY. """
"DURACLOUD-759","Story","Utility",1,"Sync Tool: Hidden password option","""This task is to provide an option for the Sync Tool which will allow users to supply their DuraCloud password in a way other than via the command line options. The reason this is an issue, is because the full command used to run the sync tool remains available in the process list of the machine on which the sync tool is running.  The suggested fix for this concern is to allow users to define an environment variable which contains their DuraCloud password, which would be picked up by the Sync Tool if the -p option is not provided. """
"DURACLOUD-758","Story","UI",2,"UI: Check box near space name","""In DurAdmin, each space name has to its left a checkbox. Users expect that selecting the check box will perform the same action as selecting the space name text. Instead, selecting the checkbox (of one space or more) brings up a multi-select display.  A user from UCAR/NCAR was recently caught by this issue, and could not understand why the listing of content items was not showing up until they contacted Carissa for assistance.  This task is to discover and implement an alternative to the current UI functionality described above which will be more easily understandable.  From Carissa: Three users within the past month have had the misunderstanding that selecting the checkbox next to a space name would then allow them to view their content. Each time I had to field either a support email or call and explain that they should *not* select the checkbox next to the space name to view the content, add content, edit content, etc. but that they should only click on the name to select/highlight the space to view the content.   Ideally either clicking directly on the checkbox or the space name will select the space (add the checkmark) and both actions will behave identically: they will display the content of the space with all the other associated actions. The two actions that we lose by doing this are the """"delete selected space"""" and """"edit properties"""" on the space level. I believe we should determine another way for those options to appear."""
"DURACLOUD-768","Bug","Services",1,"Bit Integrity Tools: Service report not created for empty spaces","""When running the Bit Integrity Tools service over a space with 0 content items, it completes successfully with a link to a report file, but that report file does not actually exist.  Note that this is the same problem which was reported and resolved in DURACLOUD-704. It appears to have been re-introduced.  This task is to ensure that bit integrity reports get generated and stored in x-service-out for empty spaces."""
"DURACLOUD-769","Bug","UI",1,"Remove Space Properties and Tags in Duradmin","""In order to support Bill's strategy for glacier, see DURACLOUD-767"""
"DURACLOUD-775","Story","UI",2,"UI: Make client-side tools easily available","""This task is to update DurAdmin to provide very obvious links which allow users to download the client-side tools (Sync Tool, Upload Tool, UpSync, Retreival Tool)."""
"DURACLOUD-776","Story","Client",2,"Option for Retrieval Tool to set time stamps on retrieved files","""DURACLOUD-737 allows the Sync Tool to preserve local time stamp information in DuraCloud content item properties. This task is to add an option to the Retrieval Tool which will set the time stamps of files that have been retrieved (assuming that those files have time stamp information recorded in DuraCloud)."""
"DURACLOUD-778","Story","UI",1,"UI: Handle Glacier storage state errors gracefully","""When content is stored in Glacier, attempts to download, view, copy, or edit the properties of that content will result in an error (http status 409). This task is to provide users with useful feedback when they attempt any of these actions on a content item in Glacier.   More specifically, when a call is made on a Glacier content item via the storeclient, a ContentStateException is thrown. (If the content item was recently added or has been retrieved from Glacier, it will simply download as expected) This task is to show the user an appropriate error message indicating that the content is in Glacier. For now, that error message can indicate that the user should contact DuraCloud support if they wish to retrieve that content item."""
"DURACLOUD-780","Story","Client|Utility",1,"sync tool include top level directory option/flag","""After requests from several trial and customer users, the synchronization tool should provide a configuration option/flag in which the entire directory path is included upon upload. Currently, the top level directory is ignored and not persisted in the naming of the content items that are uploaded via the sync tool. This new flag for the sync tool would enable the entire folder structure to be included in the name of the uploaded content."""
"DURACLOUD-788","Bug","UI",2,"SyncToolUI: Notify user that restart is required after change to configuration.","""Configuration tab: When changing the configuration, this does not take effect until there is a stop/start cycle of the tool. This should be indicated to the user, and an option should be provided to perform a stop/start now or to wait. """
"DURACLOUD-800","Story","Utility",1,"SyncToolUI: Better feedback for user without write permissions on space","""The SyncToolUI should be updated to provide better feedback to users when they have selected a space to sync to which they do not have permissions to write to. Since there is not a simple way to collect this information up front, this task is to pay attention to exceptions that are coming back from a sync activity to determine if it is likely that they are a result of lacking permissions, then provide information to the user that will allow them to be aware of he problem and a suggested resolution."""
"DURACLOUD-794","Bug","Utility",1,"SyncToolUI: Allow clearing of errors","""This task is to provide a way, in the SyncToolUI, to clear any errors that have been noted on the errors list."""
"DURACLOUD-801","Story","Security",1,"Shibboleth: Add 403 Access Denied Page","""This improvement is dependent on the Shibboleth branch.  A DuraCloud-branded 403 page should be rendered when an authenticated user who is not authorized to access DuraCloud tries to log in."""
"DURACLOUD-804","Story","Storage",5,"Use JClouds library for all calls to OpenStack providers","""The current OpenStack storage provider implementation uses both the client originally provided by Rackspace (which has now been discontinued) as well as the JClouds library (which is now the client recommended by Rackspace for Java development: http://docs.rackspace.com/sdks/guide/content/java.html).  This task is to update the OpenStack and Rackspace storage providers to use only JClouds."""
"DURACLOUD-805","Bug","UI",1,"Can only perform a bulk action (e.g. deletion) on a maximum of 2 spaces at a time","""Today I went in to cleanup some old demo/test content in 'dspacetest.duracloud.org'.  When I selected multiple spaces, I found that no matter how many spaces I selected, the total always read """"2 space(s) selected"""".   Even worse, I selected a total of 5 spaces and clicked """"Delete Selected Spaces"""" button.  Only the first 2 spaces I selected were deleted.  The other 3 were kept.  It seems as though the multi-select option only captures the first two spaces you select...after that, any other selections are ignored.  Carissa has verified that this also seems to occur on demo.duracloud.org."""
"DURACLOUD-813","Story","UI",3,"UI: Remove upload tool applet, reinstate single file upload","""Now that there is a solid UI as part of the Sync Tool, and because of the seemingly constant issues with java applet technology, the multi-file upload applet should be removed from DurAdmin and the single file upload option should be re-instated.  This work should occur alongside DURACLOUD-775, which provides easy access to the Sync Tool."""
"DURACLOUD-824","Story","Utility",3,"Sync Tool: Ability to restart on system reboot","""This task is to provide a way, on Windows, Mac, and Linux systems for a Sync Tool that is running on shutdown to restart and continue running after a system restart."""
"DURACLOUD-825","Bug","Storage",2,"S3StorageProvider: Remove dependency on a particular access key","""The S3StorageProvider makes use of the AWS access key as a prefix for bucket names, just to guarantee that the names are unique. The listing of buckets is also limited to only those with a matching access key.  Now that AWS does not make the secret key (essentially the password) available, if we were to lose the secret key, we would have to create another credential pair. If we were to do that, though, the S3StorageProvider would show an empty space listing because the new access key will not match the bucket prefix. This also currently makes it impossible to use the AWS IAM service, which is a best practice.  This task is to allow the S3StorageProvider to display and work with buckets regardless of the access key prefix. The prefix should still be used, since uniqueness is still necessary, and should still be stripped before displaying the space names for users. However, rather than requiring a specific access key, any key should work.  Since this match will likely require a regex: According to AWS docs, the Access Key ID is a 20-character, alphanumeric sequence."""
"DURACLOUD-828","Story","Client",1,"Retrieval Tool: Hidden password option","""DURACLOUD-759 added a hidden password for the Sync Tool. This task is to make use of the same environment variable to pick up the password for the Retrieval Tool. This will help to keep the functionality of the two tools in sync."""
"DURACLOUD-832","Bug","Utility",1,"RetrievalTool NullPointerException when using all spaces option (-a)","""The retrievaltool throws a NullPointerException when using the """"all-spaces"""" or """"-a"""" command line option and the """"spaces"""" or """"-s"""" option is not specified, which the """"spaces"""" option shouldn't need to be when using """"all-spaces"""".  The culprit is in RetrievalTool#startRetrievalManager at the line: boolean createSpaceDir = retConfig.getSpaces().size() > 1; because RetrievalToolConfig#getSpaces returns null when the """"spaces"""" command line option is not used."""
"DURACLOUD-838","Story","Utility",1,"List contents of space from a ""pre-chunked"" point of view (Retrieval Tool)","""It would be handy to be able to optionally list a space contents as it  will appear when retrieved.  That is, only list contentIds as they will appear after they are restitched (do not show chunks or manifests).  It's a kind of dry run for the retrieval tool in a way."""
"DURACLOUD-837","Story","Utility",1,"List MD5 option for space listing function of Retrieval Tool","""It would be nice to be able to optionally list all the md5s as well as the raw list of contentIds for a space."""
"DURACLOUD-841","Story","UI",2,"Image gallery viewer","""In a cloud service strategy meeting on Aug 6, 2013 (https://wiki.duraspace.org/display/DSPINT/2013-08-06+-+Cloud+Service+Strategy) there was a discussion about a need expressed by UNC to have a way to view images in DuraCloud as a gallery, in order to aid in the finding of images in their collection.  I was thinking that this could be accomplished with an html/css/javascript app that is stored in one of the user's spaces, and allows them to select a space (if that's actually necessary, could be hard coded to the one that is their image library) and view a set of images. The javascript would need to make calls to the DuraCloud REST API to get the list of content items and display each one. The images would likely be scaled down a bit, to make browsing easier, and clicking on them would display the (slightly) larger size. The REST API would also be used to allow paging through the content items (and not trying to display too many at once). The option to specify a prefix for filtering would need to be there, and the user would need to be able to see the full content ID of the item they are viewing, since that will be the link back to the full size archival image on their internal system.  There is an expectation that the UNC folks will be generating the necessary low-res images that would be viewed through this gallery viewer, and would load those images into a DuraCloud space."""
"DURACLOUD-846","Story","Storage",1,"Update to the latest JClouds","""In DuraCloud release 2.4 an issue with the JClouds library that was used (the latest at the time) was that it would not perform reauthentication when the auth token expired. This required a work around in DuraStore. The issue has now been fixed: https://issues.apache.org/jira/browse/JCLOUDS-178.  This task is to update to the latest JClouds library when possible."""
"DURACLOUD-847","Bug","Client",1,"SyncTool/StoreClient failing when attempting to connect to a DuraCloud instance with a configured Glacier provider","""From ucar customer, when attempting to run the sync tool (version 2.1.0) against a DuraCloud 2.4 instance with a Glacier storage provider configured, the following error appears:  Starting up the Sync Tool ...Exception in thread """"main"""" java.lang.RuntimeException: Could not create connection to DuraStore due to Error retrieving content stores. null at org.duracloud.sync.util.StoreClientUtil.createContentStore(StoreClientUtil.java:40) at org.duracloud.sync.SyncTool.startSyncManager(SyncTool.java:148) at org.duracloud.sync.SyncTool.runSyncTool(SyncTool.java:292) at org.duracloud.sync.SyncTool.main(SyncTool.java:355) Caused by: org.duracloud.error.ContentStoreException: Error retrieving content stores. null at org.duracloud.client.ContentStoreManagerImpl.getStorageAccounts(ContentStoreManagerImpl.java:164) at org.duracloud.client.ContentStoreManagerImpl.getPrimaryContentStore(ContentStoreManagerImpl.java:118) at org.duracloud.sync.util.StoreClientUtil.createContentStore(StoreClientUtil.java:37) ... 3 more Caused by: java.lang.NullPointerException at org.duracloud.storage.domain.StorageAccountManager.initialize(StorageAccountManager.java:50) at org.duracloud.client.ContentStoreManagerImpl.getStorageAccounts(ContentStoreManagerImpl.java:152) ... 5 more"""
"DURACLOUD-848","Story","Client",1,"Bulk Select/Delete Tool","""Several customers have requested the need for a tool that will allow them to perform a bulk delete of a subset of content in a space. They need a tool that will allow them to, first, specify which content to delete from a space and then, second, perform a bulk delete for that content."""
"DURACLOUD-869","Story","Utility",2,"Sync Tool: add content ID prefix option","""In a discussion with NCDCR, they noted that they would like to be able to break up their data set, and perform syncs at lower levels in their path hierarchy, but are prevented from doing so because they would like the full directory path to be included in the content ID. Currently, the only way to do this is (in a Windows environment) to either run the Sync/Upload tool from a high level directory, or move content around. Moving content around, in their production storage system is not practical.  The new feature requested to resolve this problem: Allow for a prefix option, that would be prepended on all content items being transferred.  To keep this simple, the prefix provided would apply to all files in all specified content directories."""
"DURACLOUD-881","Bug","Client",2,"Cannot configure or turn off logging of Retrier in ContentStoreImpl","""The ContentStoreImpl currently has hardcoded settings for how it logs errors encountered during """"retries"""".  Unfortunately, this is not ideal for all use cases of the API.  For example, in the Replication Task Suite, we use ContentStoreImpl.getContentProperties() method as a way to tell whether content already exists in DuraCloud. If that content does not exist, we expect to receive a NotFoundException. This lets us perform logic like: """"If content exists in DuraCloud, see what checksum DuraCloud reports. If DuraCloud checksum differs from local checksum, re-upload the content.""""  Unfortunately, however, getContentProperties() logs this same warning message to log4j 4 times in a row (1 + 3 retries) if the content does NOT yet exist in DuraCloud:  2014-07-14 16:46:28,336 WARN  org.duracloud.client.ContentStoreImpl @ Error attempting to get properties 'ITEM@10673-10.zip' in 'dspace-dev-backup' due to: Response code was 404, expected value was 200. Response body value: null  This causes the logs for the Replication Task Suite to actually fill up with unnecessary warnings from the DuraCloud v3.1.1 API. For example, anytime we want to upload NEW content to DuraCloud, we first check if it already exists (which logs that error x 4) before the new content is uploaded. The logged warnings would cause unnecessary worry for anyone looking at the logs -- in reality they are harmless in this scenario, as the content obviously doesn't exist before it is first uploaded.  It looks like the WARN message is generated by """"doGetContentProperties"""" here: https://github.com/duracloud/duracloud/blob/master/storeclient/src/main/java/org/duracloud/client/ContentStoreImpl.java#L904  It is then repeated 4 times as a """"log.warn"""" in the default execute() method (which is configured to do 3 retries): https://github.com/duracloud/duracloud/blob/master/storeclient/src/main/java/org/duracloud/client/ContentStoreImpl.java#L216  Ideally, there should be some way to configure the logging in the ContentStoreImpl. I like that this same task is retried 3 times. But in many scenarios, I'd rather it just throw me a final Error if all retries failed, rather than logging the same error message multiple times in a row.   If logging cannot be easily configurable, then switching the default execute() method to just do a """"log.debug"""" would be better. That way I can see the underlying error if I turn on debugging, but by default my logs don't get filled with the same errors repeated.  NOTE: This was discovered while attempting to upgrade the DSpace Replication Task Suite to use DuraCloud API version 3.1.1 (JARS: storeclient, storeprovider, common). Unfortunately, until logging is cleaned up in some way, it's unlikely I'll release the upgraded Replication Task Suite code."""
"DURACLOUD-882","Bug","UI",3,"Fixity check green bar not being displayed","""The green bar that show the date of the last fixity check is not being displayed in DuraCloud 3.1. This feature needs to be re-instated as the new bit integrity system is put in place to allow users to see the dates of health checks."""
"DURACLOUD-884","Bug","Storage",3,"Better handling for content files added with an incorrect checksum","""Currently when a content item is added to a storage provider via a PUT content REST call, if the checksum included with that content item does not match the checksum computed by the provider, a 500 response is generated, and the file itself remains on the storage provider.  This task is to: 1. Ensure that if content fails the checksum check, it is either not added to or is removed from the space. 2. Return a response with an error code and body text that better describes the issue."""
"DURACLOUD-895","Bug","UI",1,"Synctool fails when the max file size is greater than max java integer value","""Using the synctool, uploads of files greater than Integer.MAX_VALUE fail when the max file size is set appropriately high (ie > 2 GBs).   """
"DURACLOUD-896","Story","Utility",2,"Add SyncTool feature which allows for skipping existance checks for new content sets","""This feature allows initial transfers of data sets to proceed without the usual checks to see if the content is already in DuraCloud (since we know that it is not.) Instead, all files will simply be transferred.  The need for this feature comes from GSU. With a large set of small files (4.7 million under 1 MB), the overhead of doing the checks for each file was slowing down the overall transfer considerably. """
"DURACLOUD-898","Bug","UI",1,"Spaces no longer loading in Firefox 33.0+ in duradmin","""After upgrading to Firefox 33.0 spaces are not longer loading."""
"DURACLOUD-904","Bug","Utility",1,"SyncTool: Make sure files restored from change list on re-start are in the current set of content directories","""An issue reported by NCDCR:  The SyncTool performed a restart and picked up an old change list file even though the set of content directories was completely different. This happened because the SyncTool was started (writing the config) then killed before the old change list could be overwritten. On the next run, the config matched, so a restarted was carried out, pulling in change list files which really should have been ignored.    To fix this problem, the proposal is add a check on restart, just after the change list is read in, to remove any files from the change list that don't actually exist in the list of content directories."""
"DURACLOUD-912","Bug","UI",1,"Copy dialog in UI has multiple progress spinners next to space selection","""As shown in the attached image, when performing a copy via DurAdmin, multiple spinning circles to indicate loading or progress are shown next to the space drop-down selection. This becomes more of an issue when the storage provider selection is used to change the selected provider.    Previously, there was one of these spinners, which was present as the list of spaces was generated and then went away one the list was populated. That was great. Now when I transition between storage providers, a string of these are presented (I've counted at least 9) with overlapping text (making the text impossible to read). Some of the spinners do disappear, but 2 seem to remain even after the space listing is fully populated."""
"DURACLOUD-911","Bug","Storage",2,"Failure with space and %20 in content ID on SDSC","""Several failures have been noted recently in the mill when attempting to perform a duplication of a content item with a content ID that includes """"%20"""" in the content ID from Amazon to SDSC. (Note that %20 is the url encoding for a blank space.) The attached file is a set of errors from the mill dead letter queue.    I was able to reproduce the issue by attempting to create a content item in SDSC with the name: """"test-file spaces%20percents.txt"""". Note that I did not see an issue with """"test-file spaces.txt"""" or """"test-file%20percents.txt"""", so it would appear that the combination of the two characters (an actual space, and """"%20"""") is necessary to provoke the issue."""
"DURACLOUD-917","Bug","UI",1,"Storage report display values are inconsistent","""The storage report charts in the DurAdmin display do not show consistent values between the line chart (historical size) and the pie charts. This inconsistency is because one of the two uses GiB (Gibibytes) and the other uses GB (Gigabytes). A GiB is 1024^3 bytes, while a GB is 1000^3 bytes.    This issue should be resolved by updating the storage reports to make use of GB rather than GiB. This will provide greater consistency.    Note that this is also an issue reported in DURACHRON-79, where the inconsistency is between the storage reports and the snapshot."""
"DURACLOUD-929","Bug","UI",1,"Multiple space selection does not work","""In DuraCloud v3.3.0, when multiple spaces are selected, the UI displays as if no spaces were selected. There is no option to delete the selected spaces or edit properties (as there was in 3.2.2 and previous versions)    To reproduce:    1. Select a space.  2. Click on the checkbox of another space.  3. The multiple space selection panel does not show up in the detail area."""
"DURACLOUD-940","Bug","UI",1,"Bit Integrity Reports are not showing up in duradmin for secondary providers.","""(from an email from bbranan)  I was looking at some bit integrity results this morning and noticed in all of the accounts I looked at (colum, icpsr, and demo), that there are no green bit integrity bars on any of the spaces in any secondary providers. I spot checked a few, and there are successful bit report entries for those spaces in the mill db, they just aren't being shown in the UI.    When I select a space on SDSC providers in duradmin, it takes a while for the space to load. It appears to be attempting to get the bit integrity report, but it fails to do so. Looking at the logs, I see consistent errors like this:    ERROR  2015/09/11 13:26:40 [ajp-bio-8009-exec-25212] (SpaceController.java:117) [populateBitIntegrityResults()] - failed to populate bit integrity results due to error:Error attempting to get bit integrity report  properties 'carissa-folder-test' due to: Response code was 500, expected value was 200. Response body value: null  org.duracloud.error.ContentStoreException: Error attempting to get bit integrity report properties 'carissa-folder-test' due to: Response code was 500, expected value was 200. Response body value: null          at org.duracloud.client.ContentStoreImpl.getBitIntegrityReportProperties(ContentStoreImpl.java:1214) ~[storeclient-3.3.0.jar:na]          at org.duracloud.duradmin.spaces.controller.SpaceController.populateBitIntegrityResults(SpaceController.java:109) [SpaceController.class:na]          at org.duracloud.duradmin.spaces.controller.SpaceController.get(SpaceController.java:96) [SpaceController.class:na]  """
"DURACLOUD-942","Story","Storage",2,"Add support for S3 - Infrequently Accessed storage option","""According to this announcement: https://aws.amazon.com/blogs/aws/aws-storage-update-new-lower-cost-s3-storage-option-glacier-price-reduction/?sc_ichannel=em&sc_icountry=global&sc_icampaigntype=launch&sc_icampaign=em_148542750&sc_idetail=em_2049897831&ref_=pe_430550_148542750_7, Amazon is now offering the option of a lower cost S3 tier for infrequently accessed data. This task is to transition all DuraCloud content to this new option.    The best way to take advantage of S3 - IA is via bucket lifecycle policies. Because of the additional cost of content deletes in the first 30 days, it would be best to set these policies to transition content from S3 Standard storage to S3 - IA storage after the content has been stored for 30 days. This policy should be created when a new space is created (via the S3StorageProvider)    As part of this work, the current S3 task which transitions content to Reduced Redundancy storage should be replaced with a task that adds the bucket policy for S3 - IA to an existing bucket. To complete this transition, a script will need to be written which uses this task to update all current accounts.    The storage class init parameter should also be removed (from both app-config, and from the MC). It no longer makes sense to support reduced redundancy storage."""
"DURACLOUD-957","Story","Utility",1,"Backup thread runs too frequently on synctool.","""Currently the synctool's backup thread is running on the same schedule as the directory polling period which is 10 seconds by default.  The back up thread period should not be tied to the polling period.  Instead it should run at least every 5 minutes by default.  Also thread synchronization on on the ChangedList.persist method is causing threads to wait until the backup file is completely written rather than waiting only until the file list is copied in memory."""
"DURACLOUD-974","Story","UI",3,"Finish storage report conversion:  relative space byte and item count sizes.","""For beanstalk version implement storage stats pie chart view of space size and space item count as of x day to match what is currently available in duracloud 3.6.0."""
"DURACLOUD-978","Bug","Report",1,"Bit Integrity Report REST call incorrectly returns 204 code when space is not found.","""It should be returning 404"""
"DURACLOUD-983","Bug","Storage",2,"Durastore:  TaskProviderFactory is not aware of global account repo","""With the recent beanstalk-oriented changes, any durastore instance can serve requests for any account.    However it appears that the TaskProviderFactoryImpl is not aware of these changes.  It is still thinking that it must be initialized externally as opposed to reading from the global account store."""
"DURACLOUD-984","Story","Common",3,"Remove classic init from DuraCloud","""As we move towards an Elastic Beanstalk oriented deployment,  we no longer need to support classic two phase init (ie xml posted to the application)."""
"DURACLOUD-994","Bug","Services",1,"Duplicate response headers from REST API","""Calling the REST API for GetContentProperties return some duplicate headers, excerpted below:    $ curl -I -u """"${DURACLOUD_USER}:${DURACLOUD_PASSWORD}"""" https://${DURACLOUD_HOST}/durastore/rest-api-testing/foo2    HTTP/1.1 200 OK  Date: Tue, 05 Apr 2016 19:38:14 GMT  ETag: 26dc5f719443fb5ff49b87b3853d5d7c  ETag: 26dc5f719443fb5ff49b87b3853d5d7c  Content-MD5: 26dc5f719443fb5ff49b87b3853d5d7c  Content-MD5: 26dc5f719443fb5ff49b87b3853d5d7c  Last-Modified: 2016-04-05T18:36:52  Last-Modified: 2016-04-05T18:36:52"""
"DURACLOUD-1020","Task","Service Infrastructure",2,"Move Bit Integrity Producer on to the Sentinel","""In order to better utilize our AWS resources we should do the following:      1. Retire the Bit Integrity Producer  Autoscale group and configuration.  2. Move the bit integrity producer process onto the sentinel and have it run continuously.  3. Upgrade the sentinel to an m3.medium.   4. Ensure that the bit report autoscale group is scaling down when the bit report queue has been empty for more than 3 hours."""
"DURACLOUD-1061","Story","Utility",2,"Add large file test coverage for chunked files in the DuraStoreChunkSyncEndpoint","""This test should ensure that a 3 GB file is chunked properly through the DuraStoreChunkSyncEndpoint.   Also, make sure that the test is written in such a way that we can easily add in tests for much larger files should the need arise."""
"DURACLOUD-1115","Bug","Mill",3,"Manually set ""Modified"" timestamp values are not  persisted to the audit_log_item and manifest_item tables.","""We use the """"modified"""" field of the audit_log_item and manifest_item fields to record the time of the audit events moving through the system.  However we are also using the field for jpa versioning.   JPA as a result is overwriting the values we are setting programmatically just before persisting the data causing the event to appear to have occurred later in time than it actually occurred.   The result is that the manifest can fall out of sync with the storage provider in a couple of ways when deletes and updates occur within relatively narrow timeframes and there is high latency in the audit message processing times:  1) a manifest record may appear to be missing.  2) the checksum on the manifest may be out of sync with the file."""
"DURACLOUD-1120","Story","Mill",2,"notifications@duracloud.org is hardcoded in SESNotificationManager","""The notifications email sender should be configurable so that non-DuraSpace DuraCloud providers will send mill notifications to the proper place."""
"DURACLOUD-1133","Bug","Utility",2,"Reintroduce exclusions into DirWalk for the sake of efficiency","""Currently (as of 4.3.6) the DirWalker does not exclude directories directly.  Rather it looks at files only and then traverses the ancestors of the file in search of matching directories to exclude.  Thus the DirWalker will unnecessarily slow to a crawl when traversing an excluded directory with large numbers of files.  With the recent commit to resolve duracloud-1129 the exclusion check was moved from DirWalker to ChangedList.  However,  without exclusion checks in the DirWalker,  all files within an excluded directory will still be traversed thus slowing the DirWalker.  It should be noted that on reintroduction,  it is necessary to add logic that was previously missing (ie in 4.3.6) to ensure that directories are filtered directly."""
"DURACLOUD-1166","Bug","UI",2,"The management console assumes duracloud.org as domain","""In the management console UI some tables of accounts hardcoded the .duracloud.org domain"""
